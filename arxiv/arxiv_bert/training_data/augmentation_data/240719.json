[
    {
        "url": "https://arxiv.org/pdf/2407.08109",
        "title": "Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter",
        "abstract": "Urban waterlogging poses a major risk to public safety and infrastructure. Conventional methods using water-level sensors need high-maintenance to hardly achieve full coverage. Recent advances employ surveillance camera imagery and deep learning for detection, yet these struggle amidst scarce data and adverse environmental conditions. In this paper, we establish a challenging Urban Waterlogging Benchmark (UW-Bench) under diverse adverse conditions to advance real-world applications. We propose a Large-Small Model co-adapter paradigm (LSM-adapter), which harnesses the substantial generic segmentation potential of large model and the specific task-directed guidance of small model. Specifically, a Triple-S Prompt Adapter module alongside a Dynamic Prompt Combiner are proposed to generate then merge multiple prompts for mask decoder adaptation. Meanwhile, a Histogram Equalization Adap-ter module is designed to infuse the image specific information for image encoder adaptation. Results and analysis show the challenge and superiority of our developed benchmark and algorithm. Project page: \\url{this https URL}",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08108",
        "title": "CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data",
        "abstract": "Deep learning recommendation models (DLRMs) are at the heart of the current e-commerce industry. However, the amount of training data used to train these large models is growing exponentially, leading to substantial training hurdles. The training dataset contains two primary types of information: content-based information (features of users and items) and collaborative information (interactions between users and items). One approach to reduce the training dataset is to remove user-item interactions. But that significantly diminishes collaborative information, which is crucial for maintaining accuracy due to its inclusion of interaction histories. This loss profoundly impacts DLRM performance.\n This paper makes an important observation that if one can capture the user-item interaction history to enrich the user and item embeddings, then the interaction history can be compressed without losing model accuracy. Thus, this work, Collaborative Aware Data Compression (CADC), takes a two-step approach to training dataset compression. In the first step, we use matrix factorization of the user-item interaction matrix to create a novel embedding representation for both the users and items. Once the user and item embeddings are enriched by the interaction history information the approach then applies uniform random sampling of the training dataset to drastically reduce the training dataset size while minimizing model accuracy drop. The source code of CADC is available at \\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08093",
        "title": "MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters",
        "abstract": "Many existing learning-based deformable image registration methods impose constraints on deformation fields to ensure they are globally smooth and continuous. However, this assumption does not hold in cardiac image registration, where different anatomical regions exhibit asymmetric motions during respiration and movements due to sliding organs within the chest. Consequently, such global constraints fail to accommodate local discontinuities across organ boundaries, potentially resulting in erroneous and unrealistic displacement fields. In this paper, we address this issue with MemWarp, a learning framework that leverages a memory network to store prototypical information tailored to different anatomical regions. MemWarp is different from earlier approaches in two main aspects: firstly, by decoupling feature extraction from similarity matching in moving and fixed images, it facilitates more effective utilization of feature maps; secondly, despite its capability to preserve discontinuities, it eliminates the need for segmentation masks during model inference. In experiments on a publicly available cardiac dataset, our method achieves considerable improvements in registration accuracy and producing realistic deformations, outperforming state-of-the-art methods with a remarkable 7.1\\% Dice score improvement over the runner-up semi-supervised method. Source code will be available at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08064",
        "title": "TinyGraph: Joint Feature and Node Condensation for Graph Neural Networks",
        "abstract": "Training graph neural networks (GNNs) on large-scale graphs can be challenging due to the high computational expense caused by the massive number of nodes and high-dimensional nodal features. Existing graph condensation studies tackle this problem only by reducing the number of nodes in the graph. However, the resulting condensed graph data can still be cumbersome. Specifically, although the nodes of the Citeseer dataset are reduced to 0.9% (30 nodes) in training, the number of features is 3,703, severely exceeding the training sample magnitude. Faced with this challenge, we study the problem of joint condensation for both features and nodes in large-scale graphs. This task is challenging mainly due to 1) the intertwined nature of the node features and the graph structure calls for the feature condensation solver to be structure-aware; and 2) the difficulty of keeping useful information in the condensed graph. To address these challenges, we propose a novel framework TinyGraph, to condense features and nodes simultaneously in graphs. Specifically, we cast the problem as matching the gradients of GNN weights trained on the condensed graph and the gradients obtained from training over the original graph, where the feature condensation is achieved by a trainable function. The condensed graph obtained by minimizing the matching loss along the training trajectory can henceforth retain critical information in the original graph. Extensive experiments were carried out to demonstrate the effectiveness of the proposed TinyGraph. For example, a GNN trained with TinyGraph retains 98.5% and 97.5% of the original test accuracy on the Cora and Citeseer datasets, respectively, while significantly reducing the number of nodes by 97.4% and 98.2%, and the number of features by 90.0% on both datasets.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08003",
        "title": "Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data",
        "abstract": "Amyotrophic Lateral Sclerosis (ALS) is characterized as a rapidly progressive neurodegenerative disease that presents individuals with limited treatment options in the realm of medical interventions and therapies. The disease showcases a diverse range of onset patterns and progression trajectories, emphasizing the critical importance of early detection of functional decline to enable tailored care strategies and timely therapeutic interventions. The present investigation, spearheaded by the iDPP@CLEF 2024 challenge, focuses on utilizing sensor-derived data obtained through an app. This data is used to construct various machine learning models specifically designed to forecast the advancement of the ALS Functional Rating Scale-Revised (ALSFRS-R) score, leveraging the dataset provided by the organizers. In our analysis, multiple predictive models were evaluated to determine their efficacy in handling ALS sensor data. The temporal aspect of the sensor data was compressed and amalgamated using statistical methods, thereby augmenting the interpretability and applicability of the gathered information for predictive modeling objectives. The models that demonstrated optimal performance were a naive baseline and ElasticNet regression. The naive model achieved a Mean Absolute Error (MAE) of 0.20 and a Root Mean Square Error (RMSE) of 0.49, slightly outperforming the ElasticNet model, which recorded an MAE of 0.22 and an RMSE of 0.50. Our comparative analysis suggests that while the naive approach yielded marginally better predictive accuracy, the ElasticNet model provides a robust framework for understanding feature contributions.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08001",
        "title": "Automated Neural Patent Landscaping in the Small Data Regime",
        "abstract": "Patent landscaping is the process of identifying all patents related to a particular technological area, and is important for assessing various aspects of the intellectual property context. Traditionally, constructing patent landscapes is intensely laborious and expensive, and the rapid expansion of patenting activity in recent decades has driven an increasing need for efficient and effective automated patent landscaping approaches. In particular, it is critical that we be able to construct patent landscapes using a minimal number of labeled examples, as labeling patents for a narrow technology area requires highly specialized (and hence expensive) technical knowledge. We present an automated neural patent landscaping system that demonstrates significantly improved performance on difficult examples (0.69 $F_1$ on 'hard' examples, versus 0.6 for previously reported systems), and also significant improvements with much less training data (overall 0.75 $F_1$ on as few as 24 examples). Furthermore, in evaluating such automated landscaping systems, acquiring good data is challenge; we demonstrate a higher-quality training data generation procedure by merging Abood and Feltenberger's (2018) \"seed/anti-seed\" approach with active learning to collect difficult labeled examples near the decision boundary. Using this procedure we created a new dataset of labeled AI patents for training and testing. As in prior work we compare our approach with a number of baseline systems, and we release our code and data for others to build upon.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.07924",
        "title": "Solving General Natural-Language-Description Optimization Problems with Large Language Models",
        "abstract": "Optimization problems seek to find the best solution to an objective under a set of constraints, and have been widely investigated in real-world applications. Modeling and solving optimization problems in a specific domain typically require a combination of domain knowledge, mathematical skills, and programming ability, making it difficult for general users and even domain professionals. In this paper, we propose a novel framework called OptLLM that augments LLMs with external solvers. Specifically, OptLLM accepts user queries in natural language, convert them into mathematical formulations and programming codes, and calls the solvers to calculate the results for decision-making. In addition, OptLLM supports multi-round dialogues to gradually refine the modeling and solving of optimization problems. To illustrate the effectiveness of OptLLM, we provide tutorials on three typical optimization applications and conduct experiments on both prompt-based GPT models and a fine-tuned Qwen model using a large-scale selfdeveloped optimization dataset. Experimental results show that OptLLM works with various LLMs, and the fine-tuned model achieves an accuracy boost compared to the promptbased models. Some features of OptLLM framework have been available for trial since June 2023 (this https URL or this https URL).",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08733",
        "title": "Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist",
        "abstract": "Exceptional mathematical reasoning ability is one of the key features that demonstrate the power of large language models (LLMs). How to comprehensively define and evaluate the mathematical abilities of LLMs, and even reflect the user experience in real-world scenarios, has emerged as a critical issue. Current benchmarks predominantly concentrate on problem-solving capabilities, which presents a substantial risk of model overfitting and fails to accurately represent genuine mathematical reasoning abilities. In this paper, we argue that if a model really understands a problem, it should be robustly and readily applied across a diverse array of tasks. Motivated by this, we introduce MATHCHECK, a well-designed checklist for testing task generalization and reasoning robustness, as well as an automatic tool to generate checklists efficiently. MATHCHECK includes multiple mathematical reasoning tasks and robustness test types to facilitate a comprehensive evaluation of both mathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we develop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual reasoning and multi-modal reasoning capabilities, respectively, serving as upgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K. We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs, assessing their comprehensive mathematical reasoning abilities. Our results demonstrate that while frontier LLMs like GPT-4o continue to excel in various abilities on the checklist, many other model families exhibit a significant decline. Further experiments indicate that, compared to traditional math benchmarks, MATHCHECK better reflects true mathematical abilities and represents mathematical intelligence more linearly, thereby supporting our design. On our MATHCHECK, we can easily conduct detailed behavior analysis to deeply investigate models.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08713",
        "title": "GTA: A Benchmark for General Tool Agents",
        "abstract": "Significant focus has been placed on integrating large language models (LLMs) with various tools in developing general-purpose agents. This poses a challenge to LLMs' tool-use capabilities. However, there are evident gaps between existing tool-use evaluations and real-world scenarios. Current evaluations often use AI-generated queries, single-step tasks, dummy tools, and text-only interactions, failing to reveal the agents' real-world problem-solving abilities effectively. To address this, we propose GTA, a benchmark for General Tool Agents, featuring three main aspects: (i) Real user queries: human-written queries with simple real-world objectives but implicit tool-use, requiring the LLM to reason the suitable tools and plan the solution steps. (ii) Real deployed tools: an evaluation platform equipped with tools across perception, operation, logic, and creativity categories to evaluate the agents' actual task execution performance. (iii) Real multimodal inputs: authentic image files, such as spatial scenes, web page screenshots, tables, code snippets, and printed/handwritten materials, used as the query contexts to align with real-world scenarios closely. We design 229 real-world tasks and executable tool chains to evaluate mainstream LLMs. Our findings show that real-world user queries are challenging for existing LLMs, with GPT-4 completing less than 50% of the tasks and most LLMs achieving below 25%. This evaluation reveals the bottlenecks in the tool-use capabilities of current LLMs in real-world scenarios, which provides future direction for advancing general-purpose tool agents. The code and dataset are available at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08475",
        "title": "Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective",
        "abstract": "With the rapid development of the large model domain, research related to fine-tuning has concurrently seen significant advancement, given that fine-tuning is a constituent part of the training process for large-scale models. Data engineering plays a fundamental role in the training process of models, which includes data infrastructure, data processing, etc. Data during fine-tuning likewise forms the base for large models. In order to embrace the power and explore new possibilities of fine-tuning datasets, this paper reviews current public fine-tuning datasets from the perspective of data construction. An overview of public fine-tuning datasets from two sides: evolution and taxonomy, is provided in this review, aiming to chart the development trajectory. Construction techniques and methods for public fine-tuning datasets of Large Language Models (LLMs), including data generation and data augmentation among others, are detailed. This elaboration follows the aforementioned taxonomy, specifically across demonstration, comparison, and generalist categories. Additionally, a category tree of data generation techniques has been abstracted in our review to assist researchers in gaining a deeper understanding of fine-tuning datasets from the construction dimension. Our review also summarizes the construction features in different data preparation phases of current practices in this field, aiming to provide a comprehensive overview and inform future research. Fine-tuning dataset practices, encompassing various data modalities, are also discussed from a construction perspective in our review. Towards the end of the article, we offer insights and considerations regarding the future construction and developments of fine-tuning datasets.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08440",
        "title": "Beyond Instruction Following: Evaluating Rule Following of Large Language Models",
        "abstract": "Although Large Language Models (LLMs) have demonstrated strong instruction-following ability to be helpful, they are further supposed to be controlled and guided by rules in real-world scenarios to be safe, and accurate in responses. This demands the possession of rule-following capability of LLMs. However, few works have made a clear evaluation of the rule-following capability of LLMs. Previous studies that try to evaluate the rule-following capability of LLMs fail to distinguish the rule-following scenarios from the instruction-following scenarios. Therefore, this paper first makes a clarification of the concept of rule-following, and curates a comprehensive benchmark, RuleBench, to evaluate a diversified range of rule-following abilities. Our experimental results on a variety of LLMs show that they are still limited in following rules. Our further analysis provides insights into the improvements for LLMs toward a better rule-following intelligent agent. The data and code can be found at: https://anonymous.4open.science/r/llm-rule-following-B3E3/",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08351",
        "title": "AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models",
        "abstract": "Evaluation is critical for assessing capabilities, tracking scientific progress, and informing model selection. In this paper, we present three desiderata for a good benchmark for language models: (i) salience (e.g., knowledge about World War II is more salient than a random day in history), (ii) novelty (i.e., the benchmark reveals new trends in model rankings not shown by previous benchmarks), and (iii) difficulty (i.e., the benchmark should be difficult for existing models, leaving headroom for future improvement). We operationalize these three desiderata and cast benchmark creation as a search problem, that of finding benchmarks that that satisfy all three desiderata. To tackle this search problem, we present AutoBencher, which uses a language model to automatically search for datasets that meet the three desiderata. AutoBencher uses privileged information (e.g. relevant documents) to construct reliable datasets, and adaptivity with reranking to optimize for the search objective. We use AutoBencher to create datasets for math, multilingual, and knowledge-intensive question answering. The scalability of AutoBencher allows it to test fine-grained categories and tail knowledge, creating datasets that are on average 27% more novel and 22% more difficult than existing benchmarks. A closer investigation of our constructed datasets shows that we can identify specific gaps in LM knowledge in language models that are not captured by existing benchmarks, such as Gemini Pro performing much worse on question answering about the Permian Extinction and Fordism, while OpenAGI-7B performing surprisingly well on QA about COVID-19.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08219",
        "title": "Generating Contextually-Relevant Navigation Instructions for Blind and Low Vision People",
        "abstract": "Navigating unfamiliar environments presents significant challenges for blind and low-vision (BLV) individuals. In this work, we construct a dataset of images and goals across different scenarios such as searching through kitchens or navigating outdoors. We then investigate how grounded instruction generation methods can provide contextually-relevant navigational guidance to users in these instances. Through a sighted user study, we demonstrate that large pretrained language models can produce correct and useful instructions perceived as beneficial for BLV users. We also conduct a survey and interview with 4 BLV users and observe useful insights on preferences for different instructions based on the scenario.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08206",
        "title": "System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation",
        "abstract": "This system report presents our approaches and results for the Chinese Essay Fluency Evaluation (CEFE) task at CCL-2024. For Track 1, we optimized predictions for challenging fine-grained error types using binary classification models and trained coarse-grained models on the Chinese Learner 4W corpus. In Track 2, we enhanced performance by constructing a pseudo-dataset with multiple error types per sentence. For Track 3, where we achieved first place, we generated fluency-rated pseudo-data via back-translation for pre-training and used an NSP-based strategy with Symmetric Cross Entropy loss to capture context and mitigate long dependencies. Our methods effectively address key challenges in Chinese Essay Fluency Evaluation.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08147",
        "title": "Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication",
        "abstract": "Reduplication and repetition, though similar in form, serve distinct linguistic purposes. Reduplication is a deliberate morphological process used to express grammatical, semantic, or pragmatic nuances, while repetition is often unintentional and indicative of disfluency. This paper presents the first large-scale study of reduplication and repetition in speech using computational linguistics. We introduce IndicRedRep, a new publicly available dataset containing Hindi, Telugu, and Marathi text annotated with reduplication and repetition at the word level. We evaluate transformer-based models for multi-class reduplication and repetition token classification, utilizing the Reparandum-Interregnum-Repair structure to distinguish between the two phenomena. Our models achieve macro F1 scores of up to 85.62% in Hindi, 83.95% in Telugu, and 84.82% in Marathi for reduplication-repetition classification.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08734",
        "title": "Transformer Circuit Faithfulness Metrics are not Robust",
        "abstract": "Mechanistic interpretability work attempts to reverse engineer the learned algorithms present inside neural networks. One focus of this work has been to discover 'circuits' -- subgraphs of the full model that explain behaviour on specific tasks. But how do we measure the performance of such circuits? Prior work has attempted to measure circuit 'faithfulness' -- the degree to which the circuit replicates the performance of the full model. In this work, we survey many considerations for designing experiments that measure circuit faithfulness by ablating portions of the model's computation. Concerningly, we find existing methods are highly sensitive to seemingly insignificant changes in the ablation methodology. We conclude that existing circuit faithfulness scores reflect both the methodological choices of researchers as well as the actual components of the circuit - the task a circuit is required to perform depends on the ablation used to test it. The ultimate goal of mechanistic interpretability work is to understand neural networks, so we emphasize the need for more clarity in the precise claims being made about circuits. We open source a library at this https URL that includes highly efficient implementations of a wide range of ablation methodologies and circuit discovery algorithms.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08521",
        "title": "Emergent Visual-Semantic Hierarchies in Image-Text Representations",
        "abstract": "While recent vision-and-language models (VLMs) like CLIP are a powerful tool for analyzing text and images in a shared semantic space, they do not explicitly model the hierarchical nature of the set of texts which may describe an image. Conversely, existing multimodal hierarchical representation learning methods require costly training from scratch, failing to leverage the knowledge encoded by state-of-the-art multimodal foundation models. In this work, we study the knowledge of existing foundation models, finding that they exhibit emergent understanding of visual-semantic hierarchies despite not being directly trained for this purpose. We propose the Radial Embedding (RE) framework for probing and optimizing hierarchical understanding, and contribute the HierarCaps dataset, a benchmark facilitating the study of hierarchical knowledge in image--text representations, constructed automatically via large language models. Our results show that foundation VLMs exhibit zero-shot hierarchical understanding, surpassing the performance of prior models explicitly designed for this purpose. Furthermore, we show that foundation models may be better aligned to hierarchical reasoning via a text-only fine-tuning phase, while retaining pretraining knowledge.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08488",
        "title": "Lynx: An Open Source Hallucination Evaluation Model",
        "abstract": "Retrieval Augmented Generation (RAG) techniques aim to mitigate hallucinations in Large Language Models (LLMs). However, LLMs can still produce information that is unsupported or contradictory to the retrieved contexts. We introduce LYNX, a SOTA hallucination detection LLM that is capable of advanced reasoning on challenging real-world hallucination scenarios. To evaluate LYNX, we present HaluBench, a comprehensive hallucination evaluation benchmark, consisting of 15k samples sourced from various real-world domains. Our experiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and closed and open-source LLM-as-a-judge models on HaluBench. We release LYNX, HaluBench and our evaluation code for public access.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08348",
        "title": "Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On",
        "abstract": "In this paper, we investigate the underlying factors that potentially enhance the mathematical reasoning capabilities of large language models (LLMs). We argue that the data scaling law for math reasoning capabilities in modern LLMs is far from being saturated, highlighting how the model's quality improves with increases in data quantity. To support this claim, we introduce the Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved impressive accuracies of 51.2% on the competition-level MATH benchmark and 83.9% on the GSM8K benchmark using only SFT data, outperforming an early version of GPT-4 on MATH. The superior performance of Skywork-Math models contributes to our novel two-stage data synthesis and model SFT pipelines, which include three different augmentation methods and a diverse seed problem set, ensuring both the quantity and quality of Skywork-MathQA dataset across varying difficulty levels. Most importantly, we provide several practical takeaways to enhance math reasoning abilities in LLMs for both research and industry applications.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08185",
        "title": "Automatic Generation of Web Censorship Probe Lists",
        "abstract": "Domain probe lists--used to determine which URLs to probe for Web censorship--play a critical role in Internet censorship measurement studies. Indeed, the size and accuracy of the domain probe list limits the set of censored pages that can be detected; inaccurate lists can lead to an incomplete view of the censorship landscape or biased results. Previous efforts to generate domain probe lists have been mostly manual or crowdsourced. This approach is time-consuming, prone to errors, and does not scale well to the ever-changing censorship landscape.\n In this paper, we explore methods for automatically generating probe lists that are both comprehensive and up-to-date for Web censorship measurement. We start from an initial set of 139,957 unique URLs from various existing test lists consisting of pages from a variety of languages to generate new candidate pages. By analyzing content from these URLs (i.e., performing topic and keyword extraction), expanding these topics, and using them as a feed to search engines, our method produces 119,255 new URLs across 35,147 domains. We then test the new candidate pages by attempting to access each URL from servers in eleven different global locations over a span of four months to check for their connectivity and potential signs of censorship. Our measurements reveal that our method discovered over 1,400 domains--not present in the original dataset--we suspect to be blocked. In short, automatically updating probe lists is possible, and can help further automate censorship measurements at scale.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08029",
        "title": "A Critical Review of Causal Reasoning Benchmarks for Large Language Models",
        "abstract": "Numerous benchmarks aim to evaluate the capabilities of Large Language Models (LLMs) for causal inference and reasoning. However, many of them can likely be solved through the retrieval of domain knowledge, questioning whether they achieve their purpose. In this review, we present a comprehensive overview of LLM benchmarks for causality. We highlight how recent benchmarks move towards a more thorough definition of causal reasoning by incorporating interventional or counterfactual reasoning. We derive a set of criteria that a useful benchmark or set of benchmarks should aim to satisfy. We hope this work will pave the way towards a general framework for the assessment of causal understanding in LLMs and the design of novel benchmarks.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08739",
        "title": "MAVIS: Mathematical Visual Instruction Tuning",
        "abstract": "Multi-modal Large Language Models (MLLMs) have recently emerged as a significant focus in academia and industry. Despite their proficiency in general multi-modal scenarios, the mathematical problem-solving capabilities in visual contexts remain insufficiently explored. We identify three key areas within MLLMs that need to be improved: visual encoding of math diagrams, diagram-language alignment, and mathematical reasoning skills. This draws forth an urgent demand for large-scale, high-quality data and training pipelines in visual mathematics. In this paper, we propose MAVIS, the first MAthematical VISual instruction tuning paradigm for MLLMs, involving a series of mathematical visual datasets and specialized MLLMs. Targeting the three issues, MAVIS contains three progressive training stages from scratch. First, we curate MAVIS-Caption, consisting of 558K diagram-caption pairs, to fine-tune a math-specific vision encoder (CLIP-Math) through contrastive learning, tailored for improved diagram visual encoding. Second, we utilize MAVIS-Caption to align the CLIP-Math with a large language model (LLM) by a projection layer, enhancing vision-language alignment in mathematical domains. Third, we introduce MAVIS-Instruct, including 900K meticulously collected and annotated visual math problems, which is adopted to finally instruct-tune the MLLM for robust mathematical reasoning skills. In MAVIS-Instruct, we incorporate complete chain-of-thought (CoT) rationales for each problem, and minimize textual redundancy, thereby concentrating the model towards the visual elements. Data and Models are released at this https URL",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.04434",
        "title": "From Showgirls to Performers: Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs",
        "abstract": "Gender bias is not only prevalent in Large Language Models (LLMs) and their training data, but also firmly ingrained into the structural aspects of language itself. Therefore, adapting linguistic structures within LLM training data to promote gender-inclusivity can make gender representations within the model more inclusive. The focus of our work are genderexclusive affixes in English, such as in showgirl or man-cave, which can perpetuate gender stereotypes and binary conceptions of gender. We use an LLM training dataset to compile a catalogue of 692 gender-exclusive terms along with gender-neutral variants and from this, develop a gender-inclusive fine-tuning dataset, the Tiny Heap. Fine-tuning three different LLMs with this dataset, we observe an overall reduction in gender-stereotyping tendencies across the models. Our approach provides a practical method for enhancing gender inclusivity in LLM training data and contributes to incorporating queer-feminist linguistic activism in bias mitigation research in NLP.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/1904.01130",
        "title": "PAWS: Paraphrase Adversaries from Word Scrambling",
        "abstract": "Existing paraphrase identification datasets lack sentence pairs that have high lexical over- lap without being paraphrases. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well- formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State- of-the-art models trained on existing datasets have dismal performance on PAWS (<40% accuracy); however, including PAWS train- ing data for these models improves their ac- curacy to 85% while maintaining performance on existing tasks. In contrast, models that do not capture non-local contextual informa- tion fail even with PAWS training examples. As such, PAWS provides an effective instru- ment for driving further progress on models that better exploit structure, context, and pair- wise comparisons.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2210.01979",
        "title": "GAPX: Generalized Autoregressive Paraphrase-Identification X",
        "abstract": "Paraphrase Identification is a fundamental task in Natural Language Processing. While much progress has been made in the field, the performance of many state-of- the-art models often suffer from distribution shift during inference time. We verify that a major source of this performance drop comes from biases introduced by negative examples. To overcome these biases, we propose in this paper to train two separate models, one that only utilizes the positive pairs and the other the negative pairs. This enables us the option of deciding how much to utilize the negative model, for which we introduce a perplexity based out-of-distribution metric that we show can effectively and automatically determine how much weight it should be given during inference. We support our findings with strong empirical results.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/1811.00491",
        "title": "A Corpus for Reasoning About Natural Language Grounded in Photographs",
        "abstract": "We introduce a new dataset for joint reason- ing about natural language and images, with a focus on semantic diversity, compositionality, and visual reasoning challenges. The data con- tains 107,292 examples of English sentences paired with web photographs. The task is to determine whether a natural language cap- tion is true about a pair of photographs. We crowdsource the data using sets of visually rich images and a compare-and-contrast task to elicit linguistically diverse language. Quali- tative analysis shows the data requires compo- sitional joint reasoning, including about quan- tities, comparisons, and relations. Evaluation using state-of-the-art visual reasoning meth- ods shows the data presents a strong challenge.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2404.12010v1",
        "title": "ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity",
        "abstract": "]Paraphrase generation is a pivotal task in natural language processing(NLP).Existing datasets in the domain lack syntactic and lexical diversity, resulting in paraphrases that closely resemble the source sentences. Moreover, these datasets often contain hate speech and noise, and may unintentionally include non-English language sentences. This research introduces ParaFusion, a large-scale, high-quality English paraphrase dataset developed using Large Language Models (LLM) to address these challenges. ParaFusion augments existing datasets with high-quality data, significantly enhancing both lexical and syntactic diversity while maintaining close semantic sim- ilarity. It also mitigates the presence of hate speech and reduces noise, ensuring a cleaner and more focused English dataset. Results show that ParaFusion offers at least a 25% improvement in both syntactic and lexical diversity, measured across several metrics for each data source. The paper also aims to set a gold standard for paraphrase evaluation as it contains one of the most comprehensive evaluation strategies to date. The results underscore the potential of ParaFusion as a valuable resource for improving NLP applications.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2105.05241",
        "title": "Addressing \"Documentation Debt\" in Machine Learning Research: A Retrospective Datasheet for BookCorpus",
        "abstract": "Recent literature has underscored the importance of dataset documentation work for machine learning, and part of this work involves addressing \u201cdocumentation debt\u201d for datasets that have been used widely but documented sparsely. This paper aims to help address documentation debt for BookCorpus, a popular text dataset for training large language models. Notably, researchers have used BookCorpus to train OpenAI\u2019s GPT-N models and Google\u2019s BERT models, even though little to no documentation exists about the dataset\u2019s motivation, composition, collection process, etc. We offer a preliminary datasheet that provides key context and information about BookCorpus, highlighting several notable deficiencies. In particular, we find evidence that (1) BookCorpus likely violates copyright restrictions for many books, (2) BookCorpus contains thousands of duplicated books, and (3) BookCorpus exhibits significant skews in genre representation. We also find hints of other potential deficiencies that call for future research, including problematic content, potential skews in religious representation, and lopsided author contributions. While more work remains, this initial effort to provide a datasheet for BookCorpus adds to growing literature that urges more careful and systematic documentation for machine learning datasets.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2101.00027",
        "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling",
        "abstract": "Recent work has demonstrated that increased training dataset diversity improves general cross-domain knowledge and downstream generalization capability for large-scale language models. With this in mind, we present \\textit{the Pile}: an 825 GiB English text corpus targeted at training large-scale language models. The Pile is constructed from 22 diverse high-quality subsets -- both existing and newly constructed -- many of which derive from academic or professional sources. Our evaluation of the untuned performance of GPT-2 and GPT-3 on the Pile shows that these models struggle on many of its components, such as academic writing. Conversely, models trained on the Pile improve significantly over both Raw CC and CC-100 on all components of the Pile, while improving performance on downstream evaluations. Through an in-depth exploratory analysis, we document potentially concerning aspects of the data for prospective users. We make publicly available the code used in its construction.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09359",
        "title": "A Unified Anomaly Synthesis Strategy with Gradient Ascent for Industrial Anomaly Detection and Localization",
        "abstract": "Anomaly synthesis strategies can effectively enhance unsupervised anomaly detection. However, existing strategies have limitations in the coverage and controllability of anomaly synthesis, particularly for weak defects that are very similar to normal regions. In this paper, we propose Global and Local Anomaly co-Synthesis Strategy (GLASS), a novel unified framework designed to synthesize a broader coverage of anomalies under the manifold and hypersphere distribution constraints of Global Anomaly Synthesis (GAS) at the feature level and Local Anomaly Synthesis (LAS) at the image level. Our method synthesizes near-in-distribution anomalies in a controllable way using Gaussian noise guided by gradient ascent and truncated projection. GLASS achieves state-of-the-art results on the MVTec AD (detection AUROC of 99.9\\%), VisA, and MPDD datasets and excels in weak defect detection. The effectiveness and efficiency have been further validated in industrial applications for woven fabric defect detection. The code and dataset are available at: \\url{this https URL}.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09285",
        "title": "MetaFood CVPR 2024 Challenge on Physically Informed 3D Food Reconstruction: Methods and Results",
        "abstract": "The increasing interest in computer vision applications for nutrition and dietary monitoring has led to the development of advanced 3D reconstruction techniques for food items. However, the scarcity of high-quality data and limited collaboration between industry and academia have constrained progress in this field. Building on recent advancements in 3D reconstruction, we host the MetaFood Workshop and its challenge for Physically Informed 3D Food Reconstruction. This challenge focuses on reconstructing volume-accurate 3D models of food items from 2D images, using a visible checkerboard as a size reference. Participants were tasked with reconstructing 3D models for 20 selected food items of varying difficulty levels: easy, medium, and hard. The easy level provides 200 images, the medium level provides 30 images, and the hard level provides only 1 image for reconstruction. In total, 16 teams submitted results in the final testing phase. The solutions developed in this challenge achieved promising results in 3D food reconstruction, with significant potential for improving portion estimation for dietary assessment and nutritional monitoring. More details about this workshop challenge and access to the dataset can be found at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08876",
        "title": "DegustaBot: Zero-Shot Visual Preference Estimation for Personalized Multi-Object Rearrangement",
        "abstract": "De gustibus non est disputandum (\"there is no accounting for others' tastes\") is a common Latin maxim describing how many solutions in life are determined by people's personal preferences. Many household tasks, in particular, can only be considered fully successful when they account for personal preferences such as the visual aesthetic of the scene. For example, setting a table could be optimized by arranging utensils according to traditional rules of Western table setting decorum, without considering the color, shape, or material of each object, but this may not be a completely satisfying solution for a given person. Toward this end, we present DegustaBot, an algorithm for visual preference learning that solves household multi-object rearrangement tasks according to personal preference. To do this, we use internet-scale pre-trained vision-and-language foundation models (VLMs) with novel zero-shot visual prompting techniques. To evaluate our method, we collect a large dataset of naturalistic personal preferences in a simulated table-setting task, and conduct a user study in order to develop two novel metrics for determining success based on personal preference. This is a challenging problem and we find that 50% of our model's predictions are likely to be found acceptable by at least 20% of people.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09189",
        "title": "Segmenting Medical Images with Limited Data",
        "abstract": "While computer vision has proven valuable for medical image segmentation, its application faces challenges such as limited dataset sizes and the complexity of effectively leveraging unlabeled images. To address these challenges, we present a novel semi-supervised, consistency-based approach termed the data-efficient medical segmenter (DEMS). The DEMS features an encoder-decoder architecture and incorporates the developed online automatic augmenter (OAA) and residual robustness enhancement (RRE) blocks. The OAA augments input data with various image transformations, thereby diversifying the dataset to improve the generalization ability. The RRE enriches feature diversity and introduces perturbations to create varied inputs for different decoders, thereby providing enhanced variability. Moreover, we introduce a sensitive loss to further enhance consistency across different decoders and stabilize the training process. Extensive experimental results on both our own and three public datasets affirm the effectiveness of DEMS. Under extreme data shortage scenarios, our DEMS achieves 16.85\\% and 10.37\\% improvement in dice score compared with the U-Net and top-performed state-of-the-art method, respectively. Given its superior data efficiency, DEMS could present significant advancements in medical segmentation under small data regimes. The project homepage can be accessed at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08948",
        "title": "Symmetry Awareness Encoded Deep Learning Framework for Brain Imaging Analysis",
        "abstract": "The heterogeneity of neurological conditions, ranging from structural anomalies to functional impairments, presents a significant challenge in medical imaging analysis tasks. Moreover, the limited availability of well-annotated datasets constrains the development of robust analysis models. Against this backdrop, this study introduces a novel approach leveraging the inherent anatomical symmetrical features of the human brain to enhance the subsequent detection and segmentation analysis for brain diseases. A novel Symmetry-Aware Cross-Attention (SACA) module is proposed to encode symmetrical features of left and right hemispheres, and a proxy task to detect symmetrical features as the Symmetry-Aware Head (SAH) is proposed, which guides the pretraining of the whole network on a vast 3D brain imaging dataset comprising both healthy and diseased brain images across various MRI and CT. Through meticulous experimentation on downstream tasks, including both classification and segmentation for brain diseases, our model demonstrates superior performance over state-of-the-art methodologies, particularly highlighting the significance of symmetry-aware learning. Our findings advocate for the effectiveness of incorporating symmetry awareness into pretraining and set a new benchmark for medical imaging analysis, promising significant strides toward accurate and efficient diagnostic processes. Code is available at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08874",
        "title": "Implications of mappings between ICD clinical diagnosis codes and Human Phenotype Ontology terms",
        "abstract": "Objective: Integrating EHR data with other resources is essential in rare disease research due to low disease prevalence. Such integration is dependent on the alignment of ontologies used for data annotation. The International Classification of Diseases (ICD) is used to annotate clinical diagnoses; the Human Phenotype Ontology (HPO) to annotate phenotypes. Although these ontologies overlap in biomedical entities described, the extent to which they are interoperable is unknown. We investigate how well aligned these ontologies are and whether such alignments facilitate EHR data integration.\n Materials and Methods: We conducted an empirical analysis of the coverage of mappings between ICD and HPO. We interpret this mapping coverage as a proxy for how easily clinical data can be integrated with research ontologies such as HPO. We quantify how exhaustively ICD codes are mapped to HPO by analyzing mappings in the UMLS Metathesaurus. We analyze the proportion of ICD codes mapped to HPO within a real-world EHR dataset.\n Results and Discussion: Our analysis revealed that only 2.2% of ICD codes have direct mappings to HPO in UMLS. Within our EHR dataset, less than 50% of ICD codes have mappings to HPO terms. ICD codes that are used frequently in EHR data tend to have mappings to HPO; ICD codes that represent rarer medical conditions are seldom mapped.\n Conclusion: We find that interoperability between ICD and HPO via UMLS is limited. While other mapping sources could be incorporated, there are no established conventions for what resources should be used to complement UMLS.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09373",
        "title": "Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories",
        "abstract": "Quantifying a patient's health status provides clinicians with insight into patient risk, and the ability to better triage and manage resources. Early Warning Scores (EWS) are widely deployed to measure overall health status, and risk of adverse outcomes, in hospital patients. However, current EWS are limited both by their lack of personalisation and use of static observations. We propose a pipeline that groups intensive care unit patients by the trajectories of observations data throughout their stay as a basis for the development of personalised risk predictions. Feature importance is considered to provide model explainability. Using the MIMIC-IV dataset, six clusters were identified, capturing differences in disease codes, observations, lengths of admissions and outcomes. Applying the pipeline to data from just the first four hours of each ICU stay assigns the majority of patients to the same cluster as when the entire stay duration is considered. In-hospital mortality prediction models trained on individual clusters had higher F1 score performance in five of the six clusters when compared against the unclustered patient cohort. The pipeline could form the basis of a clinical decision support tool, working to improve the clinical characterisation of risk groups and the early detection of patient deterioration.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.10878",
        "title": "Deep Causal Learning to Explain and Quantify The Geo-Tension's Impact on Natural Gas Market",
        "abstract": "Natural gas demand is a crucial factor for predicting natural gas prices and thus has a direct influence on the power system. However, existing methods face challenges in assessing the impact of shocks, such as the outbreak of the Russian-Ukrainian war. In this context, we apply deep neural network-based Granger causality to identify important drivers of natural gas demand. Furthermore, the resulting dependencies are used to construct a counterfactual case without the outbreak of the war, providing a quantifiable estimate of the overall effect of the shock on various German energy sectors. The code and dataset are available at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.10446",
        "title": "DDFAD: Dataset Distillation Framework for Audio Data",
        "abstract": "Deep neural networks (DNNs) have achieved significant success in numerous applications. The remarkable performance of DNNs is largely attributed to the availability of massive, high-quality training datasets. However, processing such massive training data requires huge computational and storage resources. Dataset distillation is a promising solution to this problem, offering the capability to compress a large dataset into a smaller distilled dataset. The model trained on the distilled dataset can achieve comparable performance to the model trained on the whole dataset.\n While dataset distillation has been demonstrated in image data, none have explored dataset distillation for audio data. In this work, for the first time, we propose a Dataset Distillation Framework for Audio Data (DDFAD). Specifically, we first propose the Fused Differential MFCC (FD-MFCC) as extracted features for audio data. After that, the FD-MFCC is distilled through the matching training trajectory distillation method. Finally, we propose an audio signal reconstruction algorithm based on the Griffin-Lim Algorithm to reconstruct the audio signal from the distilled FD-MFCC. Extensive experiments demonstrate the effectiveness of DDFAD on various audio datasets. In addition, we show that DDFAD has promising application prospects in many applications, such as continual learning and neural architecture search.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09544",
        "title": "A Transformer-Based Multi-Stream Approach for Isolated Iranian Sign Language Recognition",
        "abstract": "Sign language is an essential means of communication for millions of people around the world and serves as their primary language. However, most communication tools are developed for spoken and written languages which can cause problems and difficulties for the deaf and hard of hearing community. By developing a sign language recognition system, we can bridge this communication gap and enable people who use sign language as their main form of expression to better communicate with people and their surroundings. This recognition system increases the quality of health services, improves public services, and creates equal opportunities for the deaf community. This research aims to recognize Iranian Sign Language words with the help of the latest deep learning tools such as transformers. The dataset used includes 101 Iranian Sign Language words frequently used in academic environments such as universities. The network used is a combination of early fusion and late fusion transformer encoder-based networks optimized with the help of genetic algorithm. The selected features to train this network include hands and lips key points, and the distance and angle between hands extracted from the sign videos. Also, in addition to the training model for the classes, the embedding vectors of words are used as multi-task learning to have smoother and more efficient training. This model was also tested on sentences generated from our word dataset using a windowing technique for sentence translation. Finally, the sign language training software that provides real-time feedback to users with the help of the developed model, which has 90.2% accuracy on test data, was introduced, and in a survey, the effectiveness and efficiency of this type of sign language learning software and the impact of feedback were investigated.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09833",
        "title": "LiveHPS++: Robust and Coherent Motion Capture in Dynamic Free Environment",
        "abstract": "LiDAR-based human motion capture has garnered significant interest in recent years for its practicability in large-scale and unconstrained environments. However, most methods rely on cleanly segmented human point clouds as input, the accuracy and smoothness of their motion results are compromised when faced with noisy data, rendering them unsuitable for practical applications. To address these limitations and enhance the robustness and precision of motion capture with noise interference, we introduce LiveHPS++, an innovative and effective solution based on a single LiDAR system. Benefiting from three meticulously designed modules, our method can learn dynamic and kinematic features from human movements, and further enable the precise capture of coherent human motions in open settings, making it highly applicable to real-world scenarios. Through extensive experiments, LiveHPS++ has proven to significantly surpass existing state-of-the-art methods across various datasets, establishing a new benchmark in the field.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.10902",
        "title": "Interpreting Hand gestures using Object Detection and Digits Classification",
        "abstract": "Hand gestures have evolved into a natural and intuitive means of engaging with technology. The objective of this research is to develop a robust system that can accurately recognize and classify hand gestures representing numbers. The proposed approach involves collecting a dataset of hand gesture images, preprocessing and enhancing the images, extracting relevant features, and training a machine learning model. The advancement of computer vision technology and object detection techniques, in conjunction with OpenCV's capability to analyze and comprehend hand gestures, presents a chance to transform the identification of numerical digits and its potential applications. The advancement of computer vision technology and object identification technologies, along with OpenCV's capacity to analyze and interpret hand gestures, has the potential to revolutionize human interaction, boosting people's access to information, education, and employment opportunities. Keywords: Computer Vision, Machine learning, Deep Learning, Neural Networks",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.11701",
        "title": "Novel Artistic Scene-Centric Datasets for Effective Transfer Learning in Fragrant Spaces",
        "abstract": "Olfaction, often overlooked in cultural heritage studies, holds profound significance in shaping human experiences and identities. Examining historical depictions of olfactory scenes can offer valuable insights into the role of smells in history. We show that a transfer-learning approach using weakly labeled training data can remarkably improve the classification of fragrant spaces and, more generally, artistic scene depictions. We fine-tune Places365-pre-trained models by querying two cultural heritage data sources and using the search terms as supervision signal. The models are evaluated on two manually corrected test splits. This work lays a foundation for further exploration of fragrant spaces recognition and artistic scene classification. All images and labels are released as the ArtPlaces dataset at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.11569",
        "title": "SFPNet: Sparse Focal Point Network for Semantic Segmentation on General LiDAR Point Clouds",
        "abstract": "Although LiDAR semantic segmentation advances rapidly, state-of-the-art methods often incorporate specifically designed inductive bias derived from benchmarks originating from mechanical spinning LiDAR. This can limit model generalizability to other kinds of LiDAR technologies and make hyperparameter tuning more complex. To tackle these issues, we propose a generalized framework to accommodate various types of LiDAR prevalent in the market by replacing window-attention with our sparse focal point modulation. Our SFPNet is capable of extracting multi-level contexts and dynamically aggregating them using a gate mechanism. By implementing a channel-wise information query, features that incorporate both local and global contexts are encoded. We also introduce a novel large-scale hybrid-solid LiDAR semantic segmentation dataset for robotic applications. SFPNet demonstrates competitive performance on conventional benchmarks derived from mechanical spinning LiDAR, while achieving state-of-the-art results on benchmark derived from solid-state LiDAR. Additionally, it outperforms existing methods on our novel dataset sourced from hybrid-solid LiDAR. Code and dataset are available at this https URL and https://www.semanticindustry.top.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.11784",
        "title": "Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development",
        "abstract": "The emergence of large-scale multi-modal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a novel sandbox suite tailored for integrated data-model co-development. This sandbox provides a comprehensive experimental platform, enabling rapid iteration and insight-driven refinement of both data and models. Our proposed \"Probe-Analyze-Refine\" workflow, validated through applications on state-of-the-art LLaVA-like and DiT based models, yields significant performance boosts, such as topping the VBench leaderboard. We also uncover fruitful insights gleaned from exhaustive benchmarks, shedding light on the critical interplay between data quality, diversity, and model behavior. With the hope of fostering deeper understanding and future progress in multi-modal data and generative modeling, our codes, datasets, and models are maintained and accessible at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1607.00937",
        "title": "Temperature scaling of effective polaron mobility in energetically\n  disordered media",
        "abstract": "We study effective mobility in 2 dimensional (2D) and 3 dimensional (3D)\n systems, where hopping transitions of carriers are described by the Marcus\n equation under a Gaussian density of states in the dilute limit. Using an\n effective medium approximation (EMA), we determined the coefficient $C_d$ for\n the effective mobility expressed by $\\mu_{\\rm\n eff}\\propto\\exp\\left[-\\lambda/\\left(4 k_{\\rm B} T\\right)-\n C_d\\sigma^2/\\left(k_{\\rm B} T\\right)^2 \\right]/\\left[\\sqrt{\\lambda} (k_{\\rm B}\n T)^{3/2}\\right]$, where $\\lambda$ is the reorganization energy, $\\sigma$ is the\n standard deviation of the Gaussian density of states, and $k_{\\rm B} T$ takes\n its usual meaning. We found $C_d=1/2$ for both 2D and 3D. While various\n estimates of the coefficient $C_d$ for 3D systems are available in the\n literature, we provide for the first time the expected $C_d$ value for a 2D\n system. By means of kinetic Monte-Carlo simulations, we show that the effective\n mobility is well described by the equation shown above under certain conditions\n on $\\lambda$. We also give examples of analysis of experimental data for 2D and\n 3D systems based on our theoretical results.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1704.02513",
        "title": "Transcription factor clusters regulate genes in eukaryotic cells",
        "abstract": "Transcription is regulated through binding factors to gene promoters to\n activate or repress expression, however, the mechanisms by which factors find\n targets remain unclear. Using single-molecule fluorescence microscopy, we\n determined in vivo stoichiometry and spatiotemporal dynamics of a GFP tagged\n repressor, Mig1, from a paradigm signaling pathway of Saccharomyces cerevisiae.\n We find the repressor operates in clusters, which upon extracellular signal\n detection, translocate from the cytoplasm, bind to nuclear targets and\n turnover. Simulations of Mig1 configuration within a 3D yeast genome model\n combined with a promoter-specific, fluorescent translation reporter confirmed\n clusters are the functional unit of gene regulation. In vitro and structural\n analysis on reconstituted Mig1 suggests that clusters are stabilized by\n depletion forces between intrinsically disordered sequences. We observed\n similar clusters of a co-regulatory activator from a different pathway,\n supporting a generalized cluster model for transcription factors that reduces\n promoter search times through intersegment transfer while stabilizing gene\n expression.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2402.06926",
        "title": "On a mixed local-nonlocal evolution equation with singular nonlinearity",
        "abstract": "We will prove several existence and regularity results for the mixed\n local-nonlocal parabolic equation of the form \\begin{eqnarray} \\begin{split}\n u_t-\\Delta u+(-\\Delta)^s u&=\\frac{f(x,t)}{u^{\\gamma(x,t)}} \\text { in }\n \\Omega_T:=\\Omega \\times(0, T), \\\\ u&=0 \\text { in }(\\mathbb{R}^n \\backslash\n \\Omega) \\times(0, T), \\\\ u(x, 0)&=u_0(x) \\text { in } \\Omega ; \\end{split}\n \\end{eqnarray} where \\begin{equation*} (-\\Delta )^s u=\n c_{n,s}\\operatorname{P.V.}\\int_{\\mathbb{R}^n}\\frac{u(x,t)-u(y,t)}{|x-y|^{n+2s}}\n d y. \\end{equation*} Under the assumptions that $\\gamma$ is a positive\n continuous function on $\\overline{\\Omega}_T$ and $\\Omega$ is a bounded domain\n %of class $\\mathcal{C}^{1,1}$ with Lipschitz boundary in $\\mathbb{R}^{n}$, $n>\n 2$, $s\\in(0,1)$, $0<T<+\\infty$, $f\\geq 0$, $u_0\\geq 0$, $f$ and $u_0$ belongs\n to suitable Lebesgue spaces. Here $c_{n,s}$ is a suitable normalization\n constant, and $\\operatorname{P.V.}$ stands for Cauchy Principal Value.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2112.02962",
        "title": "DANets: Deep Abstract Networks for Tabular Data Classification and\n  Regression",
        "abstract": "Tabular data are ubiquitous in real world applications. Although many\n commonly-used neural components (e.g., convolution) and extensible neural\n networks (e.g., ResNet) have been developed by the machine learning community,\n few of them were effective for tabular data and few designs were adequately\n tailored for tabular data structures. In this paper, we propose a novel and\n flexible neural component for tabular data, called Abstract Layer (AbstLay),\n which learns to explicitly group correlative input features and generate\n higher-level features for semantics abstraction. Also, we design a structure\n re-parameterization method to compress the learned AbstLay, thus reducing the\n computational complexity by a clear margin in the reference phase. A special\n basic block is built using AbstLays, and we construct a family of Deep Abstract\n Networks (DANets) for tabular data classification and regression by stacking\n such blocks. In DANets, a special shortcut path is introduced to fetch\n information from raw tabular features, assisting feature interactions across\n different levels. Comprehensive experiments on seven real-world tabular\n datasets show that our AbstLay and DANets are effective for tabular data\n classification and regression, and the computational complexity is superior to\n competitive methods. Besides, we evaluate the performance gains of DANet as it\n goes deep, verifying the extendibility of our method. Our code is available at\n https://github.com/WhatAShot/DANet.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2305.14422",
        "title": "Identifying non-Abelian anyons with upstream noise",
        "abstract": "Non-Abelian phases are among the most highly-sought states of matter, with\n those whose anyons permit universal quantum gates constituting the ultimate\n prize. The most promising candidate of such a phase is the fractional quantum\n Hall plateau at filling factors $\\nu=\\frac{12}{5}$, which putatively\n facilitates Fibonacci anyons. Experimental validation of this assertion poses a\n major challenge and remains elusive. We present a measurement protocol that\n could achieve this goal with already-demonstrated experimental techniques.\n Interfacing the $\\nu=\\frac{12}{5}$ state with any readily-available Abelian\n state yields a binary outcome of upstream noise or no noise. Judicious choices\n of the Abelian states can produce a sequence of yes--no outcomes that\n fingerprint the possible non-Abelian phase by ruling out its competitors.\n Crucially, this identification is insensitive to the precise value of the\n measured noise and can uniquely identify the anyon type at filling factors\n $\\nu=\\frac{12}{5}$. In addition, it can distinguish any non-Abelian candidates\n at half-filling in graphene and semiconductor heterostructures.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2204.02206",
        "title": "Hot 2DHG states in tellurium",
        "abstract": "Element semiconductor Te is very popular in both fundamental electronic\n structure study, and device fabrication research area due to its unique band\n structure. Specifically, in low temperatures, Te possesses strong quantum\n oscillations with magnetic field applied in basal plane, either following\n Shubnikov-de Haas (SdH) oscillation rule or following log-periodic oscillation\n rule. With magnetic field applied along the [001] direction, the SdH\n oscillations are attributed to the two-dimensional hole gas (2DHG) surface\n states. Here we reported an interesting SdH oscillation in Te-based single\n crystals, with the magnetic field applied along the [001] direction of the\n crystals, showing the maximum oscillation intensity at ~ 75 K, and still\n traceable at 200 K, which indicates a rather hot 2DHG state. The nontrivial\n Berry phase can be also obtained from the oscillations, implying the\n contribution from topological states. More importantly, the high temperature\n SdH oscillation phenomena are observed in different Te single crystals samples,\n and Te single crystals with nonmagnetic/magnetic dopants, showing robustness to\n bulk defects. Therefore, the oscillation may be contributed by the bulk\n symmetry protected hot 2DHG states, which will offer a new platform for\n high-temperature quantum transport studies.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2112.10093",
        "title": "Epistatic models predict mutable sites in SARS-CoV-2 proteins and\n  epitopes",
        "abstract": "The emergence of new variants of SARS-CoV-2 is a major concern given their\n potential impact on the transmissibility and pathogenicity of the virus as well\n as the efficacy of therapeutic interventions. Here, we predict the mutability\n of all positions in SARS-CoV-2 protein domains to forecast the appearance of\n unseen variants. Using sequence data from other coronaviruses, pre-existing to\n SARS-CoV-2, we build statistical models that do not only capture amino-acid\n conservation but more complex patterns resulting from epistasis. We show that\n these models are notably superior to conservation profiles in estimating the\n already observable SARS-CoV-2 variability. In the receptor binding domain of\n the spike protein, we observe that the predicted mutability correlates well\n with experimental measures of protein stability and that both are reliable\n mutability predictors (ROC AUC ~0.8). Most interestingly, we observe an\n increasing agreement between our model and the observed variability as more\n data become available over time, proving the anticipatory capacity of our\n model. When combined with data concerning the immune response, our approach\n identifies positions where current variants of concern are highly\n overrepresented. These results could assist studies on viral evolution, future\n viral outbreaks and, in particular, guide the exploration and anticipation of\n potentially harmful future SARS-CoV-2 variants.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1406.5508",
        "title": "The influence of diffuse scattered light I. The PSF and its role to\n  observations of the edge-on galaxy NGC 5907",
        "abstract": "All telescopes and instruments are to some degree affected by scattered\n light. It is possible to estimate the amount of such scattered light, and even\n correct for it, with a radially extended point spread function (PSF). The outer\n parts of the PSF have only rarely been determined, since they are faint and\n therefore difficult to measure. A mostly complete overview of existing\n properties and measurements of radially extended PSFs is presented, to both\n show their similarities and to indicate how bright extended objects can be used\n to measure the faintest regions. The importance of the far wings of the PSF and\n their possible temporal variations are demonstrated in three edge-on galaxy\n models. The same study is applied to the first edge-on galaxy where earlier\n observations reveal a halo, NGC 5907. All PSFs were collected in two diagrams,\n after they were offset or normalized, when that was possible.\n Surface-brightness structures of edge-on galaxies were modelled and analysed to\n study scattered-light haloes that result with an exponential disc. The models\n were convolved with both a lower-limit PSF and a more average PSF. The PSF of\n the observed data could be used in the case of NGC 5907. The comparison of the\n PSFs demonstrates a lower-limit $r^{-2}$ power-law decline at larger radii. The\n analysis of the galaxy models shows that also the outer parts of the PSF are\n important to correctly model and analyse observations and, in particular,\n fainter regions. The reassessed analysis of the earlier measurements of NGC\n 5907 reveals an explanation for the faint halo in scattered light, within the\n quoted level of accuracy.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2301.02583",
        "title": "Elastic diffeological spaces",
        "abstract": "We introduce a class of diffeological spaces, called elastic, on which the\n left Kan extension of the tangent functor of smooth manifolds defines an\n abstract tangent functor in the sense of Rosicky. On elastic spaces there is a\n natural Cartan calculus, consisting of vector fields and differential forms,\n together with the Lie bracket, de Rham differential, inner derivative, and Lie\n derivative, satisfying the usual graded commutation relations. Elastic spaces\n are closed under arbitrary coproducts, finite products, and retracts. Examples\n include manifolds with corners and cusps, diffeological groups and\n diffeological vector spaces with a mild extra condition, mapping spaces between\n smooth manifolds, and spaces of sections of smooth fiber bundles. This paper is\n a condensed preview of a longer work, explaining its motivation, main concepts,\n and results, but omitting most of the proofs.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1410.7793",
        "title": "Investigation of the magnetic dipole field at the atomic scale in\n  quasi-one-dimensional paramagnetic conductor Li$_{0.9}$Mo$_{6}$O$_{17}$",
        "abstract": "We report magnetic dipole field investigation at the atomic scale in a single\n crystal of quasi-one-dimensional (Q1D) paramagnetic conductor\n Li$_{0.9}$Mo$_{6}$O$_{17}$, using a paramagnetic electron model and\n $^{7}$Li-NMR spectroscopy measurements with an externally applied magnetic\n field $B_{0}$ = 9 T. We find that the magnetic dipole field component\n ($B_{||}^{\\text{dip}}$) parallel to $B_{0}$ at the Li site from the Mo\n electrons has no lattice axial symmetry; it is small around the middle between\n the lattice $c$ and $a$ axes in the $ac$-plane with the minimum at the field\n orientation angle $\\theta$ = +52.5$^{\\circ}$, while the $B_{||}^{\\text{dip}}$\n maximum is at $\\theta$ = +142.5$^{\\circ}$ when $B_{0}$ is applied perpendicular\n to $b$ ($B_{0}$ $\\perp$ $b$), where $\\theta$ = 0$^{\\circ}$ represents the\n direction of $B_{0}$ $\\parallel$ $c$. Further estimate indicates that\n $B_{||}^{\\text{dip}}$ has a maximum value of 0.35 G at $B_{0}$ = 9 T, and the\n Mo ions have a possible effective magnetic dipole moment 0.015 $\\mu_{\\text{B}}$\n per ion, which is significantly smaller than that of a spin 1/2 free electron.\n By minimizing potential magnetic contributions to the NMR spectrum satellites\n with the NMR spectroscopy measurements at the direction where the value of the\n magnetic dipole field is the smallest, the behavior of the independent charge\n contributions is observed. This work demonstrates that the magnetic dipole\n field from the Mo electrons is the dominant source of the local magnetic fields\n at the Li site, and it suggests that the mysterious \"metal-insulator\" crossover\n at low temperatures is not a charge effect. The work also reveals valuable\n local field information for further NMR investigation which is suggested\n recently [Phys. Rev. B $\\bf{85}$, 235128 (2012)] to be key important to the\n understanding of many mysterious properties of this Q1D material of particular\n interest.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1304.0246",
        "title": "The number of accessible paths in the hypercube",
        "abstract": "Motivated by an evolutionary biology question, we study the following\n problem: we consider the hypercube $\\{0,1\\}^L$ where each node carries an\n independent random variable uniformly distributed on $[0,1]$, except\n $(1,1,\\ldots,1)$ which carries the value $1$ and $(0,0,\\ldots,0)$ which carries\n the value $x\\in[0,1]$. We study the number $\\Theta$ of paths from vertex\n $(0,0,\\ldots,0)$ to the opposite vertex $(1,1,\\ldots,1)$ along which the values\n on the nodes form an increasing sequence. We show that if the value on\n $(0,0,\\ldots,0)$ is set to $x=X/L$ then $\\Theta/L$ converges in law as\n $L\\to\\infty$ to $\\mathrm{e}^{-X}$ times the product of two standard independent\n exponential variables. As a first step in the analysis, we study the same\n question when the graph is that of a tree where the root has arity $L$, each\n node at level 1 has arity $L-1$, \\ldots, and the nodes at level $L-1$ have only\n one offspring which are the leaves of the tree (all the leaves are assigned the\n value 1, the root the value $x\\in[0,1]$).",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1911.09574",
        "title": "Rank-two 5d SCFTs from M-theory at isolated toric singularities: a\n  systematic study",
        "abstract": "We carry out a detailed exploration of the deformations of rank-two\n five-dimensional superconformal field theories (SCFTs)\n $\\mathcal{T}_{\\mathbf{X}}$, which are geometrically engineered by M-theory on\n the space transverse to isolated toric Calabi-Yau (CY) threefold singularities\n $\\mathbf{X}$. Deformations of 5d $\\mathcal{N}=1$ SCFTs can lead to\n \"gauge-theory phases,\" but also to \"non-gauge-theoretic phases,\" which have no\n known Lagrangian interpretation. In previous work, a technique relying on\n fiberwise M-theory/type IIA duality was developed to associate a type IIA\n background to any resolution of $\\mathbf{X}$ which admits a suitable projection\n of its toric diagram. The type IIA background consists of an A-type ALE space\n fibered over the real line, with stacks of coincident D6-branes wrapping\n 2-cycles in the ALE resolution. In this work, we combine that technique with\n some elementary ideas from graph theory, to analyze mass deformations of\n $\\mathcal{T}_{\\mathbf{X}}$ when $\\mathbf{X}$ is a isolated toric CY$_3$\n singularity of rank-two (that is, it has two compact divisors). We explicitly\n derive type IIA descriptions of all isolated rank-two CY$_3$ toric\n singularities. We also comment on the renormalization group flows in the\n extended parameter spaces of these theories, which frequently relate distinct\n geometries by flowing to theories with lower flavor symmetries, including those\n that describe non-gauge-theoretic phases.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/0711.3837",
        "title": "Coevolution of Mercy and Altruistic Cooperation",
        "abstract": "Besides altruistic punishment and group selection, we argue that, mercy can\n lead to altruistic cooperation. Modeling the micro economic behavior of the\n mercy, with two alleles of genes (Cooperation or Defection & Mercy or No mercy)\n agents in a network, we present the computational simulation results in the\n spatiotemporal evolution game theory frame to prove the above argument. Here,\n mercy (or as 'Love thy neighbors') means, the agents, with mercy preference,\n might share his own fitness with his poorest neighbor who poorer than himself.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1903.09118",
        "title": "Some new results related to Lorentz G-gamma spaces and interpolation",
        "abstract": "We compute the K-functional related to some couple of spaces as small or\n classical Lebesgue space or Lorentz-Marcinkiewicz spaces completing the results\n of the previous works of the authors. This computation allows to determine the\n interpolation space in the sense of Peetre for such couple. It happens that the\n result is always a G-gamma space, since this last space covers many spaces. The\n motivations of such study are various, among them we wish to obtain a\n regularity estimate for the so called very weak solution of linear equation in\n a domain Omega with data in the space of the integrable function with respect\n to the distance function to the boundary of Omega.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2205.11137",
        "title": "Decentralized Federated Learning Based on Committees and Blockchain",
        "abstract": "Machine learning algorithms are undoubtedly one of the most popular\n algorithms in recent years, and neural networks have demonstrated unprecedented\n precision. In daily life, different communities may have different user\n characteristics, which also means that training a strong model requires the\n union of different communities, so the privacy issue needs to be solved\n urgently. Federated learning is a popular privacy solution, each community does\n not need to expose specific data, but only needs to upload sub-models to the\n coordination server to train more powerful models. However, federated learning\n also has some problems, such as the security and fairness of the coordination\n server. A proven solution to the problem is a decentralized implementation of\n federated learning. In this paper, we apply decentralized tools such as\n blockchain and consensus algorithms to design a support system that supports\n the decentralized operation of federated learning in an alliance environment,\n involving the exploration of incentives, security, fairness and other issues.\n Finally, we experimentally verify the performance of our system, the effect of\n federated learning, and the availability of privacy protection.",
        "label": 0.0
    },
    {
        "url": "https://aclanthology.org/2021.findings-emnlp.333.pdf",
        "title": "Benchmarking Meta-embeddings: What Works and What Does Not",
        "abstract": "In the last few years, several methods have been proposed to build meta-embeddings. The general aim was to obtain new representa- tions integrating complementary knowledge from different source pre-trained embeddings thereby improving their overall quality. How- ever, previous meta-embeddings have been evaluated using a variety of methods and datasets, which makes it difficult to draw meaningful conclusions regarding the merits of each approach. In this paper we propose a unified common framework, including both intrinsic and extrinsic tasks, for a fair and objective meta-embeddings evaluation. Fur- thermore, we present a new method to gen- erate meta-embeddings, outperforming previ- ous work on a large number of intrinsic evalu- ation benchmarks. Our evaluation framework also allows us to conclude that previous extrin- sic evaluations of meta-embeddings have been overestimated.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1911.07176",
        "title": "Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering",
        "abstract": "We propose an unsupervised strategy for the selection of justification sentences for multi- hop question answering (QA) that (a) maxi- mizes the relevance of the selected sentences, (b) minimizes the overlap between the selected facts, and (c) maximizes the coverage of both question and answer. This unsupervised sen- tence selection method can be coupled with any supervised QA approach. We show that the sentences selected by our method im- prove the performance of a state-of-the-art supervised QA model on two multi-hop QA datasets: AI2\u2019s Reasoning Challenge (ARC) and Multi-Sentence Reading Comprehension (MultiRC). We obtain new state-of-the-art per- formance on both datasets among approaches that do not use external resources for training the QA system: 56.82% F1 on ARC (41.24% on Challenge and 64.49% on Easy) and 26.1% EM0 on MultiRC. Our justification sentences have higher quality than the justifications se- lected by a strong information retrieval base- line, e.g., by 5.4% F1 in MultiRC. We also show that our unsupervised selection of justifi- cation sentences is more stable across domains than a state-of-the-art supervised sentence se- lection method.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1806.00358",
        "title": "A Systematic Classification of Knowledge, Reasoning, and Context within the ARC Dataset",
        "abstract": "The recent work of Clark et al. (2018) introduces the AI2 Reasoning Challenge (ARC) and the associated ARC dataset that partitions open domain, complex sci- ence questions into an Easy Set and a Challenge Set. That paper includes an analysis of 100 questions with respect to the types of knowledge and reasoning re- quired to answer them; however, it does not include clear definitions of these types, nor does it offer information about the quality of the labels. We propose a com- prehensive set of definitions of knowledge and reasoning types necessary for answer- ing the questions in the ARC dataset. Us- ing ten annotators and a sophisticated an- notation interface, we analyze the distri- bution of labels across the Challenge Set and statistics related to them. Addition- ally, we demonstrate that although naive information retrieval methods return sen- tences that are irrelevant to answering the query, sufficient supporting text is of- ten present in the (ARC) corpus. Eval- uating with human-selected relevant sen- tences improves the performance of a neu- ral machine comprehension model by 42 points.\n",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2210.13432",
        "title": "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models",
        "abstract": "Large language models (LLM) trained using the next-token-prediction objective, such as GPT3 and PaLM, have revolutionized natural language processing in recent years by showing impressive zero-shot and few-shot capabilities across a wide range of tasks. In this work, we propose a sim- ple technique that significantly boosts the perfor- mance of LLMs without adding computational cost. Our key observation is that, by perform- ing the next token prediction task with randomly selected past tokens masked out, we can im- prove the quality of the learned representations for downstream language understanding tasks. We hypothesize that randomly masking past to- kens prevents over-attending to recent tokens and encourages attention to tokens in the distant past. We find that our method, Forgetful Causal Mask- ing (FCM), significantly improves both few-shot and finetuning performance of PaLM. We further consider a simple extension, T-FCM, which in- troduces bidirectional context to causal language model without altering the sequence order, and further improves finetuning performance.\n",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12057v1",
        "title": "NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker and AWS Trainium and Inferentia2",
        "abstract": "Retrieval-augmented generation (RAG) techniques are widely used today to retrieve and present information in a conversational format. This paper presents a set of enhancements to traditional RAG techniques, focusing on large language models (LLMs) fine-tuned and hosted on AWS Trainium and Inferentia2 AI chips via SageMaker. These chips are characterized by their elasticity, affordability, and efficient performance for AI compute tasks. Besides enabling deployment on these chips, this work aims to improve tool usage, add citation capabilities, and mitigate the risks of hallucinations and unsafe responses due to context bias. We benchmark our RAG system's performance on the Natural Questions and HotPotQA datasets, achieving an accuracy of 62% and 59% respectively, exceeding other models such as DBRX and Mixtral Instruct.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12018v1",
        "title": "Empirical Evaluation of Public HateSpeech Datasets",
        "abstract": "Despite the extensive communication benefits offered by social media platforms, numerous challenges must be addressed to ensure user safety. One of the most significant risks faced by users on these platforms is targeted hate speech. Social media platforms are widely utilised for generating datasets employed in training and evaluating machine learning algorithms for hate speech detection. However, existing public datasets exhibit numerous limitations, hindering the effective training of these algorithms and leading to inaccurate hate speech classification. This study provides a comprehensive empirical evaluation of several public datasets commonly used in automated hate speech classification. Through rigorous analysis, we present compelling evidence highlighting the limitations of current hate speech datasets. Additionally, we conduct a range of statistical analyses to elucidate the strengths and weaknesses inherent in these datasets. This work aims to advance the development of more accurate and reliable machine learning models for hate speech detection by addressing the dataset limitations identified.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12483v1",
        "title": "Towards AI-Powered Video Assistant Referee System for Association Football",
        "abstract": "Over the past decade, the technology used by referees in football has improved substantially, enhancing the fairness and accuracy of decisions. This progress has culminated in the implementation of the Video Assistant Referee (VAR), an innovation that enables backstage referees to review incidents on the pitch from multiple points of view. However, the VAR is currently limited to professional leagues due to its expensive infrastructure and the lack of referees worldwide. In this paper, we present the semi-automated Video Assistant Referee System (VARS) that leverages the latest findings in multi-view video analysis. VARS sets a new state-of-the-art on the SoccerNet-MVFoul dataset, a multi-view video dataset of football fouls. Our VARS achieves a new state-of-the-art on the SoccerNet-MVFoul dataset by recognizing the type of foul in 50% of instances and the appropriate sanction in 46% of cases. Finally, we conducted a comparative study to investigate human performance in classifying fouls and their corresponding severity and compared these findings to our VARS. The results of our study highlight the potential of our VARS to reach human performance and support football refereeing across all levels of professional and amateur federations.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12002v1",
        "title": "A Multimodal Transformer for Live Streaming Highlight Prediction",
        "abstract": "Recently, live streaming platforms have gained immense popularity. Traditional video highlight detection mainly focuses on visual features and utilizes both past and future content for prediction. However, live streaming requires models to infer without future frames and process complex multimodal interactions, including images, audio and text comments. To address these issues, we propose a multimodal transformer that incorporates historical look-back windows. We introduce a novel Modality Temporal Alignment Module to handle the temporal shift of cross-modal signals. Additionally, using existing datasets with limited manual annotations is insufficient for live streaming whose topics are constantly updated and changed. Therefore, we propose a novel Border-aware Pairwise Loss to learn from a large-scale dataset and utilize user implicit feedback as a weak supervision signal. Extensive experiments show our model outperforms various strong baselines on both real-world scenarios and public datasets. And we will release our dataset and code to better assess this topic.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12193v1",
        "title": "ClaimCompare: A Data Pipeline for Evaluation of Novelty Destroying Patent Pairs",
        "abstract": "A fundamental step in the patent application process is the determination of whether there exist prior patents that are novelty destroying. This step is routinely performed by both applicants and examiners, in order to assess the novelty of proposed inventions among the millions of applications filed annually. However, conducting this search is time and labor-intensive, as searchers must navigate complex legal and technical jargon while covering a large amount of legal claims. Automated approaches using information retrieval and machine learning approaches to detect novelty destroying patents present a promising avenue to streamline this process, yet research focusing on this space remains limited. In this paper, we introduce a novel data pipeline, ClaimCompare, designed to generate labeled patent claim datasets suitable for training IR and ML models to address this challenge of novelty destruction assessment. To the best of our knowledge, ClaimCompare is the first pipeline that can generate multiple novelty destroying patent datasets. To illustrate the practical relevance of this pipeline, we utilize it to construct a sample dataset comprising of over 27K patents in the electrochemical domain: 1,045 base patents from USPTO, each associated with 25 related patents labeled according to their novelty destruction towards the base patent. Subsequently, we conduct preliminary experiments showcasing the efficacy of this dataset in fine-tuning transformer models to identify novelty destroying patents, demonstrating 29.2% and 32.7% absolute improvement in MRR and P@1, respectively.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12730v1",
        "title": "RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal Models",
        "abstract": "Large Multi-modal Models (LMMs) have significantly advanced a variety of vision-language tasks. The scalability and availability of high-quality training data play a pivotal role in the success of LMMs. In the realm of food, while comprehensive food datasets such as Recipe1M offer an abundance of ingredient and recipe information, they often fall short of providing ample data for nutritional analysis. The Recipe1M+ dataset, despite offering a subset for nutritional evaluation, is limited in the scale and accuracy of nutrition information. To bridge this gap, we introduce Uni-Food, a unified food dataset that comprises over 100,000 images with various food labels, including categories, ingredients, recipes, and ingredient-level nutritional information. Uni-Food is designed to provide a more holistic approach to food data analysis, thereby enhancing the performance and capabilities of LMMs in this domain. To mitigate the conflicts arising from multi-task supervision during fine-tuning of LMMs, we introduce a novel Linear Rectification Mixture of Diverse Experts (RoDE) approach. RoDE utilizes a diverse array of experts to address tasks of varying complexity, thereby facilitating the coordination of trainable parameters, i.e., it allocates more parameters for more complex tasks and, conversely, fewer parameters for simpler tasks. RoDE implements linear rectification union to refine the router's functionality, thereby enhancing the efficiency of sparse task allocation. These design choices endow RoDE with features that ensure GPU memory efficiency and ease of optimization. Our experimental results validate the effectiveness of our proposed approach in addressing the inherent challenges of food-related multitasking.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12663v1",
        "title": "Is That Rain? Understanding Effects on Visual Odometry Performance for Autonomous UAVs and Efficient DNN-based Rain Classification at the Edge",
        "abstract": "The development of safe and reliable autonomous unmanned aerial vehicles relies on the ability of the system to recognise and adapt to changes in the local environment based on sensor inputs. State-of-the-art local tracking and trajectory planning are typically performed using camera sensor input to the flight control algorithm, but the extent to which environmental disturbances like rain affect the performance of these systems is largely unknown. In this paper, we first describe the development of an open dataset comprising ~335k images to examine these effects for seven different classes of precipitation conditions and show that a worst-case average tracking error of 1.5 m is possible for a state-of-the-art visual odometry system (VINS-Fusion). We then use the dataset to train a set of deep neural network models suited to mobile and constrained deployment scenarios to determine the extent to which it may be possible to efficiently and accurately classify these `rainy' conditions. The most lightweight of these models (MobileNetV3 small) can achieve an accuracy of 90% with a memory footprint of just 1.28 MB and a frame rate of 93 FPS, which is suitable for deployment in resource-constrained and latency-sensitive systems. We demonstrate a classification latency in the order of milliseconds using typical flight computer hardware. Accordingly, such a model can feed into the disturbance estimation component of an autonomous flight controller. In addition, data from unmanned aerial vehicles with the ability to accurately determine environmental conditions in real time may contribute to developing more granular timely localised weather forecasting.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12579v1",
        "title": "The Fabrication of Reality and Fantasy: Scene Generation with LLM-Assisted Prompt Interpretation",
        "abstract": "In spite of recent advancements in text-to-image generation, limitations persist in handling complex and imaginative prompts due to the restricted diversity and complexity of training data. This work explores how diffusion models can generate images from prompts requiring artistic creativity or specialized knowledge. We introduce the Realistic-Fantasy Benchmark (RFBench), a novel evaluation framework blending realistic and fantastical scenarios. To address these challenges, we propose the Realistic-Fantasy Network (RFNet), a training-free approach integrating diffusion models with LLMs. Extensive human evaluations and GPT-based compositional assessments demonstrate our approach's superiority over state-of-the-art methods. Our code and dataset is available at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12505v1",
        "title": "Subequivariant Reinforcement Learning in 3D Multi-Entity Physical Environments",
        "abstract": "Learning policies for multi-entity systems in 3D environments is far more complicated against single-entity scenarios, due to the exponential expansion of the global state space as the number of entities increases. One potential solution of alleviating the exponential complexity is dividing the global space into independent local views that are invariant to transformations including translations and rotations. To this end, this paper proposes Subequivariant Hierarchical Neural Networks (SHNN) to facilitate multi-entity policy learning. In particular, SHNN first dynamically decouples the global space into local entity-level graphs via task assignment. Second, it leverages subequivariant message passing over the local entity-level graphs to devise local reference frames, remarkably compressing the representation redundancy, particularly in gravity-affected environments. Furthermore, to overcome the limitations of existing benchmarks in capturing the subtleties of multi-entity systems under the Euclidean symmetry, we propose the Multi-entity Benchmark (MEBEN), a new suite of environments tailored for exploring a wide range of multi-entity reinforcement learning. Extensive experiments demonstrate significant advancements of SHNN on the proposed benchmarks compared to existing methods. Comprehensive ablations are conducted to verify the indispensability of task assignment and subequivariance.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12449v1",
        "title": "Close the Sim2real Gap via Physically-based Structured Light Synthetic Data Simulation",
        "abstract": "Despite the substantial progress in deep learning, its adoption in industrial robotics projects remains limited, primarily due to challenges in data acquisition and labeling. Previous sim2real approaches using domain randomization require extensive scene and model optimization. To address these issues, we introduce an innovative physically-based structured light simulation system, generating both RGB and physically realistic depth images, surpassing previous dataset generation tools. We create an RGBD dataset tailored for robotic industrial grasping scenarios and evaluate it across various tasks, including object detection, instance segmentation, and embedding sim2real visual perception in industrial robotic grasping. By reducing the sim2real gap and enhancing deep learning training, we facilitate the application of deep learning models in industrial settings. Project details are available at this https URL light 3D synthesizer/.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12421v1",
        "title": "SafePowerGraph: Safety-aware Evaluation of Graph Neural Networks for Transmission Power Grids",
        "abstract": "Power grids are critical infrastructures of paramount importance to modern society and their rapid evolution and interconnections has heightened the complexity of power systems (PS) operations. Traditional methods for grid analysis struggle with the computational demands of large-scale RES and ES integration, prompting the adoption of machine learning (ML) techniques, particularly Graph Neural Networks (GNNs). GNNs have proven effective in solving the alternating current (AC) Power Flow (PF) and Optimal Power Flow (OPF) problems, crucial for operational planning. However, existing benchmarks and datasets completely ignore safety and robustness requirements in their evaluation and never consider realistic safety-critical scenarios that most impact the operations of the power grids. We present SafePowerGraph, the first simulator-agnostic, safety-oriented framework and benchmark for GNNs in PS operations. SafePowerGraph integrates multiple PF and OPF simulators and assesses GNN performance under diverse scenarios, including energy price variations and power line outages. Our extensive experiments underscore the importance of self-supervised learning and graph attention architectures for GNN robustness. We provide at this https URL our open-source repository, a comprehensive leaderboard, a dataset and model zoo and expect our framework to standardize and advance research in the critical field of GNN for power systems.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12371v1",
        "title": "HIMO: A New Benchmark for Full-Body Human Interacting with Multiple Objects",
        "abstract": "Generating human-object interactions (HOIs) is critical with the tremendous advances of digital avatars. Existing datasets are typically limited to humans interacting with a single object while neglecting the ubiquitous manipulation of multiple objects. Thus, we propose HIMO, a large-scale MoCap dataset of full-body human interacting with multiple objects, containing 3.3K 4D HOI sequences and 4.08M 3D HOI frames. We also annotate HIMO with detailed textual descriptions and temporal segments, benchmarking two novel tasks of HOI synthesis conditioned on either the whole text prompt or the segmented text prompts as fine-grained timeline control. To address these novel tasks, we propose a dual-branch conditional diffusion model with a mutual interaction module for HOI synthesis. Besides, an auto-regressive generation pipeline is also designed to obtain smooth transitions between HOI segments. Experimental results demonstrate the generalization ability to unseen object geometries and temporal compositions.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12025v1",
        "title": "LLM4DESIGN: An Automated Multi-Modal System for Architectural and Environmental Design",
        "abstract": "This study introduces LLM4DESIGN, a highly automated system for generating architectural and environmental design proposals. LLM4DESIGN, relying solely on site conditions and design requirements, employs Multi-Agent systems to foster creativity, Retrieval Augmented Generation (RAG) to ground designs in realism, and Visual Language Models (VLM) to synchronize all information. This system resulting in coherent, multi-illustrated, and multi-textual design schemes. The system meets the dual needs of narrative storytelling and objective drawing presentation in generating architectural and environmental design proposals. Extensive comparative and ablation experiments confirm the innovativeness of LLM4DESIGN's narrative and the grounded applicability of its plans, demonstrating its superior performance in the field of urban renewal design. Lastly, we have created the first cross-modal design scheme dataset covering architecture, landscape, interior, and urban design, providing rich resources for future research.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12023v1",
        "title": "CMMaTH: A Chinese Multi-modal Math Skill Evaluation Benchmark for Foundation Models",
        "abstract": "Due to the rapid advancements in multimodal large language models, evaluating their multimodal mathematical capabilities continues to receive wide attention. Despite the datasets like MathVista proposed benchmarks for assessing mathematical capabilities in multimodal scenarios, there is still a lack of corresponding evaluation tools and datasets for fine-grained assessment in the context of K12 education in Chinese language. To systematically evaluate the capability of multimodal large models in solving Chinese multimodal mathematical problems, we propose a Chinese Multi-modal Math Skill Evaluation Benchmark, named CMMaTH, contraining 23k multimodal K12 math related questions, forming the largest Chinese multimodal mathematical problem benchmark to date. CMMaTH questions from elementary to high school levels, provide increased diversity in problem types, solution objectives, visual elements, detailed knowledge points, and standard solution annotations. We have constructed an open-source tool GradeGPT integrated with the CMMaTH dataset, facilitating stable, rapid, and cost-free model evaluation. Our data and code are available.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12020v1",
        "title": "SignSpeak: Open-Source Time Series Classification for ASL Translation",
        "abstract": "The lack of fluency in sign language remains a barrier to seamless communication for hearing and speech-impaired communities. In this work, we propose a low-cost, real-time ASL-to-speech translation glove and an exhaustive training dataset of sign language patterns. We then benchmarked this dataset with supervised learning models, such as LSTMs, GRUs and Transformers, where our best model achieved 92% accuracy. The SignSpeak dataset has 7200 samples encompassing 36 classes (A-Z, 1-10) and aims to capture realistic signing patterns by using five low-cost flex sensors to measure finger positions at each time step at 36 Hz. Our open-source dataset, models and glove designs, provide an accurate and efficient ASL translator while maintaining cost-effectiveness, establishing a framework for future work to build on.",
        "label": 1.0
    }
]