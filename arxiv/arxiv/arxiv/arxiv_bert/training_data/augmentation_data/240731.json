[
    {
        "url": "https://arxiv.org/pdf/2407.08109",
        "title": "Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter",
        "abstract": "Urban waterlogging poses a major risk to public safety and infrastructure. Conventional methods using water-level sensors need high-maintenance to hardly achieve full coverage. Recent advances employ surveillance camera imagery and deep learning for detection, yet these struggle amidst scarce data and adverse environmental conditions. In this paper, we establish a challenging Urban Waterlogging Benchmark (UW-Bench) under diverse adverse conditions to advance real-world applications. We propose a Large-Small Model co-adapter paradigm (LSM-adapter), which harnesses the substantial generic segmentation potential of large model and the specific task-directed guidance of small model. Specifically, a Triple-S Prompt Adapter module alongside a Dynamic Prompt Combiner are proposed to generate then merge multiple prompts for mask decoder adaptation. Meanwhile, a Histogram Equalization Adap-ter module is designed to infuse the image specific information for image encoder adaptation. Results and analysis show the challenge and superiority of our developed benchmark and algorithm. Project page: \\url{this https URL}",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08108",
        "title": "CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data",
        "abstract": "Deep learning recommendation models (DLRMs) are at the heart of the current e-commerce industry. However, the amount of training data used to train these large models is growing exponentially, leading to substantial training hurdles. The training dataset contains two primary types of information: content-based information (features of users and items) and collaborative information (interactions between users and items). One approach to reduce the training dataset is to remove user-item interactions. But that significantly diminishes collaborative information, which is crucial for maintaining accuracy due to its inclusion of interaction histories. This loss profoundly impacts DLRM performance.\n This paper makes an important observation that if one can capture the user-item interaction history to enrich the user and item embeddings, then the interaction history can be compressed without losing model accuracy. Thus, this work, Collaborative Aware Data Compression (CADC), takes a two-step approach to training dataset compression. In the first step, we use matrix factorization of the user-item interaction matrix to create a novel embedding representation for both the users and items. Once the user and item embeddings are enriched by the interaction history information the approach then applies uniform random sampling of the training dataset to drastically reduce the training dataset size while minimizing model accuracy drop. The source code of CADC is available at \\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08093",
        "title": "MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters",
        "abstract": "Many existing learning-based deformable image registration methods impose constraints on deformation fields to ensure they are globally smooth and continuous. However, this assumption does not hold in cardiac image registration, where different anatomical regions exhibit asymmetric motions during respiration and movements due to sliding organs within the chest. Consequently, such global constraints fail to accommodate local discontinuities across organ boundaries, potentially resulting in erroneous and unrealistic displacement fields. In this paper, we address this issue with MemWarp, a learning framework that leverages a memory network to store prototypical information tailored to different anatomical regions. MemWarp is different from earlier approaches in two main aspects: firstly, by decoupling feature extraction from similarity matching in moving and fixed images, it facilitates more effective utilization of feature maps; secondly, despite its capability to preserve discontinuities, it eliminates the need for segmentation masks during model inference. In experiments on a publicly available cardiac dataset, our method achieves considerable improvements in registration accuracy and producing realistic deformations, outperforming state-of-the-art methods with a remarkable 7.1\\% Dice score improvement over the runner-up semi-supervised method. Source code will be available at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08064",
        "title": "TinyGraph: Joint Feature and Node Condensation for Graph Neural Networks",
        "abstract": "Training graph neural networks (GNNs) on large-scale graphs can be challenging due to the high computational expense caused by the massive number of nodes and high-dimensional nodal features. Existing graph condensation studies tackle this problem only by reducing the number of nodes in the graph. However, the resulting condensed graph data can still be cumbersome. Specifically, although the nodes of the Citeseer dataset are reduced to 0.9% (30 nodes) in training, the number of features is 3,703, severely exceeding the training sample magnitude. Faced with this challenge, we study the problem of joint condensation for both features and nodes in large-scale graphs. This task is challenging mainly due to 1) the intertwined nature of the node features and the graph structure calls for the feature condensation solver to be structure-aware; and 2) the difficulty of keeping useful information in the condensed graph. To address these challenges, we propose a novel framework TinyGraph, to condense features and nodes simultaneously in graphs. Specifically, we cast the problem as matching the gradients of GNN weights trained on the condensed graph and the gradients obtained from training over the original graph, where the feature condensation is achieved by a trainable function. The condensed graph obtained by minimizing the matching loss along the training trajectory can henceforth retain critical information in the original graph. Extensive experiments were carried out to demonstrate the effectiveness of the proposed TinyGraph. For example, a GNN trained with TinyGraph retains 98.5% and 97.5% of the original test accuracy on the Cora and Citeseer datasets, respectively, while significantly reducing the number of nodes by 97.4% and 98.2%, and the number of features by 90.0% on both datasets.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08003",
        "title": "Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data",
        "abstract": "Amyotrophic Lateral Sclerosis (ALS) is characterized as a rapidly progressive neurodegenerative disease that presents individuals with limited treatment options in the realm of medical interventions and therapies. The disease showcases a diverse range of onset patterns and progression trajectories, emphasizing the critical importance of early detection of functional decline to enable tailored care strategies and timely therapeutic interventions. The present investigation, spearheaded by the iDPP@CLEF 2024 challenge, focuses on utilizing sensor-derived data obtained through an app. This data is used to construct various machine learning models specifically designed to forecast the advancement of the ALS Functional Rating Scale-Revised (ALSFRS-R) score, leveraging the dataset provided by the organizers. In our analysis, multiple predictive models were evaluated to determine their efficacy in handling ALS sensor data. The temporal aspect of the sensor data was compressed and amalgamated using statistical methods, thereby augmenting the interpretability and applicability of the gathered information for predictive modeling objectives. The models that demonstrated optimal performance were a naive baseline and ElasticNet regression. The naive model achieved a Mean Absolute Error (MAE) of 0.20 and a Root Mean Square Error (RMSE) of 0.49, slightly outperforming the ElasticNet model, which recorded an MAE of 0.22 and an RMSE of 0.50. Our comparative analysis suggests that while the naive approach yielded marginally better predictive accuracy, the ElasticNet model provides a robust framework for understanding feature contributions.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08001",
        "title": "Automated Neural Patent Landscaping in the Small Data Regime",
        "abstract": "Patent landscaping is the process of identifying all patents related to a particular technological area, and is important for assessing various aspects of the intellectual property context. Traditionally, constructing patent landscapes is intensely laborious and expensive, and the rapid expansion of patenting activity in recent decades has driven an increasing need for efficient and effective automated patent landscaping approaches. In particular, it is critical that we be able to construct patent landscapes using a minimal number of labeled examples, as labeling patents for a narrow technology area requires highly specialized (and hence expensive) technical knowledge. We present an automated neural patent landscaping system that demonstrates significantly improved performance on difficult examples (0.69 $F_1$ on 'hard' examples, versus 0.6 for previously reported systems), and also significant improvements with much less training data (overall 0.75 $F_1$ on as few as 24 examples). Furthermore, in evaluating such automated landscaping systems, acquiring good data is challenge; we demonstrate a higher-quality training data generation procedure by merging Abood and Feltenberger's (2018) \"seed/anti-seed\" approach with active learning to collect difficult labeled examples near the decision boundary. Using this procedure we created a new dataset of labeled AI patents for training and testing. As in prior work we compare our approach with a number of baseline systems, and we release our code and data for others to build upon.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.07924",
        "title": "Solving General Natural-Language-Description Optimization Problems with Large Language Models",
        "abstract": "Optimization problems seek to find the best solution to an objective under a set of constraints, and have been widely investigated in real-world applications. Modeling and solving optimization problems in a specific domain typically require a combination of domain knowledge, mathematical skills, and programming ability, making it difficult for general users and even domain professionals. In this paper, we propose a novel framework called OptLLM that augments LLMs with external solvers. Specifically, OptLLM accepts user queries in natural language, convert them into mathematical formulations and programming codes, and calls the solvers to calculate the results for decision-making. In addition, OptLLM supports multi-round dialogues to gradually refine the modeling and solving of optimization problems. To illustrate the effectiveness of OptLLM, we provide tutorials on three typical optimization applications and conduct experiments on both prompt-based GPT models and a fine-tuned Qwen model using a large-scale selfdeveloped optimization dataset. Experimental results show that OptLLM works with various LLMs, and the fine-tuned model achieves an accuracy boost compared to the promptbased models. Some features of OptLLM framework have been available for trial since June 2023 (this https URL or this https URL).",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08733",
        "title": "Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist",
        "abstract": "Exceptional mathematical reasoning ability is one of the key features that demonstrate the power of large language models (LLMs). How to comprehensively define and evaluate the mathematical abilities of LLMs, and even reflect the user experience in real-world scenarios, has emerged as a critical issue. Current benchmarks predominantly concentrate on problem-solving capabilities, which presents a substantial risk of model overfitting and fails to accurately represent genuine mathematical reasoning abilities. In this paper, we argue that if a model really understands a problem, it should be robustly and readily applied across a diverse array of tasks. Motivated by this, we introduce MATHCHECK, a well-designed checklist for testing task generalization and reasoning robustness, as well as an automatic tool to generate checklists efficiently. MATHCHECK includes multiple mathematical reasoning tasks and robustness test types to facilitate a comprehensive evaluation of both mathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we develop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual reasoning and multi-modal reasoning capabilities, respectively, serving as upgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K. We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs, assessing their comprehensive mathematical reasoning abilities. Our results demonstrate that while frontier LLMs like GPT-4o continue to excel in various abilities on the checklist, many other model families exhibit a significant decline. Further experiments indicate that, compared to traditional math benchmarks, MATHCHECK better reflects true mathematical abilities and represents mathematical intelligence more linearly, thereby supporting our design. On our MATHCHECK, we can easily conduct detailed behavior analysis to deeply investigate models.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08713",
        "title": "GTA: A Benchmark for General Tool Agents",
        "abstract": "Significant focus has been placed on integrating large language models (LLMs) with various tools in developing general-purpose agents. This poses a challenge to LLMs' tool-use capabilities. However, there are evident gaps between existing tool-use evaluations and real-world scenarios. Current evaluations often use AI-generated queries, single-step tasks, dummy tools, and text-only interactions, failing to reveal the agents' real-world problem-solving abilities effectively. To address this, we propose GTA, a benchmark for General Tool Agents, featuring three main aspects: (i) Real user queries: human-written queries with simple real-world objectives but implicit tool-use, requiring the LLM to reason the suitable tools and plan the solution steps. (ii) Real deployed tools: an evaluation platform equipped with tools across perception, operation, logic, and creativity categories to evaluate the agents' actual task execution performance. (iii) Real multimodal inputs: authentic image files, such as spatial scenes, web page screenshots, tables, code snippets, and printed/handwritten materials, used as the query contexts to align with real-world scenarios closely. We design 229 real-world tasks and executable tool chains to evaluate mainstream LLMs. Our findings show that real-world user queries are challenging for existing LLMs, with GPT-4 completing less than 50% of the tasks and most LLMs achieving below 25%. This evaluation reveals the bottlenecks in the tool-use capabilities of current LLMs in real-world scenarios, which provides future direction for advancing general-purpose tool agents. The code and dataset are available at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08475",
        "title": "Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective",
        "abstract": "With the rapid development of the large model domain, research related to fine-tuning has concurrently seen significant advancement, given that fine-tuning is a constituent part of the training process for large-scale models. Data engineering plays a fundamental role in the training process of models, which includes data infrastructure, data processing, etc. Data during fine-tuning likewise forms the base for large models. In order to embrace the power and explore new possibilities of fine-tuning datasets, this paper reviews current public fine-tuning datasets from the perspective of data construction. An overview of public fine-tuning datasets from two sides: evolution and taxonomy, is provided in this review, aiming to chart the development trajectory. Construction techniques and methods for public fine-tuning datasets of Large Language Models (LLMs), including data generation and data augmentation among others, are detailed. This elaboration follows the aforementioned taxonomy, specifically across demonstration, comparison, and generalist categories. Additionally, a category tree of data generation techniques has been abstracted in our review to assist researchers in gaining a deeper understanding of fine-tuning datasets from the construction dimension. Our review also summarizes the construction features in different data preparation phases of current practices in this field, aiming to provide a comprehensive overview and inform future research. Fine-tuning dataset practices, encompassing various data modalities, are also discussed from a construction perspective in our review. Towards the end of the article, we offer insights and considerations regarding the future construction and developments of fine-tuning datasets.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08440",
        "title": "Beyond Instruction Following: Evaluating Rule Following of Large Language Models",
        "abstract": "Although Large Language Models (LLMs) have demonstrated strong instruction-following ability to be helpful, they are further supposed to be controlled and guided by rules in real-world scenarios to be safe, and accurate in responses. This demands the possession of rule-following capability of LLMs. However, few works have made a clear evaluation of the rule-following capability of LLMs. Previous studies that try to evaluate the rule-following capability of LLMs fail to distinguish the rule-following scenarios from the instruction-following scenarios. Therefore, this paper first makes a clarification of the concept of rule-following, and curates a comprehensive benchmark, RuleBench, to evaluate a diversified range of rule-following abilities. Our experimental results on a variety of LLMs show that they are still limited in following rules. Our further analysis provides insights into the improvements for LLMs toward a better rule-following intelligent agent. The data and code can be found at: https://anonymous.4open.science/r/llm-rule-following-B3E3/",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08351",
        "title": "AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models",
        "abstract": "Evaluation is critical for assessing capabilities, tracking scientific progress, and informing model selection. In this paper, we present three desiderata for a good benchmark for language models: (i) salience (e.g., knowledge about World War II is more salient than a random day in history), (ii) novelty (i.e., the benchmark reveals new trends in model rankings not shown by previous benchmarks), and (iii) difficulty (i.e., the benchmark should be difficult for existing models, leaving headroom for future improvement). We operationalize these three desiderata and cast benchmark creation as a search problem, that of finding benchmarks that that satisfy all three desiderata. To tackle this search problem, we present AutoBencher, which uses a language model to automatically search for datasets that meet the three desiderata. AutoBencher uses privileged information (e.g. relevant documents) to construct reliable datasets, and adaptivity with reranking to optimize for the search objective. We use AutoBencher to create datasets for math, multilingual, and knowledge-intensive question answering. The scalability of AutoBencher allows it to test fine-grained categories and tail knowledge, creating datasets that are on average 27% more novel and 22% more difficult than existing benchmarks. A closer investigation of our constructed datasets shows that we can identify specific gaps in LM knowledge in language models that are not captured by existing benchmarks, such as Gemini Pro performing much worse on question answering about the Permian Extinction and Fordism, while OpenAGI-7B performing surprisingly well on QA about COVID-19.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08219",
        "title": "Generating Contextually-Relevant Navigation Instructions for Blind and Low Vision People",
        "abstract": "Navigating unfamiliar environments presents significant challenges for blind and low-vision (BLV) individuals. In this work, we construct a dataset of images and goals across different scenarios such as searching through kitchens or navigating outdoors. We then investigate how grounded instruction generation methods can provide contextually-relevant navigational guidance to users in these instances. Through a sighted user study, we demonstrate that large pretrained language models can produce correct and useful instructions perceived as beneficial for BLV users. We also conduct a survey and interview with 4 BLV users and observe useful insights on preferences for different instructions based on the scenario.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08206",
        "title": "System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation",
        "abstract": "This system report presents our approaches and results for the Chinese Essay Fluency Evaluation (CEFE) task at CCL-2024. For Track 1, we optimized predictions for challenging fine-grained error types using binary classification models and trained coarse-grained models on the Chinese Learner 4W corpus. In Track 2, we enhanced performance by constructing a pseudo-dataset with multiple error types per sentence. For Track 3, where we achieved first place, we generated fluency-rated pseudo-data via back-translation for pre-training and used an NSP-based strategy with Symmetric Cross Entropy loss to capture context and mitigate long dependencies. Our methods effectively address key challenges in Chinese Essay Fluency Evaluation.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08147",
        "title": "Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication",
        "abstract": "Reduplication and repetition, though similar in form, serve distinct linguistic purposes. Reduplication is a deliberate morphological process used to express grammatical, semantic, or pragmatic nuances, while repetition is often unintentional and indicative of disfluency. This paper presents the first large-scale study of reduplication and repetition in speech using computational linguistics. We introduce IndicRedRep, a new publicly available dataset containing Hindi, Telugu, and Marathi text annotated with reduplication and repetition at the word level. We evaluate transformer-based models for multi-class reduplication and repetition token classification, utilizing the Reparandum-Interregnum-Repair structure to distinguish between the two phenomena. Our models achieve macro F1 scores of up to 85.62% in Hindi, 83.95% in Telugu, and 84.82% in Marathi for reduplication-repetition classification.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08734",
        "title": "Transformer Circuit Faithfulness Metrics are not Robust",
        "abstract": "Mechanistic interpretability work attempts to reverse engineer the learned algorithms present inside neural networks. One focus of this work has been to discover 'circuits' -- subgraphs of the full model that explain behaviour on specific tasks. But how do we measure the performance of such circuits? Prior work has attempted to measure circuit 'faithfulness' -- the degree to which the circuit replicates the performance of the full model. In this work, we survey many considerations for designing experiments that measure circuit faithfulness by ablating portions of the model's computation. Concerningly, we find existing methods are highly sensitive to seemingly insignificant changes in the ablation methodology. We conclude that existing circuit faithfulness scores reflect both the methodological choices of researchers as well as the actual components of the circuit - the task a circuit is required to perform depends on the ablation used to test it. The ultimate goal of mechanistic interpretability work is to understand neural networks, so we emphasize the need for more clarity in the precise claims being made about circuits. We open source a library at this https URL that includes highly efficient implementations of a wide range of ablation methodologies and circuit discovery algorithms.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08521",
        "title": "Emergent Visual-Semantic Hierarchies in Image-Text Representations",
        "abstract": "While recent vision-and-language models (VLMs) like CLIP are a powerful tool for analyzing text and images in a shared semantic space, they do not explicitly model the hierarchical nature of the set of texts which may describe an image. Conversely, existing multimodal hierarchical representation learning methods require costly training from scratch, failing to leverage the knowledge encoded by state-of-the-art multimodal foundation models. In this work, we study the knowledge of existing foundation models, finding that they exhibit emergent understanding of visual-semantic hierarchies despite not being directly trained for this purpose. We propose the Radial Embedding (RE) framework for probing and optimizing hierarchical understanding, and contribute the HierarCaps dataset, a benchmark facilitating the study of hierarchical knowledge in image--text representations, constructed automatically via large language models. Our results show that foundation VLMs exhibit zero-shot hierarchical understanding, surpassing the performance of prior models explicitly designed for this purpose. Furthermore, we show that foundation models may be better aligned to hierarchical reasoning via a text-only fine-tuning phase, while retaining pretraining knowledge.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08488",
        "title": "Lynx: An Open Source Hallucination Evaluation Model",
        "abstract": "Retrieval Augmented Generation (RAG) techniques aim to mitigate hallucinations in Large Language Models (LLMs). However, LLMs can still produce information that is unsupported or contradictory to the retrieved contexts. We introduce LYNX, a SOTA hallucination detection LLM that is capable of advanced reasoning on challenging real-world hallucination scenarios. To evaluate LYNX, we present HaluBench, a comprehensive hallucination evaluation benchmark, consisting of 15k samples sourced from various real-world domains. Our experiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and closed and open-source LLM-as-a-judge models on HaluBench. We release LYNX, HaluBench and our evaluation code for public access.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08348",
        "title": "Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On",
        "abstract": "In this paper, we investigate the underlying factors that potentially enhance the mathematical reasoning capabilities of large language models (LLMs). We argue that the data scaling law for math reasoning capabilities in modern LLMs is far from being saturated, highlighting how the model's quality improves with increases in data quantity. To support this claim, we introduce the Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved impressive accuracies of 51.2% on the competition-level MATH benchmark and 83.9% on the GSM8K benchmark using only SFT data, outperforming an early version of GPT-4 on MATH. The superior performance of Skywork-Math models contributes to our novel two-stage data synthesis and model SFT pipelines, which include three different augmentation methods and a diverse seed problem set, ensuring both the quantity and quality of Skywork-MathQA dataset across varying difficulty levels. Most importantly, we provide several practical takeaways to enhance math reasoning abilities in LLMs for both research and industry applications.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08185",
        "title": "Automatic Generation of Web Censorship Probe Lists",
        "abstract": "Domain probe lists--used to determine which URLs to probe for Web censorship--play a critical role in Internet censorship measurement studies. Indeed, the size and accuracy of the domain probe list limits the set of censored pages that can be detected; inaccurate lists can lead to an incomplete view of the censorship landscape or biased results. Previous efforts to generate domain probe lists have been mostly manual or crowdsourced. This approach is time-consuming, prone to errors, and does not scale well to the ever-changing censorship landscape.\n In this paper, we explore methods for automatically generating probe lists that are both comprehensive and up-to-date for Web censorship measurement. We start from an initial set of 139,957 unique URLs from various existing test lists consisting of pages from a variety of languages to generate new candidate pages. By analyzing content from these URLs (i.e., performing topic and keyword extraction), expanding these topics, and using them as a feed to search engines, our method produces 119,255 new URLs across 35,147 domains. We then test the new candidate pages by attempting to access each URL from servers in eleven different global locations over a span of four months to check for their connectivity and potential signs of censorship. Our measurements reveal that our method discovered over 1,400 domains--not present in the original dataset--we suspect to be blocked. In short, automatically updating probe lists is possible, and can help further automate censorship measurements at scale.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08029",
        "title": "A Critical Review of Causal Reasoning Benchmarks for Large Language Models",
        "abstract": "Numerous benchmarks aim to evaluate the capabilities of Large Language Models (LLMs) for causal inference and reasoning. However, many of them can likely be solved through the retrieval of domain knowledge, questioning whether they achieve their purpose. In this review, we present a comprehensive overview of LLM benchmarks for causality. We highlight how recent benchmarks move towards a more thorough definition of causal reasoning by incorporating interventional or counterfactual reasoning. We derive a set of criteria that a useful benchmark or set of benchmarks should aim to satisfy. We hope this work will pave the way towards a general framework for the assessment of causal understanding in LLMs and the design of novel benchmarks.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08739",
        "title": "MAVIS: Mathematical Visual Instruction Tuning",
        "abstract": "Multi-modal Large Language Models (MLLMs) have recently emerged as a significant focus in academia and industry. Despite their proficiency in general multi-modal scenarios, the mathematical problem-solving capabilities in visual contexts remain insufficiently explored. We identify three key areas within MLLMs that need to be improved: visual encoding of math diagrams, diagram-language alignment, and mathematical reasoning skills. This draws forth an urgent demand for large-scale, high-quality data and training pipelines in visual mathematics. In this paper, we propose MAVIS, the first MAthematical VISual instruction tuning paradigm for MLLMs, involving a series of mathematical visual datasets and specialized MLLMs. Targeting the three issues, MAVIS contains three progressive training stages from scratch. First, we curate MAVIS-Caption, consisting of 558K diagram-caption pairs, to fine-tune a math-specific vision encoder (CLIP-Math) through contrastive learning, tailored for improved diagram visual encoding. Second, we utilize MAVIS-Caption to align the CLIP-Math with a large language model (LLM) by a projection layer, enhancing vision-language alignment in mathematical domains. Third, we introduce MAVIS-Instruct, including 900K meticulously collected and annotated visual math problems, which is adopted to finally instruct-tune the MLLM for robust mathematical reasoning skills. In MAVIS-Instruct, we incorporate complete chain-of-thought (CoT) rationales for each problem, and minimize textual redundancy, thereby concentrating the model towards the visual elements. Data and Models are released at this https URL",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.04434",
        "title": "From Showgirls to Performers: Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs",
        "abstract": "Gender bias is not only prevalent in Large Language Models (LLMs) and their training data, but also firmly ingrained into the structural aspects of language itself. Therefore, adapting linguistic structures within LLM training data to promote gender-inclusivity can make gender representations within the model more inclusive. The focus of our work are genderexclusive affixes in English, such as in showgirl or man-cave, which can perpetuate gender stereotypes and binary conceptions of gender. We use an LLM training dataset to compile a catalogue of 692 gender-exclusive terms along with gender-neutral variants and from this, develop a gender-inclusive fine-tuning dataset, the Tiny Heap. Fine-tuning three different LLMs with this dataset, we observe an overall reduction in gender-stereotyping tendencies across the models. Our approach provides a practical method for enhancing gender inclusivity in LLM training data and contributes to incorporating queer-feminist linguistic activism in bias mitigation research in NLP.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/1904.01130",
        "title": "PAWS: Paraphrase Adversaries from Word Scrambling",
        "abstract": "Existing paraphrase identification datasets lack sentence pairs that have high lexical over- lap without being paraphrases. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well- formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State- of-the-art models trained on existing datasets have dismal performance on PAWS (<40% accuracy); however, including PAWS train- ing data for these models improves their ac- curacy to 85% while maintaining performance on existing tasks. In contrast, models that do not capture non-local contextual informa- tion fail even with PAWS training examples. As such, PAWS provides an effective instru- ment for driving further progress on models that better exploit structure, context, and pair- wise comparisons.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2210.01979",
        "title": "GAPX: Generalized Autoregressive Paraphrase-Identification X",
        "abstract": "Paraphrase Identification is a fundamental task in Natural Language Processing. While much progress has been made in the field, the performance of many state-of- the-art models often suffer from distribution shift during inference time. We verify that a major source of this performance drop comes from biases introduced by negative examples. To overcome these biases, we propose in this paper to train two separate models, one that only utilizes the positive pairs and the other the negative pairs. This enables us the option of deciding how much to utilize the negative model, for which we introduce a perplexity based out-of-distribution metric that we show can effectively and automatically determine how much weight it should be given during inference. We support our findings with strong empirical results.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/1811.00491",
        "title": "A Corpus for Reasoning About Natural Language Grounded in Photographs",
        "abstract": "We introduce a new dataset for joint reason- ing about natural language and images, with a focus on semantic diversity, compositionality, and visual reasoning challenges. The data con- tains 107,292 examples of English sentences paired with web photographs. The task is to determine whether a natural language cap- tion is true about a pair of photographs. We crowdsource the data using sets of visually rich images and a compare-and-contrast task to elicit linguistically diverse language. Quali- tative analysis shows the data requires compo- sitional joint reasoning, including about quan- tities, comparisons, and relations. Evaluation using state-of-the-art visual reasoning meth- ods shows the data presents a strong challenge.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2404.12010v1",
        "title": "ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity",
        "abstract": "]Paraphrase generation is a pivotal task in natural language processing(NLP).Existing datasets in the domain lack syntactic and lexical diversity, resulting in paraphrases that closely resemble the source sentences. Moreover, these datasets often contain hate speech and noise, and may unintentionally include non-English language sentences. This research introduces ParaFusion, a large-scale, high-quality English paraphrase dataset developed using Large Language Models (LLM) to address these challenges. ParaFusion augments existing datasets with high-quality data, significantly enhancing both lexical and syntactic diversity while maintaining close semantic sim- ilarity. It also mitigates the presence of hate speech and reduces noise, ensuring a cleaner and more focused English dataset. Results show that ParaFusion offers at least a 25% improvement in both syntactic and lexical diversity, measured across several metrics for each data source. The paper also aims to set a gold standard for paraphrase evaluation as it contains one of the most comprehensive evaluation strategies to date. The results underscore the potential of ParaFusion as a valuable resource for improving NLP applications.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2105.05241",
        "title": "Addressing \"Documentation Debt\" in Machine Learning Research: A Retrospective Datasheet for BookCorpus",
        "abstract": "Recent literature has underscored the importance of dataset documentation work for machine learning, and part of this work involves addressing \u201cdocumentation debt\u201d for datasets that have been used widely but documented sparsely. This paper aims to help address documentation debt for BookCorpus, a popular text dataset for training large language models. Notably, researchers have used BookCorpus to train OpenAI\u2019s GPT-N models and Google\u2019s BERT models, even though little to no documentation exists about the dataset\u2019s motivation, composition, collection process, etc. We offer a preliminary datasheet that provides key context and information about BookCorpus, highlighting several notable deficiencies. In particular, we find evidence that (1) BookCorpus likely violates copyright restrictions for many books, (2) BookCorpus contains thousands of duplicated books, and (3) BookCorpus exhibits significant skews in genre representation. We also find hints of other potential deficiencies that call for future research, including problematic content, potential skews in religious representation, and lopsided author contributions. While more work remains, this initial effort to provide a datasheet for BookCorpus adds to growing literature that urges more careful and systematic documentation for machine learning datasets.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2101.00027",
        "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling",
        "abstract": "Recent work has demonstrated that increased training dataset diversity improves general cross-domain knowledge and downstream generalization capability for large-scale language models. With this in mind, we present \\textit{the Pile}: an 825 GiB English text corpus targeted at training large-scale language models. The Pile is constructed from 22 diverse high-quality subsets -- both existing and newly constructed -- many of which derive from academic or professional sources. Our evaluation of the untuned performance of GPT-2 and GPT-3 on the Pile shows that these models struggle on many of its components, such as academic writing. Conversely, models trained on the Pile improve significantly over both Raw CC and CC-100 on all components of the Pile, while improving performance on downstream evaluations. Through an in-depth exploratory analysis, we document potentially concerning aspects of the data for prospective users. We make publicly available the code used in its construction.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09359",
        "title": "A Unified Anomaly Synthesis Strategy with Gradient Ascent for Industrial Anomaly Detection and Localization",
        "abstract": "Anomaly synthesis strategies can effectively enhance unsupervised anomaly detection. However, existing strategies have limitations in the coverage and controllability of anomaly synthesis, particularly for weak defects that are very similar to normal regions. In this paper, we propose Global and Local Anomaly co-Synthesis Strategy (GLASS), a novel unified framework designed to synthesize a broader coverage of anomalies under the manifold and hypersphere distribution constraints of Global Anomaly Synthesis (GAS) at the feature level and Local Anomaly Synthesis (LAS) at the image level. Our method synthesizes near-in-distribution anomalies in a controllable way using Gaussian noise guided by gradient ascent and truncated projection. GLASS achieves state-of-the-art results on the MVTec AD (detection AUROC of 99.9\\%), VisA, and MPDD datasets and excels in weak defect detection. The effectiveness and efficiency have been further validated in industrial applications for woven fabric defect detection. The code and dataset are available at: \\url{this https URL}.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09285",
        "title": "MetaFood CVPR 2024 Challenge on Physically Informed 3D Food Reconstruction: Methods and Results",
        "abstract": "The increasing interest in computer vision applications for nutrition and dietary monitoring has led to the development of advanced 3D reconstruction techniques for food items. However, the scarcity of high-quality data and limited collaboration between industry and academia have constrained progress in this field. Building on recent advancements in 3D reconstruction, we host the MetaFood Workshop and its challenge for Physically Informed 3D Food Reconstruction. This challenge focuses on reconstructing volume-accurate 3D models of food items from 2D images, using a visible checkerboard as a size reference. Participants were tasked with reconstructing 3D models for 20 selected food items of varying difficulty levels: easy, medium, and hard. The easy level provides 200 images, the medium level provides 30 images, and the hard level provides only 1 image for reconstruction. In total, 16 teams submitted results in the final testing phase. The solutions developed in this challenge achieved promising results in 3D food reconstruction, with significant potential for improving portion estimation for dietary assessment and nutritional monitoring. More details about this workshop challenge and access to the dataset can be found at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08876",
        "title": "DegustaBot: Zero-Shot Visual Preference Estimation for Personalized Multi-Object Rearrangement",
        "abstract": "De gustibus non est disputandum (\"there is no accounting for others' tastes\") is a common Latin maxim describing how many solutions in life are determined by people's personal preferences. Many household tasks, in particular, can only be considered fully successful when they account for personal preferences such as the visual aesthetic of the scene. For example, setting a table could be optimized by arranging utensils according to traditional rules of Western table setting decorum, without considering the color, shape, or material of each object, but this may not be a completely satisfying solution for a given person. Toward this end, we present DegustaBot, an algorithm for visual preference learning that solves household multi-object rearrangement tasks according to personal preference. To do this, we use internet-scale pre-trained vision-and-language foundation models (VLMs) with novel zero-shot visual prompting techniques. To evaluate our method, we collect a large dataset of naturalistic personal preferences in a simulated table-setting task, and conduct a user study in order to develop two novel metrics for determining success based on personal preference. This is a challenging problem and we find that 50% of our model's predictions are likely to be found acceptable by at least 20% of people.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09189",
        "title": "Segmenting Medical Images with Limited Data",
        "abstract": "While computer vision has proven valuable for medical image segmentation, its application faces challenges such as limited dataset sizes and the complexity of effectively leveraging unlabeled images. To address these challenges, we present a novel semi-supervised, consistency-based approach termed the data-efficient medical segmenter (DEMS). The DEMS features an encoder-decoder architecture and incorporates the developed online automatic augmenter (OAA) and residual robustness enhancement (RRE) blocks. The OAA augments input data with various image transformations, thereby diversifying the dataset to improve the generalization ability. The RRE enriches feature diversity and introduces perturbations to create varied inputs for different decoders, thereby providing enhanced variability. Moreover, we introduce a sensitive loss to further enhance consistency across different decoders and stabilize the training process. Extensive experimental results on both our own and three public datasets affirm the effectiveness of DEMS. Under extreme data shortage scenarios, our DEMS achieves 16.85\\% and 10.37\\% improvement in dice score compared with the U-Net and top-performed state-of-the-art method, respectively. Given its superior data efficiency, DEMS could present significant advancements in medical segmentation under small data regimes. The project homepage can be accessed at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08948",
        "title": "Symmetry Awareness Encoded Deep Learning Framework for Brain Imaging Analysis",
        "abstract": "The heterogeneity of neurological conditions, ranging from structural anomalies to functional impairments, presents a significant challenge in medical imaging analysis tasks. Moreover, the limited availability of well-annotated datasets constrains the development of robust analysis models. Against this backdrop, this study introduces a novel approach leveraging the inherent anatomical symmetrical features of the human brain to enhance the subsequent detection and segmentation analysis for brain diseases. A novel Symmetry-Aware Cross-Attention (SACA) module is proposed to encode symmetrical features of left and right hemispheres, and a proxy task to detect symmetrical features as the Symmetry-Aware Head (SAH) is proposed, which guides the pretraining of the whole network on a vast 3D brain imaging dataset comprising both healthy and diseased brain images across various MRI and CT. Through meticulous experimentation on downstream tasks, including both classification and segmentation for brain diseases, our model demonstrates superior performance over state-of-the-art methodologies, particularly highlighting the significance of symmetry-aware learning. Our findings advocate for the effectiveness of incorporating symmetry awareness into pretraining and set a new benchmark for medical imaging analysis, promising significant strides toward accurate and efficient diagnostic processes. Code is available at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.08874",
        "title": "Implications of mappings between ICD clinical diagnosis codes and Human Phenotype Ontology terms",
        "abstract": "Objective: Integrating EHR data with other resources is essential in rare disease research due to low disease prevalence. Such integration is dependent on the alignment of ontologies used for data annotation. The International Classification of Diseases (ICD) is used to annotate clinical diagnoses; the Human Phenotype Ontology (HPO) to annotate phenotypes. Although these ontologies overlap in biomedical entities described, the extent to which they are interoperable is unknown. We investigate how well aligned these ontologies are and whether such alignments facilitate EHR data integration.\n Materials and Methods: We conducted an empirical analysis of the coverage of mappings between ICD and HPO. We interpret this mapping coverage as a proxy for how easily clinical data can be integrated with research ontologies such as HPO. We quantify how exhaustively ICD codes are mapped to HPO by analyzing mappings in the UMLS Metathesaurus. We analyze the proportion of ICD codes mapped to HPO within a real-world EHR dataset.\n Results and Discussion: Our analysis revealed that only 2.2% of ICD codes have direct mappings to HPO in UMLS. Within our EHR dataset, less than 50% of ICD codes have mappings to HPO terms. ICD codes that are used frequently in EHR data tend to have mappings to HPO; ICD codes that represent rarer medical conditions are seldom mapped.\n Conclusion: We find that interoperability between ICD and HPO via UMLS is limited. While other mapping sources could be incorporated, there are no established conventions for what resources should be used to complement UMLS.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09373",
        "title": "Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories",
        "abstract": "Quantifying a patient's health status provides clinicians with insight into patient risk, and the ability to better triage and manage resources. Early Warning Scores (EWS) are widely deployed to measure overall health status, and risk of adverse outcomes, in hospital patients. However, current EWS are limited both by their lack of personalisation and use of static observations. We propose a pipeline that groups intensive care unit patients by the trajectories of observations data throughout their stay as a basis for the development of personalised risk predictions. Feature importance is considered to provide model explainability. Using the MIMIC-IV dataset, six clusters were identified, capturing differences in disease codes, observations, lengths of admissions and outcomes. Applying the pipeline to data from just the first four hours of each ICU stay assigns the majority of patients to the same cluster as when the entire stay duration is considered. In-hospital mortality prediction models trained on individual clusters had higher F1 score performance in five of the six clusters when compared against the unclustered patient cohort. The pipeline could form the basis of a clinical decision support tool, working to improve the clinical characterisation of risk groups and the early detection of patient deterioration.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.10878",
        "title": "Deep Causal Learning to Explain and Quantify The Geo-Tension's Impact on Natural Gas Market",
        "abstract": "Natural gas demand is a crucial factor for predicting natural gas prices and thus has a direct influence on the power system. However, existing methods face challenges in assessing the impact of shocks, such as the outbreak of the Russian-Ukrainian war. In this context, we apply deep neural network-based Granger causality to identify important drivers of natural gas demand. Furthermore, the resulting dependencies are used to construct a counterfactual case without the outbreak of the war, providing a quantifiable estimate of the overall effect of the shock on various German energy sectors. The code and dataset are available at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.10446",
        "title": "DDFAD: Dataset Distillation Framework for Audio Data",
        "abstract": "Deep neural networks (DNNs) have achieved significant success in numerous applications. The remarkable performance of DNNs is largely attributed to the availability of massive, high-quality training datasets. However, processing such massive training data requires huge computational and storage resources. Dataset distillation is a promising solution to this problem, offering the capability to compress a large dataset into a smaller distilled dataset. The model trained on the distilled dataset can achieve comparable performance to the model trained on the whole dataset.\n While dataset distillation has been demonstrated in image data, none have explored dataset distillation for audio data. In this work, for the first time, we propose a Dataset Distillation Framework for Audio Data (DDFAD). Specifically, we first propose the Fused Differential MFCC (FD-MFCC) as extracted features for audio data. After that, the FD-MFCC is distilled through the matching training trajectory distillation method. Finally, we propose an audio signal reconstruction algorithm based on the Griffin-Lim Algorithm to reconstruct the audio signal from the distilled FD-MFCC. Extensive experiments demonstrate the effectiveness of DDFAD on various audio datasets. In addition, we show that DDFAD has promising application prospects in many applications, such as continual learning and neural architecture search.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09544",
        "title": "A Transformer-Based Multi-Stream Approach for Isolated Iranian Sign Language Recognition",
        "abstract": "Sign language is an essential means of communication for millions of people around the world and serves as their primary language. However, most communication tools are developed for spoken and written languages which can cause problems and difficulties for the deaf and hard of hearing community. By developing a sign language recognition system, we can bridge this communication gap and enable people who use sign language as their main form of expression to better communicate with people and their surroundings. This recognition system increases the quality of health services, improves public services, and creates equal opportunities for the deaf community. This research aims to recognize Iranian Sign Language words with the help of the latest deep learning tools such as transformers. The dataset used includes 101 Iranian Sign Language words frequently used in academic environments such as universities. The network used is a combination of early fusion and late fusion transformer encoder-based networks optimized with the help of genetic algorithm. The selected features to train this network include hands and lips key points, and the distance and angle between hands extracted from the sign videos. Also, in addition to the training model for the classes, the embedding vectors of words are used as multi-task learning to have smoother and more efficient training. This model was also tested on sentences generated from our word dataset using a windowing technique for sentence translation. Finally, the sign language training software that provides real-time feedback to users with the help of the developed model, which has 90.2% accuracy on test data, was introduced, and in a survey, the effectiveness and efficiency of this type of sign language learning software and the impact of feedback were investigated.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.09833",
        "title": "LiveHPS++: Robust and Coherent Motion Capture in Dynamic Free Environment",
        "abstract": "LiDAR-based human motion capture has garnered significant interest in recent years for its practicability in large-scale and unconstrained environments. However, most methods rely on cleanly segmented human point clouds as input, the accuracy and smoothness of their motion results are compromised when faced with noisy data, rendering them unsuitable for practical applications. To address these limitations and enhance the robustness and precision of motion capture with noise interference, we introduce LiveHPS++, an innovative and effective solution based on a single LiDAR system. Benefiting from three meticulously designed modules, our method can learn dynamic and kinematic features from human movements, and further enable the precise capture of coherent human motions in open settings, making it highly applicable to real-world scenarios. Through extensive experiments, LiveHPS++ has proven to significantly surpass existing state-of-the-art methods across various datasets, establishing a new benchmark in the field.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.10902",
        "title": "Interpreting Hand gestures using Object Detection and Digits Classification",
        "abstract": "Hand gestures have evolved into a natural and intuitive means of engaging with technology. The objective of this research is to develop a robust system that can accurately recognize and classify hand gestures representing numbers. The proposed approach involves collecting a dataset of hand gesture images, preprocessing and enhancing the images, extracting relevant features, and training a machine learning model. The advancement of computer vision technology and object detection techniques, in conjunction with OpenCV's capability to analyze and comprehend hand gestures, presents a chance to transform the identification of numerical digits and its potential applications. The advancement of computer vision technology and object identification technologies, along with OpenCV's capacity to analyze and interpret hand gestures, has the potential to revolutionize human interaction, boosting people's access to information, education, and employment opportunities. Keywords: Computer Vision, Machine learning, Deep Learning, Neural Networks",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.11701",
        "title": "Novel Artistic Scene-Centric Datasets for Effective Transfer Learning in Fragrant Spaces",
        "abstract": "Olfaction, often overlooked in cultural heritage studies, holds profound significance in shaping human experiences and identities. Examining historical depictions of olfactory scenes can offer valuable insights into the role of smells in history. We show that a transfer-learning approach using weakly labeled training data can remarkably improve the classification of fragrant spaces and, more generally, artistic scene depictions. We fine-tune Places365-pre-trained models by querying two cultural heritage data sources and using the search terms as supervision signal. The models are evaluated on two manually corrected test splits. This work lays a foundation for further exploration of fragrant spaces recognition and artistic scene classification. All images and labels are released as the ArtPlaces dataset at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.11569",
        "title": "SFPNet: Sparse Focal Point Network for Semantic Segmentation on General LiDAR Point Clouds",
        "abstract": "Although LiDAR semantic segmentation advances rapidly, state-of-the-art methods often incorporate specifically designed inductive bias derived from benchmarks originating from mechanical spinning LiDAR. This can limit model generalizability to other kinds of LiDAR technologies and make hyperparameter tuning more complex. To tackle these issues, we propose a generalized framework to accommodate various types of LiDAR prevalent in the market by replacing window-attention with our sparse focal point modulation. Our SFPNet is capable of extracting multi-level contexts and dynamically aggregating them using a gate mechanism. By implementing a channel-wise information query, features that incorporate both local and global contexts are encoded. We also introduce a novel large-scale hybrid-solid LiDAR semantic segmentation dataset for robotic applications. SFPNet demonstrates competitive performance on conventional benchmarks derived from mechanical spinning LiDAR, while achieving state-of-the-art results on benchmark derived from solid-state LiDAR. Additionally, it outperforms existing methods on our novel dataset sourced from hybrid-solid LiDAR. Code and dataset are available at this https URL and https://www.semanticindustry.top.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.11784",
        "title": "Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development",
        "abstract": "The emergence of large-scale multi-modal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a novel sandbox suite tailored for integrated data-model co-development. This sandbox provides a comprehensive experimental platform, enabling rapid iteration and insight-driven refinement of both data and models. Our proposed \"Probe-Analyze-Refine\" workflow, validated through applications on state-of-the-art LLaVA-like and DiT based models, yields significant performance boosts, such as topping the VBench leaderboard. We also uncover fruitful insights gleaned from exhaustive benchmarks, shedding light on the critical interplay between data quality, diversity, and model behavior. With the hope of fostering deeper understanding and future progress in multi-modal data and generative modeling, our codes, datasets, and models are maintained and accessible at this https URL.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1607.00937",
        "title": "Temperature scaling of effective polaron mobility in energetically\n  disordered media",
        "abstract": "We study effective mobility in 2 dimensional (2D) and 3 dimensional (3D)\n systems, where hopping transitions of carriers are described by the Marcus\n equation under a Gaussian density of states in the dilute limit. Using an\n effective medium approximation (EMA), we determined the coefficient $C_d$ for\n the effective mobility expressed by $\\mu_{\\rm\n eff}\\propto\\exp\\left[-\\lambda/\\left(4 k_{\\rm B} T\\right)-\n C_d\\sigma^2/\\left(k_{\\rm B} T\\right)^2 \\right]/\\left[\\sqrt{\\lambda} (k_{\\rm B}\n T)^{3/2}\\right]$, where $\\lambda$ is the reorganization energy, $\\sigma$ is the\n standard deviation of the Gaussian density of states, and $k_{\\rm B} T$ takes\n its usual meaning. We found $C_d=1/2$ for both 2D and 3D. While various\n estimates of the coefficient $C_d$ for 3D systems are available in the\n literature, we provide for the first time the expected $C_d$ value for a 2D\n system. By means of kinetic Monte-Carlo simulations, we show that the effective\n mobility is well described by the equation shown above under certain conditions\n on $\\lambda$. We also give examples of analysis of experimental data for 2D and\n 3D systems based on our theoretical results.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1704.02513",
        "title": "Transcription factor clusters regulate genes in eukaryotic cells",
        "abstract": "Transcription is regulated through binding factors to gene promoters to\n activate or repress expression, however, the mechanisms by which factors find\n targets remain unclear. Using single-molecule fluorescence microscopy, we\n determined in vivo stoichiometry and spatiotemporal dynamics of a GFP tagged\n repressor, Mig1, from a paradigm signaling pathway of Saccharomyces cerevisiae.\n We find the repressor operates in clusters, which upon extracellular signal\n detection, translocate from the cytoplasm, bind to nuclear targets and\n turnover. Simulations of Mig1 configuration within a 3D yeast genome model\n combined with a promoter-specific, fluorescent translation reporter confirmed\n clusters are the functional unit of gene regulation. In vitro and structural\n analysis on reconstituted Mig1 suggests that clusters are stabilized by\n depletion forces between intrinsically disordered sequences. We observed\n similar clusters of a co-regulatory activator from a different pathway,\n supporting a generalized cluster model for transcription factors that reduces\n promoter search times through intersegment transfer while stabilizing gene\n expression.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2402.06926",
        "title": "On a mixed local-nonlocal evolution equation with singular nonlinearity",
        "abstract": "We will prove several existence and regularity results for the mixed\n local-nonlocal parabolic equation of the form \\begin{eqnarray} \\begin{split}\n u_t-\\Delta u+(-\\Delta)^s u&=\\frac{f(x,t)}{u^{\\gamma(x,t)}} \\text { in }\n \\Omega_T:=\\Omega \\times(0, T), \\\\ u&=0 \\text { in }(\\mathbb{R}^n \\backslash\n \\Omega) \\times(0, T), \\\\ u(x, 0)&=u_0(x) \\text { in } \\Omega ; \\end{split}\n \\end{eqnarray} where \\begin{equation*} (-\\Delta )^s u=\n c_{n,s}\\operatorname{P.V.}\\int_{\\mathbb{R}^n}\\frac{u(x,t)-u(y,t)}{|x-y|^{n+2s}}\n d y. \\end{equation*} Under the assumptions that $\\gamma$ is a positive\n continuous function on $\\overline{\\Omega}_T$ and $\\Omega$ is a bounded domain\n %of class $\\mathcal{C}^{1,1}$ with Lipschitz boundary in $\\mathbb{R}^{n}$, $n>\n 2$, $s\\in(0,1)$, $0<T<+\\infty$, $f\\geq 0$, $u_0\\geq 0$, $f$ and $u_0$ belongs\n to suitable Lebesgue spaces. Here $c_{n,s}$ is a suitable normalization\n constant, and $\\operatorname{P.V.}$ stands for Cauchy Principal Value.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2112.02962",
        "title": "DANets: Deep Abstract Networks for Tabular Data Classification and\n  Regression",
        "abstract": "Tabular data are ubiquitous in real world applications. Although many\n commonly-used neural components (e.g., convolution) and extensible neural\n networks (e.g., ResNet) have been developed by the machine learning community,\n few of them were effective for tabular data and few designs were adequately\n tailored for tabular data structures. In this paper, we propose a novel and\n flexible neural component for tabular data, called Abstract Layer (AbstLay),\n which learns to explicitly group correlative input features and generate\n higher-level features for semantics abstraction. Also, we design a structure\n re-parameterization method to compress the learned AbstLay, thus reducing the\n computational complexity by a clear margin in the reference phase. A special\n basic block is built using AbstLays, and we construct a family of Deep Abstract\n Networks (DANets) for tabular data classification and regression by stacking\n such blocks. In DANets, a special shortcut path is introduced to fetch\n information from raw tabular features, assisting feature interactions across\n different levels. Comprehensive experiments on seven real-world tabular\n datasets show that our AbstLay and DANets are effective for tabular data\n classification and regression, and the computational complexity is superior to\n competitive methods. Besides, we evaluate the performance gains of DANet as it\n goes deep, verifying the extendibility of our method. Our code is available at\n https://github.com/WhatAShot/DANet.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2305.14422",
        "title": "Identifying non-Abelian anyons with upstream noise",
        "abstract": "Non-Abelian phases are among the most highly-sought states of matter, with\n those whose anyons permit universal quantum gates constituting the ultimate\n prize. The most promising candidate of such a phase is the fractional quantum\n Hall plateau at filling factors $\\nu=\\frac{12}{5}$, which putatively\n facilitates Fibonacci anyons. Experimental validation of this assertion poses a\n major challenge and remains elusive. We present a measurement protocol that\n could achieve this goal with already-demonstrated experimental techniques.\n Interfacing the $\\nu=\\frac{12}{5}$ state with any readily-available Abelian\n state yields a binary outcome of upstream noise or no noise. Judicious choices\n of the Abelian states can produce a sequence of yes--no outcomes that\n fingerprint the possible non-Abelian phase by ruling out its competitors.\n Crucially, this identification is insensitive to the precise value of the\n measured noise and can uniquely identify the anyon type at filling factors\n $\\nu=\\frac{12}{5}$. In addition, it can distinguish any non-Abelian candidates\n at half-filling in graphene and semiconductor heterostructures.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2204.02206",
        "title": "Hot 2DHG states in tellurium",
        "abstract": "Element semiconductor Te is very popular in both fundamental electronic\n structure study, and device fabrication research area due to its unique band\n structure. Specifically, in low temperatures, Te possesses strong quantum\n oscillations with magnetic field applied in basal plane, either following\n Shubnikov-de Haas (SdH) oscillation rule or following log-periodic oscillation\n rule. With magnetic field applied along the [001] direction, the SdH\n oscillations are attributed to the two-dimensional hole gas (2DHG) surface\n states. Here we reported an interesting SdH oscillation in Te-based single\n crystals, with the magnetic field applied along the [001] direction of the\n crystals, showing the maximum oscillation intensity at ~ 75 K, and still\n traceable at 200 K, which indicates a rather hot 2DHG state. The nontrivial\n Berry phase can be also obtained from the oscillations, implying the\n contribution from topological states. More importantly, the high temperature\n SdH oscillation phenomena are observed in different Te single crystals samples,\n and Te single crystals with nonmagnetic/magnetic dopants, showing robustness to\n bulk defects. Therefore, the oscillation may be contributed by the bulk\n symmetry protected hot 2DHG states, which will offer a new platform for\n high-temperature quantum transport studies.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2112.10093",
        "title": "Epistatic models predict mutable sites in SARS-CoV-2 proteins and\n  epitopes",
        "abstract": "The emergence of new variants of SARS-CoV-2 is a major concern given their\n potential impact on the transmissibility and pathogenicity of the virus as well\n as the efficacy of therapeutic interventions. Here, we predict the mutability\n of all positions in SARS-CoV-2 protein domains to forecast the appearance of\n unseen variants. Using sequence data from other coronaviruses, pre-existing to\n SARS-CoV-2, we build statistical models that do not only capture amino-acid\n conservation but more complex patterns resulting from epistasis. We show that\n these models are notably superior to conservation profiles in estimating the\n already observable SARS-CoV-2 variability. In the receptor binding domain of\n the spike protein, we observe that the predicted mutability correlates well\n with experimental measures of protein stability and that both are reliable\n mutability predictors (ROC AUC ~0.8). Most interestingly, we observe an\n increasing agreement between our model and the observed variability as more\n data become available over time, proving the anticipatory capacity of our\n model. When combined with data concerning the immune response, our approach\n identifies positions where current variants of concern are highly\n overrepresented. These results could assist studies on viral evolution, future\n viral outbreaks and, in particular, guide the exploration and anticipation of\n potentially harmful future SARS-CoV-2 variants.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1406.5508",
        "title": "The influence of diffuse scattered light I. The PSF and its role to\n  observations of the edge-on galaxy NGC 5907",
        "abstract": "All telescopes and instruments are to some degree affected by scattered\n light. It is possible to estimate the amount of such scattered light, and even\n correct for it, with a radially extended point spread function (PSF). The outer\n parts of the PSF have only rarely been determined, since they are faint and\n therefore difficult to measure. A mostly complete overview of existing\n properties and measurements of radially extended PSFs is presented, to both\n show their similarities and to indicate how bright extended objects can be used\n to measure the faintest regions. The importance of the far wings of the PSF and\n their possible temporal variations are demonstrated in three edge-on galaxy\n models. The same study is applied to the first edge-on galaxy where earlier\n observations reveal a halo, NGC 5907. All PSFs were collected in two diagrams,\n after they were offset or normalized, when that was possible.\n Surface-brightness structures of edge-on galaxies were modelled and analysed to\n study scattered-light haloes that result with an exponential disc. The models\n were convolved with both a lower-limit PSF and a more average PSF. The PSF of\n the observed data could be used in the case of NGC 5907. The comparison of the\n PSFs demonstrates a lower-limit $r^{-2}$ power-law decline at larger radii. The\n analysis of the galaxy models shows that also the outer parts of the PSF are\n important to correctly model and analyse observations and, in particular,\n fainter regions. The reassessed analysis of the earlier measurements of NGC\n 5907 reveals an explanation for the faint halo in scattered light, within the\n quoted level of accuracy.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2301.02583",
        "title": "Elastic diffeological spaces",
        "abstract": "We introduce a class of diffeological spaces, called elastic, on which the\n left Kan extension of the tangent functor of smooth manifolds defines an\n abstract tangent functor in the sense of Rosicky. On elastic spaces there is a\n natural Cartan calculus, consisting of vector fields and differential forms,\n together with the Lie bracket, de Rham differential, inner derivative, and Lie\n derivative, satisfying the usual graded commutation relations. Elastic spaces\n are closed under arbitrary coproducts, finite products, and retracts. Examples\n include manifolds with corners and cusps, diffeological groups and\n diffeological vector spaces with a mild extra condition, mapping spaces between\n smooth manifolds, and spaces of sections of smooth fiber bundles. This paper is\n a condensed preview of a longer work, explaining its motivation, main concepts,\n and results, but omitting most of the proofs.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1410.7793",
        "title": "Investigation of the magnetic dipole field at the atomic scale in\n  quasi-one-dimensional paramagnetic conductor Li$_{0.9}$Mo$_{6}$O$_{17}$",
        "abstract": "We report magnetic dipole field investigation at the atomic scale in a single\n crystal of quasi-one-dimensional (Q1D) paramagnetic conductor\n Li$_{0.9}$Mo$_{6}$O$_{17}$, using a paramagnetic electron model and\n $^{7}$Li-NMR spectroscopy measurements with an externally applied magnetic\n field $B_{0}$ = 9 T. We find that the magnetic dipole field component\n ($B_{||}^{\\text{dip}}$) parallel to $B_{0}$ at the Li site from the Mo\n electrons has no lattice axial symmetry; it is small around the middle between\n the lattice $c$ and $a$ axes in the $ac$-plane with the minimum at the field\n orientation angle $\\theta$ = +52.5$^{\\circ}$, while the $B_{||}^{\\text{dip}}$\n maximum is at $\\theta$ = +142.5$^{\\circ}$ when $B_{0}$ is applied perpendicular\n to $b$ ($B_{0}$ $\\perp$ $b$), where $\\theta$ = 0$^{\\circ}$ represents the\n direction of $B_{0}$ $\\parallel$ $c$. Further estimate indicates that\n $B_{||}^{\\text{dip}}$ has a maximum value of 0.35 G at $B_{0}$ = 9 T, and the\n Mo ions have a possible effective magnetic dipole moment 0.015 $\\mu_{\\text{B}}$\n per ion, which is significantly smaller than that of a spin 1/2 free electron.\n By minimizing potential magnetic contributions to the NMR spectrum satellites\n with the NMR spectroscopy measurements at the direction where the value of the\n magnetic dipole field is the smallest, the behavior of the independent charge\n contributions is observed. This work demonstrates that the magnetic dipole\n field from the Mo electrons is the dominant source of the local magnetic fields\n at the Li site, and it suggests that the mysterious \"metal-insulator\" crossover\n at low temperatures is not a charge effect. The work also reveals valuable\n local field information for further NMR investigation which is suggested\n recently [Phys. Rev. B $\\bf{85}$, 235128 (2012)] to be key important to the\n understanding of many mysterious properties of this Q1D material of particular\n interest.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1304.0246",
        "title": "The number of accessible paths in the hypercube",
        "abstract": "Motivated by an evolutionary biology question, we study the following\n problem: we consider the hypercube $\\{0,1\\}^L$ where each node carries an\n independent random variable uniformly distributed on $[0,1]$, except\n $(1,1,\\ldots,1)$ which carries the value $1$ and $(0,0,\\ldots,0)$ which carries\n the value $x\\in[0,1]$. We study the number $\\Theta$ of paths from vertex\n $(0,0,\\ldots,0)$ to the opposite vertex $(1,1,\\ldots,1)$ along which the values\n on the nodes form an increasing sequence. We show that if the value on\n $(0,0,\\ldots,0)$ is set to $x=X/L$ then $\\Theta/L$ converges in law as\n $L\\to\\infty$ to $\\mathrm{e}^{-X}$ times the product of two standard independent\n exponential variables. As a first step in the analysis, we study the same\n question when the graph is that of a tree where the root has arity $L$, each\n node at level 1 has arity $L-1$, \\ldots, and the nodes at level $L-1$ have only\n one offspring which are the leaves of the tree (all the leaves are assigned the\n value 1, the root the value $x\\in[0,1]$).",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1911.09574",
        "title": "Rank-two 5d SCFTs from M-theory at isolated toric singularities: a\n  systematic study",
        "abstract": "We carry out a detailed exploration of the deformations of rank-two\n five-dimensional superconformal field theories (SCFTs)\n $\\mathcal{T}_{\\mathbf{X}}$, which are geometrically engineered by M-theory on\n the space transverse to isolated toric Calabi-Yau (CY) threefold singularities\n $\\mathbf{X}$. Deformations of 5d $\\mathcal{N}=1$ SCFTs can lead to\n \"gauge-theory phases,\" but also to \"non-gauge-theoretic phases,\" which have no\n known Lagrangian interpretation. In previous work, a technique relying on\n fiberwise M-theory/type IIA duality was developed to associate a type IIA\n background to any resolution of $\\mathbf{X}$ which admits a suitable projection\n of its toric diagram. The type IIA background consists of an A-type ALE space\n fibered over the real line, with stacks of coincident D6-branes wrapping\n 2-cycles in the ALE resolution. In this work, we combine that technique with\n some elementary ideas from graph theory, to analyze mass deformations of\n $\\mathcal{T}_{\\mathbf{X}}$ when $\\mathbf{X}$ is a isolated toric CY$_3$\n singularity of rank-two (that is, it has two compact divisors). We explicitly\n derive type IIA descriptions of all isolated rank-two CY$_3$ toric\n singularities. We also comment on the renormalization group flows in the\n extended parameter spaces of these theories, which frequently relate distinct\n geometries by flowing to theories with lower flavor symmetries, including those\n that describe non-gauge-theoretic phases.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/0711.3837",
        "title": "Coevolution of Mercy and Altruistic Cooperation",
        "abstract": "Besides altruistic punishment and group selection, we argue that, mercy can\n lead to altruistic cooperation. Modeling the micro economic behavior of the\n mercy, with two alleles of genes (Cooperation or Defection & Mercy or No mercy)\n agents in a network, we present the computational simulation results in the\n spatiotemporal evolution game theory frame to prove the above argument. Here,\n mercy (or as 'Love thy neighbors') means, the agents, with mercy preference,\n might share his own fitness with his poorest neighbor who poorer than himself.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1903.09118",
        "title": "Some new results related to Lorentz G-gamma spaces and interpolation",
        "abstract": "We compute the K-functional related to some couple of spaces as small or\n classical Lebesgue space or Lorentz-Marcinkiewicz spaces completing the results\n of the previous works of the authors. This computation allows to determine the\n interpolation space in the sense of Peetre for such couple. It happens that the\n result is always a G-gamma space, since this last space covers many spaces. The\n motivations of such study are various, among them we wish to obtain a\n regularity estimate for the so called very weak solution of linear equation in\n a domain Omega with data in the space of the integrable function with respect\n to the distance function to the boundary of Omega.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2205.11137",
        "title": "Decentralized Federated Learning Based on Committees and Blockchain",
        "abstract": "Machine learning algorithms are undoubtedly one of the most popular\n algorithms in recent years, and neural networks have demonstrated unprecedented\n precision. In daily life, different communities may have different user\n characteristics, which also means that training a strong model requires the\n union of different communities, so the privacy issue needs to be solved\n urgently. Federated learning is a popular privacy solution, each community does\n not need to expose specific data, but only needs to upload sub-models to the\n coordination server to train more powerful models. However, federated learning\n also has some problems, such as the security and fairness of the coordination\n server. A proven solution to the problem is a decentralized implementation of\n federated learning. In this paper, we apply decentralized tools such as\n blockchain and consensus algorithms to design a support system that supports\n the decentralized operation of federated learning in an alliance environment,\n involving the exploration of incentives, security, fairness and other issues.\n Finally, we experimentally verify the performance of our system, the effect of\n federated learning, and the availability of privacy protection.",
        "label": 0.0
    },
    {
        "url": "https://aclanthology.org/2021.findings-emnlp.333.pdf",
        "title": "Benchmarking Meta-embeddings: What Works and What Does Not",
        "abstract": "In the last few years, several methods have been proposed to build meta-embeddings. The general aim was to obtain new representa- tions integrating complementary knowledge from different source pre-trained embeddings thereby improving their overall quality. How- ever, previous meta-embeddings have been evaluated using a variety of methods and datasets, which makes it difficult to draw meaningful conclusions regarding the merits of each approach. In this paper we propose a unified common framework, including both intrinsic and extrinsic tasks, for a fair and objective meta-embeddings evaluation. Fur- thermore, we present a new method to gen- erate meta-embeddings, outperforming previ- ous work on a large number of intrinsic evalu- ation benchmarks. Our evaluation framework also allows us to conclude that previous extrin- sic evaluations of meta-embeddings have been overestimated.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1911.07176",
        "title": "Quick and (not so) Dirty: Unsupervised Selection of Justification Sentences for Multi-hop Question Answering",
        "abstract": "We propose an unsupervised strategy for the selection of justification sentences for multi- hop question answering (QA) that (a) maxi- mizes the relevance of the selected sentences, (b) minimizes the overlap between the selected facts, and (c) maximizes the coverage of both question and answer. This unsupervised sen- tence selection method can be coupled with any supervised QA approach. We show that the sentences selected by our method im- prove the performance of a state-of-the-art supervised QA model on two multi-hop QA datasets: AI2\u2019s Reasoning Challenge (ARC) and Multi-Sentence Reading Comprehension (MultiRC). We obtain new state-of-the-art per- formance on both datasets among approaches that do not use external resources for training the QA system: 56.82% F1 on ARC (41.24% on Challenge and 64.49% on Easy) and 26.1% EM0 on MultiRC. Our justification sentences have higher quality than the justifications se- lected by a strong information retrieval base- line, e.g., by 5.4% F1 in MultiRC. We also show that our unsupervised selection of justifi- cation sentences is more stable across domains than a state-of-the-art supervised sentence se- lection method.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/1806.00358",
        "title": "A Systematic Classification of Knowledge, Reasoning, and Context within the ARC Dataset",
        "abstract": "The recent work of Clark et al. (2018) introduces the AI2 Reasoning Challenge (ARC) and the associated ARC dataset that partitions open domain, complex sci- ence questions into an Easy Set and a Challenge Set. That paper includes an analysis of 100 questions with respect to the types of knowledge and reasoning re- quired to answer them; however, it does not include clear definitions of these types, nor does it offer information about the quality of the labels. We propose a com- prehensive set of definitions of knowledge and reasoning types necessary for answer- ing the questions in the ARC dataset. Us- ing ten annotators and a sophisticated an- notation interface, we analyze the distri- bution of labels across the Challenge Set and statistics related to them. Addition- ally, we demonstrate that although naive information retrieval methods return sen- tences that are irrelevant to answering the query, sufficient supporting text is of- ten present in the (ARC) corpus. Eval- uating with human-selected relevant sen- tences improves the performance of a neu- ral machine comprehension model by 42 points.\n",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/pdf/2210.13432",
        "title": "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models",
        "abstract": "Large language models (LLM) trained using the next-token-prediction objective, such as GPT3 and PaLM, have revolutionized natural language processing in recent years by showing impressive zero-shot and few-shot capabilities across a wide range of tasks. In this work, we propose a sim- ple technique that significantly boosts the perfor- mance of LLMs without adding computational cost. Our key observation is that, by perform- ing the next token prediction task with randomly selected past tokens masked out, we can im- prove the quality of the learned representations for downstream language understanding tasks. We hypothesize that randomly masking past to- kens prevents over-attending to recent tokens and encourages attention to tokens in the distant past. We find that our method, Forgetful Causal Mask- ing (FCM), significantly improves both few-shot and finetuning performance of PaLM. We further consider a simple extension, T-FCM, which in- troduces bidirectional context to causal language model without altering the sequence order, and further improves finetuning performance.\n",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12057v1",
        "title": "NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker and AWS Trainium and Inferentia2",
        "abstract": "Retrieval-augmented generation (RAG) techniques are widely used today to retrieve and present information in a conversational format. This paper presents a set of enhancements to traditional RAG techniques, focusing on large language models (LLMs) fine-tuned and hosted on AWS Trainium and Inferentia2 AI chips via SageMaker. These chips are characterized by their elasticity, affordability, and efficient performance for AI compute tasks. Besides enabling deployment on these chips, this work aims to improve tool usage, add citation capabilities, and mitigate the risks of hallucinations and unsafe responses due to context bias. We benchmark our RAG system's performance on the Natural Questions and HotPotQA datasets, achieving an accuracy of 62% and 59% respectively, exceeding other models such as DBRX and Mixtral Instruct.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12018v1",
        "title": "Empirical Evaluation of Public HateSpeech Datasets",
        "abstract": "Despite the extensive communication benefits offered by social media platforms, numerous challenges must be addressed to ensure user safety. One of the most significant risks faced by users on these platforms is targeted hate speech. Social media platforms are widely utilised for generating datasets employed in training and evaluating machine learning algorithms for hate speech detection. However, existing public datasets exhibit numerous limitations, hindering the effective training of these algorithms and leading to inaccurate hate speech classification. This study provides a comprehensive empirical evaluation of several public datasets commonly used in automated hate speech classification. Through rigorous analysis, we present compelling evidence highlighting the limitations of current hate speech datasets. Additionally, we conduct a range of statistical analyses to elucidate the strengths and weaknesses inherent in these datasets. This work aims to advance the development of more accurate and reliable machine learning models for hate speech detection by addressing the dataset limitations identified.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12483v1",
        "title": "Towards AI-Powered Video Assistant Referee System for Association Football",
        "abstract": "Over the past decade, the technology used by referees in football has improved substantially, enhancing the fairness and accuracy of decisions. This progress has culminated in the implementation of the Video Assistant Referee (VAR), an innovation that enables backstage referees to review incidents on the pitch from multiple points of view. However, the VAR is currently limited to professional leagues due to its expensive infrastructure and the lack of referees worldwide. In this paper, we present the semi-automated Video Assistant Referee System (VARS) that leverages the latest findings in multi-view video analysis. VARS sets a new state-of-the-art on the SoccerNet-MVFoul dataset, a multi-view video dataset of football fouls. Our VARS achieves a new state-of-the-art on the SoccerNet-MVFoul dataset by recognizing the type of foul in 50% of instances and the appropriate sanction in 46% of cases. Finally, we conducted a comparative study to investigate human performance in classifying fouls and their corresponding severity and compared these findings to our VARS. The results of our study highlight the potential of our VARS to reach human performance and support football refereeing across all levels of professional and amateur federations.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12002v1",
        "title": "A Multimodal Transformer for Live Streaming Highlight Prediction",
        "abstract": "Recently, live streaming platforms have gained immense popularity. Traditional video highlight detection mainly focuses on visual features and utilizes both past and future content for prediction. However, live streaming requires models to infer without future frames and process complex multimodal interactions, including images, audio and text comments. To address these issues, we propose a multimodal transformer that incorporates historical look-back windows. We introduce a novel Modality Temporal Alignment Module to handle the temporal shift of cross-modal signals. Additionally, using existing datasets with limited manual annotations is insufficient for live streaming whose topics are constantly updated and changed. Therefore, we propose a novel Border-aware Pairwise Loss to learn from a large-scale dataset and utilize user implicit feedback as a weak supervision signal. Extensive experiments show our model outperforms various strong baselines on both real-world scenarios and public datasets. And we will release our dataset and code to better assess this topic.",
        "label": 0.0
    },
    {
        "url": "https://arxiv.org/html/2407.12193v1",
        "title": "ClaimCompare: A Data Pipeline for Evaluation of Novelty Destroying Patent Pairs",
        "abstract": "A fundamental step in the patent application process is the determination of whether there exist prior patents that are novelty destroying. This step is routinely performed by both applicants and examiners, in order to assess the novelty of proposed inventions among the millions of applications filed annually. However, conducting this search is time and labor-intensive, as searchers must navigate complex legal and technical jargon while covering a large amount of legal claims. Automated approaches using information retrieval and machine learning approaches to detect novelty destroying patents present a promising avenue to streamline this process, yet research focusing on this space remains limited. In this paper, we introduce a novel data pipeline, ClaimCompare, designed to generate labeled patent claim datasets suitable for training IR and ML models to address this challenge of novelty destruction assessment. To the best of our knowledge, ClaimCompare is the first pipeline that can generate multiple novelty destroying patent datasets. To illustrate the practical relevance of this pipeline, we utilize it to construct a sample dataset comprising of over 27K patents in the electrochemical domain: 1,045 base patents from USPTO, each associated with 25 related patents labeled according to their novelty destruction towards the base patent. Subsequently, we conduct preliminary experiments showcasing the efficacy of this dataset in fine-tuning transformer models to identify novelty destroying patents, demonstrating 29.2% and 32.7% absolute improvement in MRR and P@1, respectively.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12730v1",
        "title": "RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal Models",
        "abstract": "Large Multi-modal Models (LMMs) have significantly advanced a variety of vision-language tasks. The scalability and availability of high-quality training data play a pivotal role in the success of LMMs. In the realm of food, while comprehensive food datasets such as Recipe1M offer an abundance of ingredient and recipe information, they often fall short of providing ample data for nutritional analysis. The Recipe1M+ dataset, despite offering a subset for nutritional evaluation, is limited in the scale and accuracy of nutrition information. To bridge this gap, we introduce Uni-Food, a unified food dataset that comprises over 100,000 images with various food labels, including categories, ingredients, recipes, and ingredient-level nutritional information. Uni-Food is designed to provide a more holistic approach to food data analysis, thereby enhancing the performance and capabilities of LMMs in this domain. To mitigate the conflicts arising from multi-task supervision during fine-tuning of LMMs, we introduce a novel Linear Rectification Mixture of Diverse Experts (RoDE) approach. RoDE utilizes a diverse array of experts to address tasks of varying complexity, thereby facilitating the coordination of trainable parameters, i.e., it allocates more parameters for more complex tasks and, conversely, fewer parameters for simpler tasks. RoDE implements linear rectification union to refine the router's functionality, thereby enhancing the efficiency of sparse task allocation. These design choices endow RoDE with features that ensure GPU memory efficiency and ease of optimization. Our experimental results validate the effectiveness of our proposed approach in addressing the inherent challenges of food-related multitasking.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12663v1",
        "title": "Is That Rain? Understanding Effects on Visual Odometry Performance for Autonomous UAVs and Efficient DNN-based Rain Classification at the Edge",
        "abstract": "The development of safe and reliable autonomous unmanned aerial vehicles relies on the ability of the system to recognise and adapt to changes in the local environment based on sensor inputs. State-of-the-art local tracking and trajectory planning are typically performed using camera sensor input to the flight control algorithm, but the extent to which environmental disturbances like rain affect the performance of these systems is largely unknown. In this paper, we first describe the development of an open dataset comprising ~335k images to examine these effects for seven different classes of precipitation conditions and show that a worst-case average tracking error of 1.5 m is possible for a state-of-the-art visual odometry system (VINS-Fusion). We then use the dataset to train a set of deep neural network models suited to mobile and constrained deployment scenarios to determine the extent to which it may be possible to efficiently and accurately classify these `rainy' conditions. The most lightweight of these models (MobileNetV3 small) can achieve an accuracy of 90% with a memory footprint of just 1.28 MB and a frame rate of 93 FPS, which is suitable for deployment in resource-constrained and latency-sensitive systems. We demonstrate a classification latency in the order of milliseconds using typical flight computer hardware. Accordingly, such a model can feed into the disturbance estimation component of an autonomous flight controller. In addition, data from unmanned aerial vehicles with the ability to accurately determine environmental conditions in real time may contribute to developing more granular timely localised weather forecasting.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12579v1",
        "title": "The Fabrication of Reality and Fantasy: Scene Generation with LLM-Assisted Prompt Interpretation",
        "abstract": "In spite of recent advancements in text-to-image generation, limitations persist in handling complex and imaginative prompts due to the restricted diversity and complexity of training data. This work explores how diffusion models can generate images from prompts requiring artistic creativity or specialized knowledge. We introduce the Realistic-Fantasy Benchmark (RFBench), a novel evaluation framework blending realistic and fantastical scenarios. To address these challenges, we propose the Realistic-Fantasy Network (RFNet), a training-free approach integrating diffusion models with LLMs. Extensive human evaluations and GPT-based compositional assessments demonstrate our approach's superiority over state-of-the-art methods. Our code and dataset is available at this https URL.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12505v1",
        "title": "Subequivariant Reinforcement Learning in 3D Multi-Entity Physical Environments",
        "abstract": "Learning policies for multi-entity systems in 3D environments is far more complicated against single-entity scenarios, due to the exponential expansion of the global state space as the number of entities increases. One potential solution of alleviating the exponential complexity is dividing the global space into independent local views that are invariant to transformations including translations and rotations. To this end, this paper proposes Subequivariant Hierarchical Neural Networks (SHNN) to facilitate multi-entity policy learning. In particular, SHNN first dynamically decouples the global space into local entity-level graphs via task assignment. Second, it leverages subequivariant message passing over the local entity-level graphs to devise local reference frames, remarkably compressing the representation redundancy, particularly in gravity-affected environments. Furthermore, to overcome the limitations of existing benchmarks in capturing the subtleties of multi-entity systems under the Euclidean symmetry, we propose the Multi-entity Benchmark (MEBEN), a new suite of environments tailored for exploring a wide range of multi-entity reinforcement learning. Extensive experiments demonstrate significant advancements of SHNN on the proposed benchmarks compared to existing methods. Comprehensive ablations are conducted to verify the indispensability of task assignment and subequivariance.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12449v1",
        "title": "Close the Sim2real Gap via Physically-based Structured Light Synthetic Data Simulation",
        "abstract": "Despite the substantial progress in deep learning, its adoption in industrial robotics projects remains limited, primarily due to challenges in data acquisition and labeling. Previous sim2real approaches using domain randomization require extensive scene and model optimization. To address these issues, we introduce an innovative physically-based structured light simulation system, generating both RGB and physically realistic depth images, surpassing previous dataset generation tools. We create an RGBD dataset tailored for robotic industrial grasping scenarios and evaluate it across various tasks, including object detection, instance segmentation, and embedding sim2real visual perception in industrial robotic grasping. By reducing the sim2real gap and enhancing deep learning training, we facilitate the application of deep learning models in industrial settings. Project details are available at this https URL light 3D synthesizer/.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12421v1",
        "title": "SafePowerGraph: Safety-aware Evaluation of Graph Neural Networks for Transmission Power Grids",
        "abstract": "Power grids are critical infrastructures of paramount importance to modern society and their rapid evolution and interconnections has heightened the complexity of power systems (PS) operations. Traditional methods for grid analysis struggle with the computational demands of large-scale RES and ES integration, prompting the adoption of machine learning (ML) techniques, particularly Graph Neural Networks (GNNs). GNNs have proven effective in solving the alternating current (AC) Power Flow (PF) and Optimal Power Flow (OPF) problems, crucial for operational planning. However, existing benchmarks and datasets completely ignore safety and robustness requirements in their evaluation and never consider realistic safety-critical scenarios that most impact the operations of the power grids. We present SafePowerGraph, the first simulator-agnostic, safety-oriented framework and benchmark for GNNs in PS operations. SafePowerGraph integrates multiple PF and OPF simulators and assesses GNN performance under diverse scenarios, including energy price variations and power line outages. Our extensive experiments underscore the importance of self-supervised learning and graph attention architectures for GNN robustness. We provide at this https URL our open-source repository, a comprehensive leaderboard, a dataset and model zoo and expect our framework to standardize and advance research in the critical field of GNN for power systems.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12371v1",
        "title": "HIMO: A New Benchmark for Full-Body Human Interacting with Multiple Objects",
        "abstract": "Generating human-object interactions (HOIs) is critical with the tremendous advances of digital avatars. Existing datasets are typically limited to humans interacting with a single object while neglecting the ubiquitous manipulation of multiple objects. Thus, we propose HIMO, a large-scale MoCap dataset of full-body human interacting with multiple objects, containing 3.3K 4D HOI sequences and 4.08M 3D HOI frames. We also annotate HIMO with detailed textual descriptions and temporal segments, benchmarking two novel tasks of HOI synthesis conditioned on either the whole text prompt or the segmented text prompts as fine-grained timeline control. To address these novel tasks, we propose a dual-branch conditional diffusion model with a mutual interaction module for HOI synthesis. Besides, an auto-regressive generation pipeline is also designed to obtain smooth transitions between HOI segments. Experimental results demonstrate the generalization ability to unseen object geometries and temporal compositions.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12025v1",
        "title": "LLM4DESIGN: An Automated Multi-Modal System for Architectural and Environmental Design",
        "abstract": "This study introduces LLM4DESIGN, a highly automated system for generating architectural and environmental design proposals. LLM4DESIGN, relying solely on site conditions and design requirements, employs Multi-Agent systems to foster creativity, Retrieval Augmented Generation (RAG) to ground designs in realism, and Visual Language Models (VLM) to synchronize all information. This system resulting in coherent, multi-illustrated, and multi-textual design schemes. The system meets the dual needs of narrative storytelling and objective drawing presentation in generating architectural and environmental design proposals. Extensive comparative and ablation experiments confirm the innovativeness of LLM4DESIGN's narrative and the grounded applicability of its plans, demonstrating its superior performance in the field of urban renewal design. Lastly, we have created the first cross-modal design scheme dataset covering architecture, landscape, interior, and urban design, providing rich resources for future research.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12023v1",
        "title": "CMMaTH: A Chinese Multi-modal Math Skill Evaluation Benchmark for Foundation Models",
        "abstract": "Due to the rapid advancements in multimodal large language models, evaluating their multimodal mathematical capabilities continues to receive wide attention. Despite the datasets like MathVista proposed benchmarks for assessing mathematical capabilities in multimodal scenarios, there is still a lack of corresponding evaluation tools and datasets for fine-grained assessment in the context of K12 education in Chinese language. To systematically evaluate the capability of multimodal large models in solving Chinese multimodal mathematical problems, we propose a Chinese Multi-modal Math Skill Evaluation Benchmark, named CMMaTH, contraining 23k multimodal K12 math related questions, forming the largest Chinese multimodal mathematical problem benchmark to date. CMMaTH questions from elementary to high school levels, provide increased diversity in problem types, solution objectives, visual elements, detailed knowledge points, and standard solution annotations. We have constructed an open-source tool GradeGPT integrated with the CMMaTH dataset, facilitating stable, rapid, and cost-free model evaluation. Our data and code are available.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/html/2407.12020v1",
        "title": "SignSpeak: Open-Source Time Series Classification for ASL Translation",
        "abstract": "The lack of fluency in sign language remains a barrier to seamless communication for hearing and speech-impaired communities. In this work, we propose a low-cost, real-time ASL-to-speech translation glove and an exhaustive training dataset of sign language patterns. We then benchmarked this dataset with supervised learning models, such as LSTMs, GRUs and Transformers, where our best model achieved 92% accuracy. The SignSpeak dataset has 7200 samples encompassing 36 classes (A-Z, 1-10) and aims to capture realistic signing patterns by using five low-cost flex sensors to measure finger positions at each time step at 36 Hz. Our open-source dataset, models and glove designs, provide an accurate and efficient ASL translator while maintaining cost-effectiveness, establishing a framework for future work to build on.",
        "label": 1.0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20446",
        "title": "MEVDT: Multi-Modal Event-Based Vehicle Detection and Tracking Dataset",
        "abstract": "In this data article, we introduce the Multi-Modal Event-based Vehicle Detection and Tracking (MEVDT) dataset. This dataset provides a synchronized stream of event data and grayscale images of traffic scenes, captured using the Dynamic and Active-Pixel Vision Sensor (DAVIS) 240c hybrid event-based camera. MEVDT comprises 63 multi-modal sequences with approximately 13k images, 5M events, 10k object labels, and 85 unique object tracking trajectories. Additionally, MEVDT includes manually annotated ground truth labels $\\unicode{x2014}$ consisting of object classifications, pixel-precise bounding boxes, and unique object IDs $\\unicode{x2014}$ which are provided at a labeling frequency of 24 Hz. Designed to advance the research in the domain of event-based vision, MEVDT aims to address the critical need for high-quality, real-world annotated datasets that enable the development and evaluation of object detection and tracking algorithms in automotive environments.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.21009",
        "title": "AI-Assisted Generation of Difficult Math Questions",
        "abstract": "Current LLM training positions mathematical reasoning as a core capability. With publicly available sources fully tapped, there is unmet demand for diverse and challenging math questions. Relying solely on human experts is both time-consuming and costly, while LLM-generated questions often lack the requisite diversity and difficulty. We present a design framework that combines the strengths of LLMs with a human-in-the-loop approach to generate a diverse array of challenging math questions. We leverage LLM metacognition skills [Didolkar et al., 2024] of a strong LLM to extract core \"skills\" from existing math datasets. These skills serve as the basis for generating novel and difficult questions by prompting the LLM with random pairs of core skills. The use of two different skills within each question makes finding such questions an \"out of distribution\" task for both LLMs and humans. Our pipeline employs LLMs to iteratively generate and refine questions and solutions through multiturn prompting. Human annotators then verify and further refine the questions, with their efficiency enhanced via further LLM interactions. Applying this pipeline on skills extracted from the MATH dataset [Hendrycks et al., 2021] resulted in MATH$^2$ - a dataset of higher-quality math questions, as evidenced by: (a) Lower performance of all models on MATH$^2$ than on MATH (b) Higher performance on MATH when using MATH$^2$ questions as in-context examples. Although focused on mathematics, our methodology seems applicable to other domains requiring structured reasoning, and potentially as a component of scalable oversight. Also of interest is a striking relationship observed between models' performance on the new dataset: the success rate on MATH$^2$ is the square on MATH, suggesting that successfully solving the question in MATH$^2$ requires a nontrivial combination of two distinct math skills.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20806",
        "title": "ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning",
        "abstract": "This paper introduces ARCLE, an environment designed to facilitate reinforcement learning research on the Abstraction and Reasoning Corpus (ARC). Addressing this inductive reasoning benchmark with reinforcement learning presents these challenges: a vast action space, a hard-to-reach goal, and a variety of tasks. We demonstrate that an agent with proximal policy optimization can learn individual tasks through ARCLE. The adoption of non-factorial policies and auxiliary losses led to performance enhancements, effectively mitigating issues associated with action spaces and goal attainment. Based on these insights, we propose several research directions and motivations for using ARCLE, including MAML, GFlowNets, and World Models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20377",
        "title": "Leveraging Natural Language and Item Response Theory Models for ESG Scoring",
        "abstract": "This paper explores an innovative approach to Environmental, Social, and Governance (ESG) scoring by integrating Natural Language Processing (NLP) techniques with Item Response Theory (IRT), specifically the Rasch model. The study utilizes a comprehensive dataset of news articles in Portuguese related to Petrobras, a major oil company in Brazil, collected from 2022 and 2023. The data is filtered and classified for ESG-related sentiments using advanced NLP methods. The Rasch model is then applied to evaluate the psychometric properties of these ESG measures, providing a nuanced assessment of ESG sentiment trends over time. The results demonstrate the efficacy of this methodology in offering a more precise and reliable measurement of ESG factors, highlighting significant periods and trends. This approach may enhance the robustness of ESG metrics and contribute to the broader field of sustainability and finance by offering a deeper understanding of the temporal dynamics in ESG reporting.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.21001",
        "title": "GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models",
        "abstract": "Vision-language models (VLMs) are intensively used in many downstream tasks, including those requiring assessments of individuals appearing in the images. While VLMs perform well in simple single-person scenarios, in real-world applications, we often face complex situations in which there are persons of different genders doing different activities. We show that in such cases, VLMs are biased towards identifying the individual with the expected gender (according to ingrained gender stereotypes in the model or other forms of sample selection bias) as the performer of the activity. We refer to this bias in associating an activity with the gender of its actual performer in an image or text as the Gender-Activity Binding (GAB) bias and analyze how this bias is internalized in VLMs. To assess this bias, we have introduced the GAB dataset with approximately 5500 AI-generated images that represent a variety of activities, addressing the scarcity of real-world images for some scenarios. To have extensive quality control, the generated images are evaluated for their diversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on this dataset in the context of text-to-image and image-to-text retrieval to measure the effect of this bias on their predictions. Additionally, we have carried out supplementary experiments to quantify the bias in VLMs' text encoders and to evaluate VLMs' capability to recognize activities. Our experiments indicate that VLMs experience an average performance decline of about 13.2% when confronted with gender-activity binding bias.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20635",
        "title": "Autonomous Improvement of Instruction Following Skills via Foundation Models",
        "abstract": "Intelligent instruction-following robots capable of improving from autonomously collected experience have the potential to transform robot learning: instead of collecting costly teleoperated demonstration data, large-scale deployment of fleets of robots can quickly collect larger quantities of autonomous data that can collectively improve their performance. However, autonomous improvement requires solving two key problems: (i) fully automating a scalable data collection procedure that can collect diverse and semantically meaningful robot data and (ii) learning from non-optimal, autonomous data with no human annotations. To this end, we propose a novel approach that addresses these challenges, allowing instruction-following policies to improve from autonomously collected data without human supervision. Our framework leverages vision-language models to collect and evaluate semantically meaningful experiences in new environments, and then utilizes a decomposition of instruction following tasks into (semantic) language-conditioned image generation and (non-semantic) goal reaching, which makes it significantly more practical to improve from this autonomously collected data without any human annotations. We carry out extensive experiments in the real world to demonstrate the effectiveness of our approach, and find that in a suite of unseen environments, the robot policy can be improved significantly with autonomously collected data. We open-source the code for our semantic autonomous improvement pipeline, as well as our autonomous dataset of 30.5K trajectories collected across five tabletop environments.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20582",
        "title": "Image-based Detection of Segment Misalignment in Multi-mirror Satellites using Transfer Learning",
        "abstract": "In this paper, we introduce a system based on transfer learning for detecting segment misalignment in multimirror satellites, such as future CubeSat designs and the James Webb Space Telescope (JWST), using image-based methods. When a mirror segment becomes misaligned due to various environmental factors, such as space debris, the images can become distorted with a shifted copy of itself called a \"ghost image\". To detect whether segments are misaligned, we use pre-trained, large-scale image models trained on the Fast Fourier Transform (FFT) of patches of satellite images in grayscale. Multi-mirror designs can use any arbitrary number of mirrors. For our purposes, the tests were performed on simulated CubeSats with 4, 6, and 8 segments. For system design, we took this into account when we want to know when a satellite has a misaligned segment and how many segments are misaligned. The intensity of the ghost image is directly proportional to the number of segments misaligned. Models trained for intensity classification attempted to classify N-1 segments. Across eight classes, binary models were able to achieve a classification accuracy of 98.75%, and models for intensity classification were able to achieve an accuracy of 98.05%.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20578",
        "title": "Comparison of Large Language Models for Generating Contextually Relevant Questions",
        "abstract": "This study explores the effectiveness of Large Language Models (LLMs) for Automatic Question Generation in educational settings. Three LLMs are compared in their ability to create questions from university slide text without fine-tuning. Questions were obtained in a two-step pipeline: first, answer phrases were extracted from slides using Llama 2-Chat 13B; then, the three models generated questions for each answer. To analyze whether the questions would be suitable in educational applications for students, a survey was conducted with 46 students who evaluated a total of 246 questions across five metrics: clarity, relevance, difficulty, slide relation, and question-answer alignment. Results indicate that GPT-3.5 and Llama 2-Chat 13B outperform Flan T5 XXL by a small margin, particularly in terms of clarity and question-answer alignment. GPT-3.5 especially excels at tailoring questions to match the input answers. The contribution of this research is the analysis of the capacity of LLMs for Automatic Question Generation in education.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20563",
        "title": "Pyramid Coder: Hierarchical Code Generator for Compositional Visual Question Answering",
        "abstract": "Visual question answering (VQA) is the task of providing accurate answers to natural language questions based on visual input. Programmatic VQA (PVQA) models have been gaining attention recently. These use large language models (LLMs) to formulate executable programs that address questions requiring complex visual reasoning. However, there are challenges in enabling LLMs to comprehend the usage of image processing modules and generate relevant code. To overcome these challenges, this paper introduces PyramidCoder, a novel prompting framework for PVQA models. PyramidCoder consists of three hierarchical levels, each serving a distinct purpose: query rephrasing, code generation, and answer aggregation. Notably, PyramidCoder utilizes a single frozen LLM and pre-defined prompts at each level, eliminating the need for additional training and ensuring flexibility across various LLM architectures. Compared to the state-of-the-art PVQA model, our approach improves accuracy by at least 0.5% on the GQA dataset, 1.4% on the VQAv2 dataset, and 2.9% on the NLVR2 dataset.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20557",
        "title": "CELLM: An Efficient Communication in Large Language Models Training for Federated Learning",
        "abstract": "Federated Learning (FL) is a recent model training paradigm in which client devices collaboratively train a model without ever aggregating their data. Crucially, this scheme offers users potential privacy and security benefits by only ever communicating updates to the model weights to a central server as opposed to traditional machine learning (ML) training which directly communicates and aggregates data. However, FL training suffers from statistical heterogeneity as clients may have differing local data distributions. Large language models (LLMs) offer a potential solution to this issue of heterogeneity given that they have consistently been shown to be able to learn on vast amounts of noisy data. While LLMs are a promising development for resolving the consistent issue of non-I.I.D. Clients in federated settings exacerbate two other bottlenecks in FL: limited local computing and expensive communication. This thesis aims to develop efficient training methods for LLMs in FL. To this end, we employ two critical techniques in enabling efficient training. First, we use low-rank adaptation (LoRA) to reduce the computational load of local model training. Second, we communicate sparse updates throughout training to significantly cut down on communication costs. Taken together, our method reduces communication costs by up to 10x over vanilla LoRA and up to 5x over more complex sparse LoRA baselines while achieving greater utility. We emphasize the importance of carefully applying sparsity and picking effective rank and sparsity configurations for federated LLM training.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20519",
        "title": "DuA: Dual Attentive Transformer in Long-Term Continuous EEG Emotion Analysis",
        "abstract": "Affective brain-computer interfaces (aBCIs) are increasingly recognized for their potential in monitoring and interpreting emotional states through electroencephalography (EEG) signals. Current EEG-based emotion recognition methods perform well with short segments of EEG data. However, these methods encounter significant challenges in real-life scenarios where emotional states evolve over extended periods. To address this issue, we propose a Dual Attentive (DuA) transformer framework for long-term continuous EEG emotion analysis. Unlike segment-based approaches, the DuA transformer processes an entire EEG trial as a whole, identifying emotions at the trial level, referred to as trial-based emotion analysis. This framework is designed to adapt to varying signal lengths, providing a substantial advantage over traditional methods. The DuA transformer incorporates three key modules: the spatial-spectral network module, the temporal network module, and the transfer learning module. The spatial-spectral network module simultaneously captures spatial and spectral information from EEG signals, while the temporal network module detects temporal dependencies within long-term EEG data. The transfer learning module enhances the model's adaptability across different subjects and conditions. We extensively evaluate the DuA transformer using a self-constructed long-term EEG emotion database, along with two benchmark EEG emotion databases. On the basis of the trial-based leave-one-subject-out cross-subject cross-validation protocol, our experimental results demonstrate that the proposed DuA transformer significantly outperforms existing methods in long-term continuous EEG emotion analysis, with an average enhancement of 5.28%.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20518",
        "title": "High-Resolution Spatial Transcriptomics from Histology Images using HisToSGE",
        "abstract": "Spatial transcriptomics (ST) is a groundbreaking genomic technology that enables spatial localization analysis of gene expression within tissue sections. However, it is significantly limited by high costs and sparse spatial resolution. An alternative, more cost-effective strategy is to use deep learning methods to predict high-density gene expression profiles from histological images. However, existing methods struggle to capture rich image features effectively or rely on low-dimensional positional coordinates, making it difficult to accurately predict high-resolution gene expression profiles. To address these limitations, we developed HisToSGE, a method that employs a Pathology Image Large Model (PILM) to extract rich image features from histological images and utilizes a feature learning module to robustly generate high-resolution gene expression profiles. We evaluated HisToSGE on four ST datasets, comparing its performance with five state-of-the-art baseline methods. The results demonstrate that HisToSGE excels in generating high-resolution gene expression profiles and performing downstream tasks such as spatial domain identification. All code and public datasets used in this paper are available at this https URL and this https URL.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20516",
        "title": "Machine Unlearning in Generative AI: A Survey",
        "abstract": "Generative AI technologies have been deployed in many places, such as (multimodal) large language models and vision generative models. Their remarkable performance should be attributed to massive training data and emergent reasoning abilities. However, the models would memorize and generate sensitive, biased, or dangerous information originated from the training data especially those from web crawl. New machine unlearning (MU) techniques are being developed to reduce or eliminate undesirable knowledge and its effects from the models, because those that were designed for traditional classification tasks could not be applied for Generative AI. We offer a comprehensive survey on many things about MU in Generative AI, such as a new problem formulation, evaluation methods, and a structured discussion on the advantages and limitations of different kinds of MU techniques. It also presents several critical challenges and promising directions in MU research. A curated list of readings can be found: this https URL.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20515",
        "title": "Markers Identification for Relative Pose Estimation of an Uncooperative Target",
        "abstract": "This paper introduces a novel method using chaser spacecraft image processing and Convolutional Neural Networks (CNNs) to detect structural markers on the European Space Agency's (ESA) Environmental Satellite (ENVISAT) for safe de-orbiting. Advanced image pre-processing techniques, including noise addition and blurring, are employed to improve marker detection accuracy and robustness. Initial results show promising potential for autonomous space debris removal, supporting proactive strategies for space sustainability. The effectiveness of our approach suggests that our estimation method could significantly enhance the safety and efficiency of debris removal operations by implementing more robust and autonomous systems in actual space missions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20513",
        "title": "Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language",
        "abstract": "This paper presents a conversational pipeline for crafting domain knowledge for complex neuro-symbolic models through natural language prompts. It leverages large language models to generate declarative programs in the DomiKnowS framework. The programs in this framework express concepts and their relationships as a graph in addition to logical constraints between them. The graph, later, can be connected to trainable neural models according to those specifications. Our proposed pipeline utilizes techniques like dynamic in-context demonstration retrieval, model refinement based on feedback from a symbolic parser, visualization, and user interaction to generate the tasks' structure and formal knowledge representation. This approach empowers domain experts, even those not well-versed in ML/AI, to formally declare their knowledge to be incorporated in customized neural models in the DomiKnowS framework.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20506",
        "title": "Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge",
        "abstract": "The effectiveness of model training heavily relies on the quality of available training resources. However, budget constraints often impose limitations on data collection efforts. To tackle this challenge, we introduce causal exploration in this paper, a strategy that leverages the underlying causal knowledge for both data collection and model training. We, in particular, focus on enhancing the sample efficiency and reliability of the world model learning within the domain of task-agnostic reinforcement learning. During the exploration phase, the agent actively selects actions expected to yield causal insights most beneficial for world model training. Concurrently, the causal knowledge is acquired and incrementally refined with the ongoing collection of data. We demonstrate that causal exploration aids in learning accurate world models using fewer data and provide theoretical guarantees for its convergence. Empirical experiments, on both synthetic data and real-world applications, further validate the benefits of causal exploration.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20503",
        "title": "A federated large language model for long-term time series forecasting",
        "abstract": "Long-term time series forecasting in centralized environments poses unique challenges regarding data privacy, communication overhead, and scalability. To address these challenges, we propose FedTime, a federated large language model (LLM) tailored for long-range time series prediction. Specifically, we introduce a federated pre-trained LLM with fine-tuning and alignment strategies. Prior to the learning process, we employ K-means clustering to partition edge devices or clients into distinct clusters, thereby facilitating more focused model training. We also incorporate channel independence and patching to better preserve local semantic information, ensuring that important contextual details are retained while minimizing the risk of information loss. We demonstrate the effectiveness of our FedTime model through extensive experiments on various real-world forecasting benchmarks, showcasing substantial improvements over recent approaches. In addition, we demonstrate the efficiency of FedTime in streamlining resource usage, resulting in reduced communication overhead.0",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20496",
        "title": "Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs",
        "abstract": "N:M sparsity pruning is a powerful technique for compressing deep neural networks, utilizing NVIDIA's Sparse Tensor Core technology. This method benefits from hardware support for sparse indexing, enabling the adoption of fine-grained sparsity to maintain model accuracy while minimizing the overhead typically associated with irregular data access. Although restricted to a fixed level of sparsity due to its reliance on hardware, N:M sparsity can be combined with coarser sparsity techniques to achieve diverse compression ratios. Initially, column-wise vector sparsity is applied to a dense model, followed by row-wise N:M sparsity on the preserved column vectors. We call this multi-level approach as hierarchical N:M (HiNM) sparsity. Similar to earlier single-level sparsity techniques, HiNM sparsity necessitates an effective channel permutation strategy to maximize the accuracy of the compressed networks. However, it introduces further complexities by requiring the rearrangement of both input and output channels, addressing challenges such as permutation sequence, HiNM-sparsity-aware permutation, and maintaining consistency in channel ordering across layers. In this paper, we introduce a channel permutation method designed specifically for HiNM sparsity, named gyro-permutation. This method is crafted to exploit the unique characteristics of HiNM pruning, incorporating a strategic policy in each permutation phase, including channel sampling, clustering, and assignment, to circumvent local minima. Additionally, we have developed a GPU kernel that facilitates independent layer permutation during the execution of HiNM sparse networks. Our extensive experimental evaluations on various DNN models demonstrate that our gyro-permutation significantly enhances the accuracy of HiNM sparse networks, allowing them to reach performance levels comparable to those of unstructured sparse networks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20466",
        "title": "A Method for Fast Autonomy Transfer in Reinforcement Learning",
        "abstract": "This paper introduces a novel reinforcement learning (RL) strategy designed to facilitate rapid autonomy transfer by utilizing pre-trained critic value functions from multiple environments. Unlike traditional methods that require extensive retraining or fine-tuning, our approach integrates existing knowledge, enabling an RL agent to adapt swiftly to new settings without requiring extensive computational resources. Our contributions include development of the Multi-Critic Actor-Critic (MCAC) algorithm, establishing its convergence, and empirical evidence demonstrating its efficacy. Our experimental results show that MCAC significantly outperforms the baseline actor-critic algorithm, achieving up to 22.76x faster autonomy transfer and higher reward accumulation. This advancement underscores the potential of leveraging accumulated knowledge for efficient adaptation in RL applications.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20445",
        "title": "Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation",
        "abstract": "Existing music captioning methods are limited to generating concise global descriptions of short music clips, which fail to capture fine-grained musical characteristics and time-aware musical changes. To address these limitations, we propose FUTGA, a model equipped with fined-grained music understanding capabilities through learning from generative augmentation with temporal compositions. We leverage existing music caption datasets and large language models (LLMs) to synthesize fine-grained music captions with structural descriptions and time boundaries for full-length songs. Augmented by the proposed synthetic dataset, FUTGA is enabled to identify the music's temporal changes at key transition points and their musical functions, as well as generate detailed descriptions for each music segment. We further introduce a full-length music caption dataset generated by FUTGA, as the augmentation of the MusicCaps and the Song Describer datasets. We evaluate the automatically generated captions on several downstream tasks, including music generation and retrieval. The experiments demonstrate the quality of the generated captions and the better performance in various downstream tasks achieved by the proposed music captioning approach. Our code and datasets can be found in \\href{this https URL}{\\textcolor{blue}{this https URL}}.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20438",
        "title": "Generating Gender Alternatives in Machine Translation",
        "abstract": "Machine translation (MT) systems often translate terms with ambiguous gender (e.g., English term \"the nurse\") into the gendered form that is most prevalent in the systems' training data (e.g., \"enfermera\", the Spanish term for a female nurse). This often reflects and perpetuates harmful stereotypes present in society. With MT user interfaces in mind that allow for resolving gender ambiguity in a frictionless manner, we study the problem of generating all grammatically correct gendered translation alternatives. We open source train and test datasets for five language pairs and establish benchmarks for this task. Our key technical contribution is a novel semi-supervised solution for generating alternatives that integrates seamlessly with standard MT models and maintains high performance without requiring additional components or increasing inference overhead.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20395",
        "title": "Dense Self-Supervised Learning for Medical Image Segmentation",
        "abstract": "Deep learning has revolutionized medical image segmentation, but it relies heavily on high-quality annotations. The time, cost and expertise required to label images at the pixel-level for each new task has slowed down widespread adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL) approach for few-shot segmentation, that reduces the manual annotation burden by learning powerful pixel-level representations directly from unlabeled images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for contrastive SSL on whole images. It is applied to generic encoder-decoder deep learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance of the learned image-level representations under intensity and spatial image augmentations, Pix2Rep enforces equivariance of the pixel-level representations. We demonstrate the framework on a task of cardiac MRI segmentation. Results show improved performance compared to existing semi- and self-supervised approaches; and a 5-fold reduction in the annotation burden for equivalent performance versus a fully supervised U-Net baseline. This includes a 30% (resp. 31%) DICE improvement for one-shot segmentation under linear-probing (resp. fine-tuning). Finally, we also integrate the novel Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even better segmentation performance.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20371",
        "title": "Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval",
        "abstract": "Artificial intelligence (AI) hiring tools have revolutionized resume screening, and large language models (LLMs) have the potential to do the same. However, given the biases which are embedded within LLMs, it is unclear whether they can be used in this scenario without disadvantaging groups based on their protected attributes. In this work, we investigate the possibilities of using LLMs in a resume screening setting via a document retrieval framework that simulates job candidate selection. Using that framework, we then perform a resume audit study to determine whether a selection of Massive Text Embedding (MTE) models are biased in resume screening scenarios. We simulate this for nine occupations, using a collection of over 500 publicly available resumes and 500 job descriptions. We find that the MTEs are biased, significantly favoring White-associated names in 85.1\\% of cases and female-associated names in only 11.1\\% of cases, with a minority of cases showing no statistically significant differences. Further analyses show that Black males are disadvantaged in up to 100\\% of cases, replicating real-world patterns of bias in employment settings, and validate three hypotheses of intersectionality. We also find an impact of document length as well as the corpus frequency of names in the selection of resumes. These findings have implications for widely used AI tools that are automating employment, fairness, and tech policy.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20351",
        "title": "LiteEFG: An Efficient Python Library for Solving Extensive-form Games",
        "abstract": "LiteEFG is an efficient library with easy-to-use Python bindings, which can solve multiplayer extensive-form games (EFGs). LiteEFG enables the user to express computation graphs in Python to define updates on the game tree structure. The graph is then executed by the C++ backend, leading to significant speedups compared to running the algorithm in Python. Moreover, in LiteEFG, the user needs to only specify the computation graph of the update rule in a decision node of the game, and LiteEFG will automatically distribute the update rule to each decision node and handle the structure of the imperfect-information game.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20341",
        "title": "BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues",
        "abstract": "Effectively aligning with human judgment when evaluating machine-generated image captions represents a complex yet intriguing challenge. Existing evaluation metrics like CIDEr or CLIP-Score fall short in this regard as they do not take into account the corresponding image or lack the capability of encoding fine-grained details and penalizing hallucinations. To overcome these issues, in this paper, we propose BRIDGE, a new learnable and reference-free image captioning metric that employs a novel module to map visual features into dense vectors and integrates them into multi-modal pseudo-captions which are built during the evaluation process. This approach results in a multimodal metric that properly incorporates information from the input image without relying on reference captions, bridging the gap between human judgment and machine-generated image captions. Experiments spanning several datasets demonstrate that our proposal achieves state-of-the-art results compared to existing reference-free evaluation scores. Our source code and trained models are publicly available at: this https URL.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20337",
        "title": "Contrasting Deepfakes Diffusion via Contrastive Learning and Global-Local Similarities",
        "abstract": "Discerning between authentic content and that generated by advanced AI methods has become increasingly challenging. While previous research primarily addresses the detection of fake faces, the identification of generated natural images has only recently surfaced. This prompted the recent exploration of solutions that employ foundation vision-and-language models, like CLIP. However, the CLIP embedding space is optimized for global image-to-text alignment and is not inherently designed for deepfake detection, neglecting the potential benefits of tailored training and local image features. In this study, we propose CoDE (Contrastive Deepfake Embeddings), a novel embedding space specifically designed for deepfake detection. CoDE is trained via contrastive learning by additionally enforcing global-local similarities. To sustain the training of our model, we generate a comprehensive dataset that focuses on images generated by diffusion models and encompasses a collection of 9.2 million images produced by using four different generators. Experimental results demonstrate that CoDE achieves state-of-the-art accuracy on the newly collected dataset, while also showing excellent generalization capabilities to unseen image generators. Our source code, trained models, and collected dataset are publicly available at: this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20301",
        "title": "Legal Aspects of Decentralized and Platform-Driven Economies",
        "abstract": "The sharing economy is sprawling across almost every sector and activity around the world. About a decade ago, there were only a handful of platform driven companies operating on the market. Zipcar, BlaBlaCar and Couchsurfing among them. Then Airbnb and Uber revolutionized the transportation and hospitality industries with a presence in virtually every major city. Access over ownership is the paradigm shift from the traditional business model that grants individuals the use of products or services without the necessity of buying them. Digital platforms, data and algorithm-driven companies as well as decentralized blockchain technologies have tremendous potential. But they are also changing the rules of the game. One of such technologies challenging the legal system are AI systems that will also reshape the current legal framework concerning the liability of operators, users and manufacturers. Therefore, this introductory chapter deals with explaining and describing the legal issues of some of these disruptive technologies. The chapter argues for a more forward-thinking and flexible regulatory structure.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20299",
        "title": "Dataset Distillation for Offline Reinforcement Learning",
        "abstract": "Offline reinforcement learning often requires a quality dataset that we can train a policy on. However, in many situations, it is not possible to get such a dataset, nor is it easy to train a policy to perform well in the actual environment given the offline data. We propose using data distillation to train and distill a better dataset which can then be used for training a better policy model. We show that our method is able to synthesize a dataset where a model trained on it achieves similar performance to a model trained on the full dataset or a model trained using percentile behavioral cloning. Our project site is available at this https URL. We also provide our implementation at this GitHub repository: this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20294",
        "title": "A Bayesian Flow Network Framework for Chemistry Tasks",
        "abstract": "In this work, we introduce ChemBFN, a language model that handles chemistry tasks based on Bayesian flow networks working on discrete data. A new accuracy schedule is proposed to improve the sampling quality by significantly reducing the reconstruction loss. We show evidence that our method is appropriate for generating molecules with satisfied diversity even when a smaller number of sampling steps is used. A classifier-free guidance method is adapted for conditional generation. It is also worthwhile to point out that after generative training, our model can be fine-tuned on regression and classification tasks with the state-of-the-art performance, which opens the gate of building all-in-one models in a single module style. Our model has been open sourced at this https URL.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20276",
        "title": "Assessing AI Rationality: The Random Guesser Test for Sequential Decision-Making Systems",
        "abstract": "We propose a general approach to quantitatively assessing the risk and vulnerability of artificial intelligence (AI) systems to biased decisions. The guiding principle of the proposed approach is that any AI algorithm must outperform a random guesser. This may appear trivial, but empirical results from a simplistic sequential decision-making scenario involving roulette games show that sophisticated AI-based approaches often underperform the random guesser by a significant margin. We highlight that modern recommender systems may exhibit a similar tendency to favor overly low-risk options. We argue that this \"random guesser test\" can serve as a useful tool for evaluating the rationality of AI actions, and also points towards increasing exploration as a potential improvement to such systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20274",
        "title": "Exploring the Plausibility of Hate and Counter Speech Detectors with Explainable AI",
        "abstract": "In this paper we investigate the explainability of transformer models and their plausibility for hate speech and counter speech detection. We compare representatives of four different explainability approaches, i.e., gradient-based, perturbation-based, attention-based, and prototype-based approaches, and analyze them quantitatively with an ablation study and qualitatively in a user study. Results show that perturbation-based explainability performs best, followed by gradient-based and attention-based explainability. Prototypebased experiments did not yield useful results. Overall, we observe that explainability strongly supports the users in better understanding the model predictions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20272",
        "title": "An Efficient Inference Framework for Early-exit Large Language Models",
        "abstract": "Building efficient inference framework has gained increasing interests for research community. Early-exit models, a variant of LLMs, improves the inference efficiency of LLMs by skipping rest layers and directly generate output tokens when they are confident enough. However, there is no work of LLM inference framework that takes early-exit models into consideration. This is non-trivial as prior art on LLM inference cannot be directly applied to early-exit models. In this work, we solves two key challenges in building efficient inference framework for early-exit models: (1) batch inference at iteration-level granularity; and (2) KV cache management. For the former, we propose to process the batch until all sequences surpass the early-exit confidence threshold. For the latter, we propose to fill the KV cache of rest layers before the iteration terminates. Our evaluation shows that, compared with the original vLLM operating at full layers, our solution achieves up to 1.25x speed up.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20271",
        "title": "Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models",
        "abstract": "Recent advancements in machine learning, especially in Natural Language Processing (NLP), have led to the development of sophisticated models trained on vast datasets, but this progress has raised concerns about potential sensitive information leakage. In response, regulatory measures like the EU General Data Protection Regulation (GDPR) have driven the exploration of Machine Unlearning techniques, which aim to enable models to selectively forget certain data entries. While early approaches focused on pre-processing methods, recent research has shifted towards training-based machine unlearning methods. However, many existing methods require access to original training data, posing challenges in scenarios where such data is unavailable. Besides, directly facilitating unlearning may undermine the language model's general expressive ability. To this end, in this paper, we introduce the Iterative Contrastive Unlearning (ICU) framework, which addresses these challenges by incorporating three key components. We propose a Knowledge Unlearning Induction module for unlearning specific target sequences and a Contrastive Learning Enhancement module to prevent degrading in generation capacity. Additionally, an Iterative Unlearning Refinement module is integrated to make the process more adaptive to each target sample respectively. Experimental results demonstrate the efficacy of ICU in maintaining performance while efficiently unlearning sensitive information, offering a promising avenue for privacy-conscious machine learning applications.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20267",
        "title": "A Large Encoder-Decoder Family of Foundation Models For Chemical Language",
        "abstract": "Large-scale pre-training methodologies for chemical language models represent a breakthrough in cheminformatics. These methods excel in tasks such as property prediction and molecule generation by learning contextualized representations of input tokens through self-supervised learning on large unlabeled corpora. Typically, this involves pre-training on unlabeled data followed by fine-tuning on specific tasks, reducing dependence on annotated datasets and broadening chemical language representation understanding. This paper introduces a large encoder-decoder chemical foundation models pre-trained on a curated dataset of 91 million SMILES samples sourced from PubChem, which is equivalent to 4 billion of molecular tokens. The proposed foundation model supports different complex tasks, including quantum property prediction, and offer flexibility with two main variants (289M and $8\\times289M$). Our experiments across multiple benchmark datasets validate the capacity of the proposed model in providing state-of-the-art results for different tasks. We also provide a preliminary assessment of the compositionality of the embedding space as a prerequisite for the reasoning tasks. We demonstrate that the produced latent space is separable compared to the state-of-the-art with few-shot learning capabilities.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20250",
        "title": "Riemannian Geometry-Based EEG Approaches: A Literature Review",
        "abstract": "The application of Riemannian geometry in the decoding of brain-computer interfaces (BCIs) has swiftly garnered attention because of its straightforwardness, precision, and resilience, along with its aptitude for transfer learning, which has been demonstrated through significant achievements in global BCI competitions. This paper presents a comprehensive review of recent advancements in the integration of deep learning with Riemannian geometry to enhance EEG signal decoding in BCIs. Our review updates the findings since the last major review in 2017, comparing modern approaches that utilize deep learning to improve the handling of non-Euclidean data structures inherent in EEG signals. We discuss how these approaches not only tackle the traditional challenges of noise sensitivity, non-stationarity, and lengthy calibration times but also introduce novel classification frameworks and signal processing techniques to reduce these limitations significantly. Furthermore, we identify current shortcomings and propose future research directions in manifold learning and riemannian-based classification, focusing on practical implementations and theoretical expansions, such as feature tracking on manifolds, multitask learning, feature extraction, and transfer learning. This review aims to bridge the gap between theoretical research and practical, real-world applications, making sophisticated mathematical approaches accessible and actionable for BCI enhancements.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20248",
        "title": "LAPIS: Language Model-Augmented Police Investigation System",
        "abstract": "Crime situations are race against time. An AI-assisted criminal investigation system, providing prompt but precise legal counsel is in need for police officers. We introduce LAPIS (Language Model Augmented Police Investigation System), an automated system that assists police officers to perform rational and legal investigative actions. We constructed a finetuning dataset and retrieval knowledgebase specialized in crime investigation legal reasoning task. We extended the dataset's quality by incorporating manual curation efforts done by a group of domain experts. We then finetuned the pretrained weights of a smaller Korean language model to the newly constructed dataset and integrated it with the crime investigation knowledgebase retrieval approach. Experimental results show LAPIS' potential in providing reliable legal guidance for police officers, even better than the proprietary GPT-4 model. Qualitative analysis on the rationales generated by LAPIS demonstrate the model's reasoning ability to leverage the premises and derive legally correct conclusions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20247",
        "title": "How Homogenizing the Channel-wise Magnitude Can Enhance EEG Classification Model?",
        "abstract": "A significant challenge in the electroencephalogram EEG lies in the fact that current data representations involve multiple electrode signals, resulting in data redundancy and dominant lead information. However extensive research conducted on EEG classification focuses on designing model architectures without tackling the underlying issues. Otherwise, there has been a notable gap in addressing data preprocessing for EEG, leading to considerable computational overhead in Deep Learning (DL) processes. In light of these issues, we propose a simple yet effective approach for EEG data pre-processing. Our method first transforms the EEG data into an encoded image by an Inverted Channel-wise Magnitude Homogenization (ICWMH) to mitigate inter-channel biases. Next, we apply the edge detection technique on the EEG-encoded image combined with skip connection to emphasize the most significant transitions in the data while preserving structural and invariant information. By doing so, we can improve the EEG learning process efficiently without using a huge DL network. Our experimental evaluations reveal that we can significantly improve (i.e., from 2% to 5%) over current baselines.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20244",
        "title": "Steamroller Problems: An Evaluation of LLM Reasoning Capability with Automated Theorem Prover Strategies",
        "abstract": "This study presents the first examination of the ability of Large Language Models (LLMs) to follow reasoning strategies that are used to guide Automated Theorem Provers (ATPs). We evaluate the performance of GPT4, GPT3.5 Turbo and Google's recent Gemini model on problems from a steamroller domain. In addition to determining accuracy we make use of the Natural Language Processing library spaCy to explore new methods of investigating LLM's reasoning capabilities. This led to one alarming result, the low correlation between correct reasoning and correct answers for any of the tested models. We found that the models' performance when using the ATP reasoning strategies was comparable to one-shot chain of thought and observe that attention to uncertainty in the accuracy results is critical when drawing conclusions about model performance. Consistent with previous speculation we confirm that LLMs have a preference for, and are best able to follow, bottom up reasoning processes. However, the reasoning strategies can still be beneficial for deriving small and relevant sets of formulas for external processing by a trusted inference engine.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20743",
        "title": "Meltemi: The first open Large Language Model for Greek",
        "abstract": "We describe the development and capabilities of Meltemi 7B, the first open Large Language Model for the Greek language. Meltemi 7B has 7 billion parameters and is trained on a 40 billion token Greek corpus. For the development of Meltemi 7B, we adapt Mistral, by continuous pretraining on the Greek Corpus. Meltemi 7B contains upto-date information up to September 2023. Furthermore, we have translated and curated a Greek instruction corpus, which has been used for the instruction-tuning of a chat model, named Meltemi 7B Instruct. Special care has been given to the alignment and the removal of toxic content for the Meltemi 7B Instruct. The developed models are evaluated on a broad set of collected evaluation corpora, and examples of prompts and responses are presented. Both Meltemi 7B and Meltemi 7B Instruct are available 1 under the Apache 2.0 license.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20729",
        "title": "Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework",
        "abstract": "As large language models (LLMs) become increasingly integrated into operational workflows (LLM-Ops), there is a pressing need for effective guardrails to ensure safe and aligned interactions, including the ability to detect potentially unsafe or inappropriate content across languages. However, existing safe-for-work classifiers are primarily focused on English text. To address this gap for the Malaysian language, we present a novel safe-for-work text classifier tailored specifically for Malaysian language content. By curating and annotating a first-of-its-kind dataset of Malaysian text spanning multiple content categories, we trained a classification model capable of identifying potentially unsafe material using state-of-the-art natural language processing techniques. This work represents an important step in enabling safer interactions and content filtering to mitigate potential risks and ensure responsible deployment of LLMs. To maximize accessibility and promote further research towards enhancing alignment in LLM-Ops for the Malaysian context, the model is publicly released at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20663",
        "title": "ArabicNLU 2024: The First Arabic Natural Language Understanding Shared Task",
        "abstract": "This paper presents an overview of the Arabic Natural Language Understanding (ArabicNLU 2024) shared task, focusing on two subtasks: Word Sense Disambiguation (WSD) and Location Mention Disambiguation (LMD). The task aimed to evaluate the ability of automated systems to resolve word ambiguity and identify locations mentioned in Arabic text. We provided participants with novel datasets, including a sense-annotated corpus for WSD, called SALMA with approximately 34k annotated tokens, and the IDRISI-DA dataset with 3,893 annotations and 763 unique location mentions. These are challenging tasks. Out of the 38 registered teams, only three teams participated in the final evaluation phase, with the highest accuracy being 77.8% for WSD and the highest MRR@1 being 95.0% for LMD. The shared task not only facilitated the evaluation and comparison of different techniques, but also provided valuable insights and resources for the continued advancement of Arabic NLU technologies.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20564",
        "title": "CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge",
        "abstract": "While large language models (LLMs) have demonstrated impressive capabilities across various natural language processing tasks by acquiring rich factual knowledge from their broad training data, their ability to synthesize and logically reason with this knowledge in complex ways remains underexplored. In this work, we present a systematic evaluation of state-of-the-art LLMs' complex logical reasoning abilities through a novel benchmark of automatically generated complex reasoning questions over general domain and biomedical knowledge graphs. Our extensive experiments, employing diverse in-context learning techniques, reveal that LLMs excel at reasoning over general world knowledge but face significant challenges with specialized domain-specific knowledge. We find that prompting with explicit Chain-of-Thought demonstrations can substantially improve LLM performance on complex logical reasoning tasks with diverse logical operations. Interestingly, our controlled evaluations uncover an asymmetry where LLMs display proficiency at set union operations, but struggle considerably with set intersections - a key building block of logical reasoning. To foster further work, we will publicly release our evaluation benchmark and code.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.20756",
        "title": "SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models",
        "abstract": "Recently, with the rise of web images, managing and understanding large-scale image datasets has become increasingly important. Vision Large Language Models (VLLMs) have recently emerged due to their robust vision-understanding capabilities. However, training these models requires vast amounts of data, posing challenges to efficiency, effectiveness, data quality, and privacy. In this paper, we introduce SynthVLM, a novel data synthesis pipeline for VLLMs. Unlike existing methods that generate captions from images, SynthVLM employs advanced diffusion models and high-quality captions to automatically generate and select high-resolution images from captions, creating precisely aligned image-text pairs. Leveraging these pairs, we achieve state-of-the-art (SoTA) performance on various vision question answering tasks, maintaining high alignment quality and preserving advanced language abilities. Moreover, SynthVLM surpasses traditional GPT-4 Vision-based caption generation methods in performance while significantly reducing computational overhead. Crucially, our method's reliance on purely generated data ensures the preservation of privacy, achieving SoTA performance with just 100k data points (only 18% of the official dataset size).",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20595",
        "title": "Harvesting Textual and Structured Data from the HAL Publication Repository",
        "abstract": "HAL (Hyper Articles en Ligne) is the French national publication repository, used by most higher education and research organizations for their open science policy. As a digital library, it is a rich repository of scholarly documents, but its potential for advanced research has been underutilized. We present HALvest, a unique dataset that bridges the gap between citation networks and the full text of papers submitted on HAL. We craft our dataset by filtering HAL for scholarly publications, resulting in approximately 700,000 documents, spanning 34 languages across 13 identified domains, suitable for language model training, and yielding approximately 16.5 billion tokens (with 8 billion in French and 7 billion in English, the most represented languages). We transform the metadata of each paper into a citation network, producing a directed heterogeneous graph. This graph includes uniquely identified authors on HAL, as well as all open submitted papers, and their citations. We provide a baseline for authorship attribution using the dataset, implement a range of state-of-the-art models in graph representation learning for link prediction, and discuss the usefulness of our generated knowledge graph structure.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.21016",
        "title": "Add-SD: Rational Generation without Manual Reference",
        "abstract": "Diffusion models have exhibited remarkable prowess in visual generalization. Building on this success, we introduce an instruction-based object addition pipeline, named Add-SD, which automatically inserts objects into realistic scenes with rational sizes and positions. Different from layout-conditioned methods, Add-SD is solely conditioned on simple text prompts rather than any other human-costly references like bounding boxes. Our work contributes in three aspects: proposing a dataset containing numerous instructed image pairs; fine-tuning a diffusion model for rational generation; and generating synthetic data to boost downstream tasks. The first aspect involves creating a RemovalDataset consisting of original-edited image pairs with textual instructions, where an object has been removed from the original image while maintaining strong pixel consistency in the background. These data pairs are then used for fine-tuning the Stable Diffusion (SD) model. Subsequently, the pretrained Add-SD model allows for the insertion of expected objects into an image with good rationale. Additionally, we generate synthetic instances for downstream task datasets at scale, particularly for tail classes, to alleviate the long-tailed problem. Downstream tasks benefit from the enriched dataset with enhanced diversity and rationale. Experiments on LVIS val demonstrate that Add-SD yields an improvement of 4.3 mAP on rare classes over the baseline. Code and models are available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20987",
        "title": "PIXELMOD: Improving Soft Moderation of Visual Misleading Information on Twitter",
        "abstract": "Images are a powerful and immediate vehicle to carry misleading or outright false messages, yet identifying image-based misinformation at scale poses unique challenges. In this paper, we present PIXELMOD, a system that leverages perceptual hashes, vector databases, and optical character recognition (OCR) to efficiently identify images that are candidates to receive soft moderation labels on Twitter. We show that PIXELMOD outperforms existing image similarity approaches when applied to soft moderation, with negligible performance overhead. We then test PIXELMOD on a dataset of tweets surrounding the 2020 US Presidential Election, and find that it is able to identify visually misleading images that are candidates for soft moderation with 0.99% false detection and 2.06% false negatives.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20962",
        "title": "MMTrail: A Multimodal Trailer Video Dataset with Language and Music Descriptions",
        "abstract": "Massive multi-modality datasets play a significant role in facilitating the success of large video-language models. However, current video-language datasets primarily provide text descriptions for visual frames, considering audio to be weakly related information. They usually overlook exploring the potential of inherent audio-visual correlation, leading to monotonous annotation within each modality instead of comprehensive and precise descriptions. Such ignorance results in the difficulty of multiple cross-modality studies. To fulfill this gap, we present MMTrail, a large-scale multi-modality video-language dataset incorporating more than 20M trailer clips with visual captions, and 2M high-quality clips with multimodal captions. Trailers preview full-length video works and integrate context, visual frames, and background music. In particular, the trailer has two main advantages: (1) the topics are diverse, and the content characters are of various types, e.g., film, news, and gaming. (2) the corresponding background music is custom-designed, making it more coherent with the visual context. Upon these insights, we propose a systemic captioning framework, achieving various modality annotations with more than 27.1k hours of trailer videos. Here, to ensure the caption retains music perspective while preserving the authority of visual context, we leverage the advanced LLM to merge all annotations adaptively. In this fashion, our MMtrail dataset potentially paves the path for fine-grained large multimodal-language model training. In experiments, we provide evaluation metrics and benchmark results on our dataset, demonstrating the high quality of our annotation and its effectiveness for model training.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20950",
        "title": "dopanim: A Dataset of Doppelganger Animals with Noisy Annotations from Multiple Humans",
        "abstract": "Human annotators typically provide annotated data for training machine learning models, such as neural networks. Yet, human annotations are subject to noise, impairing generalization performances. Methodological research on approaches counteracting noisy annotations requires corresponding datasets for a meaningful empirical evaluation. Consequently, we introduce a novel benchmark dataset, dopanim, consisting of about 15,750 animal images of 15 classes with ground truth labels. For approximately 10,500 of these images, 20 humans provided over 52,000 annotations with an accuracy of circa 67%. Its key attributes include (1) the challenging task of classifying doppelganger animals, (2) human-estimated likelihoods as annotations, and (3) annotator metadata. We benchmark well-known multi-annotator learning approaches using seven variants of this dataset and outline further evaluation use cases such as learning beyond hard class labels and active learning. Our dataset and a comprehensive codebase are publicly available to emulate the data collection process and to reproduce all empirical results.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20845",
        "title": "Assessing Graphical Perception of Image Embedding Models using Channel Effectiveness",
        "abstract": "Recent advancements in vision models have greatly improved their ability to handle complex chart understanding tasks, like chart captioning and question answering. However, it remains challenging to assess how these models process charts. Existing benchmarks only roughly evaluate model performance without evaluating the underlying mechanisms, such as how models extract image embeddings. This limits our understanding of the model's ability to perceive fundamental graphical components. To address this, we introduce a novel evaluation framework to assess the graphical perception of image embedding models. For chart comprehension, we examine two main aspects of channel effectiveness: accuracy and discriminability of various visual channels. Channel accuracy is assessed through the linearity of embeddings, measuring how well the perceived magnitude aligns with the size of the stimulus. Discriminability is evaluated based on the distances between embeddings, indicating their distinctness. Our experiments with the CLIP model show that it perceives channel accuracy differently from humans and shows unique discriminability in channels like length, tilt, and curvature. We aim to develop this work into a broader benchmark for reliable visual encoders, enhancing models for precise chart comprehension and human-like perception in future applications.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20818",
        "title": "WARM-3D: A Weakly-Supervised Sim2Real Domain Adaptation Framework for Roadside Monocular 3D Object Detection",
        "abstract": "Existing roadside perception systems are limited by the absence of publicly available, large-scale, high-quality 3D datasets. Exploring the use of cost-effective, extensive synthetic datasets offers a viable solution to tackle this challenge and enhance the performance of roadside monocular 3D detection. In this study, we introduce the TUMTraf Synthetic Dataset, offering a diverse and substantial collection of high-quality 3D data to augment scarce real-world datasets. Besides, we present WARM-3D, a concise yet effective framework to aid the Sim2Real domain transfer for roadside monocular 3D detection. Our method leverages cheap synthetic datasets and 2D labels from an off-the-shelf 2D detector for weak supervision. We show that WARM-3D significantly enhances performance, achieving a +12.40% increase in mAP 3D over the baseline with only pseudo-2D supervision. With 2D GT as weak labels, WARM-3D even reaches performance close to the Oracle baseline. Moreover, WARM-3D improves the ability of 3D detectors to unseen sample recognition across various real-world environments, highlighting its potential for practical applications.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20664",
        "title": "3D-GRES: Generalized 3D Referring Expression Segmentation",
        "abstract": "3D Referring Expression Segmentation (3D-RES) is dedicated to segmenting a specific instance within a 3D space based on a natural language description. However, current approaches are limited to segmenting a single target, restricting the versatility of the task. To overcome this limitation, we introduce Generalized 3D Referring Expression Segmentation (3D-GRES), which extends the capability to segment any number of instances based on natural language instructions. In addressing this broader task, we propose the Multi-Query Decoupled Interaction Network (MDIN), designed to break down multi-object segmentation tasks into simpler, individual segmentations. MDIN comprises two fundamental components: Text-driven Sparse Queries (TSQ) and Multi-object Decoupling Optimization (MDO). TSQ generates sparse point cloud features distributed over key targets as the initialization for queries. Meanwhile, MDO is tasked with assigning each target in multi-object scenarios to different queries while maintaining their semantic consistency. To adapt to this new task, we build a new dataset, namely Multi3DRes. Our comprehensive evaluations on this dataset demonstrate substantial enhancements over existing models, thus charting a new path for intricate multi-object 3D scene comprehension. The benchmark and code are available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20662",
        "title": "DocXPand-25k: a large and diverse benchmark dataset for identity documents analysis",
        "abstract": "Identity document (ID) image analysis has become essential for many online services, like bank account opening or insurance subscription. In recent years, much research has been conducted on subjects like document localization, text recognition and fraud detection, to achieve a level of accuracy reliable enough to automatize identity verification. However, there are only a few available datasets to benchmark ID analysis methods, mainly because of privacy restrictions, security requirements and legal reasons.\n In this paper, we present the DocXPand-25k dataset, which consists of 24,994 richly labeled IDs images, generated using custom-made vectorial templates representing nine fictitious ID designs, including four identity cards, two residence permits and three passports designs. These synthetic IDs feature artificially generated personal information (names, dates, identifiers, faces, barcodes, ...), and present a rich diversity in the visual layouts and textual contents.\n We collected about 5.8k diverse backgrounds coming from real-world photos, scans and screenshots of IDs to guarantee the variety of the backgrounds. The software we wrote to generate these images has been published (this https URL) under the terms of the MIT license, and our dataset has been published (this https URL) under the terms of the CC-BY-NC-SA 4.0 License.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20643",
        "title": "Generalizing AI-driven Assessment of Immunohistochemistry across Immunostains and Cancer Types: A Universal Immunohistochemistry Analyzer",
        "abstract": "Despite advancements in methodologies, immunohistochemistry (IHC) remains the most utilized ancillary test for histopathologic and companion diagnostics in targeted therapies. However, objective IHC assessment poses challenges. Artificial intelligence (AI) has emerged as a potential solution, yet its development requires extensive training for each cancer and IHC type, limiting versatility. We developed a Universal IHC (UIHC) analyzer, an AI model for interpreting IHC images regardless of tumor or IHC types, using training datasets from various cancers stained for PD-L1 and/or HER2. This multi-cohort trained model outperforms conventional single-cohort models in interpreting unseen IHCs (Kappa score 0.578 vs. up to 0.509) and consistently shows superior performance across different positive staining cutoff values. Qualitative analysis reveals that UIHC effectively clusters patches based on expression levels. The UIHC model also quantitatively assesses c-MET expression with MET mutations, representing a significant advancement in AI application in the era of personalized medicine and accumulating novel biomarkers.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20623",
        "title": "SharkTrack: an accurate, generalisable software for streamlining shark and ray underwater video analysis",
        "abstract": "Elasmobranchs (sharks and rays) can be important components of marine ecosystems but are experiencing global population declines. Effective monitoring of these populations is essential to their protection. Baited Remote Underwater Video Stations (BRUVS) have been a key tool for monitoring, but require time-consuming manual analysis. To address these challenges, we developed SharkTrack, an AI-enhanced BRUVS analysis software. SharkTrack uses Convolutional Neural Networks and Multi-Object Tracking to detect and track elasmobranchs and provides an annotation pipeline to manually classify elasmobranch species and compute MaxN, the standard metric of relative abundance. We tested SharkTrack on BRUVS footage from locations unseen by the model during training. SharkTrack computed MaxN with 89% accuracy over 207 hours of footage. The semi-automatic SharkTrack pipeline required two minutes of manual classification per hour of video, a 97% reduction of manual BRUVS analysis time compared to traditional methods, estimated conservatively at one hour per hour of video. Furthermore, we demonstrate SharkTrack application across diverse marine ecosystems and elasmobranch species, an advancement compared to previous models, which were limited to specific species or locations. SharkTrack applications extend beyond BRUVS analysis, facilitating rapid annotation of unlabeled videos, aiding the development of further models to classify elasmobranch species. We provide public access to the software and an unprecedentedly diverse dataset, facilitating future research in an important area of marine conservation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20566",
        "title": "Monocular Human-Object Reconstruction in the Wild",
        "abstract": "Learning the prior knowledge of the 3D human-object spatial relation is crucial for reconstructing human-object interaction from images and understanding how humans interact with objects in 3D space. Previous works learn this prior from datasets collected in controlled environments, but due to the diversity of domains, they struggle to generalize to real-world scenarios. To overcome this limitation, we present a 2D-supervised method that learns the 3D human-object spatial relation prior purely from 2D images in the wild. Our method utilizes a flow-based neural network to learn the prior distribution of the 2D human-object keypoint layout and viewports for each image in the dataset. The effectiveness of the prior learned from 2D images is demonstrated on the human-object reconstruction task by applying the prior to tune the relative pose between the human and the object during the post-optimization stage. To validate and benchmark our method on in-the-wild images, we collect the WildHOI dataset from the YouTube website, which consists of various interactions with 8 objects in real-world scenarios. We conduct the experiments on the indoor BEHAVE dataset and the outdoor WildHOI dataset. The results show that our method achieves almost comparable performance with fully 3D supervised methods on the BEHAVE dataset, even if we have only utilized the 2D layout information, and outperforms previous methods in terms of generality and interaction diversity on in-the-wild images.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20502",
        "title": "Restoring Real-World Degraded Events Improves Deblurring Quality",
        "abstract": "Due to its high speed and low latency, DVS is frequently employed in motion deblurring. Ideally, high-quality events would adeptly capture intricate motion information. However, real-world events are generally degraded, thereby introducing significant artifacts into the deblurred results. In response to this challenge, we model the degradation of events and propose RDNet to improve the quality of image deblurring. Specifically, we first analyze the mechanisms underlying degradation and simulate paired events based on that. These paired events are then fed into the first stage of the RDNet for training the restoration model. The events restored in this stage serve as a guide for the second-stage deblurring process. To better assess the deblurring performance of different methods on real-world degraded events, we present a new real-world dataset named DavisMCR. This dataset incorporates events with diverse degradation levels, collected by manipulating environmental brightness and target object contrast. Our experiments are conducted on synthetic datasets (GOPRO), real-world datasets (REBlur), and the proposed dataset (DavisMCR). The results demonstrate that RDNet outperforms classical event denoising methods in event restoration. Furthermore, RDNet exhibits better performance in deblurring tasks compared to state-of-the-art methods. DavisMCR are available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20372",
        "title": "A Model Generalization Study in Localizing Indoor Cows with COw LOcalization (COLO) dataset",
        "abstract": "Precision livestock farming (PLF) increasingly relies on advanced object localization techniques to monitor livestock health and optimize resource management. This study investigates the generalization capabilities of YOLOv8 and YOLOv9 models for cow detection in indoor free-stall barn settings, focusing on varying training data characteristics such as view angles and lighting, and model complexities. Leveraging the newly released public dataset, COws LOcalization (COLO) dataset, we explore three key hypotheses: (1) Model generalization is equally influenced by changes in lighting conditions and camera angles; (2) Higher model complexity guarantees better generalization performance; (3) Fine-tuning with custom initial weights trained on relevant tasks always brings advantages to detection tasks. Our findings reveal considerable challenges in detecting cows in images taken from side views and underscore the importance of including diverse camera angles in building a detection model. Furthermore, our results emphasize that higher model complexity does not necessarily lead to better performance. The optimal model configuration heavily depends on the specific task and dataset. Lastly, while fine-tuning with custom initial weights trained on relevant tasks offers advantages to detection tasks, simpler models do not benefit similarly from this approach. It is more efficient to train a simple model with pre-trained weights without relying on prior relevant information, which can require intensive labor efforts. Future work should focus on adaptive methods and advanced data augmentation to improve generalization and robustness. This study provides practical guidelines for PLF researchers on deploying computer vision models from existing studies, highlights generalization issues, and contributes the COLO dataset containing 1254 images and 11818 cow instances for further research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20868",
        "title": "A Comparative Study of Neural Surface Reconstruction for Scientific Visualization",
        "abstract": "This comparative study evaluates various neural surface reconstruction methods, particularly focusing on their implications for scientific visualization through reconstructing 3D surfaces via multi-view rendering images. We categorize ten methods into neural radiance fields and neural implicit surfaces, uncovering the benefits of leveraging distance functions (i.e., SDFs and UDFs) to enhance the accuracy and smoothness of the reconstructed surfaces. Our findings highlight the efficiency and quality of NeuS2 for reconstructing closed surfaces and identify NeUDF as a promising candidate for reconstructing open surfaces despite some limitations. By sharing our benchmark dataset, we invite researchers to test the performance of their methods, contributing to the advancement of surface reconstruction solutions for scientific visualization.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20495",
        "title": "Enhancing Quantitative Image Synthesis through Pretraining and Resolution Scaling for Bone Mineral Density Estimation from a Plain X-ray Image",
        "abstract": "While most vision tasks are essentially visual in nature (for recognition), some important tasks, especially in the medical field, also require quantitative analysis (for quantification) using quantitative images. Unlike in visual analysis, pixel values in quantitative images correspond to physical metrics measured by specific devices (e.g., a depth image). However, recent work has shown that it is sometimes possible to synthesize accurate quantitative values from visual ones (e.g., depth from visual cues or defocus). This research aims to improve quantitative image synthesis (QIS) by exploring pretraining and image resolution scaling. We propose a benchmark for evaluating pretraining performance using the task of QIS-based bone mineral density (BMD) estimation from plain X-ray images, where the synthesized quantitative image is used to derive BMD. Our results show that appropriate pretraining can improve QIS performance, significantly raising the correlation of BMD estimation from 0.820 to 0.898, while others do not help or even hinder it. Scaling-up the resolution can further boost the correlation up to 0.923, a significant enhancement over conventional methods. Future work will include exploring more pretraining strategies and validating them on other image synthesis tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.20387",
        "title": "Two-Phase Segmentation Approach for Accurate Left Ventricle Segmentation in Cardiac MRI using Machine Learning",
        "abstract": "Accurate segmentation of the Left Ventricle (LV) holds substantial importance due to its implications in disease detection, regional analysis, and the development of complex models for cardiac surgical planning. CMR is a golden standard for diagnosis of serveral cardiac diseases. LV in CMR comprises of three distinct sections: Basal, Mid-Ventricle, and Apical. This research focuses on the precise segmentation of the LV from Cardiac MRI (CMR) scans, joining with the capabilities of Machine Learning (ML). The central challenge in this research revolves around the absence of a set of parameters applicable to all three types of LV slices. Parameters optimized for basal slices often fall short when applied to mid-ventricular and apical slices, and vice versa. To handle this issue, a new method is proposed to enhance LV segmentation. The proposed method involves using distinct sets of parameters for each type of slice, resulting in a two-phase segmentation approach. The initial phase categorizes images into three groups based on the type of LV slice, while the second phase aims to segment CMR images using parameters derived from the preceding phase. A publicly available dataset (Automated Cardiac Diagnosis Challenge (ACDC)) is used. 10-Fold Cross Validation is used and it achieved a mean score of 0.9228. Comprehensive testing indicates that the best parameter set for a particular type of slice does not perform adequately for the other slice types. All results show that the proposed approach fills a critical void in parameter standardization through a two-phase segmentation model for the LV, aiming to not only improve the accuracy of cardiac image analysis but also contribute advancements to the field of LV segmentation.",
        "label": 0
    }
]