[
    {
        "url": "https://arxiv.org/pdf/2406.08920",
        "label": 0,
        "title": "a v-gs: learning material and geometry aware priors for novel view acoustic synthesis swapnil bhosale",
        "abstract": "novel view acoustic synthesis (nv as) aims to render binaural audio at any target viewpoint, given a mono audio emitted by a sound source at a 3d scene. existing methods have proposed nerf-based implicit models to exploit visual cues as a condition for synthesizing binaural audio. however, in addition to low efficiency originating from heavy nerf rendering, these methods all have a limited ability of characterizing the entire scene environment such as room geometry, material prop- erties, and the spatial relation between the listener and sound source. to address these issues, we propose a novel audio-visual gaussian splatting (a v-gs) model. to obtain a material-aware and geometry-aware condition for audio synthesis, we learn an explicit point-based scene representation with an audio-guidance param- eter on locally initialized gaussian points, taking into account the space relation from the listener and sound source. to make the visual scene model audio adaptive, we propose a point densification and pruning strategy to optimally distribute the gaussian points, with the per-point contribution in sound propagation (e.g., more points needed for texture-less wall surfaces as they affect sound path diversion). extensive experiments validate the superiority of our a v-gs over existing alterna- tives on the real-world rwas and simulation-based soundspaces datasets. project page: https://surrey-uplab.github.io/research/avgs/ "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09021",
        "label": 0,
        "title": "contextual distillation model for diversified recommendation fan li",
        "abstract": "the diversity of recommendation is equally crucial as accuracy in improving user experience. existing studies, e.g., determinantal point process (dpp) and maximal marginal relevance (mmr), em- ploy a greedy paradigm to iteratively select items that optimize both accuracy and diversity. however, prior methods typically exhibit quadratic complexity, limiting their applications to the re-ranking stage and are not applicable to other recommendation stages with a larger pool of candidate items, such as the pre-ranking andranking stages. in this paper, we propose contextual distillation model (cdm), an efficient recommendation model that addresses diver- sification, suitable for the deployment in all stages of industrial recommendation pipelines. specifically, cdm utilizes the candidate items in the same user request as context to enhance the diversifi- cation of the results. we propose a contrastive context encoder that employs attention mechanisms to model both positive and negative contexts. for the training of cdm, we compare each target item with its context embedding and utilize the knowledge distillation framework to learn the win probability of each target item under the mmr algorithm, where the teacher is derived from mmr outputs. during inference, ranking is performed through a linear combina- tion of the recommendation and student model scores, ensuring both diversity and efficiency. we perform offline evaluations on two industrial datasets and conduct online a/btest of cdm on the short-video platform kuaishou . the considerable enhancements \u2217equal contributions. \u2020corresponding author. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than the author(s) must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. kdd \u201924, august 25\u201329, 2024, barcelona, spain \u00a92024 copyright held by the owner/author(s). publication rights licensed to acm. acm isbn 979-8-4007-0490-1/24/08. . . $15.00 https://doi.org/10.1145/3637528.3671514observed in both recommendation quality and diversity, as shown by metrics, provide strong superiority for the effectiveness of cdm. ccs concepts \u2022information systems \u2192recommender systems . keywords recommender system, knowledge distillation, diversified recom- mendation acm reference format: fan li, xu si, shisong tang, dingmin wang, kunyan han, bing han, guorui zhou, yang song, and hechang chen. 2024. contextual distillation model for diversified recommendation. in proceedings of the 30th acm sigkdd conference on knowledge discovery and data mining (kdd \u201924), august 25\u201329, 2024, barcelona, spain. acm, new york, ny, usa, 10 pages. https: //doi.org/10.1145/3637528.3671514 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09215",
        "label": 0,
        "title": "on softmax direct preference optimization for recommendation yuxin chen1",
        "abstract": "recommender systems aim to predict personalized rankings based on user pref- erence data. with the rise of language models (lms), lm-based recommenders have been widely explored due to their extensive world knowledge and power- ful reasoning abilities. most of the lm-based recommenders convert historical interactions into language prompts, pairing with a positive item as the target re- sponse and fine-tuning lm with a language modeling loss. however, the current objective fails to fully leverage preference data and is not optimized for personal- ized ranking tasks, which hinders the performance of lm-based recommenders. inspired by the current advancement of direct preference optimization (dpo) in human preference alignment and the success of softmax loss in recommenda- tions, we propose softmax-dpo ( s-dpo ) to instill ranking information into the lm to help lm-based recommenders distinguish preferred items from negatives, rather than solely focusing on positives. specifically, we incorporate multiple negatives in user preference data and devise an alternative version of dpo loss tailored for lm-based recommenders, connected to softmax sampling strategies. theoretically, we bridge s-dpo with the softmax loss over negative sampling and find that it has a side effect of mining hard negatives, which assures its excep- tional capabilities in recommendation tasks. empirically, extensive experiments conducted on three real-world datasets demonstrate the superiority of s-dpo to effectively model user preference and further boost recommendation performance while mitigating the data likelihood decline issue of dpo. our codes are available athttps://github.com/chenyuxin1999/s-dpo . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08587",
        "label": 1,
        "title": "cs-bench: a comprehensive benchmark for large language models towards computer science mastery xiaoshuai song",
        "abstract": "computer science (cs) stands as a testament to the intricacies of human intelli- gence, profoundly advancing the development of artificial intelligence and modern society. however, the current community of large language models (llms) overly focuses on benchmarks for analyzing specific foundational skills (e.g. mathematics and code generation), neglecting an all-round evaluation of the computer science field. to bridge this gap, we introduce cs-bench, the first bilingual (chinese- english) benchmark dedicated to evaluating the performance of llms in computer science. cs-bench comprises approximately 5k meticulously curated test samples, covering 26 subfields across 4 key areas of computer science, encompassing var- ious task forms and divisions of knowledge and reasoning. utilizing cs-bench, we conduct a comprehensive evaluation of over 30 mainstream llms, revealing the relationship between cs performance and model scales. we also quantita- tively analyze the reasons for failures in existing llms and highlight directions for improvements, including knowledge supplementation and cs-specific reason- ing. further cross-capability experiments show a high correlation between llms\u2019 capabilities in computer science and their abilities in mathematics and coding. moreover, expert llms specialized in mathematics and coding also demonstrate strong performances in several cs subfields. looking ahead, we envision cs- bench serving as a cornerstone for llm applications in the cs field and paving new avenues in assessing llms\u2019 diverse reasoning capabilities. the cs-bench data and evaluation code are available at https://github.com/csbench/csbench. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08973",
        "label": 1,
        "title": "xland-100b: a large-scale multi-task dataset for in-context reinforcement learning alexander nikulin",
        "abstract": "following the success of the in-context learning paradigm in large-scale language and computer vision models, the recently emerging field of in-context reinforce- ment learning is experiencing a rapid growth. however, its development has been held back by the lack of challenging benchmarks, as all the experiments have been carried out in simple environments and on small-scale datasets. we present xland-100b , a large-scale dataset for in-context reinforcement learning based on the xland-minigrid environment, as a first step to alleviate this prob- lem. it contains complete learning histories for nearly 30,000different tasks, covering 100b transitions and 2.5b episodes. it took 50,000gpu hours to col- lect the dataset, which is beyond the reach of most academic labs. along with the dataset, we provide the utilities to reproduce or expand it even further. with this substantial effort, we aim to democratize research in the rapidly growing field of in-context reinforcement learning and provide a solid foundation for fur- ther scaling. the code is open-source and available under apache 2.0 licence at https://github.com/dunno-lab/xland-minigrid-datasets . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08598",
        "label": 1,
        "title": "language model council: benchmarking foundation models on highly subjective tasks by consensus justin zhao1",
        "abstract": "the rapid advancement of large language models (llms) necessitates robust and challenging benchmarks. leaderboards like chatbot arena rank llms based on how well their responses align with human preferences. however, many tasks such as those related to emotional intelligence, creative writing, or persuasiveness, are highly subjective and often lack majoritarian human agreement. judges may have irreconcilable disagreements about what constitutes a better response. to address the challenge of ranking llms on highly subjective tasks, we propose a novel benchmarking framework, the language model council (lmc) . the lmc operates through a democratic process to: 1) formulate a test set through equal participation, 2) administer the test among council members, and 3) evaluate responses as a collective jury. we deploy a council of 20 newest llms on an open-ended emotional intelligence task: responding to interpersonal dilemmas. our results show that the lmc produces rankings that are more separable, robust, and less biased than those from any individual llm judge, and is more consistent with a human-established leaderboard compared to other benchmarks. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08979",
        "label": 1,
        "title": "multi-agent software development through cross-team collaboration zhuoyun du\u2020\u2663chen qian\u2020",
        "abstract": "the latest breakthroughs in large language models (llms), e.g., chatdev, have catalyzed profound transformations, particularly through multi-agent collaboration for software devel- opment. llm agents can collaborate in teams like humans, and follow the waterfall model to sequentially work on requirements analysis, development, review, testing, and other phases to perform autonomous software generation. however, for an agent team, each phase in a single development process yields only one pos- sible outcome. this results in the completion of only one development chain, thereby losing the opportunity to explore multiple potential decision paths within the solution space. con- sequently, this may lead to obtaining subop- timal results. to address this challenge, we introduce cross-teamcollaboration (ctc), a scalable multi-team framework that enables orchestrated teams to jointly propose various decisions and communicate with their insights in a cross-team collaboration environment for superior content generation. experimental re- sults in software development reveal a notable increase in quality compared to state-of-the- art baselines, underscoring the efficacy of our framework. the significant improvements in story generation demonstrate the promising generalization ability of our framework across various domains. we anticipate that our work will guide llm agents towards a cross-team paradigm and contribute to their significant growth in but not limited to software devel- opment. the code and data will be available at https://github.com/openbmb/chatdev . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09043",
        "label": 0,
        "title": "language models are crossword solvers soumadeep saha and sutanoya chakraborty and saptarshi saha and utpal gar",
        "abstract": "crosswords are a form of word puzzle that re- quire a solver to demonstrate a high degree of proficiency in natural language understand- ing, wordplay, reasoning, and world knowl- edge, along with adherence to character and length constraints. in this paper we tackle the challenge of solving crosswords with large language models (llms). we demonstrate that the current generation of state-of-the art (sota) language models show significant com- petence at deciphering cryptic crossword clues, and outperform previously reported sota re- sults by a factor of 2-3 in relevant benchmarks. we also develop a search algorithm that builds off this performance to tackle the problem of solving full crossword grids with llms for the very first time, achieving an accuracy of 93% on new york times crossword puzzles. contrary to previous work in this area which concluded that llms lag human expert perfor- mance significantly, our research suggests this gap is a lot narrower. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09009",
        "label": 0,
        "title": "fredformer: frequency debiased transformer for time series forecasting xihao piao",
        "abstract": "the transformer model has shown leading performance in time se- ries forecasting. nevertheless, in some complex scenarios, it tends to learn low-frequency features in the data and overlook high- frequency features, showing a frequency bias. this bias prevents the model from accurately capturing important high-frequency data features. in this paper, we undertake empirical analyses to understand this bias and discover that frequency bias results from the model disproportionately focusing on frequency features with higher energy. based on our analysis, we formulate this bias and propose fredformer , a transformer-based framework designed to mitigate frequency bias by learning features equally across dif- ferent frequency bands. this approach prevents the model from overlooking lower amplitude features important for accurate fore- casting. extensive experiments show the effectiveness of our pro- posed approach, which can outperform other baselines in differ- ent real-world time-series datasets. furthermore, we introduce a lightweight variant of the fredformer with an attention matrix approximation, which achieves comparable performance but with much fewer parameters and lower computation costs. the code is available at: https://github.com/chenzrg/fredformer ccs concepts \u2022computing methodologies \u2192artificial intelligence ;neural networks . keywords time series forecasting, deep learning acm reference format: xihao piao*, zheng chen*, taichi murayama, yasuko matsubara, and ya- sushi sakurai. 2024. fredformer: frequency debiased transformer for * indicates corresponding authors. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than the author(s) must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. kdd \u201924, august 25\u201329, 2024, barcelona, spain \u00a92024 copyright held by the owner/author(s). publication rights licensed to acm. acm isbn 979-8-4007-0490-1/24/08 https://doi.org/10.1145/3637528.3671928time series forecasting . in proceedings of the 30th acm sigkdd con- ference on knowledge discovery and data mining (kdd \u201924), august 25\u2013 29, 2024, barcelona, spain. acm, new york, ny, usa, 18 pages. https: //doi.org/10.1145/3637528.3671928 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08680",
        "label": 0,
        "title": "analyzing large language models for classroom discussion assessment nhat tran",
        "abstract": "automatically assessing classroom discussion quality is be- coming increasingly feasible with the help of new nlp ad- vancements such as large language models (llms). in this work, we examine how the assessment performance of 2 llms interacts with 3 factors that may affect performance: task formulation, context length, and few-shot examples. we also explore the computational efficiency and predic- tive consistency of the 2 llms. our results suggest that the 3 aforementioned factors do affect the performance of the tested llms and there is a relation between consistency and performance. we recommend a llm-based assessment approach that has a good balance in terms of predictive per- formance, computational efficiency, and consistency. keywords classroom discussion, large language models, scoring 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.08707",
        "label": 1,
        "title": "moscar: a large-scale multilingual and multimodal document-level corpus matthieu futeral",
        "abstract": "multimodal large language models (mllms) are trained on a large amount of text-image data. while most mllms are trained on caption-like data only, alayrac et al. [2022] showed that additionally training them on interleaved sequences of text and images can lead to the emergence of in-context learning capabilities. however, the dataset they used, m3w, is not public and is only in english. there have been attempts to reproduce their results but the released datasets are english-only. in contrast, current multilingual and multimodal datasets are either composed of caption-like only or medium-scale or fully private data. this limits mllm research for the 7,000 other languages spoken in the world. we therefore introduce moscar, to the best of our knowledge the first large-scale multilingual and multimodal document corpus crawled from the web. it covers 163 languages, 315m documents, 214b tokens and 1.2b images. we carefully conduct a set of filtering and evaluation steps to make sure moscar is sufficiently safe, diverse and of good quality. we additionally train two types of multilingual model to prove the benefits of moscar: (1) a model trained on a subset of moscar and captioning data and (2) a model train on captioning data only. the model additionally trained on moscar shows a strong boost in few-shot learning performance across various multilingual image-text tasks and benchmarks, confirming previous findings for english-only mllms. the dataset can be accessed here.2 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09031",
        "label": 1,
        "title": "a c omprehensive graph pooling benchmark : effectiveness",
        "abstract": "graph pooling has gained attention for its ability to obtain effective node and graph representations for various downstream tasks. despite the recent surge in graph pooling approaches, there is a lack of standardized experimental settings and fair benchmarks to evaluate their performance. to address this issue, we have constructed a comprehensive benchmark that includes 15 graph pooling methods and 21 different graph datasets. this benchmark systematically assesses the performance of graph pooling methods in three dimensions, i.e., effectiveness, robustness, and generalizability. we first evaluate the performance of these graph pooling approaches across different tasks including graph classification, graph regression and node classification. then, we investigate their performance under potential noise attacks and out-of-distribution shifts in real-world scenarios. we also involve detailed efficiency analysis and parameter analysis. extensive experiments validate the strong capability and applicability of graph pooling approaches in various scenarios, which can provide valuable insights and guidance for deep geometric learning research. the source code of our benchmark is available at https://github.com/goose315/graph_pooling_benchmark . keywords graph pooling; benchmark; graph neural networks; graph machine learning "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09052",
        "label": 0,
        "title": "data-free generative replay for class-incremental learning on imbalanced data sohaib younis",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.08726",
        "label": 0,
        "title": "standardlanguage ideology inai-generated language genevievesmith",
        "abstract": "in this position paper, we explore standard language ideolo gy in languagegeneratedbylargelanguagemodels(llms).first, weout- linehowstandardlanguageideologyisre\ufb02ectedandreinfor ced in llms. we then present a taxonomy of open problems regarding standard language ideology in ai-generated language with i mpli- cations for minoritized language communities. we introduc e the concept of standard ai-generated language ideology, the pr ocess bywhich ai-generated language regards standard american e ng- lish(sae)asalinguisticdefaultandreinforcesalinguist icbiasthat sae is the most \u201cappropriate\u201d language. finally, we discuss ten- sions that remain, including re\ufb02ecting on what desirable sy stem behaviorlookslike,aswellasadvantagesanddrawbacksofg ener- ative ai tools imitating\u2014or often not\u2014di\ufb00erent english lan guage varieties.throughout,wediscussstandardlanguageideol ogyasa manifestation of existing global power structures in and th rough ai-generated language before ending with questions to move to- wards alternative, moreemancipatorydigital futures. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08757",
        "label": 1,
        "title": "srfund: a multi-granularity hierarchical structure reconstruction benchmark in form understanding jiefeng ma1y",
        "abstract": "accurately identifying and organizing textual content is crucial for the automation of document processing in the field of form understanding. existing datasets, such as funsd and xfund, support entity classification and relationship prediction tasks but are typically limited to local and entity-level annotations. this limitation overlooks the hierarchically structured representation of documents, constraining comprehensive understanding of complex forms. to address this issue, we present the srfund, a hierarchically structured multi-task form understanding bench- mark. srfund provides refined annotations on top of the original funsd and xfund datasets, encompassing five tasks: (1) word to text-line merging , (2) text-line to entity merging , (3) entity category classification , (4) item table lo- calization , and (5) entity-based full-document hierarchical structure recovery . we meticulously supplemented the original dataset with missing annotations at various levels of granularity and added detailed annotations for multi-item table regions within the forms. additionally, we introduce global hierarchical struc- ture dependencies for entity relation prediction tasks, surpassing traditional local key-value associations. the srfund dataset includes eight languages including english, chinese, japanese, german, french, spanish, italian, and portuguese , making it a powerful tool for cross-lingual form understanding. extensive exper- imental results demonstrate that the srfund dataset presents new challenges and significant opportunities in handling diverse layouts and global hierarchical structures of forms, thus providing deep insights into the field of form understand- ing. the original dataset and implementations of baseline methods are available at https://sprateam-ustc.github.io/srfund . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08796",
        "label": 1,
        "title": "deep exploration of cross-lingual zero-shot generalization in instruction tuning janghoon han",
        "abstract": "instruction tuning has emerged as a powerful technique, significantly boosting zero-shot per- formance on unseen tasks. while recent work has explored cross-lingual generalization by ap- plying instruction tuning to multilingual mod- els, previous studies have primarily focused on english, with a limited exploration of non- english tasks. for an in-depth exploration of cross-lingual generalization in instruction tun- ing, we perform instruction tuning individu- ally for two distinct language meta-datasets. subsequently, we assess the performance on unseen tasks in a language different from the one used for training. to facilitate this inves- tigation, we introduce a novel non-english meta-dataset named \"korani\" (korean natu- ral instruction), comprising 51 korean bench- marks. moreover, we design cross-lingual tem- plates to mitigate discrepancies in language and instruction-format of the template between training and inference within the cross-lingual setting. our experiments reveal consistent im- provements through cross-lingual generaliza- tion in both english and korean, outperforming baseline by average scores of 20.7% and 13.6%, respectively. remarkably, these enhancements are comparable to those achieved by monolin- gual instruction tuning and even surpass them in some tasks. the result underscores the sig- nificance of relevant data acquisition across lan- guages over linguistic congruence with unseen tasks during instruction tuning1. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09105",
        "label": 1,
        "title": "ins-mmbench: a comprehensive benchmark for evaluating lvlms\u2019 performance in insurance chenwei lin",
        "abstract": "large vision-language models (lvlms) have demonstrated outstanding per- formance in various general multimodal applications such as image recogni- tion and visual reasoning, and have also shown promising potential in special- ized domains. however, the application potential of lvlms in the insurance domain\u2014characterized by rich application scenarios and abundant multimodal data\u2014has not been effectively explored. there is no systematic review of multi- modal tasks in the insurance domain, nor a benchmark specifically designed to evaluate the capabilities of lvlms in insurance. this gap hinders the development of lvlms within the insurance domain. in this paper, we systematically review and distill multimodal tasks for four representative types of insurance: auto insurance, property insurance, health insurance, and agricultural insurance. we propose ins- mmbench, the first comprehensive lvlms benchmark tailored for the insurance domain. ins-mmbench comprises a total of 2.2k thoroughly designed multiple- choice questions, covering 12 meta-tasks and 22 fundamental tasks. furthermore, we evaluate multiple representative lvlms, including closed-source models such as gpt-4o and open-source models like blip-2. this evaluation not only validates the effectiveness of our benchmark but also provides an in-depth performance analysis of current lvlms on various multimodal tasks in the insurance domain. we hope that ins-mmbench will facilitate the further application of lvlms in the insurance domain and inspire interdisciplinary development. our dataset and evaluation code are available at https://github.com/fdu-ins/ins-mmbench . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09112",
        "label": 0,
        "title": "large-scale evaluation of open-set image classification techniques halil bisgin bisgin",
        "abstract": "the goal for classification is to correctly assign labels to unseen samples. however, most methods misclassify samples with unseen labels and assign them to one of the known classes. open-set classification (osc) algorithms aim to maximize both closed and open-set recog- nition capabilities. recent studies showed the utility of such algorithms on small-scale data sets, but limited experimentation makes it difficult to assess their performances in real-world problems. here, we provide a comprehensive comparison of various osc algo- rithms, including training-based (softmax, garbage, eos) and post-processing methods (maximum softmax scores, maximum logit scores, openmax, evm, proser), the lat- ter are applied on features from the former. we perform our evaluation on three large-scale protocols that mimic real-world challenges, where we train on known and negative open-set samples, and test on known and unknown instances. our results show that eos helps to improve performance of almost all post-processing algorithms. particularly, openmax and proser are able to exploit better-trained networks, demonstrating the utility of hybrid models. however, while most algorithms work well on negative test samples \u2013 samples of open-set classes seen during training \u2013 they tend to perform poorly when tested on samples of previously unseen unknown classes, especially in challenging conditions. keywords: open-set classification, large-scale evaluation, image classification, deep learn- ing, reproducible research 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09155",
        "label": 1,
        "title": "defan: definitive answer dataset for llms hallucination evaluation a b m ashikur rahman",
        "abstract": "large language models (llms) have demonstrated remarkable capabilities, revo- lutionizing the integration of ai in daily life applications. however, they are prone to hallucinations, generating claims that contradict established facts, deviating from prompts, and producing inconsistent responses when the same prompt is presented multiple times. addressing these issues is challenging due to the lack of com- prehensive and easily assessable benchmark datasets. most existing datasets are small and rely on multiple-choice questions, which are inadequate for evaluating the generative prowess of llms. to measure hallucination in llms, this paper introduces a comprehensive benchmark dataset comprising over 75,000 prompts across eight domains. these prompts are designed to elicit definitive, concise, and informative answers. the dataset is divided into two segments: one publicly available for testing and assessing llm performance and a hidden segment for benchmarking various llms. in our experiments, we tested six llms\u2014gpt-3.5, llama 2, llama 3, gemini, mixtral, and zephyr\u2014revealing that overall factual hallucination ranges from 59% to 82% on the public dataset and 57% to 76% in the hidden benchmark. prompt misalignment hallucination ranges from 6% to 95% in the public dataset and 17% to 94% in the hidden counterpart. average consistency ranges from 21% to 61% and 22% to 63%, respectively. domain-wise analysis shows that llm performance significantly deteriorates when asked for specific numeric information while performing moderately with person, location, and date queries. our dataset demonstrates its efficacy and serves as a comprehensive benchmark for llm performance evaluation. our dataset and llms responses are available at https://github.com/ashikiut/defan. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12793",
        "label": 0,
        "title": "chatglm: a family of large language models from glm-130b to glm-4 all tools team glm",
        "abstract": "we introduce chatglm, an evolving family of large language models that we have been developing over time. this report primarily focuses on the glm-4 language series, which includes glm-4, glm-4-air, and glm-4-9b. they represent our most capable models that are trained with all the insights and lessons gained from the preceding three generations of chatglm. to date, the glm-4 models are pre-trained on ten trillions of tokens mostly in chinese and english, along with a small set of corpus from 24 languages, and aligned primarily for chinese and english usage. the high-quality alignment is achieved via a multi-stage post- training process, which involves supervised fine-tuning and learning from human feedback. evaluations show that glm-4 1) closely rivals or outperforms gpt-4 in terms of general metrics such as mmlu, gsm8k, math, bbh, gpqa, and humaneval, 2) gets close to gpt-4-turbo in instruction following as measured by ifeval, 3) matches gpt-4 turbo (128k) and claude 3 for long context tasks, and 4) outperforms gpt-4 in chinese alignments as measured by alignbench. the glm- 4 all tools model is further aligned to understand user intent and autonomously decide when and which tool(s) to use\u2014including web browser, python interpreter, text-to-image model, and user-defined functions\u2014to effectively complete complex tasks. in practical applications, it matches and even surpasses gpt-4 all tools in tasks like accessing online information via web browsing and solving math problems using python interpreter. over the course, we have open-sourced a series of models, including chatglm-6b (three generations), glm-4-9b (128k, 1m), glm-4v-9b, webglm, and codegeex, attracting over 10 million downloads on hugging face in the year 2023 alone. the open models can be accessed through https://github.com/thudm andhttps://huggingface.co/thudm . *team glm: aohan zeng, bin xu, bowen wang, chenhui zhang, da yin, diego rojas, guanyu feng, hanlin zhao, hanyu lai, hao yu, hongning wang, jiadai sun, jiajie zhang, jiale cheng, jiayi gui, jie tang, jing zhang, juanzi li, lei zhao, lindong wu, lucen zhong, mingdao liu, minlie huang, peng zhang, qinkai zheng, rui lu, shuaiqi duan, shudan zhang, shulin cao, shuxun yang, weng lam tam, wenyi zhao, xiao liu, xiao xia, xiaohan zhang, xiaotao gu, xin lv, xinghan liu, xinyi liu, xinyue yang, xixuan song, xunkai zhang, yifan an, yifan xu, yilin niu, yuantao yang, yueyan li, yushi bai, yuxiao dong, zehan qi, zhaoyu wang, zhen yang, zhengxiao du, zhenyu hou, zihan wang. \u2020team members are listed alphabetically by first name. preprint. under review.arxiv:2406.12793v1  [cs.cl]  18 jun 2024glmmar. 2021glm-10bjun. 2021glm-130bcodegeex-13baug. 2022glm-proembeddingcharacterglmjun. 2023chatglm2-6bchatglm2-6b-32kcodegeex2-6bglm-4(0116)glm-4vcogview3jan. 2024 chatglm-130bmar. 2023chatglm-6bvisualglm-6bglm-3-turbooct. 2023chatglm3-6bchatglm3-6b-32kcogvlm-17b apisopen llmsopenvlmsglm-4(0520)glm-4-air(0605)jun. 2024glm-4-9bglm-4-9b-chatglm-4-9b-chat-1mglm-4v-9bcogvlm2-19bglm-4alltools webglmcodegeexcode interpreter agentmodelsautowebglm cogviewapr. 2022cogview2cogvideo(dec.)cogagent (may) (may)(may)(128k) (32k)(128k) (jul.)oct. 2022glm-130b(32k)(aug.)glm-10bmglm-1bfigure 1: the timeline of the glm family of language, code, vision, and agent models. the focus of this report is primarily on the language models, i.e., chatglm. the apis are publicly available at https://bigmodel.cn and open models can be accessed through https://github.com/thudm . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12822",
        "label": 0,
        "title": "is it good data for multilingual instruction tuning or just bad multilingual evaluation for large language mod",
        "abstract": "large language models, particularly multilin- gual ones, are designed, claimed, and expected to cater to native speakers of varied languages. we hypothesise that the current practices of fine-tuning and evaluating these models may mismatch this intention owing to a heavy re- liance on translation, which can introduce trans- lation artefacts and defects. it remains un- known whether the nature of the instruction data has an impact on the model output; on the other hand, it remains questionable whether translated test sets can capture such nuances. due to the often coupled practices of using translated data in both stages, such imperfec- tions could have been overlooked. this work investigates these issues by using controlled na- tive or translated data during instruction tuning and evaluation stages and observing model re- sults. experiments on eight base models and eight different benchmarks reveal that native or generation benchmarks display a notable dif- ference between native and translated instruc- tion data especially when model performance is high, whereas other types of test sets cannot. finally, we demonstrate that regularization is beneficial to bridging this gap on structured but not generative tasks.1 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12845",
        "label": 0,
        "title": "interpretable preferences via multi-objective reward modeling and mixture-of-experts haoxiang wang",
        "abstract": "reinforcement learning from human feedback (rlhf) has emerged as the primary method foraligninglargelanguagemodels(llms)withhumanpreferences. therlhfprocesstypically starts by training a reward model (rm) using human preference data. conventional rms are trained on pairwise responses to the same user request, with relative ratings indicating which response humans prefer. the trained rm serves as a proxy for human preferences. however, due to the black-box nature of rms, their outputs lack interpretability, as humans cannot intuitively understand why an rm thinks a response is good or not. as rms act as human preference proxies, it is desirable for them to be human-interpretable to ensure that their internal decision processes are consistent with human preferences and to prevent reward hacking in llm alignment. to build rms with interpretable preferences, we propose a two- stage approach: i) train an absolute-rating multi-objective reward model (armorm) with multi-dimensional absolute-rating data, each dimension corresponding to a human-interpretable objective (e.g., honesty, verbosity, safety); ii) employ a mixture-of-experts (moe) strategy with a gating network that automatically selects the most suitable reward objectives based on the context. we efficiently trained an armorm with llama-3 8b and a gating network consisting of a shallow mlp on top of the armorm. our trained model, armorm-llama3-8b , obtains state- of-the-art performance on rewardbench, a benchmark evaluating rms for language modeling. notably, the performance of our model surpasses the llm-as-a-judge method with gpt-4 judges by a margin, and approaches the performance of the much larger nemotron-4 340b reward model. our code and model are released at https://github.com/rlhflow/rlhf-rewar d-modeling . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12043",
        "label": 0,
        "title": "grade score: quantifying llm performance in option selection dmitri iourovitski",
        "abstract": "this study introduces the \u201dgrade score\u201d, a novel metric designed to evaluate the consistency and fairness of large language models (llms) when used as multiple-choice judges with respect to order bias and choice consistency. the grade score combines entropy, which measures order bias, and mode frequency, which assesses choice sta- bility, offering insights into llms\u2019 reliability and impartiality. the study explores techniques such as prompt engineering and option sam- pling strategies to optimize the grade score, demonstrating their effec- tiveness in enhancing llms\u2019 performance. results showcase varying performances among llms with respect to prompts and highlight the positive impact of including irrelevant options. the study also identi- fies an emergent behavior in instruction-following models, where they adapt to instructions targeting specific biases, demonstrating their adaptability. the grade score facilitates comparisons between llms and encourages ongoing research towards optimizing their decision- making processes, with potential implications for improving their re- liability and fairness in various applications. all code is available on github1 \u2217email: dmitri.io@utexas.edu 1https://github.com/iodmitri/gradelab 1arxiv:2406.12043v2  [cs.ai]  20 jun 2024"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12072",
        "label": 1,
        "title": "dtgb: a comprehensive benchmark for dynamic text-attributed graphs jiasheng zhang1",
        "abstract": "dynamic text-attributed graphs (dytags) are prevalent in various real-world scenarios, where each node and edge are associated with text descriptions, and both the graph structure and text descriptions evolve over time. despite their broad applicability, there is a notable scarcity of benchmark datasets tailored to dytags, which hinders the potential advancement in many research fields. to address this gap, we introduce dynamic text-attributed graph benchmark ( dtgb ), a collection of large-scale, time-evolving graphs from diverse domains, with nodes and edges enriched by dynamically changing text attributes and categories. to facilitate the use of dtgb, we design standardized evaluation procedures based on four real-world use cases: future link prediction, destination node retrieval, edge classification, and textual relation generation. these tasks require models to understand both dynamic graph structures and natural language, highlighting the unique challenges posed by dytags. moreover, we conduct extensive benchmark experiments on dtgb, evaluating 7 popular dynamic graph learning algorithms and their variants of adapting to text attributes with llm embeddings, along with 6 powerful large language models (llms). our results show the limitations of existing models in handling dytags. our analysis also demonstrates the utility of dtgb in investigating the incorporation of structural and textual dynamics. the proposed dtgb fosters research on dytags and their broad applications. it offers a comprehensive benchmark for evaluating and advancing models to handle the interplay between dynamic graph structures and natural language. the dataset and source code are available at https://github.com/zjs123/dtgb . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12843",
        "label": 0,
        "title": "can go ais be adversarially robust? tom tseng far ai",
        "abstract": "prior work found that superhuman go ais like katago can be defeated by simple adversarial strategies. in this paper, we study if simple defenses can improve katago\u2019s worst-case performance. we test three natural defenses: adversarial training on hand-constructed positions, iterated adversarial training, and changing the network architecture. we find that some of these defenses are able to protect against previously discovered attacks. unfortunately, we also find that none of these defenses are able to withstand adaptive attacks. in particular, we are able to train new adversaries that reliably defeat our defended agents by causing them to blunder in ways humans would not. our results suggest that building robust ai systems is challenging even in narrow domains such as go. for interactive examples of attacks and a link to our codebase, see https://goattack.far.ai/ . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09401",
        "label": 1,
        "title": "mmscan: a multi-modal 3d scene dataset with hierarchical grounded language annotations ruiyuan lyu1",
        "abstract": "with the emergence of llms and their integration with other data modalities, multi-modal 3d perception attracts more attention due to its connectivity to the physical world and makes rapid progress. however, limited by existing datasets, previous works mainly focus on understanding object properties or inter-object spatial relationships in a 3d scene. to tackle this problem, this paper builds the first largest ever multi-modal 3d scene dataset and benchmark with hierarchical grounded language annotations, mmscan. it is constructed based on a top-down logic, from region to object level, from a single target to inter-target relation- ships, covering holistic aspects of spatial and attribute understanding. the overall pipeline incorporates powerful vlms via carefully designed prompts to initialize the annotations efficiently and further involve humans\u2019 correction in the loop to ensure the annotations are natural, correct, and comprehensive. built upon exist- ing 3d scanning data, the resulting multi-modal 3d dataset encompasses 1.4m meta-annotated captions on 109k objects and 7.7k regions as well as over 3.04m diverse samples for 3d visual grounding and question-answering benchmarks. we evaluate representative baselines on our benchmarks, analyze their capabilities in different aspects, and showcase the key problems to be addressed in the future. furthermore, we use this high-quality dataset to train state-of-the-art 3d visual grounding and llms and obtain remarkable performance improvement both on existing benchmarks and in-the-wild evaluation. codes, datasets, and benchmarks will be available at https://github.com/openrobotlab/embodiedscan . preprint. under review.arxiv:2406.09401v1  [cs.cv]  13 jun 2024"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09406",
        "label": 1,
        "title": "4m-21: an any-to-any vision model for tens of tasks and modalities roman bachmann1\u2020",
        "abstract": "current multimodal and multitask foundation models, like 4m [ 62] or uni- fiedio [ 59,58], show promising results. however, their out-of-the-box abilities to accept diverse inputs and perform diverse tasks are limited by the (usually small) number of modalities and tasks they are trained on. in this paper, we develop a single any-to-any model trained on tens of highly diverse modalities and by performing co-training on large-scale multimodal datasets and text corpora. this includes training on images and text along with several semantic and geometric modalities, feature maps from recent state of the art models like dinov2 and imagebind, pseudo labels of specialist models like sam and 4dhumans, and a range of new modalities that allow for novel ways to interact with the model and steer the generation, for example, image metadata or color palettes. a crucial step in this process is performing discrete tokenization on various modalities, whether they are image-like, neural network feature maps, vectors, structured data like instance segmentation or human poses, or data that can be represented as text. through this, we show the possibility of training one model to solve at least 3x more tasks/modalities than existing models and doing so without a loss in performance . in addition, this enables more fine-grained and controllable multimodal generation capabilities and allows studying the distillation of models trained on diverse data and objectives into one unified model. we scale the training to a three billion parameter and different datasets. the multimodal models and training code are open sourced at https://4m.epfl.ch . *equal contribution & corresponding authors. randomized order. \u2020work partially done while at epfl and apple. preprint.arxiv:2406.09406v2  [cs.cv]  14 jun 2024"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09410",
        "label": 1,
        "title": "1 scene graph generation in large-size vhr satellite imagery: a large-scale dataset and a",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09411",
        "label": 0,
        "title": "muirbench : a comprehensive benchmark for robust multi-image understanding fei wang1",
        "abstract": "we introduce muirbench , a comprehensive benchmark that focuses on robust multi-image understanding capabilities of multimodal llms. muirbench con- sists of 12 diverse multi-image tasks ( e.g., scene understanding, ordering) that involve 10 categories of multi-image relations ( e.g., multiview, temporal relations). comprising 11,264 images and 2,600 multiple-choice questions, muirbench is created in a pairwise manner, where each standard instance is paired with an unanswerable variant that has minimal semantic differences, in order for a reliable assessment. evaluated upon 20 recent multi-modal llms, our results reveal that even the best-performing models like gpt-4o and gemini pro find it challenging to solve muirbench , achieving 68.0% and 49.3% in accuracy. open-source multimodal llms trained on single images can hardly generalize to multi-image questions, hovering below 33.3% in accuracy. these results highlight the im- portance of muirbench in encouraging the community to develop multimodal llms that can look beyond a single image, suggesting potential pathways for future improvements. \u2217equal leadership. correspondance to <fwang598@usc.edu; xingyuf2@seas.upenn.edu>. \u2020equal contribution; alphabetic order. project page: https://huggingface.co/datasets/muirbench/muirbench preprint. under review.arxiv:2406.09411v1  [cs.cv]  13 jun 2024figure 2: compared with previous benchmarks, muirbench has several novel features: (1) it evaluates on a comprehensive range of 12 multi-image understanding abilities, e.g. geographic understanding and diagram understanding as introduced in \u00a73, while prior benchmarks generally contain single-image questions. (2) it contains 10 diverse multi-image relations, e.g. narrative and complementary as discussed in \u00a73. (3) it provides a robust evaluation on models by unanswerable instance variants. the samples of previous benchmarks are from [25, 37, 53]. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09979",
        "label": 1,
        "title": "hiro: hierarchical information retrieval optimization krish goel",
        "abstract": "large language models (llms) excel in natural language tasks but face limitations due to static training datasets, result- ing in outdated or contextually shallow responses. retrieval- augmented generation (rag) addresses this by integrating real-time external knowledge, enhancing model accuracy and credibility, especially for knowledge-intensive tasks. how- ever, rag-enhanced llms struggle with long contexts, caus- ing them to \u201dchoke\u201d on information overload, compromising response quality. recent rag applications use hierarchical data structures for storing documents, organized at various levels of summarization and information density. in this con- text, we introduce hiro (hierarchical information retrieval optimization), a novel querying approach for rag appli- cations using hierarchical structures for storing documents. hiro employs dfs-based recursive similarity score calcula- tion and branch pruning to minimize the context returned to the llm without informational loss. hiro outperforms ex- isting querying mechanisms on the narrativeqa dataset by an absolute performance gain of 10.85%. code \u2014 https://github.com/krishgoel/hir"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09464",
        "label": 1,
        "title": "gpt-ology",
        "abstract": "large language models have taken the cognitive sci- ence world by storm. it is perhaps timely now to take stock of the various research paradigms that have been used to make scientific inferences about \u201ccognition\u201d in these models or about human cognition. we review sev- eral emerging research paradigms\u2014gpt-ology, llms- as-computational-models, and \u201csilicon sampling\u201d\u2014 and review recent papers that have used llms under these paradigms. in doing so, we discuss their claims as well as challenges to scientific inference under these vari- ous paradigms. we highlight several outstanding is- sues about llms that have to be addressed to push our science forward: closed-source vs open-sourced mod- els; (the lack of visibility of) training data; and repro- ducibility in llm research, including forming conven- tions on new task \u201chyperparameters\u201d like instructions and prompts. keywords: large language models; cognitive scienc"
    },
    {
        "url": "https://arxiv.org/pdf/2406.17038",
        "label": 0,
        "title": "mode ling: a novel dataset for testing linguistic reasoning in language models nathan a. chi1",
        "abstract": "we introduce mode ling1, a novel benchmark of linguistics olympiad-style puzzles which tests few-shot reasoning in ai systems. solving these puzzles necessitates inferring aspects of a language\u2019s grammatical structure from a small number of examples. such puzzles provide a natural testbed for language models, as they require compositional generalization and few- shot inductive reasoning. consisting solely of new puzzles written specifically for this work, mode ling has no risk of appearing in the training data of existing ai systems: this ame- liorates the risk of data leakage, a potential con- founder for many prior evaluations of reason- ing. evaluating several large open source lan- guage models and gpt on our benchmark, we observe non-negligible accuracy, demonstrat- ing few-shot emergent reasoning ability which cannot merely be attributed to shallow mem- orization. however, imperfect model perfor- mance suggests that mode ling can be used to measure further progress in linguistic reason- ing. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09520",
        "label": 0,
        "title": "education",
        "abstract": ": the use of generative artificial intelligence (genai) in academia is a subjective and hotly  debated topic. currently, there are no agreed guidelines towards the usage of genai systems in  higher education (he) and, thus, it is still unclear how to make effective use of the technology for  teaching and learning practice. this paper provides an overview of the current state of research on  genai for teaching and learning in he. to this end, this study conducted a systematic review of  relevant studies indexed by scopus, using the preferred reporting items for systematic reviews and  meta-analyses (prisma) guidelines. the search criteria revealed a total of 625 research papers, of  which 355 met the final inclusion criteria. the findings from the review showed the current state  and the future trends in documents, citations, document sources/authors, keywords, and co- authorship. the research gaps identified suggest that while some authors have looked at  understanding the detection of ai-generated text, it may be beneficial to understand how genai can  be incorporated into supp orting the educational curriculum for assessments, teaching, and learning  delivery. furthermore, there is a need for additional interdisciplinary, multidimensional studies in he  through collaboration. this will strengthen the awareness and understanding of students, tutors,  and other stakeholders, which will be instrumental in formulating guidelines, frameworks, and  policies for genai usage.      citation: ogunleye, b.; zakariyyah,  k.i.; ajao, o.; olayinka, o.; sharma,  h. a systematic review of generative  ai for teaching and learning practice.  educ. sci. 2024 , 14, 636. https://  doi.org/10.3390 /educsci14060636     academic editor: bracha kramarski    received: 28 march 2024   revised: 6 june 2024   accepted: 11 june 2024   published: 13 june 2024         copyright: \u00a9 2024  by the authors.  licensee mdpi, basel, switzerland.  this article is an open access article  distributed under the terms and  conditions of the creative comm ons  attribution (cc by) license (https://  creativecomm ons.org/licenses/by/  4.0/). keywords: artificial intelligence; generative ai; higher education; prisma; systematic literature  review; teaching and learning; topic modelling        1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09988",
        "label": 1,
        "title": "details make a difference: object state-sensitive neurorobotic task planning xiaowen sun",
        "abstract": ". the state of an object reflects its current status or condition and is important for a robot\u2019s task planning and manipulation. how- ever, detecting an object\u2019s state and generating a state-sensitive plan for robots is challenging. recently, pre-trained large language models (llms) and vision-language models (vlms) have shown impressive capabilities in generating plans. however, to the best of our knowledge, thereishardlyanyinvestigationonwhetherllmsorvlmscanalsogen- erate object state-sensitive plans. to study this, we introduce an object state-sensitive agent (ossa), a task-planning agent empowered by pre- trained neural networks. we propose two methods for ossa: (i) a modu- larmodelconsistingofapre-trainedvisionprocessingmodule(densecap- tioning model, dcm) and a natural language processing model (llm), and (ii) a monolithic model consisting only of a vlm. to quantitatively evaluate the performances of the two methods, we use tabletop scenarios where the task is to clear the table. we contribute a multimodal bench- mark dataset that takes object states into consideration. our results show that both methods can be used for object state-sensitive tasks, but the monolithic approach outperforms the modular approach. the code for ossa is available at https://github.com/xiao-wen-sun/ossa keywords: objectstateidentification \u00b7artificialintelligence \u00b7robotics \u00b7language models \u00b7multimodality "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10144",
        "label": 0,
        "title": "discovering the unknown: improving rule mining via embedding-based link prediction n\u2019dah jean kouagoua",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.10228",
        "label": 1,
        "title": "vega  : learning interleaved image-text comprehension in vision-language large models",
        "abstract": "the swift progress of multi-modal large models (mllms) has showcased their impressive ability to tackle tasks blending vision and language. yet, most current models and benchmarks cater to scenarios with a narrow scope of visual and textual contexts. these models often fall short when faced with complex comprehension tasks, which in- volve navigating through a plethora of irrelevant and poten- tially misleading information in both text and image forms. to bridge this gap, we introduce a new, more demanding task known as interleaved image-text comprehension (iitc). this task challenges models to discern and disregard super- fluous elements in both images and text to accurately answer questions and to follow intricate instructions to pinpoint the relevant image. in support of this task, we further craft a new vega dataset, tailored for the iitc task on scien- tific content, and devised a subtask, image-text association (ita), to refine image-text correlation skills. our evaluation of four leading closed-source models, as well as various open-source models using vega, underscores the rigorous nature of iitc. even the most advanced models, such as gemini-1.5-pro and gpt4v , only achieved modest success. by employing a multi-task, multi-scale post-training strat- egy, we have set a robust baseline for mllms on the iitc task, attaining an 85.8%accuracy rate in image associa- tion and a 0.508rouge score. these results validate the effectiveness of our dataset in improving mllms capabili- ties for nuanced image-text comprehension. project page: https://zhourax.github.io/vega/ *equal contribution \u2020corresponding author \u2660project leader1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.10221",
        "label": 0,
        "title": "short film dataset (sfd): a benchmark for story-level video understanding ridouane ghermi",
        "abstract": "recent advances in vision-language models have significantly propelled video understanding. existing datasets and tasks, however, have notable limitations. most datasets are confined to short videos with limited events and narrow narratives. for example, datasets with instructional and egocentric videos often document the activities of one person in a single scene. although some movie datasets offer richer content, they are often limited to short-term tasks, lack publicly available videos and frequently encounter data leakage given the use of movie forums and other resources in llm training. to address the above limitations, we propose the short film dataset (sfd) with 1,078 publicly available amateur movies, a wide variety of genres and minimal data leakage issues. sfd offers long-term story-oriented video tasks in the form of multiple-choice and open-ended question preprint. under review.arxiv:2406.10221v1  [cs.cv]  14 jun 20240 200 400 600 800 average video length (seconds)0100200300400total hoursactivitynet-qahow2qa egoschemasfdmovieqa moviechat lvucinepile tvqanext-qa ivqamovies (accessible) movies (restricted) egocentric instructional generalfigure 2: comparison of sfd to other vqa datasets. the circle size indicates the number of qa pairs in each dataset. 19.728.922.126.333.528.93624.131.518.344.134.556.755.455.464.451.971.3 28.869.964.17570.268.57164.176 15253545556575 gemma2b(42.3)mistral7b(62.5)llama 38b(68.4)gpt-3.5(70)mixtral8x7b(70.6)claude 3haiku(75.2)claude 3sonnet(79)llama 370b(82)gpt-4(86.4)% accuracyzero-shot llm accuracysfdmovieqalvuyto: youtube-objects voc: pascal voc 2007 6model and (mmlu)figure 3: data leakage. when given only the movie title, higher zero-shot accuracy in question- answering by llms indicates greater data leakage. llms are ranked by mmlu. answering. our extensive experiments emphasize the need for long-term reasoning to solve sfd tasks. notably, we find strong signals in movie transcripts leading to the on-par performance of people and llms. we also show significantly lower performance of current models compared to people when using vision data alone. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10210",
        "label": 1,
        "title": "make it count: text-to-image generation with an accurate number of objects lital binyamin1yoad tewel2",
        "abstract": "despite the unprecedented success of text-to-image diffusion models, controlling the number of depicted objects using text is surprisingly hard. this is important for various applications from technical documents, to children\u2019s books to illustrating cooking recipes. generating object-correct counts is fundamentally challenging because the generative model needs to keep a sense of separate identity for every instance of the object, even if several objects look identical or overlap, and then carry out a global computation implicitly during generation. it is still unknown if such representations exist. to address count-correct generation, we first identify features within the diffusion model that can carry the object identity information. we then use them to separate and count instances of objects during the denoising process and detect over-generation and under-generation. we fix the latter by training a model that predicts both the shape and location of a missing object, based on the layout of existing ones, and show how it can be used to guide denoising with correct object count. our approach, countgen , does not depend on external source to determine object layout, but rather uses the prior from the diffusion model itself, creating prompt-dependent and seed-dependent layouts. evaluated on two benchmark datasets, we find that countgen strongly outperforms the count- accuracy of existing baselines. countgen  (ours) \u201ca photo of six  kittens  sitting on a  branch\u201d \u201ca photo of \ufb01ve  eggs  in a carton\u201d \u201ca realistic photo of  goldilocks and three   bears eating a porridge\u201d \u201can illustration of  four  ninja turtles \u201d sdxl  \u201ca realistic photo of  seven  dwarves  dancing  in the forest\u201d  figure 1: countgen generates the correct number of objects specified in the input prompt while maintaining a natural layout that aligns with the prompt. preprint. under review.arxiv:2406.10210v1  [cs.cv]  14 jun 2024"
    },
    {
        "url": "https://arxiv.org/pdf/2406.10163",
        "label": 1,
        "title": "meshanything: artist-created mesh generation with autoregressive transformers yiwen chen1",
        "abstract": "recently, 3d assets created via reconstruction and generation have matched the quality of manually crafted assets, highlighting their potential for replacement. however, this potential is largely unrealized because these assets always need to be converted to meshes for 3d industry applications, and the meshes produced by current mesh extraction methods are significantly inferior to artist-created meshes (ams), i.e., meshes created by human artists. specifically, current mesh extraction methods rely on dense faces and ignore geometric features, leading to inefficiencies, complicated post-processing, and lower representation quality. to address these issues, we introduce meshanything, a model that treats mesh extraction as a generation problem, producing ams aligned with specified shapes. by converting 3d assets in any 3d representation into ams, meshanything can be integrated with various 3d asset production methods, thereby enhancing their application across the 3d industry. the architecture of meshanything comprises a vq-v ae and a shape-conditioned decoder-only transformer. we first learn a mesh vocabulary using the vq-v ae, then train the shape-conditioned decoder- only transformer on this vocabulary for shape-conditioned autoregressive mesh generation. our extensive experiments show that our method generates ams with hundreds of times fewer faces, significantly improving storage, rendering, and simulation efficiencies, while achieving precision comparable to previous methods. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10157",
        "label": 0,
        "title": "robogolf: mastering real-world minigolf with a reflective multi-modality vision-language model hantao zhou1",
        "abstract": ": minigolf, a game with countless court layouts, and complex ball mo- tion, constitutes a compelling real-world testbed for the study of embodied intel- ligence. as it not only challenges spatial and kinodynamic reasoning but also re- quires reflective and corrective capacities to address erroneously designed courses. we introduce robogolf , a vlm-based framework that perceives dual-camera vi- sual inputs with nested vlm-empowered closed-loop control and reflective equi- librium loop. extensive experiments demonstrate the effectiveness of robogolf on challenging minigolf courts including those that are impossible to finish. ex- periment videos are available at https://jity16.github.io/robogolf/ . keywords: reflective equilibrium, closed-loop control, real-world minigolf, vi- sion language model "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10100",
        "label": 0,
        "title": "skysensegpt: a fine-grained instruction tuning dataset and model for remote sensing vision-language understand",
        "abstract": "remote sensing large multi-modal models (rslmms) are developing rapidly and showcase significant capabilities in remote sensing imagery (rsi) comprehension. however, due to the limitations of existing datasets, rslmms have shortcomings in understanding the rich semantic relations among objects in complex remote sensing scenes. to unlock rslmms\u2019 complex comprehension ability, we propose a large-scale instruction tuning dataset fit-rs, containing 1,800,851 instruction samples. fit-rs covers common interpretation tasks and innovatively introduces several complex comprehension tasks of escalating difficulty, ranging from re- lation reasoning to image-level scene graph generation. based on fit-rs, we build the fit-rsfg benchmark. furthermore, we establish a new benchmark to evaluate the fine-grained relation comprehension capabilities of lmms, named fit-rsrc. based on combined instruction data, we propose skysensegpt, which achieves outstanding performance on both public datasets and fit-rsfg, sur- passing existing rslmms. we hope the fit-rs dataset can enhance the relation comprehension capability of rslmms and provide a large-scale fine-grained data source for the remote sensing community. the dataset will be available at https://github.com/luo-z13/skysensegpt . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10079",
        "label": 0,
        "title": "localizing events in videos with multimodal queries gengyuan zhang1",
        "abstract": "video understanding is a pivotal task in the digital era, yet the dynamic and multi- event nature of videos makes them labor-intensive and computationally demanding to process. thus, localizing a specific event given a semantic query has gained importance in both user-oriented applications like video search and academic research into video foundation models. a significant limitation in current research is that semantic queries are typically in natural language that depicts the semantics of the target event. this setting overlooks the potential for multimodal semantic queries composed of images and texts. to address this gap, we introduce a new benchmark, icq, for localizing events in videos with multimodal queries, along with a new evaluation dataset icq-highlight. our new benchmark aims to evaluate how well models can localize an event given a multimodal semantic query that consists of a reference image, which depicts the event, and a refinement text to adjust the images\u2019 semantics. to systematically benchmark model performance, we include 4 styles of reference images and 5 types of refinement texts, allowing us to explore model performance across different domains. we propose 3 adaptation methods that tailor existing models to our new setting and evaluate 10 sota models, ranging from specialized to large-scale foundation models. we believe this benchmark is an initial step toward investigating multimodal queries in video event localization1. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09422",
        "label": 1,
        "title": "loopin: a pinfi protocol for decentralized computing yunwei mao1",
        "abstract": "networked computing power is a critical utility in the era of artificial intelligence. this paper presents a novel physical infrastructure finance (pinfi) protocol designed to facilitate the distribu- tion of computing power within networks in a decentralized manner. addressing the core challenges of coordination, pricing, and liquidity in decentralized physical infrastructure networks (depin), the pinfi protocol introduces a distinctive dynamic pricing mechanism. it enables providers to al- locate excess computing resources to a \u201cdissipative\u201d pinfi liquidity pool, distinct from traditional defi liquidity pools, ensuring seamless access for clients at equitable, market-based prices. this approach significantly reduces the costs of accessing computing power, potentially to as low as 1% compared to existing services, while simultaneously enhancing security and dependability. the pinfi protocol is poised to transform the dynamics of supply and demand in computing power networks, setting a new standard for efficiency and accessibility. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09454",
        "label": 1,
        "title": "advancing high resolution vision-language models in biomedicine zekai chen arda pekis kevin brown",
        "abstract": "multi-modal learning has transformed generative ai, particularly in vision- language modeling. advances such as the multi-modal gpt-4v and open-source projects like llav a have enabled robust conversational agents capable of zero-shot task completions. however, extending these technologies in the biomedical field introduces unique challenges. recent initiatives like llav a-med have begun to tailor instruction-tuning to biomedical contexts using extensive datasets like pmc-15m. our research contributes three significant advancements: (i) we intro- duce a new instruct dataset enriched with medical image-text pairs derived from claude3-opus and llama3 70b, (ii) we propose an innovative image encoding strategy that employs hierarchical representations to enhance fine-grained biomed- ical visual comprehension, and (iii) we develop the llama3-med model, which achieves state-of-the-art zero-shot performance on biomedical visual question an- swering benchmarks, improving performance by over 10% on average compared to prior methods. these advancements provide more precise and reliable tools for medical professionals, effectively bridging gaps in current multi-modal conversa- tional assistants and fostering further innovations in medical ai. codes available at https://github.com/standardmodelbio/llama3-med.git . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09688",
        "label": 0,
        "title": "freectrl: constructing control centers with feedforward layers for learning-free controllable text generation ",
        "abstract": "controllable text generation (ctg) seeks to craft texts adhering to specific attributes, tradi- tionally employing learning-based techniques such as training, fine-tuning, or prefix-tuning with attribute-specific datasets. these ap- proaches, while effective, demand extensive computational and data resources. in contrast, some proposed learning-free alternatives cir- cumvent learning but often yield inferior re- sults, exemplifying the fundamental machine learning trade-off between computational ex- pense and model efficacy. to overcome these limitations, we propose freectrl, a learning- free approach that dynamically adjusts the weights of selected feedforward neural network (ffn) vectors to steer the outputs of large lan- guage models (llms). freectrl hinges on the principle that the weights of different ffn vec- tors influence the likelihood of different tokens appearing in the output. by identifying and adaptively adjusting the weights of attribute- related ffn vectors, freectrl can control the output likelihood of attribute keywords in the generated content. extensive experiments on single- and multi-attribute control reveal that the learning-free freectrl outperforms other learning-free and learning-based methods, suc- cessfully resolving the dilemma between learn- ing costs and model performance1. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09760",
        "label": 1,
        "title": "bootstrapping language models with dpo implicit rewards changyu chen",
        "abstract": "human alignment in large language models (llms) is an active area of research. a recent groundbreaking work, direct preference optimization (dpo), has greatly simplified the process from past work in reinforcement learning from human feedback (rlhf) by bypassing the reward learning stage in rlhf. dpo, after training, provides an implicit reward model. in this work, we make a novel observation that this implicit reward model can by itself be used in a bootstrapping fashion to further align the llm. our approach is to use the rewards from a current llm model to construct a preference dataset, which is then used in subsequent dpo rounds. we incorporate refinements that debias the length of the responses and improve the quality of the preference dataset to further improve our approach. our approach, named self-alignment with dpoimplicit rewards (dice), shows great improvements in alignment and achieves superior performance than gemini pro on alpacaeval 2, reaching 27.55% length-controlled win rate against gpt-4 turbo, but with only 8b parameters and no external feedback. our code is available athttps://github.com/sail-sg/dice . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09455",
        "label": 0,
        "title": "pandora: towards general world model with natural language actions and video states jiannan xiang",
        "abstract": "world models simulate future states of the world in response to different actions. they facilitate interactive content creation and provides a foundation for grounded, long-horizon reasoning. current foundation models do not fully meet the capa- bilities of general world models: large language models (llms) are constrained by their reliance on language modality and their limited understanding of the physical world, while video models lack interactive action control over the world simulations. this paper makes a step towards building a general world model by introducing pandora , a hybrid autoregressive-diffusion model that simulates world states by generating videos and allows real-time control with free-text actions. pandora achieves domain generality , video consistency , and controllability through large-scale pretraining and instruction tuning. crucially, pandora bypasses the cost of training-from-scratch by integrating a pretrained llm (7b) and a pretrained video model, requiring only additional lightweight finetuning. we illustrate ex- tensive outputs by pandora across diverse domains (indoor/outdoor, natural/urban, human/robot, 2d/3d, etc.). the results indicate great potential of building stronger general world models with larger-scale training. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09486",
        "label": 1,
        "title": "semopo: learning high-quality model and policy from low-quality offline visual datasets shenghua wan1 2ziyuan ",
        "abstract": "model-based offline reinforcement learning (rl) is a promising approach that leverages existing data effectively in many real-world applications, especially those involving high-dimensional in- puts like images and videos. to alleviate the distribution shift issue in offline rl, existing model-based methods heavily rely on the uncer- tainty of learned dynamics. however, the model uncertainty estimation becomes significantly bi- ased when observations contain complex distrac- tors with non-trivial dynamics. to address this challenge, we propose a new approach - sepa- rated model-based offline policy optimization (semopo) - decomposing latent states into en- dogenous and exogenous parts via conservative sampling and estimating model uncertainty on the endogenous states only. we provide a theoret- ical guarantee of model uncertainty and perfor- mance bound of semopo. to assess the efficacy, we construct the low-quality vision deep data- driven datasets for rl (lqv-d4rl), where the data are collected by non-expert policy and the observations include moving distractors. exper- imental results show that our method substan- tially outperforms all baseline methods, and fur- ther analytical experiments validate the critical designs in our method. the project website is https://sites.google.com/view/semopo. 1school of artificial intelligence, nanjing university, china 2national key laboratory for novel software technology, nanjing university, china3school of mathematical sciences, center for statistical science, peking university, beijing, china4school of cyberspace science and technology, beijing institute of tech- nology, beijing, china. correspondence to: de-chuan zhan <zhandc@nju.edu.cn >. proceedings of the 41stinternational conference on machine learning , vienna, austria. pmlr 235, 2024. copyright 2024 by the author(s).1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09496",
        "label": 0,
        "title": "you are what you eat? feeding foundation models a regionally diverse food dataset of world wide dishes jabez m",
        "abstract": "foundation models are increasingly ubiquitous in our daily lives, used in everyday tasks such as text-image searches, interactions with chatbots, and content gener- ation. as use increases, so does concern over the disparities in performance and fairness of these models for different people in different parts of the world. to assess these growing regional disparities, we present world widedishes , a mixed text and image dataset consisting of 765 dishes, with dish names collected in 131 local languages. world widedishes has been collected purely through human contribution and decentralised means, by creating a website widely distrib- uted through social networks. using the dataset, we demonstrate a novel means of operationalising capability and representational biases in foundation models such as language models and text-to-image generative models. we enrich these studies with a pilot community review to understand, from a first-person perspective, how these models generate images for people in five african countries and the united states. we find that these models generally do not produce quality text and image outputs of dishes specific to different regions. this is true even for the us, which is typically considered to be more well-resourced in training data\u2014though the gener- ation of us dishes does outperform that of the investigated african countries. the models demonstrate a propensity to produce outputs that are inaccurate as well as culturally misrepresentative, flattening, and insensitive. these failures in capability and representational bias have the potential to further reinforce stereotypes and disproportionately contribute to erasure based on region. the dataset and code are available at https://github.com/oxai/world-wide-dishes/ . \u2217joint first author. \u2020work done in affiliation with the oxford artificial intelligence society. \u2021corresponding author: siobhan.hall@nds.ox.ac.uk. preprint. under review.arxiv:2406.09496v1  [cs.cy]  13 jun 2024example dish  dall-e 2  dall-e 3  sd v2.1 baghrir eru nyama choma ofe okazi babotie hot dog algeria cameroon kenya nigeria south africa united states figure 1: theworld widedishes dataset contains 765 unique instances of dishes from around the world. this paper presents image generation analysis of dishes associated with the united states and five countries across africa. the 1strow shows example images of the dishes from each country, and the 2ndthrough 4th rows show images generated by dall-e 2, dall-e 3, and stable diffusion v2.1, respectively. all models tend to mis-characterise the dishes. dall-e 2 often outputs the incorrect dish; dall-e 3 tends to exaggerate both visual and cultural stereotypes and to make images more cartoonish; and stable diffusion often generates incoherent images barely resembling food. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.18346",
        "label": 0,
        "title": "ai a lignment through reinforcement learning from human feedback ? contradictions and limitations adam dahlgre",
        "abstract": "this paper critically evaluates the attempts to align arti\ufb01 cial intelligence (ai) systems, especially large language models (llms), with human values and intenti ons through reinforcement learn- ing from feedback (rlxf) methods, involving either human fe edback (rlhf) or ai feedback (rlaif). speci\ufb01cally, we show the shortcomings of the broad ly pursued alignment goals of honesty, harmlessness, and helpfulness. through a multidisciplina ry sociotechnical critique, we examine both the theoretical underpinnings and practical implemen tations of rlxf techniques, revealing sig- ni\ufb01cant limitations in their approach to capturing the comp lexities of human ethics and contributing to ai safety. we highlight tensions and contradictions inhe rent in the goals of rlxf. in addition, we discuss ethically-relevant issues that tend to be neglecte d in discussions about alignment and rlxf, among which the trade-offs between user-friendliness and d eception, \ufb02exibility and interpretability, and system safety. we conclude by urging researchers and pra ctitioners alike to critically assess the sociotechnical rami\ufb01cations of rlxf, advocating for a more nuanced and re\ufb02ective approach to its application in ai development. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09622",
        "label": 1,
        "title": "dsl-fiqa: assessing facial image quality via dual-set degradation learning and landmark-guided transformer wei",
        "abstract": "generic face image quality assessment (gfiqa) evalu- ates the perceptual quality of facial images, which is crucial in improving image restoration algorithms and selecting high-quality face images for downstream tasks. we present a novel transformer-based method for gfiqa, which is aided by two unique mechanisms. first, a \u201c dual-set degradation representation learning\u201d (dsl) mechanism uses facial images with both synthetic and real degrada- tions to decouple degradation from content, ensuring gen- eralizability to real-world scenarios. this self-supervised method learns degradation features on a global scale, pro- viding a robust alternative to conventional methods that use local patch information in degradation learning. second, our transformer leverages facial landmarks to emphasize visually salient parts of a face image in evaluating its per- ceptual quality. we also introduce a balanced and diverse comprehensive generic face iqa (cgfiqa-40k) dataset of 40k images carefully designed to overcome the biases, in particular the imbalances in skin tone and gender represen- tation, in existing datasets. extensive analysis and evalua- tion demonstrate the robustness of our method, marking a significant improvement over prior methods. 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09675",
        "label": 1,
        "title": "benchmarking spectral graph neural networks: a comprehensive study on effectiveness and efficiency ningyi liao",
        "abstract": "with the recent advancements in graph neural networks (gnns), spectral gnns have received increasing popularity by virtue of their specialty in capturing graph signals in the frequency domain, demonstrating promising capability in specific tasks. however, few systematic studies have been conducted to assess their spectral characteristics. this emerging family of models also varies in terms of design and settings, leading to difficulties in comparing their performance and deciding on the suitable model for specific scenarios, especially for large-scale tasks. in this work, we extensively benchmark spectral gnns with a focus on the frequency perspective. we analyze and categorize over 30 gnns with 27 corresponding filters. then, we implement these spectral models within a unified framework with dedicated graph computations and efficient training schemes. thorough experiments are conducted on the spectral models with inclusive metrics on effectiveness and efficiency, offering practical guidelines on evaluating and selecting spectral gnns with desirable performance. our implementation enables application on larger graphs with comparable performance and less overhead, which is available at: https://github.com/gdmnl/spectral-gnn-benchmark . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09723",
        "label": 0,
        "title": "when will gradient regularization be harmful? yang zhao1hao zhang1xiuyuan hu1 abstract",
        "abstract": "gradient regularization (gr), which aims to pe- nalize the gradient norm atop the loss function, has shown promising results in training modern over-parameterized deep neural networks. how- ever, can we trust this powerful technique? this paper reveals that gr can cause performance de- generation in adaptive optimization scenarios, par- ticularly with learning rate warmup. our empiri- cal and theoretical analyses suggest this is due to gr inducing instability and divergence in gradi- ent statistics of adaptive optimizers at the initial training stage. inspired by the warmup heuristic, we propose three gr warmup strategies, each re- laxing the regularization effect to a certain extent during the warmup course to ensure the accurate and stable accumulation of gradients. with exper- iments on vision transformer family, we confirm the three gr warmup strategies can effectively circumvent these issues, thereby largely improv- ing the model performance. meanwhile, we note that scalable models tend to rely more on the gr warmup, where the performance can be improved by up to 3% on cifar10 compared to baseline gr. code is available at https://github.com/zhaoyang- 0204/gnp. 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09770",
        "label": 0,
        "title": "towards efficient pareto set approximation via mixture of experts based model fusion anke tang",
        "abstract": "solving multi-objective optimization problems for large deep neural networks is a challenging task due to the complexity of the loss landscape and the expensive computational cost of training and evaluating models. efficient pareto front approx- imation of large models enables multi-objective optimization for various tasks such as multi-task learning and trade-off analysis. existing algorithms for learning pareto set, including (1) evolutionary, hypernetworks, and hypervolume-maximization methods, are computationally expensive and have restricted scalability to large models; (2) scalarization algorithms, where a separate model is trained for each objective ray, which is inefficient for learning the entire pareto set and fails to capture the objective trade-offs effectively. inspired by the recent success of model merging, we propose a practical and scalable approach to pareto set learning prob- lem via mixture of experts (moe) based model fusion. by ensembling the weights of specialized single-task models, the moe module can effectively capture the trade-offs between multiple objectives and closely approximate the entire pareto set of large neural networks. once the routers are learned and a preference vec- tor is set, the moe module can be unloaded, thus no additional computational cost is introduced during inference. we conduct extensive experiments on vision and language tasks using large-scale models such as clip-vit and gpt-2. the experimental results demonstrate that our method efficiently approximates the entire pareto front of large models. using only hundreds of trainable parameters of the moe routers, our method even has lower memory usage compared to linear scalarization and algorithms that learn a single pareto optimal solution, and are scalable to both the number of objectives and the size of the model. our method significantly reduces the computational burden of learning the pareto set, for exam- ple, in the two-task case, it can be achieved in just a few minutes. code is available at:https://github.com/tanganke/pareto_set_learning "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09831",
        "label": 0,
        "title": "received xx month",
        "abstract": "federated learning (fl) offers a compelling framework for training large language models (llms) while addressing data privacy and decentralization challenges. this paper surveys recent advance- ments in the federated learning of large language models, with a particular focus on machine unlearning\u2014a crucial aspect for complying with privacy regulations like the right to be forgotten. machine unlearning in the context of federated llms involves systematically and securely removing individual data contributions from the learned model without retraining from scratch. we explore various strategies that enable effective unlearning, such as perturbation techniques, model decomposition, and incremental learning, highlighting their implications for maintaining model performance and data privacy. furthermore, we examine case studies and experimental results from recent literature to assess the effectiveness and efficiency of these approaches in real-world scenarios. our survey reveals a growing interest in developing more robust and scalable federated unlearning methods, suggesting a vital area for future research in the intersection of ai ethics and distributed machine learning technologies. index terms federated learning (fl), large language models (llms), swarm intelligence, efficiency, pre-trained models, privacy and security i"
    },
    {
        "url": "https://arxiv.org/pdf/2406.09838",
        "label": 1,
        "title": "vision-language models meet meteorology: developing models for extreme weather events detection with heatmaps",
        "abstract": "real-time detection and prediction of extreme weather protect human lives and infrastructure. traditional methods rely on numerical threshold setting and manual interpretation of weather heatmaps with geographic information systems (gis), which can be slow and error-prone. our research redefines extreme weather events detection (ewed) by framing it as a visual question answering (vqa) problem, thereby introducing a more precise and automated solution. leveraging vision-language models (vlm) to simultaneously process visual and textual data, we offer an effective aid to enhance the analysis process of weather heatmaps. our initial assessment of general-purpose vlms (e.g., gpt-4-vision) on ewed revealed poor performance, characterized by low accuracy and frequent halluci- nations due to inadequate color differentiation andinsufficient meteorological knowledge . to address these challenges, we introduce climateiqa , the first mete- orological vqa dataset, which includes 8,760 wind gust heatmaps and 254,040 question-answer pairs covering four question types, both generated from the latest climate reanalysis data. we also propose sparse position and outline tracking (spot) , an innovative technique that leverages opencv and k-means clustering to capture and depict color contours in heatmaps, providing climateiqa with more accurate color spatial location information. finally, we present climate-zoo , the first meteorological vlm collection, which adapts vlms to meteorological applications using the climateiqa dataset. experiment results demonstrate that models from climate-zoo substantially outperform state-of-the-art general vlms, achieving an accuracy increase from 0% to over 90% in ewed verification. the datasets and models in this study are publicly available for future climate science research: https://github.com/alexjjjchen/climate-zoo . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09870",
        "label": 1,
        "title": "igl-bench: establishing the comprehensive benchmark for imbalanced graph learning jiawen qin1",
        "abstract": "deep graph learning has gained grand popularity over the past years due to its versa- tility and success in representing graph data across a wide range of domains. how- ever, the pervasive issue of imbalanced graph data distributions, where certain parts exhibit disproportionally abundant data while others remain sparse, undermines the efficacy of conventional graph learning algorithms, leading to biased outcomes. to address this challenge, imbalanced graph learning (igl) has garnered substantial attention, enabling more balanced data distributions and better task performance. despite the proliferation of igl algorithms, the absence of consistent experimental protocols and fair performance comparisons pose a significant barrier to compre- hending advancements in this field. to bridge this gap, we introduce igl-bench , a foundational comprehensive benchmark for imbalanced graph learning, embarking on16diverse graph datasets and 24distinct igl algorithms with uniform data processing and splitting strategies. specifically, igl-bench systematically inves- tigates state-of-the-art igl algorithms in terms of effectiveness ,robustness , and efficiency on node-level and graph-level tasks, with the scope of class-imbalance andtopology-imbalance . extensive experiments demonstrate the potential benefits of igl algorithms on various imbalanced conditions, offering insights and opportu- nities in the igl field. further, we have developed an open-sourced and unified package to facilitate reproducible evaluation and inspire further innovative research, which is available at https://github.com/ringbdstack/igl-bench . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09877",
        "label": 0,
        "title": "federated learning with flexible architectures jong-ik park and carlee joe-wong \u0000[0000\u22120003\u22120785\u22129291] carnegi",
        "abstract": ". traditional federated learning (fl) methods have limited support for clients with varying computational and communication abil- ities, leading to inefficiencies and potential inaccuracies in model train- ing. this limitation hinders the widespread adoption of fl in diverse and resource-constrained environments, such as those with client devices ranging from powerful servers to mobile devices. to address this need, this paper introduces federated learning with flexible architectures (fedfa), an fl training algorithm that allows clients to train models of different widths and depths. each client can select a network architec- ture suitable for its resources, with shallower and thinner networks re- quiring fewer computing resources for training. unlike prior work in this area, fedfa incorporates the layer grafting technique to align clients\u2019 lo- cal architectures with the largest network architecture in the fl system during model aggregation. layer grafting ensures that all client contribu- tions are uniformly integrated into the global model, thereby minimizing the risk of any individual client\u2019s data skewing the model\u2019s parameters disproportionately and introducing security benefits. moreover, fedfa introduces the scalable aggregation method to manage scale variations in weights among different network architectures. experimentally, fedfa outperforms previous width and depth flexible aggregation strategies. specifically, fedfa\u2019s testing accuracy matches (1.00 times) or is up to 1.16 times higher globally for iid settings, 0.98 to 1.13 times locally, and 0.95 times to 1.20 times higher globally for non-iid settings com- pared to earlier strategies. furthermore, fedfa demonstrates increased robustness against performance degradation in backdoor attack scenar- ios compared to earlier strategies. earlier strategies exhibit more drops in testing accuracy under attacks\u2014for iid data by 1.01 to 2.11 times globally, and for non-iid data by 0.89 to 3.31 times locally, and 1.11 to 1.74 times globally, compared to fedfa. keywords: federated learning \u00b7heterogeneous local network archi- tectures \u00b7backdoor attack "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10040",
        "label": 1,
        "title": "fzi-wim at semeval-2024 task 2: self-consistent cot for complex nli in biomedical domain jin liu1",
        "abstract": "this paper describes the inference system of fzi-wim at the semeval-2024 task 2: safe biomedical natural language inference for clinical trials. our system utilizes the chain of thought (cot) paradigm to tackle this com- plex reasoning problem and further improves the cot performance with self-consistency. in- stead of greedy decoding, we sample multiple reasoning chains with the same prompt and make the final verification with majority voting. the self-consistent cot system achieves a base- line f1 score of 0.80 (1st), faithfulness score of 0.90 (3rd), and consistency score of 0.73 (12th). we release the code and data publicly1. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09948",
        "label": 1,
        "title": "ble nd: a benchmark for llms on everyday knowledge in diverse cultures and languages junho myung1",
        "abstract": "large language models (llms) often lack culture-specific knowledge of daily life, especially across diverse regions and non-english languages. existing benchmarks for evaluating llms\u2019 cultural sensitivities are limited to a single language or col- lected from online sources such as wikipedia, which do not reflect the mundane everyday lifestyles of diverse regions. that is, information about the food people eat for their birthday celebrations, spices they typically use, musical instruments youngsters play, or the sports they practice in school is common cultural knowledge but uncommon in easily collected online sources, especially for underrepresented cultures. to address this issue, we introduce ble nd, a hand-crafted benchmark designed to evaluate llms\u2019 everyday knowledge across diverse cultures and lan- guages. ble nd comprises 52.6k question-answer pairs from 16 countries/regions, in 13 different languages, including low-resource ones such as amharic, assamese, azerbaijani, hausa, and sundanese. we construct the benchmark to include two formats of questions: short-answer and multiple-choice. we show that llms perform better for cultures that are highly represented online, with a maximum 57.34% difference in gpt-4, the best-performing model, in the short-answer format. for cultures represented by mid-to-high-resource languages, llms perform better in their local languages, but for cultures represented by low-resource languages, llms perform better in english than the local languages. we make our dataset publicly available at: https://github.com/nlee0212/blend . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10099",
        "label": 0,
        "title": "know the unknown: an uncertainty-sensitive method for llm instruction tuning jiaqi li1",
        "abstract": "large language models (llms) have demon- strated remarkable capabilities across various tasks but still face challenges such as hallu- cinations. one potential reason for halluci- nations is the lack of relevant knowledge or context. thus, a promising solution to miti- gate this issue involves instructing llms to respond with \"i do not know\" when a question falls outside their knowledge domain or the provided context. however, in this work, we observed that llms struggle to admit their lack of knowledge, primarily due to existing instruc- tion datasets designed to encourage specific answers. to improve large language models\u2019 capability to recognize the boundaries of their knowledge, we propose a novel approach called uncertainty-sensitive tuning. this method in- volves two-stage training designed for uncer- tainty recognition and prompt-sensitive activa- tion. in the first stage, we guide the llm to reject unknown questions. in the second stage, we recover the decreased performance in qa tasks by incorporating designed causal instruc- tions. by leveraging this method, we aim to en- hance the model\u2019s ability to identify areas of un- certainty. the experimental results demonstrate that our proposed uncertainty-sensitive tuning method significantly improves the performance of the llama2-chat-7b model. specifically, it achieves a substantial 34.7% improvement in handling questions involving knowledge gaps compared to the original model. moreover, our approach outperforms gpt-4, exhibiting a 9.4% increase in overall performance. we open-source the model and code on github1. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10118",
        "label": 1,
        "title": "seacrowd: a multilingual multimodal data hub and benchmark suite for southeast asian languages holy lovenia",
        "abstract": "southeast asia (sea) is a region rich in lin- guistic diversity and cultural variety, with over 1,300 indigenous languages and a population of 671 million people. however, prevailing ai models suffer from a significant lack of repre- sentation of texts, images, and audio datasets from sea, compromising the quality of ai models for sea languages. evaluating models for sea languages is challenging due to the scarcity of high-quality datasets, compounded by the dominance of english training data, rais- ing concerns about potential cultural misrep- resentation. to address these challenges, we introduce seacrowd, a collaborative initia- tive that consolidates a comprehensive resource hub1that fills the resource gap by providing standardized corpora2in nearly 1,000 sea lan- guages across three modalities. through our seacrowd benchmarks, we assess the qual- ity of ai models on 36 indigenous languages across 13 tasks, offering valuable insights into the current ai landscape in sea. furthermore, we propose strategies to facilitate greater ai ad- vancements, maximizing potential utility and resource equity for the future of ai in sea. 1https://seacrowd.github.io/seacrowd-catalogue/ 2https://github.com/seacrowd/seacrowd-datahub/"
    },
    {
        "url": "https://arxiv.org/pdf/2406.10130",
        "label": 0,
        "title": "published as a conference paper at iclr 2024 thedevil is in the neurons : interpreting and mitigating social b",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.10172",
        "label": 1,
        "title": "datasets for multilingual answer sentence selection matteo gabburo1",
        "abstract": "answer sentence selection (as2) is a criti- cal task for designing effective retrieval-based question answering (qa) systems. most ad- vancements in as2 focus on english due to the scarcity of annotated datasets for other languages. this lack of resources prevents the training of effective as2 models in dif- ferent languages, creating a performance gap between qa systems in english and other lo- cales. in this paper, we introduce new high- quality datasets for as2 in five european lan- guages (french, german, italian, portuguese, and spanish), obtained through supervised au- tomatic machine translation (amt) of ex- isting english as2 datasets such as asnq, wikiqa, and trec-qa using a large lan- guage model (llm). we evaluated our ap- proach and the quality of the translated datasets through multiple experiments with different transformer architectures. the results indicate that our datasets are pivotal in producing robust and powerful multilingual as2 models, signifi- cantly contributing to closing the performance gap between english and other languages. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10173",
        "label": 1,
        "title": "intention qa: a benchmark for evaluating purchase intention comprehension abilities of language models in e-co",
        "abstract": "enhancing language models\u2019 (lms) ability to understand purchase intentions in e-commerce scenarios is crucial for their effective assis- tance in various downstream tasks. how- ever, previous approaches that distill inten- tions from lms often fail to generate mean- ingful and human-centric intentions applica- ble in real-world e-commerce contexts. this raises concerns about the true comprehension and utilization of purchase intentions by lms. in this paper, we present intention qa, a double-task multiple-choice question answer- ing benchmark to evaluate lms\u2019 comprehen- sion of purchase intentions in e-commerce. specifically, lms are tasked to infer inten- tions based on purchased products and uti- lize them to predict additional purchases. in- tention qa consists of 4,360 carefully cu- rated problems across three difficulty levels, constructed using an automated pipeline to ensure scalability on large e-commerce plat- forms. human evaluations demonstrate the high quality and low false-negative rate of our benchmark. extensive experiments across 19 language models show that they still strug- gle with certain scenarios, such as understand- ing products and intentions accurately, jointly reasoning with products and intentions, and more, in which they fall far behind human performances. our code and data are pub- licly available at https://github.com/hkust- knowcomp/intentionqa. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.10203",
        "label": 0,
        "title": "a fundamental trade-off in aligned language models and its relation to sampling adaptors naaman tan",
        "abstract": "the relationship between the quality of a string and its probability p(y)under a language model has been influential in the development of techniques to build good text generation systems. for example, several decoding algorithms have been motivated to manipulate p(y)to produce higher-quality text. in this work, we examine the probability\u2013quality relationship in language models explicitly aligned to human preferences, e.g., through reinforcement learning through human feedback (rlhf). we find that, given a general language model and its aligned version, for corpora sampled from an aligned language model, there exists a trade-off between the average reward and average log-likelihood of the strings under the general language model. we provide a formal treatment of this issue and demonstrate how a choice of sampling adaptor allows for a selection of how much likelihood we exchange for the reward. https://github.com/tanyjnaaman/ probability-quality-paradox "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11873",
        "label": 0,
        "title": "logic-based explainability: past",
        "abstract": ". in recent years, the impact of machine learning (ml) and ar- ti\ufb01cial intelligence (ai) in society has been absolutely re markable. this impact is expected to continue in the foreseeable future. ho wever, the adoption of ai/ml is also a cause of grave concern. the operat ion of the most advances ai/ml models is often beyond the grasp of hu man decision makers. as a result, decisions that impact humans m ay not be understood and may lack rigorous validation. explainable a i (xai) is concerned with providing human decision-makers with under standable explanations for the predictions made by ml models. as a resu lt, xai is a cornerstone of trustworthy ai. despite its strategic impo rtance, most work on xai lacks rigor, and so its use in high-risk or safety- critical domains serves to foster distrust instead of contributing t o build much- needed trust. logic-based xai has recently emerged as a rigo rous alter- native to those other non-rigorous methods of xai. this pape r provides a technical survey of logic-based xai, its origins, the curr ent topics of re- search, and emerging future topics of research. the paper al so highlights the many myths that pervade non-rigorous approaches for xai . keywords: explainable ai \u00b7 symbolic ai \u00b7 formal explainability \u00b7 cer- ti\ufb01cation "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11888",
        "label": 0,
        "title": "neural logic programs and neural nets christian anti \u00b4c christian.antic",
        "abstract": ". neural-symbolic integration aims to combine the connecti onist subsymbolic with the logical symbolic approach to arti\ufb01cial intelligence. in this paper , we \ufb01rst de\ufb01ne the answer set semantics of (boolean) neural nets and then introduce from \ufb01rst principl es a class of neural logic programs and show that nets and programs are equivalent. 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.11897",
        "label": 1,
        "title": "a benchmark for maximum cut: towards standardization of the evaluation of learned heuristics for combinatorial",
        "abstract": "recently, there has been much work on the design of general heuristics for graph- based, combinatorial optimization problems via the incorporation of graph neural networks (gnns) to learn distribution-specific solution structures. however, there is a lack of consistency in the evaluation of these heuristics, in terms of the baselines and instances chosen, which makes it difficult to assess the relative performance of the algorithms. in this paper, we propose an open-source benchmark suite maxcut- bench dedicated to the np-hard maximum cut problem in both its weighted and unweighted variants, based on a careful selection of instances curated from diverse graph datasets. the suite offers a unified interface to various heuristics, both traditional and machine learning-based. next, we use the benchmark in an attempt to systematically corroborate or reproduce the results of several, popular learning- based approaches, including s2v-dqn [ 31], eco-dqn [ 4], among others, in terms of three dimensions: objective value ,generalization , and scalability . our empirical results show that several of the learned heuristics fail to outperform a naive greedy algorithm, and that only one of them consistently outperforms tabu search, a simple, general heuristic based upon local search. furthermore, we find that the performance of eco-dqn remains the same or is improved if the gnn is replaced by a simple linear regression on a subset of the features that are related to tabu search. code, data, and pretrained models are available at: https://github.com/ankurnath/maxcut-bench . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11911",
        "label": 0,
        "title": "a notion of complexity for theory of mind via discrete world models x. angelo huang1",
        "abstract": "theory of mind (tom) can be used to assess the capabilities of large language models (llms) in complex scenarios where social reasoning is required. while the research community has proposed many tom benchmarks, their hard- ness varies greatly, and their complexity is not well defined. this work proposes a framework to measure the complexity of tom tasks. we quantify a problem\u2019s complexity as the number of states necessary to solve it correctly. our complexity measure also accounts for spurious states of a tom problem designed to make it apparently harder. we use our method to as- sess the complexity of five widely adopted tom benchmarks. on top of this framework, we de- sign a prompting technique that augments the information available to a model with a descrip- tion of how the environment changes with the agents\u2019 interactions. we name this technique discrete world models (dwm) and show how it elicits superior performance on tom tasks. https://github.com/flecart/ complexity-tom-dwm "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11915",
        "label": 1,
        "title": "minicodeprops: a minimal benchmark for proving code properties evan lohn",
        "abstract": "neural networks have shown initial promise in automating mathematical theorem proving in proof assistants such as lean. the same proof assistants can be used to verify the correctness of code by pairing code with specifications and proofs that the specifications hold. automating the writing of code, specifications, and proofs could lower the cost of verification, or, ambitiously, enable a machine learning sys- tem to output provably correct code. however, it remains unclear whether current neural theorem provers can automatically verify even relatively simple programs. we present minicodeprops , a benchmark of 177 program specifications in the lean proof assistant, aimed at the subproblem of automatically generating a proof for a provided program and specification. minicodeprops contains specifications about simple, self-contained programs (e.g., lists, natural numbers, binary trees) with varied proof difficulty. despite its simplicity, minicodeprops is challenging for current llm-based provers, which succeed in proving about 25 percent of the specifications. we publicly release minicodeprops as a benchmark for furthering automated theorem proving in the context of formally verified code. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11920",
        "label": 1,
        "title": "job-sdf: a multi-granularity dataset for job skill demand forecasting and benchmarking xi chen1",
        "abstract": "in a rapidly evolving job market, skill demand forecasting is crucial as it enables policymakers and businesses to anticipate and adapt to changes, ensuring that workforce skills align with market needs, thereby enhancing productivity and competitiveness. additionally, by identifying emerging skill requirements, it directs individuals towards relevant training and education opportunities, promoting continuous self-learning and development. however, the absence of comprehensive datasets presents a significant challenge, impeding research and the advancement of this field. to bridge this gap, we present job-sdf , a dataset designed to train and benchmark job-skill demand forecasting models. based on 10.35 million public job advertisements collected from major online recruitment platforms in china between 2021 and 2023, this dataset encompasses monthly recruitment demand for 2,324 types of skills across 521 companies. our dataset uniquely enables evaluating skill demand forecasting models at various granularities, including occupation, company, and regional levels. we benchmark a range of models on this dataset, evaluating their performance in standard scenarios, in predictions focused on lower value ranges, and in the presence of structural breaks, providing new insights for further research. our code and dataset are publicly accessible via the https://github.com/job-sdf/benchmark . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11928",
        "label": 0,
        "title": "flexcare: leveraging cross-task synergy for flexible multimodal healthcare prediction muhao xu",
        "abstract": "multimodal electronic health record (ehr) data can offer a holistic assessment of a patient\u2019s health status, supporting various predic- tive healthcare tasks. recently, several studies have embraced the multitask learning approach in the healthcare domain, exploiting the inherent correlations among clinical tasks to predict multi- ple outcomes simultaneously. however, existing methods necessi- tate samples to possess complete labels for all tasks, which places heavy demands on the data and restricts the flexibility of the model. meanwhile, within a multitask framework with multimodal in- puts, how to comprehensively consider the information disparity among modalities and among tasks still remains a challenging prob- lem. to tackle these issues, a unified healthcare prediction model, also named by flexcare , is proposed to flexibly accommodate in- complete multimodal inputs, promoting the adaption to multiple healthcare tasks. the proposed model breaks the conventional par- adigm of parallel multitask prediction by decomposing it into a series of asynchronous single-task prediction. specifically, a task- agnostic multimodal information extraction module is presented to capture decorrelated representations of diverse intra- and inter- modality patterns. taking full account of the information disparities between different modalities and different tasks, we present a task- guided hierarchical multimodal fusion module that integrates the \u2217corresponding author. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than the author(s) must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. kdd \u201924, august 25\u201329, 2024, barcelona, spain \u00a92024 copyright held by the owner/author(s). publication rights licensed to acm. acm isbn 979-8-4007-0490-1/24/08 https://doi.org/10.1145/3637528.3671974refined modality-level representations into an individual patient- level representation. experimental results on multiple tasks from mimic-iv/mimic-cxr/mimic-note datasets demonstrate the effectiveness of the proposed method. additionally, further anal- ysis underscores the feasibility and potential of employing such a multitask strategy in the healthcare domain. the source code is available at https://github.com/mhxu1998/flexcare. ccs concepts \u2022applied computing \u2192health informatics ;\u2022information systems\u2192data mining . keywords electronic health record, healthcare prediction, multimodal data, multitask learning acm reference format: muhao xu, zhenfeng zhu, youru li, shuai zheng, yawei zhao, kunlun he, and yao zhao. 2024. flexcare: leveraging cross-task synergy for flexible multimodal healthcare prediction. in proceedings of the 30th acm sigkdd conference on knowledge discovery and data mining (kdd \u201924), august 25\u201329, 2024, barcelona, spain. acm, new york, ny, usa, 11 pages. https: //doi.org/10.1145/3637528.3671974 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11931",
        "label": 0,
        "title": "deepseek-coder-v2: breaking the barrier of closed-source models in code intelligence qihao zhu",
        "abstract": "we present deepseek-coder-v2, an open-source mixture-of-experts (moe) code language model that achieves performance comparable to gpt4-turbo in code-specific tasks. specifically, deepseek-coder-v2 is further pre-trained from an intermediate checkpoint of deepseek-v2 with additional 6 trillion tokens. through this continued pre-training, deepseek-coder-v2 substantially enhances the coding and mathematical reasoning capabilities of deepseek-v2, while maintaining comparable performance in general language tasks. compared to deepseek- coder-33b, deepseek-coder-v2 demonstrates significant advancements in various aspects of code-related tasks, as well as reasoning and general capabilities. additionally, deepseek-coder- v2 expands its support for programming languages from 86 to 338, while extending the context length from 16k to 128k. in standard benchmark evaluations, deepseek-coder-v2 achieves superior performance compared to closed-source models such as gpt4-turbo, claude 3 opus, and gemini 1.5 pro in coding and math benchmarks. humaneval mbpp+ math gsm8k5060708090100accuracy (%)90.2 76.275.794.9 88.2 72.273.493.7 83.5 74.6 67.790.8 84.9 72.0 60.195.0 81.7 69.0 50.493.0 81.1 68.2 aider livecodebench swe-bench01020304050607080 73.7 43.4 12.763.9 45.7 18.357.1 34.1 18.768.4 34.6 11.749.2 28.751.1 31.0 2.7deepseek-coder-v2 gpt-4-turbo-0409 gemini-1.5-pro claude-3-opus llama-3-70b codestral figure 1|the performance of deepseek-coder-v2 on math and code benchmarks. *core contributorsarxiv:2406.11931v1  [cs.se]  17 jun 20241"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12020",
        "label": 0,
        "title": "when box meets graph neural network in tag-aware recommendation fake lin",
        "abstract": "last year has witnessed the re-flourishment of tag-aware recom- mender systems supported by the llm-enriched tags. unfortu- nately, though large efforts have been made, current solutions may fail to describe the diversity and uncertainty inherent in user prefer- ences with only tag-driven profiles. recently, with the development of geometry-based techniques, e.g., box embedding, diversity of user preferences now could be fully modeled as the range within a box in high dimension space. however, defect still exists as these approaches are incapable of capturing high-order neighbor signals, i.e., semantic-rich multi-hop relations within the user-tag-item tripartite graph, which severely limits the effectiveness of user modeling. to deal with this challenge, in this paper, we propose a novel algorithm, called boxgnn, to perform the message aggrega- tion via combination of logical operations, thereby incorporating high-order signals. specifically, we first embed users, items, and tags as hyper-boxes rather than simple points in the representation space, and define two logical operations to facilitate the subsequent process. next, we perform the message aggregation mechanism via the combination of logical operations, to obtain the corresponding high-order box representations. finally, we adopt a volume-based learning objective with gumbel smoothing techniques to refine \u2217corresponding author. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than the author(s) must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. kdd \u201924, august 25\u201329, 2024, barcelona, spain \u00a92024 copyright held by the owner/author(s). publication rights licensed to acm. acm isbn 979-8-4007-0490-1/24/08 https://doi.org/10.1145/3637528.3671973the representation of boxes. extensive experiments on two pub- licly available datasets and one llm-enhanced e-commerce dataset have validated the superiority of boxgnn compared with various state-of-the-art baselines. the code is released online1. ccs concepts \u2022information systems \u2192recommender systems . keywords tag-aware recommendation, box embedding, graph neural net- works acm reference format: fake lin, ziwei zhao, xi zhu, da zhang, shitian shen, xueying li, tong xu, suojuan zhang, and enhong chen. 2024. when box meets graph neural network in tag-aware recommendation. in proceedings of the 30th acm sigkdd conference on knowledge discovery and data mining (kdd \u201924), august 25\u201329, 2024, barcelona, spain. acm, new york, ny, usa, 11 pages. https://doi.org/10.1145/3637528.3671973 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11978",
        "label": 0,
        "title": "dialogue action tokens: steering language models in goal-directed dialogue with a multi-turn planner kenneth l",
        "abstract": "we present an approach called dialogue action tokens (dat) that adapts language model agents to plan goal-directed dialogues. the core idea is to treat each utterance as an action, thereby converting dialogues into games where existing approaches such as reinforcement learning can be applied. specifically, we freeze a pretrained language model and train a small planner model that predicts a continuous action vector, used for controlled generation in each round. this design avoids the problem of language degradation under reward optimization. when evaluated on the sotopia platform for social simulations, the dat-steered llama model surpasses gpt-4\u2019s performance. we also apply dat to steer an attacker language model in a novel multi-turn red-teaming setting, revealing a potential new attack surface. code: https://github.com/likenneth/dialogue_action_token . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12465",
        "label": 0,
        "title": "rigl: a unified reciprocal approach for tracing the independent and group learning processes xiaoshan yu",
        "abstract": "in the realm of education, both independent learning and group learning are esteemed as the most classic paradigms. the former allows learners to self-direct their studies, while the latter is typi- cally characterized by teacher-directed scenarios. recent studies in the field of intelligent education have leveraged deep tempo- ral models to trace the learning process, capturing the dynamics of students\u2019 knowledge states, and have achieved remarkable per- formance. however, existing approaches have primarily focused on modeling the independent learning process, with the group learning paradigm receiving less attention. moreover, the recip- rocal effect between the two learning processes, especially their combined potential to foster holistic student development, remains inadequately explored. to this end, in this paper, we propose rigl , a unified reciprocal model to trace knowledge states at both the individual and group levels, drawing from the independent and group learning processes. specifically, we first introduce a time \u2217work was done at career science lab, boss zhipin supervised by chuan qin. \u2020corresponding authors. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than acm must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. kdd \u201924, august 25\u201329, 2024, barcelona, spain \u00a92024 association for computing machinery. acm isbn 978-x-xxxx-xxxx-x/yy/mm. . . $15.00 https://doi.org/xxxxxxx.xxxxxxxframe-aware reciprocal embedding module to concurrently model both student and group response interactions across various time frames. subsequently, we employ reciprocal enhanced learning modeling to fully exploit the comprehensive and complementary information between the two behaviors. furthermore, we design a relation-guided temporal attentive network, comprised of dynamic graph modeling coupled with a temporal self-attention mechanism. it is used to delve into the dynamic influence of individual and group interactions throughout the learning processes, which is crafted to explore the dynamic intricacies of both individual and group interactions during the learning sequences. conclusively, we introduce a bias-aware contrastive learning module to bolster the stability of the model\u2019s training. extensive experiments on four real-world educational datasets clearly demonstrate the effec- tiveness of the proposed rigl model. our codes are available at https://github.com/labyrinthineleo/rigl. ccs concepts \u2022information systems \u2192data mining ;\u2022applied computing \u2192collaborative learning . keywords intelligent education, knowledge tracing, group learning, reciprocal effect, dynamic graph neural network acm reference format: xiaoshan yu, chuan qin, dazhong shen, shangshang yang, haiping ma, hengshu zhu, and xingyi zhang. 2024. rigl: a unified reciprocal ap- proach for tracing the independent and group learning processes . inarxiv:2406.12465v1  [cs.cy]  18 jun 2024kdd \u201924, august 25\u201329, 2024, barcelona, spain xiaoshan yu et al. figure 1: an illustrative example of the holistic knowledge tracing (hkt) task. the top and bottom halves indicate the individual and group learning processes, respectively, which are organized in time frames, and the radar chart in the middle represents the knowledge proficiency levels of both. proceedings of the 30th acm sigkdd conference on knowledge discovery and data mining(kdd \u201924), august 25\u201329, 2024, barcelona, spain. acm, new york, ny, usa, 12 pages. https://doi.org/xxxxxxx.xxxxxxx "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12080",
        "label": 0,
        "title": "a hierarchical 3d gaussian representation for real-time rendering of very large datasets bernhard kerbl",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12095",
        "label": 0,
        "title": "distillnerf: perceiving 3d scenes from single-glance images by distilling neural fields and foundation model f",
        "abstract": "we propose distillnerf, a self-supervised learning framework addressing the challenge of understanding 3d environments from limited 2d observations in au- tonomous driving. our method is a generalizable feedforward model that predicts a rich neural scene representation from sparse, single-frame multi-view camera inputs, and is trained self-supervised with differentiable rendering to reconstruct rgb, depth, or feature images. our first insight is to exploit per-scene optimized neural radiance fields (nerfs) by generating dense depth and virtual camera targets for training, thereby helping our model to learn 3d geometry from sparse non-overlapping image inputs. second, to learn a semantically rich 3d representa- tion, we propose distilling features from pre-trained 2d foundation models, such as clip or dinov2, thereby enabling various downstream tasks without the need for costly 3d human annotations. to leverage these two insights, we introduce a novel model architecture with a two-stage lift-splat-shoot encoder and a parameterized sparse hierarchical voxel representation. experimental results on the nuscenes dataset demonstrate that distillnerf significantly outperforms existing compara- ble self-supervised methods for scene reconstruction, novel view synthesis, and depth estimation; and it allows for competitive zero-shot 3d semantic occupancy prediction, as well as open-world scene understanding through distilled foundation model features. demos and code will be available at https://distillnerf.github.io/. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12208",
        "label": 0,
        "title": "knowledge fusion by evolving weights of language models guodong du1jing li1",
        "abstract": "fine-tuning pre-trained language models, par- ticularly large language models, demands ex- tensive computing resources and can result in varying performance outcomes across different domains and datasets. this paper examines the approach of integrating multiple models from diverse training scenarios into a unified model. this unified model excels across various data domains and exhibits the ability to generalize well on out-of-domain data. we propose a knowledge fusion method named evolver , in- spired by evolutionary algorithms, which does not need further training or additional training data. specifically, our method involves aggre- gating the weights of different language mod- els into a population and subsequently gener- ating offspring models through mutation and crossover operations. these offspring models are then evaluated against their parents, allow- ing for the preservation of those models that show enhanced performance on development datasets. importantly, our model evolving strat- egy can be seamlessly integrated with existing model merging frameworks, offering a versa- tile tool for model enhancement. experimental results on mainstream language models (i.e., encoder-only, decoder-only, encoder-decoder) reveal that evolver outperforms previous state- of-the-art models by large margins. the code is publicly available at https://github.com/ duguodong7/model-evolution . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12211",
        "label": 0,
        "title": "pcie lam solution for ego4d looking at me challenge kanokphan lertniphonphan lenovo research",
        "abstract": "this report presents our team\u2019s \u2019pcie lam\u2019 solution for the ego4d looking at me challenge at cvpr2024. the main goal of the challenge is to accurately determine if a person in the scene is looking at the camera wearer, based on a video where the faces of social partners have been lo- calized. our proposed solution, internlstm, consists of an internvl image encoder and a bi-lstm network. the in- ternvl extracts spatial features, while the bi-lstm extracts temporal features. however, this task is highly challenging due to the distance between the person in the scene and the camera movement, which results in significant blurring in the face image. to address the complexity of the task, we implemented a gaze smoothing filter to eliminate noise or spikes from the output. our approach achieved the 1stposi- tion in the looking at me challenge with 0.81 map and 0.93 accuracy rate. code is available at https://github. com/kanokphanl/ego4d_lam_internlstm 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12214",
        "label": 1,
        "title": "is your hd map constructor reliable under sensor corruptions? xiaoshuai hao1mengchuan wei1yifan yang1haimei zh",
        "abstract": "driving systems often rely on high-definition (hd) maps for precise environmental information, which is crucial for planning and navigation. while current hd map constructors perform well under ideal conditions, their resilience to real-world challenges, e.g., adverse weather and sensor failures, is not well understood, rais- ing safety concerns. this work introduces mapbench , the first comprehensive benchmark designed to evaluate the robustness of hd map construction methods against various sensor corruptions. our benchmark encompasses a total of 29types of corruptions that occur from cameras and lidar sensors. extensive evaluations across 31hd map constructors reveal significant performance degradation of ex- isting methods under adverse weather conditions and sensor failures, underscoring critical safety concerns. we identify effective strategies for enhancing robustness, including innovative approaches that leverage multi-modal fusion, advanced data augmentation, and architectural techniques. these insights provide a pathway for developing more reliable hd map construction methods, which are essential for the advancement of autonomous driving technology. the benchmark toolkit and affiliated code and model checkpoints have been made publicly accessible. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12219",
        "label": 0,
        "title": "pcie egohandpose solution for egoexo4d hand pose challenge feng chen lenovo research",
        "abstract": "this report presents our team\u2019s \u2019pcie egohandpose\u2019 solution for the egoexo4d hand pose challenge at cvpr2024. the main goal of the challenge is to accurately estimate hand poses, which involve 21 3d joints, using an rgb egocentric video images provided for the task. this task is particularly challenging due to the subtle movements and occlusions. to handle the complexity of the task, we propose the hand pose vision transformer (hp-vit). the hp-vit comprises a vit backbone and transformer head to estimate joint positions in 3d, utilizing mpjpe and rle loss function. our approach achieved the 1stposition in the hand pose challenge with 25.51 mpjpe and 8.49 pa- mpjpe. code is available at https://github.com/ kanokphanl/pcie_egohandpose 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12235",
        "label": 1,
        "title": "holmes-vad : towards unbiased and explainable video anomaly detection via multi-modal llm huaxin zhang1",
        "abstract": "towards open-ended video anomaly detection (v ad), existing methods often exhibit biased detection when faced with challenging or unseen events and lack interpretability. to address these drawbacks, we propose holmes-v ad, a novel framework that leverages precise temporal supervision and rich multimodal in- structions to enable accurate anomaly localization and comprehensive explanations. firstly, towards unbiased and explainable v ad system, we construct the first large- scale multimodal v ad instruction-tuning benchmark, i.e.,vad-instruct50k . this dataset is created using a carefully designed semi-automatic labeling paradigm. efficient single-frame annotations are applied to the collected untrimmed videos, which are then synthesized into high-quality analyses of both abnormal and normal video clips using a robust off-the-shelf video captioner and a large language model (llm). building upon the vad-instruct50k dataset, we develop a customized solution for interpretable video anomaly detection. we train a lightweight temporal sampler to select frames with high anomaly response and fine-tune a multimodal large language model (llm) to generate explanatory content. extensive experimen- tal results validate the generality and interpretability of the proposed holmes-vad , establishing it as a novel interpretable technique for real-world video anomaly analysis. to support the community, our benchmark and model will be publicly available at https://github.com/pipixin321/holmesvad . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12246",
        "label": 0,
        "title": "trol: traversal of layers for large language and vision models byung-kwan lee kaist",
        "abstract": "large language and vision models (llvms) have been driven by the generalization power of large language models (llms) and the advent of visual instruction tuning. along with scaling them up directly, these models enable llvms to showcase powerful vision language (vl) performances by covering di- verse tasks via natural language instructions. however, existing open-source llvms that perform comparably to closed-source llvms such as gpt-4v are often considered too large (e.g., 26b, 34b, and 110b parameters), hav- ing a larger number of layers. these large models demand costly, high-end resources for both training and inference. to address this issue, we present a new efficient llvm fam- ily with 1.8b, 3.8b, and 7b llm model sizes, traversal oflayers (  trol ), which enables the reuse of layers in a token-wise manner. this layer traversing technique simulates the effect of looking back and retracing the answering stream while increasing the number of forward propagation layers without physically adding more layers. we demonstrate that  trol employs a simple layer traversing approach yet efficiently outperforms the open-source llvms with larger model sizes and rivals the performances of the closed-source llvms with substantial sizes. code is available in https://github.com/byungkwanlee/trol. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12256",
        "label": 0,
        "title": "symmetric multi-similarity loss for epic-kitchens-100 multi-instance retrieval challeng e 2024 xiaoqi wang yi ",
        "abstract": "in this report, we present our champion solution for epic-kitchens-100 multi-instance retrieval challenge in cvpr 2024. essentially, this challenge differs from traditional visual-text retrieval tasks by providing a cor - relation matrix that acts as a set of soft labels for video- text clip combinations. however, existing loss functions have not fully exploited this information. motivated by this, we propose a novel loss function, symmetric multi- similarity loss, which offers a more precise learning ob- jective. together with tricks and ensemble learning, the model achieves 63.76% average map and 74.25% average ndcg on the public leaderboard, demonstrating the effec- tiveness of our approach. our code will be released at: https://github.com/xqwang14/sms-loss . 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12321",
        "label": 0,
        "title": "automatic benchmarking of large multimodal models via iterative experiment programming alessandro conti1",
        "abstract": "assessing the capabilities of large multimodal models (lmms) often requires the creation of ad-hoc evaluations. currently, building new benchmarks requires tremendous amounts of manual work for each specific analysis. this makes the evaluation process tedious and costly. in this paper, we present ape x,auto- matic programming of experiments , the first framework for automatic benchmarking of lmms. given a research question expressed in natural language, ape xleverages a large language model (llm) and a library of pre-specified tools to generate a set of experiments for the model at hand, and progressively compile a scientific report. the report drives the testing procedure: based on the current status of the investigation, ape xchooses which experiments to perform and whether the results are sufficient to draw conclusions. finally, the llm refines the report, presenting the results to the user in natural language. thanks to its modularity, our framework is flexible and extensible as new tools become available. empirically, ape xreproduces the findings of existing studies while allowing for arbitrary anal- yses and hypothesis testing. code is available at https://github.com/altndrr/apex. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12384",
        "label": 1,
        "title": "vrsbench: a versatile vision-language benchmark dataset for remote sensing image understanding xiang li jian d",
        "abstract": "we introduce a new benchmark designed to advance the development of general- purpose, large-scale vision-language models for remote sensing images. although several vision-language datasets in remote sensing have been proposed to pursue this goal, existing datasets are typically tailored to single tasks, lack detailed object information, or suffer from inadequate quality control. exploring these improvement opportunities, we present a versatile vision-language bench mark forremote sensing image understanding, termed vrsbench . this benchmark comprises 29,614 images, with 29,614 human-verified detailed captions, 52,472 object references, and 123,221 question-answer pairs. it facilitates the training and evaluation of vision-language models across a broad spectrum of remote sensing image understanding tasks. we further evaluated state-of-the-art models on this benchmark for three vision-language tasks: image captioning, visual grounding, and visual question answering. our work aims to significantly contribute to the development of advanced vision-language models in the field of remote sensing. the data and code can be accessed at https://vrsbench.github.io . the high-resolution  aerial  image  from  googleearth  shows  a waterfront  scene  with residential  areas  and  harbor  facilities . three  distinct  harbors  can be seen,  one located  on the left side and another  on the right  side of the image . between  them,  there  are homes  with different  colored  rooftops,  green  lawns,  and  driveways . a ship is docked  in the central  part of the bottom  edge,  and the water  body  exhibits  gentle   ripples . various  small  vehicles  are scattered  throughout  the residential  area,  parked  near the houses .question : how  many  harbors  are visible? answer : 3 question : what  is the object  located  furthest  to the top? answer : small vehicle question : are the visible  vehicles  near water? answer : noobject referring detailed captioningvisual question answer 1 3 4 572 0 6object  id=1:the small  vehicle  that is the farthest  to the top. object  id=4:the harbor  located  on the left side of the scene  with multiple  docks  extending  into the water . object  id=7:the harbor  situated  on the right  side of the image  with a large  dock  area. figure 1: examples of an image and corresponding annotations in vrsbench dataset. our annotations include object referring, visual question answering, and detailed captions. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12407",
        "label": 0,
        "title": "looc: localizing organs using occupancy networks and body surface depth images pit henrich1and",
        "abstract": ". we introduce a novel method employing occupancy networks for the precise localization of 67 anatomical structures from single depth images captured from the exterior of the human body. this method considers the anatomical diversity across individuals. our contributions include the application of occupancy networks for occluded structure localization, a robust method for estimating anatomical positions from depth images, and the creation of detailed, individualized 3d anatom- ical atlases. this approach promises improvements in medical imaging and automated diagnostic procedures by offering accurate, non-invasive localization of critical anatomical features. keywords: localization of anatomical structures \u00b7patient-individual 3d atlas \u00b7occupancy networks. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12448",
        "label": 1,
        "title": "journal of machine learning for biomedical imaging 2024:012 vol. 2",
        "abstract": "the emergence of clinical data warehouses (cdws), which contain the medical data of millions of patients, has paved the way for vast data sharing for research. the quality of mris gathered in cdws differs greatly from what is observed in research settings and reflects a certain clinical reality. consequently, a significant proportion of these images turns out to be unusable due to their poor quality. given the massive volume of mris contained in cdws, the manual rating of image quality is impossible. thus, it is necessary to develop an automated solution capable of effectively identifying corrupted images in cdws. \u00a92024 . license: cc-by 4.0 https://doi.org/10.59275/j.melba.2024-7fgdarxiv:2406.12448v1  [eess.iv]  18 jun 2024automated mri quality assessment in clinical data warehouses: this study presents an innovative transfer learning method for automated quality con- trol of 3d gradient echo t1-weighted brain mris within a cdw, leveraging artefact sim- ulation. we first intentionally corrupt images from research datasets by inducing poorer contrast, adding noise and introducing motion artefacts. subsequently, three artefact- specific models are pre-trained using these corrupted images to detect distinct types of artefacts. finally, the models are generalised to routine clinical data through a transfer learning technique, utilising 3660 manually annotated images. the overall image quality is inferred from the results of the three models, each designed to detect a specific type of artefact. our method was validated on an independent test set of 385 3d gradient echo t1-weighted mris. our proposed approach achieved excellent results for the detection of bad quality mris, with a balanced accuracy of over 87%, surpassing our previous approach by 3.5 percent points. additionally, we achieved a satisfactory balanced accuracy of 79% for the detection of moderate quality mris, outperforming our previous performance by 5 percent points. our framework provides a valuable tool for exploiting the potential of mris in cdws. keywords: clinical data warehouse, deep learning, transfer learning, quality control, mri 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12463",
        "label": 0,
        "title": "journal of l atex class files",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12496",
        "label": 0,
        "title": "reparameterizable dual-resolution network for real-time semantic segmentation guoyu yang",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12638",
        "label": 0,
        "title": "efficient and long-tailed generalization for pre-trained vision-language model jiang-xin shi",
        "abstract": "pre-trained vision-language models like clip have shown powerful zero-shot inference ability via image-text matching and prove to be strong few-shot learners in various downstream tasks. however, in real-world scenarios, adapting clip to downstream tasks may encounter the following challenges: 1) data may exhibit long-tailed data distributions and might not have abundant samples for all the classes; 2) there might be emerging tasks with new classes that contain no samples at all. to overcome them, we propose a novel framework to achieve efficient and long-tailed generalization, which can be termed as candle . during the training process, we propose compensating logit-adjusted loss to encourage large mar- gins of prototypes and alleviate imbalance both within the base classes and between the base and new classes. for efficient adap- tation, we treat the clip model as a black box and leverage the extracted features to obtain visual and textual prototypes for predic- tion. to make full use of multi-modal information, we also propose cross-modal attention to enrich the features from both modalities. for effective generalization, we introduce virtual prototypes for new classes to make up for their lack of training images. candle achieves state-of-the-art performance over extensive experiments on 11 diverse datasets while substantially reducing the training time, demonstrating the superiority of our approach. the source code is available at https://github.com/shijxcs/candle. ccs concepts \u2022computing methodologies \u2192supervised learning . \u2217equal contribution. \u2020corresponding author. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. copyrights for components of this work owned by others than the author(s) must be honored. abstracting with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. kdd \u201924, august 25\u201329, 2024, barcelona, spain. \u00a92024 copyright held by the owner/author(s). publication rights licensed to acm. acm isbn 979-8-4007-0490-1/24/08 https://doi.org/10.1145/3637528.3671945keywords long-tail learning, vision-language model, new class generalization acm reference format: jiang-xin shi, chi zhang, tong wei, and yu-feng li. 2024. efficient and long-tailed generalization for pre-trained vision-language model. in pro- ceedings of the 30th acm sigkdd conference on knowledge discovery and data mining (kdd \u201924), august 25\u201329, 2024, barcelona, spain. acm, new york, ny, usa, 11 pages. https://doi.org/10.1145/3637528.3671945 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12649",
        "label": 0,
        "title": "probabilistic conceptual explainers: trustworthy conceptual explanations for vision foundation models hengyi w",
        "abstract": "vision transformers (vits) have emerged as a significant area of focus, particularly for their ca- pacity to be jointly trained with large language models and to serve as robust vision foundation models. yet, the development of trustworthy ex- planation methods for vits has lagged, partic- ularly in the context of post-hoc interpretations of vit predictions. existing sub-image selection approaches, such as feature-attribution and con- ceptual models, fall short in this regard. this pa- per proposes five desiderata for explaining vits \u2013 faithfulness, stability, sparsity, multi-level struc- ture, and parsimony \u2013 and demonstrates the in- adequacy of current methods in meeting these criteria comprehensively. we introduce a varia- tional bayesian explanation framework, dubbed probabilistic concept explainers (pace), which models the distributions of patch embeddings to provide trustworthy post-hoc conceptual explana- tions. our qualitative analysis reveals the distri- butions of patch-level concepts, elucidating the effectiveness of vits by modeling the joint distri- bution of patch embeddings and vit\u2019s predictions. moreover, these patch-level explanations bridge the gap between image-level and dataset-level ex- planations, thus completing the multi-level struc- ture of pace. through extensive experiments on both synthetic and real-world datasets, we demon- strate that pace surpasses state-of-the-art meth- ods in terms of the defined desiderata1. *equal contribution1department of computer science, rutgers university, new jersey, usa. correspondence to: hengyi wang <hengyi.wang@rutgers.edu >. proceedings of the 41stinternational conference on machine learning , vienna, austria. pmlr 235, 2024. copyright 2024 by the author(s). 1code will soon be available at https://github.com/wang-ml- lab/interpretable-foundation-models1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12671",
        "label": 1,
        "title": "geobench: benchmarking and analyzing monocular geometry estimation models yongtao ge1",
        "abstract": "recent advances in discriminative and generative pretraining have yielded geometry estimation models with strong generalization capabilities. while discriminative monocular geometry estimation methods rely on large-scale fine-tuning data to achieve zero-shot generalization, several generative-based paradigms show the potential of achieving impressive generalization performance on unseen scenes by leveraging pre-trained diffusion models and fine-tuning on even a small scale of synthetic training data. frustratingly, these models are trained with different recipes on different datasets, making it hard to find out the critical factors that determine the evaluation performance. besides, the current widely used geometry evaluation benchmarks have two main drawbacks that may prevent the development of the field, i.e.,limited scene diversity andunfavorable label quality . to resolve the above issues, (1) we build fair and strong baselines in a unified codebase for evaluating and analyzing the state-of-the-art (sota) geometry estimation models in terms of both different finetuning paradigms and training recipes; (2) we evaluate monocular geometry estimators on more challenging benchmarks for geometry estimation task with diverse scenes and high-quality annotations. our results reveal that pre-trained using large data, discriminative models such as dinov2, can outperform generative counterparts with a small amount of high-quality synthetic training data under the same training configuration, which suggests that fine-tuning data quality is a more important factor than the data scale and model architecture. our observation also raises a question: if simply fine-tuning a general vision model such as dinov2 using a small amount of synthetic depth data produces sota results, do we really need complex models, e.g., marigold [ koh+24] and depthfm [ gfp+24] for depth estimation? we believe that this work can propel advancements in geometry estimation tasks and a wide range of other downstream vision tasks. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12742",
        "label": 1,
        "title": "benchmarking multi-image understanding in vision and language models: perception",
        "abstract": "the advancement of large language models (llms) has significantly broadened the scope of applications in natural language processing, with multi-modal llms extending these capabilities to integrate and interpret visual data. however, existing benchmarks for visual language models (vlms) predominantly focus on single- image inputs, neglecting the crucial aspect of multi-image understanding. in this paper, we introduce a multi-image relational benchmark mirb , designed to evaluate vlms\u2019 ability to compare, analyze, and reason across multiple images. our benchmark encompasses four categories: perception, visual world knowledge, reasoning, and multi-hop reasoning. through a comprehensive evaluation of a wide range of open-source and closed-source models, we demonstrate that while open-source vlms were shown to approach the performance of gpt-4v in single- image tasks, a significant performance gap remains in multi-image reasoning tasks. our findings also reveal that even the state-of-the-art gpt-4v model struggles with our benchmark, underscoring the need for further research and development in this area. we believe our contribution of mirb could serve as a testbed for developing the next-generation multi-modal models. preprint. under review.arxiv:2406.12742v1  [cs.cv]  18 jun 2024"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12769",
        "label": 0,
        "title": "published as a conference paper at iclr 2024 latent intuitive physics : learning to transfer hidden physics fr",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": "https://arxiv.org/pdf/2406.12847",
        "label": 0,
        "title": "journal of l atex class files",
        "abstract": "Abstract or Introduction section not found on the first page"
    },
    {
        "url": " https://arxiv.org/pdf/2406.11911",
        "label": 0,
        "title": "a notion of complexity for theory of mind via discrete world models x. angelo huang1",
        "abstract": "theory of mind (tom) can be used to assess the capabilities of large language models (llms) in complex scenarios where social reasoning is required. while the research community has proposed many tom benchmarks, their hard- ness varies greatly, and their complexity is not well defined. this work proposes a framework to measure the complexity of tom tasks. we quantify a problem\u2019s complexity as the number of states necessary to solve it correctly. our complexity measure also accounts for spurious states of a tom problem designed to make it apparently harder. we use our method to as- sess the complexity of five widely adopted tom benchmarks. on top of this framework, we de- sign a prompting technique that augments the information available to a model with a descrip- tion of how the environment changes with the agents\u2019 interactions. we name this technique discrete world models (dwm) and show how it elicits superior performance on tom tasks. https://github.com/flecart/ complexity-tom-dwm "
    },
    {
        "url": "https://arxiv.org/pdf/2406.11944",
        "label": 0,
        "title": "transcoders find interpretable llm feature circuits jacob dunefsky",
        "abstract": "a key goal in mechanistic interpretability is circuit analysis: finding sparse sub- graphs of models corresponding to specific behaviors or capabilities. however, mlp sublayers make fine-grained circuit analysis on transformer-based language models difficult. in particular, interpretable features\u2014such as those found by sparse autoencoders (saes)\u2014are typically linear combinations of extremely many neu- rons, each with its own nonlinearity to account for. circuit analysis in this setting thus either yields intractably large circuits or fails to disentangle local and global behavior. to address this we explore transcoders , which seek to faithfully approx- imate a densely activating mlp layer with a wider, sparsely-activating mlp layer. we successfully train transcoders on language models with 120m, 410m, and 1.4b parameters, and find them to perform at least on par with saes in terms of sparsity, faithfulness, and human-interpretability. we then introduce a novel method for using transcoders to perform weights-based circuit analysis through mlp sublay- ers. the resulting circuits neatly factorize into input-dependent and input-invariant terms. finally, we apply transcoders to reverse-engineer unknown circuits in the model, and we obtain novel insights regarding the \u201cgreater-than circuit\u201d in gpt2- small. our results suggest that transcoders can prove effective in decomposing model computations involving mlps into interpretable circuits. code is available athttps://github.com/jacobdunefsky/transcoder_circuits . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12036",
        "label": 1,
        "title": "medcalc-bench : evaluating large language models for medical calculations nikhil khandekar",
        "abstract": "as opposed to evaluating computation and logic-based reasoning, current bench- marks for evaluating large language models (llms) in medicine are primarily focused on question-answering involving domain knowledge and descriptive rea- soning. while such qualitative capabilities are vital to medical diagnosis, in real- world scenarios, doctors frequently use clinical calculators that follow quantitative equations and rule-based reasoning paradigms for evidence-based decision support. to this end, we propose medcalc-bench , a first-of-its-kind dataset focused on evaluating the medical calculation capability of llms. medcalc-bench contains an evaluation set of over 1000 manually reviewed instances from 55 dif- ferent medical calculation tasks. each instance in medcalc-bench consists of a patient note, a question requesting to compute a specific medical value, a ground truth answer, and a step-by-step explanation showing how the answer is obtained. while our evaluation results show the potential of llms in this area, none of them are effective enough for clinical settings. common issues include extracting the incorrect entities, not using the correct equation or rules for a calculation task, or incorrectly performing the arithmetic for the computation. we hope our study highlights the quantitative knowledge and reasoning gaps in llms within medical settings, encouraging future improvements of llms for various clinical calculation tasks.1 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12045",
        "label": 1,
        "title": "\u03c4-bench: a benchmark for t ool-a gent-u ser interaction in real-world domains shunyu yao",
        "abstract": "existing benchmarks do not test language agents on their interaction with human users or ability to follow domain-specific rules, both of which are vital for deploying them in real world applications. we propose \u03c4-bench, a benchmark emulating dynamic conversations between a user (simulated by language models) and a language agent provided with domain-specific api tools and policy guidelines. we employ an efficient and faithful evaluation process that compares the database state at the end of a conversation with the annotated goal state. we also propose a new metric (pass^k) to evaluate the reliability of agent behavior over multiple trials. our experiments show that even state-of-the-art function calling agents (like gpt-4o ) succeed on <50% of the tasks, and are quite inconsistent (pass^8 < 25% in retail). our findings point to the need for methods that can improve the ability of agents to act consistently and follow rules reliably. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12050",
        "label": 0,
        "title": "learn beyond the answer: training language models with reflection for mathematical reasoning zhihan zhang\u00001\u2020",
        "abstract": "supervised fine-tuning enhances the problem- solving abilities of language models across var- ious mathematical reasoning tasks. to maxi- mize such benefits, existing research focuses onbroadening the training set with various data augmentation techniques, which is effective for standard single-round question-answering set- tings. our work introduces a novel technique aimed at cultivating a deeper understanding of the training problems at hand, enhancing perfor- mance not only in standard settings but also in more complex scenarios that require reflective thinking. specifically, we propose reflective augmentation , a method that embeds prob- lem reflection into each training instance. it trains the model to consider alternative perspec- tives and engage with abstractions and analo- gies, thereby fostering a thorough comprehen- sion through reflective reasoning. extensive experiments validate the achievement of our aim, underscoring the unique advantages of our method and its complementary nature relative to existing augmentation techniques.1 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12052",
        "label": 0,
        "title": "uniglm: training one unified language model for text-attributed graphs yi fang1",
        "abstract": "representation learning on text-attributed graphs (tags), where nodes are represented by textual descriptions, is crucial for textual and relational knowledge systems and recom- mendation systems. currently, state-of-the-art embedding methods for tags primarily focus on fine-tuning language models (e.g., bert) using structure-aware training signals. while effective, these methods are tailored for individ- ual tag and cannot generalize across various graph scenarios. given the shared textual space, leveraging multiple tags for joint fine-tuning, aligning text and graph structure from different aspects, would be more beneficial. motivated by this, we introduce a novel unified graph language model ( uniglm ) framework, the first graph embedding model that generalizes well to both in-domain and cross-domain tags. specifically, uniglm is trained over multiple tags with different domains and scales using self-supervised contrastive learning. uniglm includes an adaptive positive sample selection technique for identifying structurally similar nodes and a lazy contrastive module that is devised to accelerate training by minimizing repetitive encoding calculations. extensive empirical results across 9 benchmark tags demonstrate uniglm\u2019s efficacy against lead- ing embedding baselines in terms of general- ization (various downstream tasks and back- bones) and transfer learning (in and out of domain scenarios). the code is available at https://github.com/nyushcs/uniglm . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12060",
        "label": 0,
        "title": "not eliminate but aggregate: post-hoc control over mixture-of-experts to address shortcut shifts in natural la",
        "abstract": "recent models for natural language under- standing are inclined to exploit simple pat- terns in datasets, commonly known as short- cuts. these shortcuts hinge on spurious cor- relations between labels and latent features existing in the training data. at inference time, shortcut-dependent models are likely to generate erroneous predictions under dis- tribution shifts, particularly when some la- tent features are no longer correlated with the labels. to avoid this, previous stud- ies have trained models to eliminate the re- liance on shortcuts. in this study, we ex- plore a different direction: pessimistically aggregating the predictions of a mixture-of- experts, assuming each expert captures rela- tively different latent features. the exper- imental results demonstrate that our post- hoc control over the experts significantly en- hances the model\u2019s robustness to the distri- bution shift in shortcuts. besides, we show that our approach has some practical advan- tages. we also analyze our model and pro- vide results to support the assumption.1 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12066",
        "label": 1,
        "title": "language models are surprisingly fragile to drug names in biomedical benchmarks jack gallifant1",
        "abstract": "medical knowledge is context-dependent and requires consistent reasoning across various natural language expressions of semantically equivalent phrases. this is particularly cru- cial for drug names, where patients often use brand names like advil or tylenol instead of their generic equivalents. to study this, we create a new robustness dataset, rabbits , to evaluate performance differences on medical benchmarks after swapping brand and generic drug names using physician expert annotations. we assess both open-source and api-based llms on medqa and medmcqa, revealing a consistent performance drop ranging from 1-10%. furthermore, we identify a potential source of this fragility as the contamination of test data in widely used pre-training datasets.1 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12091",
        "label": 0,
        "title": "is poisoning a real threat to llm alignment ? m aybe more so than you think a p reprint",
        "abstract": "recent advancements in reinforcement learning with human feedback (rlhf) have significantly impacted the alignment of large language models (llms). the sensitivity of reinforcement learning algorithms such as proximal policy optimization (ppo) has led to new line work on direct policy optimization (dpo), which treats rlhf in a supervised learning framework. the increased practical use of these rlhf methods warrants an analysis of their vulnerabilities. in this work, we investigate the vulnerabilities of dpo to poisoning attacks under different scenarios and compare the effectiveness of preference poisoning, a first of its kind. we comprehensively analyze dpo\u2019s vulnerabilities under different types of attacks, i.e., backdoor and non-backdoor attacks, and different poisoning methods across a wide array of language models, i.e., llama 7b, mistral 7b, and gemma 7b. we find that unlike ppo-based methods, which, when it comes to backdoor attacks, require at least 4% of the data to be poisoned to elicit harmful behavior, we exploit the true vulnerabilities of dpo more simply so we can poison the model with only as much as 0.5% of the data. we further investigate the potential reasons behind the vulnerability and how well this vulnerability translates into backdoor vs non-backdoor attacks. implementation of the paper is publically available athttps://github.com/pankayaraj/rlhfpoisoning . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12128",
        "label": 1,
        "title": "ai \u2018news\u2019 content farms are easy to make and hard to detect: a case study in italian giovanni puccetti\u03b1",
        "abstract": "large language models (llms) are increas- ingly used as \u2018content farm\u2019 models (cfms), to generate synthetic text that could pass for real news articles. this is already happening even for languages that do not have high-quality monolingual llms. we show that fine-tuning llama (v1), mostly trained on english, on as lit- tle as 40k italian news articles, is sufficient for producing news-like texts that native speakers of italian struggle to identify as synthetic. we investigate three llms and three methods of detecting synthetic texts (log-likelihood, de- tectgpt, and supervised classification), finding that they all perform better than human raters, but they are all impractical in the real world (requiring either access to token likelihood in- formation or a large dataset of cfm texts). we also explore the possibility of creating a proxy cfm: an llm fine-tuned on a similar dataset to one used by the real \u2018content farm\u2019. we find that even a small amount of fine-tuning data suf- fices for creating a successful detector, but we need to know which base llm is used, which is a major challenge. our results suggest that there are currently no practical methods for detecting synthetic news- like texts \u2018in the wild\u2019, while generating them is too easy. we highlight the urgency of more nlp research on this problem. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12131",
        "label": 0,
        "title": "gram 2vec: an interpretable document vectorizer peter zeng\u25b33",
        "abstract": "we present gram 2vec, a grammatical style embedding algorithm that embeds documents into a higher dimensional space by extracting the normalized relative frequencies of gram- matical features present in the text. compared to neural approaches, gram 2vecoffers in- herent interpretability based on how the feature vectors are generated. in our demo, we present a way to visualize a mapping of authors to doc- uments based on their gram 2vecvectors and highlight the ability to drop or add features to view which authors make certain linguistic choices. next, we use authorship attribution as an application to show how gram 2veccan explain why a document is attributed to a cer- tain author, using cosine similarities between thegram 2vecfeature vectors to calculate the distances between candidate documents and a query document. our gram 2veccode is on https://github.com/eric-sclafani/gram2vec, and a corresponding demo video is available at https://youtu.be/y8vj31d7woi "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12158",
        "label": 0,
        "title": "llms are prone to fallacies in causal inference nitish joshi1abulhair saparov1yixin wang2he he1 1new york",
        "abstract": "recent work shows that causal facts can be ef- fectively extracted from llms through prompt- ing, facilitating the creation of causal graphs for causal inference tasks. however, it is unclear if this success is limited to explicitly-mentioned causal facts in the pretraining data which the model can memorize. thus, this work investi- gates: can llms infer causal relations from other relational data in text? to disentangle the role of memorized causal facts vs inferred causal relations, we finetune llms on syn- thetic data containing temporal, spatial and counterfactual relations, and measure whether the llm can then infer causal relations. we find that: (a) llms are susceptible to inferring causal relations from the order of two entity mentions in text (e.g. x mentioned before y implies x causes y); (b) if the order is ran- domized, llms still suffer from the post hoc fallacy , i.e. x occurs before y (temporal re- lation) implies x causes y . we also find that while llms can correctly deduce the absence of causal relations from temporal and spatial re- lations, they have difficulty inferring causal re- lations from counterfactuals, questioning their understanding of causality. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12182",
        "label": 1,
        "title": "aqulia-med llm: pioneering full-process open-source medical language models lulu zhao1",
        "abstract": "recently, both closed-source llms and open- source communities have made significant strides, outperforming humans in various gen- eral domains. however, their performance in specific professional fields such as medicine, especially within the open-source community, remains suboptimal due to the complexity of medical knowledge. we propose aquila-med, a bilingual medical llm based on aquila, ad- dressing these challenges through continue pre- training, supervised fine-tuning (sft), and re- inforcement learning from human feedback (rlhf). we construct a large-scale chinese and english medical dataset for continue pre- training and a high-quality sft dataset, cover- ing extensive medical specialties. addition- ally, we develop a high-quality direct pref- erence optimization (dpo) dataset for fur- ther alignment. aquila-med achieves no- table results across single-turn, multi-turn di- alogues, and medical multiple-choice ques- tions, demonstrating the effectiveness of our approach. we open-source the datasets and the entire training process, contributing valu- able resources to the research community. our models and datasets will released at https://huggingface.co/baai/aquilamed-rl. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.12277",
        "label": 1,
        "title": "what matters in learning facts in language models? multifaceted knowledge probing with diverse multi-prompt da",
        "abstract": "large language models (llms) face issues in handling factual knowledge, making it vital to evaluate their true ability to understand facts. in this study, we introduce knowledge prob- ing frameworks, belief(-icl), to evaluate the knowledge understanding ability of both encoder-based and decoder-based pre-trained lms (plms) from diverse perspectives. be- liefs utilize a multi-prompt dataset to evaluate plm\u2019s accuracy, consistency, and reliability in factual knowledge understanding. to en- able a more reliable evaluation with beliefs, we semi-automatically create myriadlama, which has massively diverse prompts. we vali- date the effectiveness of beliefs in correctly and comprehensively evaluating plm\u2019s factual understanding ability via extensive evaluations with recent llms. we then investigate key fac- tors in learning facts in llms, and reveal the limitation of the prompt-based knowledge prob- ing. the dataset is anonymously publicized.1 "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09181",
        "label": 1,
        "title": "a large-scale universal evaluation benchmark for face forgery detection yijun bei",
        "abstract": "with the rapid development of ai-generated content (aigc) technology, the production of realistic fake facial images and videos that deceive human visual perception has become possible. consequently, various face forgery detection techniques have been proposed to identify such fake facial content. however, evaluating the effectiveness and generalizability of these detection techniques re- mains a significant challenge. to address this, we have constructed a large-scale evaluation benchmark called deepfacegen, aimed at quantitatively assessing the effectiveness of face forgery detection and facilitating the iterative development of forgery detection technology. deepfacegen consists of 776 ,990real face image/video samples and 773 ,812face forgery image/video samples, generated using 34mainstream face generation techniques. during the construction pro- cess, we carefully consider important factors such as content diversity, fairness across ethnicities, and availability of comprehensive labels, in order to ensure the versatility and convenience of deepfacegen. subsequently, deepfacegen is employed in this study to evaluate and analyze the performance of 13mainstream face forgery detection techniques from various perspectives. through extensive experimental analysis, we derive significant findings and propose potential direc- tions for future research. the code and dataset for deepfacegen are available at https://github.com/hengruilou/deepfacegen. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.17186",
        "label": 1,
        "title": "clerc : a dataset for legal case retrieval and retrieval-augmented analysis generation abe bohan hou\u2663orion wel",
        "abstract": "legal professionals need to write analyses that rely on citations to relevant precedents, i.e., pre- vious case decisions. intelligence systems as- sisting legal professionals in writing such doc- uments provide great benefits but are challeng- ing to design. such systems need to help lo- cate, summarize, and reason over salient prece- dents in order to be useful. to enable systems for such tasks, we work with legal profession- als to transform a large open-source legal cor- pus into a dataset1supporting two important backbone tasks: information retrieval (ir) and retrieval-augmented generation (rag). this dataset clerc (caselawevaluation and retrieval corpus), is constructed for training and evaluating models on their ability to (1) find corresponding citations for a given piece of legal analysis and to (2) compile the text of these citations (as well as previous context) into a cogent analysis that supports a reasoning goal. we benchmark state-of-the-art models on clerc , showing that current approaches still struggle: gpt-4o generates analyses with the highest rouge f-scores but hallucinates the most, while zero-shot ir models only achieve 48.3% recall@1000. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09321",
        "label": 1,
        "title": "jailbreakeval : an integrated toolkit for evaluating jailbreak attempts against large language models delong r",
        "abstract": "jailbreak attacks aim to induce large language models (llms) to generate harmful responses for forbidden instructions, presenting severe misuse threats to llms. up to now, research into jailbreak attacks and defenses is emerging, however, there is (surprisingly) no consensus on how to evaluate whether a jailbreak attempt is successful. in other words, the methods to assess the harmfulness of an llm\u2019s response are varied, such as manual annotation or prompting gpt-4 in specific ways. each approach has its own set of strengths and weaknesses, impacting their alignment with human values, as well as the time and financial cost. this diversity in evaluation presents challenges for researchers in choosing suitable evaluation methods and conducting fair comparisons across different jailbreak attacks and defenses. in this paper, we conduct a comprehensive analysis of jailbreak evaluation methodologies, drawing from nearly ninety jailbreak research released between may 2023 and april 2024. our study introduces a systematic taxonomy of jailbreak evaluators, offering in-depth insights into their strengths and weaknesses, along with the current status of their adaptation. moreover, to facilitate subsequent research, we propose jailbreakeval (https://github.com/thuccslab/ jailbreakeval ), a user-friendly toolkit focusing on the evaluation of jailbreak attempts. it includes various well-known evaluators out-of-the-box, so that users can obtain evaluation results with only a single command. jailbreakeval also allows users to customize their own evaluation workflow in a unified framework with the ease of development and comparison. in summary, we regard jailbreakeval to be a catalyst that simplifies the evaluation process in jailbreak research and fosters an inclusive standard for jailbreak evaluation within the community. "
    },
    {
        "url": "https://arxiv.org/pdf/2406.08673",
        "label": 1,
        "title": "helpsteer2: open-source dataset for training top-performing reward models zhilin wang",
        "abstract": "high-quality preference datasets are essential for traini ng reward models that can effectively guide large language models (llms) in generati ng high-quality re- sponses aligned with human preferences. as llms become stro nger and better aligned, permissively licensed preference datasets, such as open assistant, hh- rlhf, and helpsteer need to be updated to remain effective fo r reward model- ing. methods that distil preference data from proprietary l lms such as gpt-4 have restrictions on commercial usage imposed by model prov iders. to improve upon both generated responses and attribute labeling quali ty, we release help- steer2, a permissively licensed preference dataset (cc-by -4.0). using a power- ful internal base model trained on helpsteer2, we are able to achieve the sota score (92.0%) on reward-bench\u2019s primary dataset, outperfo rming currently listed open and proprietary models, as of june 12th, 2024. notably, helpsteer2 consists of only ten thousand response pairs, an order of magnitude fe wer than existing preference datasets (e.g., hh-rlhf), which makes it highly ef\ufb01cient for train- ing reward models. our extensive experiments demonstrate t hat reward models trained with helpsteer2 are effective in aligning llms. in p articular, we propose steerlm 2.0, a model alignment approach that can effectivel y make use of the rich multi-attribute score predicted by our reward models. helpsteer2 is avail- able athttps://huggingface.co/datasets/nvidia/helpsteer2 and code is available at https://github.com/nvidia/nemo-aligner . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09326",
        "label": 1,
        "title": "pianomotion10m : dataset and benchmark for hand motion generation in piano performance qijun gan",
        "abstract": "recently, artificial intelligence techniques for education have been received increas- ing attentions, while it still remains an open problem to design the effective music instrument instructing systems. although key presses can be directly derived from sheet music, the transitional movements among key presses require more extensive guidance in piano performance. in this work, we construct a piano-hand motion generation benchmark to guide hand movements and fingerings for piano playing. to this end, we collect an annotated dataset, pianomotion10m , consisting of 116 hours of piano playing videos from a bird\u2019s-eye view with 10 million annotated hand poses. we also introduce a powerful baseline model that generates hand motions from piano audios through a position predictor and a position-guided gesture generator. furthermore, a series of evaluation metrics are designed to assess the performance of the baseline model, including motion similarity, smooth- ness, positional accuracy of left and right hands, and overall fidelity of movement distribution. despite that piano key presses with respect to music scores or audios are already accessible, pianomotion10m aims to provide guidance on piano fingering for instruction purposes. the dataset and source code can be accessed at https://agnjason.github.io/pianomotion-page . "
    },
    {
        "url": "https://arxiv.org/pdf/2406.09388",
        "label": 1,
        "title": "exploring the spectrum of visio-linguistic compositionality and recognition youngtaek oh1",
        "abstract": "vision and language models (vlms) such as clip have showcased remarkable zero-shot recognition abilities yet face challenges in visio-linguistic compositionality, partic- ularly in linguistic comprehension and fine-grained image- text alignment. this paper explores the intricate relation- ship between compositionality and recognition \u2013 two piv- otal aspects of vlm capability. we conduct a compre- hensive evaluation of existing vlms, covering both pre- training approaches aimed at recognition and the fine- tuning methods designed to improve compositionality. our evaluation employs 12 benchmarks for compositionality, along with 21 zero-shot classification and two retrieval benchmarks for recognition. in our analysis from 274 clip model checkpoints, we reveal patterns and trade-offs that emerge between compositional understanding and recog- nition accuracy. ultimately, this necessitates strategic ef- forts towards developing models that improve both capabil- ities, as well as the meticulous formulation of benchmarks for compositionality. we open our evaluation framework at https://github.com/ytaek-oh/vl_compo . 1"
    },
    {
        "url": "https://arxiv.org/pdf/2406.14657",
        "title": "OpenDebateEvidence: A Massive-Scale Argument Mining and Summarization Dataset",
        "abstract": "We introduce OpenDebateEvidence, a comprehensive dataset for argument mining and summarization sourced from the American Competitive Debate community. This dataset includes over 3.5 million documents with rich metadata, making it one of the most extensive collections of debate evidence. OpenDebateEvidence captures the complexity of arguments in high school and college debates, providing valuable resources for training and evaluation. Our extensive experiments demonstrate the efficacy of fine-tuning state-of-the-art large language models for argumentative abstractive summarization across various methods, models, and datasets. By providing this comprehensive resource, we aim to advance computational argumentation and support practical applications for debaters, educators, and researchers. OpenDebateEvidence is publicly available to support further research and innovation in computational argumentation. Access it here: https://huggingface.co/datasets/Yusuf5/OpenCaselist.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15093",
        "title": "ECLIPSE: Expunging Clean-label Indiscriminate Poisons via Sparse Diffusion Purification",
        "abstract": "Clean-label indiscriminate poisoning attacks add invisible perturbations to correctly labeled training images, thus dramatically reducing the generalization capability of the victim models. Recently, defense mechanisms such as adversarial training, image transformation techniques, and image purification have been proposed. However, these schemes are either susceptible to adaptive attacks, built on unrealistic assumptions, or only effective against specific poison types, limiting their universal applicability. In this research, we propose a more universally effective, practical, and robust defense scheme called ECLIPSE. We first investigate the impact of Gaussian noise on the poisons and theoretically prove that any kind of poison will be largely assimilated when imposing sufficient random noise. In light of this, we assume the victim has access to an extremely limited number of clean images (a more practical scene) and subsequently enlarge this sparse set for training a denoising probabilistic model (a universal denoising tool). We then introduce Gaussian noise to absorb the poisons and apply the model for denoising, resulting in a roughly purified dataset. Finally, to address the trade-off of the inconsistency in the assimilation sensitivity of different poisons by Gaussian noise, we propose a lightweight corruption compensation module to effectively eliminate residual poisons, providing a more universal defense approach. Extensive experiments demonstrate that our defense approach outperforms 10 state-of-the-art defenses. We also propose an adaptive attack against ECLIPSE and verify the robustness of our defense scheme. Our code is available at https://github.com/CGCL-codes/ECLIPSE.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15252",
        "title": "VIDEOSCORE: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation",
        "abstract": "The recent years have witnessed great advances in video generation. However, the development of automatic video metrics is lagging significantly behind. None of the existing metric is able to provide reliable scores over generated videos. The main barrier is the lack of largescale human-annotated dataset. In this paper, we release VIDEOFEEDBACK, the first largescale dataset containing human-provided multiaspect score over 37.6K synthesized videos from 11 existing video generative models. We train VIDEOSCORE (initialized from Mantis) based on VIDEOFEEDBACK to enable automatic video quality assessment. Experiments show that the Spearman correlation between VIDEOSCORE and humans can reach 77.1 on VIDEOFEEDBACK-test, beating the prior best metrics by about 50 points. Further result on other held-out EvalCrafter, GenAI-Bench, and VBench show that VIDEOSCORE has consistently much higher correlation with human judges than other metrics. Due to these results, we believe VIDEOSCORE can serve as a great proxy for human raters to (1) rate different video models to track progress (2) simulate fine-grained human feedback in Reinforcement Learning with Human Feedback (RLHF) to improve current video generation models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15349",
        "title": "NAVSIM: Data-Driven Non-Reactive Autonomous Vehicle Simulation and Benchmarking",
        "abstract": "Benchmarking vision-based driving policies is challenging. On one hand, openloop evaluation with real data is easy, but these results do not reflect closedloop performance. On the other, closed-loop evaluation is possible in simulation, but is hard to scale due to its significant computational demands. Further, the simulators available today exhibit a large domain gap to real data. This has resulted in an inability to draw clear conclusions from the rapidly growing body of research on end-to-end autonomous driving. In this paper, we present NAVSIM, a middle ground between these evaluation paradigms, where we use large datasets in combination with a non-reactive simulator to enable large-scale real-world benchmarking. Specifically, we gather simulation-based metrics, such as progress and time to collision, by unrolling bird\u2019s eye view abstractions of the test scenes for a short simulation horizon. Our simulation is non-reactive, i.e., the evaluated policy and environment do not influence each other. As we demonstrate empirically, this decoupling allows open-loop metric computation while being better aligned with closed-loop evaluations than traditional displacement errors. NAVSIM enabled a new competition held at CVPR 2024, where 143 teams submitted 463 entries, resulting in several new insights. On a large set of challenging scenarios, we observe that simple methods with moderate compute requirements such as TransFuser can match recent large-scale end-to-end driving architectures such as UniAD. Our modular framework can potentially be extended with new datasets, data curation strategies, and metrics, and will be continually maintained to host future challenges. Our code is available at https://github.com/autonomousvision/navsim.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14673",
        "title": "Insights into LLM Long-Context Failures: When Transformers Know but Don\u2019t Tell",
        "abstract": "Large Language Models (LLMs) exhibit positional bias, struggling to utilize information from the middle or end of long contexts. Our study explores LLMs\u2019 long-context reasoning by probing their hidden representations. We find that while LLMs encode the position of target information, they often fail to leverage this in generating accurate responses. This reveals a disconnect between information retrieval and utilization, a \u2018know but don\u2019t tell\u2019 phenomenon. We further analyze the relationship between extraction time and final accuracy, offering insights into the underlying mechanics of transformer models. The code is accessible here: https://github.com/TaiMingLu/knowdont-tell.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.14678",
        "title": "Bidirectional Transformer Representations of (Spanish) Ambiguous Words in Context: A New Lexical Resource and Empirical Analysis",
        "abstract": "Lexical ambiguity\u2014where a single wordform takes on distinct, context-dependent meanings\u2013 serves as a useful tool to compare across different large language models\u2019 (LLMs\u2019) ability to form distinct, contextualized representations of the same stimulus. Few studies have systematically compared LLMs\u2019 contextualized word embeddings for languages beyond English. Here, we evaluate multiple bidirectional transformers\u2019 (BERTs\u2019) semantic representations of Spanish ambiguous nouns in context. We develop a novel dataset of minimal-pair sentences evoking the same or different sense for a target ambiguous noun. In a pre-registered study, we collect contextualized human relatedness judgments for each sentence pair. We find that various BERT-based LLMs\u2019 contextualized semantic representations capture some variance in human judgments but fall short of the human benchmark, and for Spanish\u2013unlike English\u2014model scale is uncorrelated with performance. We also identify stereotyped trajectories of target noun disambiguation as a proportion of traversal through a given LLM family\u2019s architecture, which we partially replicate in English. We contribute (1) a dataset of controlled, Spanish sentence stimuli with human relatedness norms, and (2) to our evolving understanding of the impact that LLM specification (architectures, training protocols) exerts on contextualized embeddings.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14570",
        "title": "Deep-Learning Approach for Tissue Classification using Acoustic Waves during Ablation with an Er:YAG Laser (Updated)",
        "abstract": "Today\u2019s mechanical tools for bone cutting (osteotomy) cause mechanical trauma that prolongs the healing process. Medical device manufacturers constantly strive to improve their tools to further minimize the trauma. One example of such a new tool and procedure is minimally invasive surgery using a laser as the cutting element. This setup allows tissue to be ablated using laser light instead of mechanical tools, which reduces the healing time after surgery. A reliable feedback system is crucial during laser surgery to avoid collateral damage to surrounding tissues. Therefore, we propose a tissue classification method that analyzes the acoustic waves generated during laser ablation and demonstrates its applicability in an ex-vivo experiment. The ablation process with a microsecond pulsed Er:YAG laser produces acoustic waves, which were acquired with an air-coupled transducer. We then used these acquired waves to classify five porcine tissue types: hard bone, soft bone, muscle, fat, and skin. For automated tissue classification of the measured acoustic waves, we compared five Neural Network (NN) approaches: a one-dimensional Convolutional Neural Network (CNN) with a time-dependent input, a Fully-connected Neural Network (FcNN) with either the frequency spectrum or the principal components of the frequency spectrum as an input, and a combination of a CNN and an FcNN with the time-dependent data and its frequency spectrum as an input. In addition, several consecutive acoustic waves were used to improve the classification task. We used GradCam to find the activation map of the frequencies and concluded that the low-frequencies were the most important ones for this classification task. Our results indicated that the highest accuracy of the classification task (65.5%-75.5%) could be achieved by combining the time-dependent data with its frequency spectrum. In addition, we showed that it was sufficient to use the frequency spectrum as input and that no additional benefit was gained by applying Principal Components Analysis (PCA) to the frequency spectrum.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14595",
        "title": "Adversaries Can Misuse Combinations of Safe Models",
        "abstract": "Developers try to evaluate whether an AI system can be misused by adversaries before releasing it; for example, they might test whether a model enables cyberoffense, user manipulation, or bioterrorism. In this work, we show that individually testing models for misuse is inadequate; adversaries can misuse combinations of models even when each individual model is safe. The adversary accomplishes this by first decomposing tasks into subtasks, then solving each subtask with the best-suited model. For example, an adversary might solve challenging-but-benign subtasks with an aligned frontier model, and easy-but-malicious subtasks with a weaker misaligned model. We study two decomposition methods: manual decomposition where a human identifies a natural decomposition of a task, and automated decomposition where a weak model generates benign tasks for a frontier model to solve, then uses the solutions in-context to solve the original task. Using these decompositions, we empirically show that adversaries can create vulnerable code, explicit images, python scripts for hacking, and manipulative tweets at much higher rates with combinations of models than either individual model. Our work suggests that even perfectly-aligned frontier systems can enable misuse without ever producing malicious outputs, and that red-teaming efforts should extend beyond single models in isolation.1",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.14760",
        "title": "An LLM Feature-based Framework for Dialogue Constructiveness Assessment",
        "abstract": "Research on dialogue constructiveness assessment focuses on (i) analysing conversational factors that influence individuals to take specific actions, win debates, change their perspectives or broaden their open-mindedness and (ii) predicting constructive outcomes following dialogues for such use cases. These objectives can be achieved by training either interpretable feature-based models (which often involve costly human annotations) or neural models such as pre-trained language models (which have empirically shown higher task accuracy but lack interpretability). We propose a novel LLM feature-based framework that combines the strengths of feature-based and neural approaches while mitigating their downsides, in assessing dialogue constructiveness. The framework first defines a set of dataset-independent and interpretable linguistic features, which can be extracted by both prompting an LLM and simple heuristics. Such features are then used to train LLM featurebased models. We apply this framework to three datasets of dialogue constructiveness and find that our LLM feature-based models significantly outperform standard feature-based models and neural models, and tend to learn more robust prediction rules instead of relying on superficial shortcuts (as seen with neural models). Further, we demonstrate that interpreting these LLM feature-based models can yield valuable insights into what makes a dialogue constructive1 .",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14670",
        "title": "Exploring Design Choices for Building Language-Specific LLMs",
        "abstract": "Despite rapid progress in large language models (LLMs), their performance on a vast majority of languages remain unsatisfactory. In this paper, we study building language-specific LLMs by adapting monolingual and multilingual LLMs. We conduct systematic experiments on how design choices (base model selection, vocabulary extension, and continued fine-tuning) impact the adapted LLM, both in terms of efficiency (how many tokens are needed to encode the same amount of information) and end task performance. We find that (1) the initial performance before the adaptation is not always indicative of the final performance. (2) Efficiency can easily improved with simple vocabulary extension and continued fine-tuning in most LLMs we study, and (3) The optimal adaptation method is highly language-dependent, and the simplest approach works well across various experimental settings. Adapting English-centric models can yield better results than adapting multilingual models despite their worse initial performance on lowresource languages. Together, our work lays foundations on efficiently building languagespecific LLMs by adapting existing LLMs.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.15132",
        "title": "Younger: The First Dataset for Artificial Intelligence-Generated Neural Network Architecture",
        "abstract": "Designing and optimizing neural network architectures typically requires extensive expertise, starting with handcrafted designs and then manual or automated refinement. This dependency presents a significant barrier to rapid innovation. Recognizing the complexity of automatically generating neural network architecture from scratch, we introduce Younger, a pioneering dataset to advance this ambitious goal. Derived from over 174K real-world models across more than 30 tasks from various public model hubs, Younger includes 7,629 unique architectures, and each is represented as a directed acyclic graph with detailed operator-level information. The dataset facilitates two primary design paradigms: global, for creating complete architectures from scratch, and local, for detailed architecture component refinement. By establishing these capabilities, Younger contributes to a new frontier, Artificial Intelligence-Generated Neural Network Architecture (AIGNNA). Our experiments explore the potential and effectiveness of Younger for automated architecture generation and, as a secondary benefit, demonstrate that Younger can serve as a benchmark dataset, advancing the development of graph neural networks. We release the dataset2 and code3 publicly to lower the entry barriers and encourage further research in this challenging area.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15168",
        "title": "This actually looks like that: Proto-BagNets for local and global interpretability-by-design",
        "abstract": "Interpretability is a key requirement for the use of machine learning models in high-stakes applications, including medical diagno- sis. Explaining black-box models mostly relies on post-hoc methods that do not faithfully reflect the model\u2019s behavior. As a remedy, prototype- based networks have been proposed, but their interpretability is limited as they have been shown to provide coarse, unreliable, and imprecise ex- planations. In this work, we introduce Proto-BagNets6, an interpretable- by-design prototype-based model that combines the advantages of bag- of-local feature models and prototype learning to provide meaningful, coherent, and relevant prototypical parts needed for accurate and in- terpretable image classification tasks. We evaluated the Proto-BagNet for drusen detection on publicly available retinal OCT data. The Proto- BagNet performed comparably to the state-of-the-art interpretable and non-interpretable models while providing faithful, accurate, and clini- cally meaningful local and global explanations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.14709",
        "title": "Factual Dialogue Summarization via Learning from Large Language Models",
        "abstract": "Factual consistency is an important quality in dialogue summarization. Large language model (LLM)-based automatic text summariza- tion models generate more factually consistent summaries compared to those by smaller pre- trained language models, but they face deploy- ment challenges in real-world applications due to privacy or resource constraints. In this paper, we investigate the use of symbolic knowledge distillation to improve the factual consistency of smaller pretrained models for dialogue sum- marization. We employ zero-shot learning to extract symbolic knowledge from LLMs, gen- erating both factually consistent (positive) and inconsistent (negative) summaries. We then ap- ply two contrastive learning objectives on these summaries to enhance smaller summarization models. Experiments with BART, PEGASUS, and Flan-T5 indicate that our approach sur- passes strong baselines that rely on complex data augmentation strategies. Our approach achieves better factual consistency while main- taining coherence, fluency, and relevance, as confirmed by various automatic evaluation met- rics. We also provide access to the data and code to facilitate future research",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.14732",
        "title": "TTQA-RS- A break-down prompting approach for Multi-hop Table-Text Question Answering with Reasoning and Summarization",
        "abstract": "Question answering (QA) over tables and text has gained much popularity over the years. Multi-hop table-text QA requires multiple hops between the table and text, making it a challenging QA task. Although several works have attempted to solve the table-text QA task, most involve training the models and requiring labeled data. In this paper, we have proposed a model - \u201cTTQA-RS: A break-down prompting approach for Multi-hop Table-Text Question Answering with Reasoning and Summarization\u201d1 . Our model uses augmented knowledge including table-text summary with decomposed sub-question with answer for a reasoning-based table-text QA. Using open-source language models our model outperformed all existing prompting methods for table-text QA tasks on existing table-text QA datasets like HybridQA and OTT-QA\u2019s development set. Our results are comparable with the training-based stateof-the-art models, demonstrating the potential of prompt-based approaches using open-source LLMs. Additionally, by using GPT-4 with LLaMA3-70B, our model achieved state-of-theart performance for prompting-based methods on multi-hop table-text QA.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.14774",
        "title": "Evaluating Numerical Reasoning in Text-to-Image Models",
        "abstract": "Text-to-image generative models are capable of producing high-quality images that often faithfully depict concepts described using natural language. In this work, we comprehensively evaluate a range of text-to-image models on numerical reasoning tasks of varying difficulty, and show that even the most advanced models have only rudimentary numerical skills. Specifically, their ability to correctly generate an exact number of objects in an image is limited to small numbers, it is highly dependent on the context the number term appears in, and it deteriorates quickly with each successive number. We also demonstrate that models have poor understanding of linguistic quantifiers (such as \u201ca few\u201d or \u201cas many as\u201d), the concept of zero, and struggle with more advanced concepts such as partial quantities and fractional representations. We bundle prompts, generated images and human annotations into GECKONUM, a novel benchmark for evaluation of numerical reasoning.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.14952",
        "title": "ESC-Eval: Evaluating Emotion Support Conversations in Large Language Models",
        "abstract": "Emotion Support Conversation (ESC) is a cru- cial application, which aims to reduce human stress, offer emotional guidance, and ultimately enhance human mental and physical well-being. With the advancement of Large Language Mod- els (LLMs), many researchers have employed LLMs as the ESC models. However, the evalu- ation of these LLM-based ESCs remains uncer- tain. Inspired by the awesome development of role-playing agents, we propose an ESC Evaluation framework (i.e., ESC-Eval), which uses a role-playing agent to interact with ESC models, followed by a manual evaluation of the interactive dialogues. In detail, we first re- organize 2,801 role-playing cards from seven existing datasets to define the roles of the role- playing agent. Second, we train a specific role- playing model - ESC-Role to mimic the be- havior of a real person experiencing distress. Third, through ESC-Role and organized role cards, we systematically conduct experiments using 14 LLMs as the ESC models, includ- ing general AI-assistant LLMs (e.g., ChatGPT) and ESC-oriented LLMs (e.g., ExTES-Llama). We conduct comprehensive human annotations on interactive multi-turn dialogues of differ- ent ESC models. The results show that ESC- oriented LLMs exhibit superior ESC abilities compared to general AI-assistant LLMs, but there is still a gap behind human performance. Moreover, to automate the evaluation of fu- ture ESC models, we developed ESC-RANK, which trained on the annotated data, achiev- ing a scoring performance surpassing 35 points of GPT-4. Our data and code are available at https://github.com/haidequanbu/ESC-Eval",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.15019",
        "title": "MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to 200K Tokens",
        "abstract": "Numerous advanced Large Language Models (LLMs) now support context lengths up to 128K, and some extend to 200K. Some benchmarks in the generic domain have also followed up on evaluating long-context capabilities. In the medical domain, tasks are distinctive due to the unique contexts and need for domain expertise, necessitating further evaluation. However, despite the frequent presence of long texts in medical scenarios, evaluation benchmarks of long-context capabilities for LLMs in this field are still rare. In this paper, we propose MedOdyssey, the first medical long-context benchmark with seven length levels ranging from 4K to 200K tokens. MedOdyssey consists of two primary components: the medical-context \u201cneedles in a haystack\u201d task and a series of tasks specific to medical applications, together comprising 10 datasets. The first component includes challenges such as counter-intuitive reasoning and novel (unknown) facts injection to mitigate knowledge leakage and data contamination of LLMs. The second component confronts the challenge of requiring professional medical expertise. Especially, we design the \u201cMaximum Identical Context\u201d principle to improve fairness by guaranteeing that different LLMs observe as many identical contexts as possible. Our experiment evaluates advanced proprietary and open-source LLMs tailored for processing long contexts and presents detailed performance analyses. This highlights that LLMs still face challenges and need for further research in this area. Our code and data are released in the repository: https://github.com/JOHNNY-fans/MedOdyssey.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15130",
        "title": "Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks",
        "abstract": "The recent success of Large Language Models (LLMs) has sparked concerns about their potential to spread misinformation. As a result, there is a pressing need for tools to identify \u201cfake arguments\u201d generated by such models. To create these tools, examples of texts generated by LLMs are needed. This paper introduces a methodology to obtain good, bad and ugly arguments from argumentative essays produced by ChatGPT, OpenAI\u2019s LLM. We then describe a novel dataset containing a set of diverse arguments, ArGPT. We assess the effectiveness of our dataset and establish baselines for several argumentation-related tasks. Finally, we show that the artificially generated data relates well to human argumentation and thus is useful as a tool to train and test systems for the defined tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15267",
        "title": "Evaluating Diversity in Automatic Poetry Generation",
        "abstract": "Natural Language Generation (NLG), and more generally generative AI, are among the currently most impactful research fields. Creative NLG, such as automatic poetry generation, is a fascinating niche in this area. While most previous research has focused on forms of the Turing test when evaluating automatic poetry generation \u2014 can humans distinguish between automatic and human generated poetry \u2014 we evaluate the diversity of automatically generated poetry, by comparing distributions of generated poetry to distributions of human poetry along structural, lexical, semantic and stylistic dimensions, assessing different model types (word vs. character-level, general purpose LLMs vs. poetry-specific models), including the very recent LLaMA3, and types of fine-tuning (conditioned vs. unconditioned). We find that current automatic poetry systems are considerably underdiverse along multiple dimensions \u2014 they often do not rhyme sufficiently, are semantically too uniform and even do not match the length distribution of human poetry. Our experiments reveal, however, that style-conditioning and character-level modeling clearly increases diversity across virtually all dimensions we explore. Our identified limitations may serve as the basis for more genuinely diverse future poetry generation models.1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15279",
        "title": "Cross-Modality Safety Alignment",
        "abstract": "As Artificial General Intelligence (AGI) becomes increasingly integrated into various facets of human life, ensuring the safety and ethical alignment of such systems is paramount. Previous studies primarily focus on single-modality threats, which may not suffice given the integrated and complex nature of cross-modality interactions. We introduce a novel safety alignment challenge called Safe Inputs but Unsafe Output (SIUO) to evaluate cross-modality safety alignment. Specifically, it considers cases where single modalities are safe independently but could potentially lead to unsafe or unethical outputs when combined. To empirically investigate this problem, we developed the SIUO, a cross-modality benchmark encompassing 9 critical safety domains, such as self-harm, illegal activities, and privacy violations. Our findings reveal substantial safety vulnerabilities in both closed- and opensource LVLMs, such as GPT-4V and LLaVA, underscoring the inadequacy of current models to reliably interpret and respond to complex, real-world scenarios.1 Warning: this paper contains example data that may be offensive or harmful.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15319",
        "title": "LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs",
        "abstract": "In traditional RAG framework, the basic retrieval units are normally short. The common retrievers like DPR normally work with 100-word Wikipedia paragraphs. Such a design forces the retriever to search over a large corpus to find the \u2018needle\u2019 unit. In contrast, the readers only need to extract answers from the short retrieved units. Such an imbalanced \u2018heavy\u2019 retriever and \u2018light\u2019 reader design can lead to sub-optimal performance. In order to alleviate the imbalance, we propose a new framework LongRAG, consisting of a \u2018long retriever\u2019 and a \u2018long reader\u2019. LongRAG processes the entire Wikipedia into 4K-token units, which is 30x longer than before. By increasing the unit size, we significantly reduce the total units from 22M to 600K. This significantly lowers the burden of retriever, which leads to a remarkable retrieval score: answer recall@1=71% on NQ (previously 52%) and answer recall@2=72% (previously 47%) on HotpotQA (full-wiki). Then we feed the top-k retrieved units (\u2248 30K tokens) to an existing long-context LLM to perform zero-shot answer extraction. Without requiring any training, LongRAG achieves an EM of 62.7% on NQ and 64.3% on HotpotQA (full-wiki), which is on par with the (fully-trained) SoTA model. Our study offers insights into the future roadmap for combining RAG with long-context LLMs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15341",
        "title": "GenoTEX: A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians",
        "abstract": "Recent advancements in machine learning have significantly improved the identification of diseaseassociated genes from gene expression datasets. However, these processes often require extensive expertise and manual effort, limiting their scalability. Large Language Model (LLM)-based agents have shown promise in automating these tasks due to their increasing problem-solving abilities. To support the evaluation and development of such methods, we introduce GenoTEX, a benchmark dataset for the automatic exploration of gene expression data, involving the tasks of dataset selection, preprocessing, and statistical analysis. GenoTEX provides annotated code and results for solving a wide range of gene identification problems, in a full analysis pipeline that follows the standard of computational genomics. These annotations are curated by human bioinformaticians who carefully analyze the datasets to ensure accuracy and reliability. To provide baselines for these tasks, we present GenoAgents, a team of LLM-based agents designed with context-aware planning, iterative correction, and domain expert consultation to collaboratively explore gene datasets. Our experiments with GenoAgents demonstrate the potential of LLM-based approaches in genomics data analysis, while error analysis highlights the challenges and areas for future improvement. We propose GenoTEX as a promising resource for benchmarking and enhancing AI-driven methods for genomics data analysis. We make our benchmark publicly available at https://github.com/Liu-Hy/GenoTex.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.15657",
        "title": "FIRST: Faster Improved Listwise Reranking with Single Token Decoding",
        "abstract": "Large Language Models (LLMs) have significantly advanced the field of information retrieval, particularly for reranking. Listwise LLM rerankers have showcased superior performance and generalizability compared to existing supervised approaches. However, conventional listwise LLM reranking methods lack efficiency as they provide ranking output in the form of a generated ordered sequence of candidate passage identifiers. Further, they are trained with the typical language modeling objective, which treats all ranking errors uniformly\u2013potentially at the cost of misranking highly relevant passages. Addressing these limitations, we introduce FIRST1 , a novel listwise LLM reranking approach leveraging the output logits of the first generated identifier to directly obtain a ranked ordering of the candidates. Further, we incorporate a learning-to-rank loss during training, prioritizing ranking accuracy for the more relevant passages. Empirical results demonstrate that FIRST accelerates inference by 50% while maintaining a robust ranking performance with gains across the BEIR benchmark. Finally, to illustrate the practical effectiveness of listwise LLM rerankers, we investigate their application in providing relevance feedback for retrievers during inference. Our results show that LLM rerankers can provide a stronger distillation signal compared to crossencoders, yielding substantial improvements in retriever recall after relevance feedback.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.16048",
        "title": "Evaluating D-MERIT of Partial-annotation on Information Retrieval",
        "abstract": "Retrieval models are often evaluated on partially-annotated datasets. Each query is mapped to a few relevant texts and the remain- ing corpus is assumed to be irrelevant. As a result, models that successfully retrieve false negatives are punished in evaluation. Unfortu- nately, completely annotating all texts for every query is not resource efficient. In this work, we show that using partially-annotated datasets in evaluation can paint a distorted picture. We curate D-MERIT, a passage retrieval evalua- tion set from Wikipedia, aspiring to contain all relevant passages for each query. Queries describe a group (e.g., \u201cjournals about linguis- tics\u201d) and relevant passages are evidence that entities belong to the group (e.g., a passage indicating that Language is a journal about lin- guistics). We show that evaluating on a dataset containing annotations for only a subset of the relevant passages might result in misleading ranking of the retrieval systems and that as more relevant texts are included in the eval- uation set, the rankings converge. We propose our dataset as a resource for evaluation and our study as a recommendation for balance be- tween resource-efficiency and reliable evalua- tion when annotating evaluation sets for text retrieval. Our dataset can be downloaded from https://D-MERIT.github.io",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.16383",
        "title": "Context-augmented Retrieval: A Novel Framework for Fast Information Retrieval based Response Generation using Large Language Model",
        "abstract": "Generating high-quality answers consistently by providing con- textual information embedded in the prompt passed to the Large Language Model (LLM) is dependent on the quality of information retrieval. As the corpus of contextual information grows, the an- swer/inference quality of Retrieval Augmented Generation (RAG) based Question Answering (QA) systems declines. This work solves this problem by combining classical text classification with the Large Language Model (LLM) to enable quick information retrieval from the vector store and ensure the relevancy of retrieved infor- mation. For the same, this work proposes a new approach Context Augmented retrieval (CAR), where partitioning of vector database by real-time classification of information flowing into the corpus is done. CAR demonstrates good quality answer generation along with significant reduction in information retrieval and answer gen- eration time.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.16828",
        "title": "Ragnar\u00f6k: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track",
        "abstract": "Did you try out the new Bing Search? Or maybe you fiddled around with Google AI Overviews? These might sound familiar because the modern-day search stack has recently evolved to include retrieval- augmented generation (RAG) systems. They allow searching and incorporating real-time data into large language models (LLMs) to provide a well-informed, attributed, concise summary in contrast to the traditional search paradigm that relies on displaying a ranked list of documents. Therefore, given these recent advancements, it is crucial to have an arena to build, test, visualize, and systematically evaluate RAG-based search systems. With this in mind, we propose the TREC 2024 RAG Track to foster innovation in evaluating RAG systems. In our work, we lay out the steps we\u2019ve made towards making this track a reality \u2014 we describe the details of our reusable framework, Ragnar\u00f6k, explain the curation of the new MS MARCO V2.1 collection choice, release the development topics for the track, and standardize the I/O definitions which assist the end user. Next, using Ragnar\u00f6k, we identify and provide key industrial baselines such as OpenAI\u2019s GPT-4o or Cohere\u2019s Command R+. Further, we introduce a web-based user interface for an interactive arena allow- ing benchmarking pairwise RAG systems by crowdsourcing. We open-source our Ragnar\u00f6k framework and baselines to achieve a unified standard for future RAG systems.\nhttps://github.com/castorini/ragnarok",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.09167",
        "title": "Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse",
        "abstract": "The efficacy of large language models (LLMs) is heavily dependent on the quality of the under- lying data, particularly within specialized do- mains. A common challenge when fine-tuning LLMs for domain-specific applications is the potential degradation of the model\u2019s generaliza- tion capabilities. To address these issues, we propose a two-stage approach for the construc- tion of production prompts designed to yield high-quality data. This method involves the generation of a diverse array of prompts that en- compass a broad spectrum of tasks and exhibit a rich variety of expressions. Furthermore, we introduce a cost-effective, multi-dimensional quality assessment framework to ensure the in- tegrity of the generated labeling data. Utilizing a dataset comprised of service provider and cus- tomer interactions from the real estate sector, we demonstrate a positive correlation between data quality and model performance. Notably, our findings indicate that the domain-specific proficiency of general LLMs can be enhanced through fine-tuning with data produced via our proposed method, without compromising their overall generalization abilities, even when ex- clusively domain-specific data is employed for fine-tuning.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.02777",
        "title": "From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models",
        "abstract": "This paper introduces RAISE (Reason- ing and Acting through Scratchpad and Examples), an advanced architecture en- hancing the integration of Large Language Models (LLMs) like GPT-4 into conver- sational agents. RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirror- ing human short-term and long-term mem- ory, to maintain context and continuity in conversations. It entails a comprehen- sive agent construction scenario, includ- ing phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase. This approach appears to enhance agent controllability and adapt- ability in complex, multi-turn dialogues. Our preliminary evaluations in a real es- tate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader appli- cations. This work contributes to the AI field by providing a robust framework for developing more context-aware and versa- tile conversational agents.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.10739",
        "title": "Efficient Multimodal Large Language Models: A Survey",
        "abstract": "In the past year, Multimodal Large Language Models (MLLMs) have demon- strated remarkable performance in tasks such as visual question answering, vi- sual understanding and reasoning. However, the extensive model size and high training and inference costs have hindered the widespread application of MLLMs in academia and industry. Thus, studying efficient and lightweight MLLMs has enormous potential, especially in edge computing scenarios. In this survey, we provide a comprehensive and systematic review of the current state of effi- cient MLLMs. Specifically, we summarize the timeline of representative effi- cient MLLMs, research state of efficient structures and strategies, and the appli- cations. Finally, we discuss the limitations of current efficient MLLM research and promising future directions. Please refer to our GitHub repository for more details: https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2301.07573",
        "title": "Synthcity: facilitating innovative use cases of synthetic data in different data modalities",
        "abstract": "Synthcity is an open-source software package for innovative use cases of synthetic data in ML fairness, privacy and augmentation across diverse tabular data modal- ities, including static data, regular and irregular time series, data with censoring, multi-source data, composite data, and more. Synthcity provides the practitioners with a single access point to cutting edge research and tools in synthetic data. It also offers the community a playground for rapid experimentation and prototyping, a one-stop-shop for SOTA benchmarks, and an opportunity for extending research impact. The library can be accessed on GitHub and pip. We warmly invite the community to join the development effort by providing feedback, reporting bugs, and contributing code.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.02611v3",
        "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
        "abstract": "Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at mul- tiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information. In this work, we propose to combine the advantages from both methods. Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. We further ex- plore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. We demonstrate the ef- fectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets, achieving the test set performance of 89.0% and 82.1% without any post-processing. Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow at https: //github.com/tensorflow/models/tree/master/research/deeplab.\nKeywords: Semanticimagesegmentation,spatialpyramidpooling,encoder- decoder, and depthwise separable convolution.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2305.17349v2",
        "title": "Condition-Invariant Semantic Segmentation",
        "abstract": "Adaptation of semantic segmentation networks to different visual conditions is vital for robust perception in autonomous cars and robots. However, previous work has shown that most feature-level adaptation methods, which employ adversarial training and are validated on synthetic-to-real adaptation, provide marginal gains in condition-level adaptation, being outperformed by simple pixel-level adaptation via stylization. Motivated by these findings, we propose to leverage stylization in performing feature-level adaptation by aligning the internal network features extracted by the encoder of the network from the original and the stylized view of each input image with a novel feature invariance loss. In this way, we encourage the encoder to extract features that are already invariant to the style of the input, allowing the decoder to focus on parsing these features and not on further abstracting from the specific style of the input. We implement our method, named Condition-Invariant Semantic Segmentation (CISS), on the current state-of-the-art domain adaptation architecture and achieve outstanding results on condition-level adaptation. In particular, CISS sets the new state of the art in the popular daytime-to-nighttime Cityscapes\u2192Dark Zurich benchmark. Furthermore, our method achieves the second-best performance on the normal-to-adverse Cityscapes\u2192ACDC benchmark. CISS is shown to generalize well to domains unseen during training, such as BDD100K-night. Code is publicly available at https://github.com/SysCV/CISS.\nIndex Terms\u2014Semantic segmentation, domain adaptation, adverse conditions, invariance, unsupervised learning. \u2726",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.09203",
        "title": "Transferring Knowledge for Food Image Segmentation using Transformers and Convolutions",
        "abstract": "Food image segmentation is an important task that has ubiquitous applications, such as estimating the nutritional value of a plate of food. Although machine learning mod- els have been used for segmentation in this domain, food images pose several challenges. One challenge is that food items can overlap and mix, making them difficult to distin- guish. Another challenge is the degree of inter-class sim- ilarity and intra-class variability, which is caused by the varying preparation methods and dishes a food item may be served in. Additionally, class imbalance is an inevitable issue in food datasets. To address these issues, two models are trained and compared, one based on convolutional neu- ral networks and the other on Bidirectional Encoder repre- sentation for Image Transformers (BEiT). The models are trained and valuated using the FoodSeg103 dataset, which is identified as a robust benchmark for food image segmen- tation. The BEiT model outperforms the previous state-of- the-art model by achieving a mean intersection over union of 49.4 on FoodSeg103. This study provides insights into transfering knowledge using convolution and Transformer- based approaches in the food image domain.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2211.15479",
        "title": "Object Detection in Aerial Imagery",
        "abstract": "\nObject detection in natural images has achieved remark- able results over the years. However, a similar progress has not yet been observed in aerial object detection due to several challenges, such as high resolution images, in- stances scale variation, class imbalance etc. We show the performance of two-stage, one-stage and attention based object detectors on the iSAID dataset. Furthermore, we de- scribe some modifications and analysis performed for dif- ferent models -\nin two stage detector: introduced weighted attention based FPN, class balanced sampler and density prediction head. in one stage detector: used weighted focal loss and intro- duced FPN\nin attention based detector: compare single,multi-scale at- tention and demonstrate effect of different backbones 1. Finally, we show a comparative study highlighting the pros and cons of different models in aerial imagery setting.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1811.07859",
        "title": "ORTHOSEG: A DEEP MULTIMODAL CONVOLUTIONAL NEURAL NETWORK\nARCHITECTURE FOR SEMANTIC SEGMENTATION OF ORTHOIMAGERY",
        "abstract": "This paper addresses the task of semantic segmentation of orthoimagery using multimodal data e.g. optical RGB, infrared and digital\nsurface model. We propose a deep convolutional neural network architecture termed OrthoSeg for semantic segmentation using\nmultimodal, orthorectified and coregistered data. We also propose a training procedure for supervised training of OrthoSeg. The\ntraining procedure complements the inherent architectural characteristics of OrthoSeg for preventing complex co-adaptations of\nlearned features, which may arise due to probable high dimensionality and spatial correlation in multimodal and/or multispectral\ncoregistered data. OrthoSeg consists of parallel encoding networks for independent encoding of multimodal feature maps and a\ndecoder designed for efficiently fusing independently encoded multimodal feature maps. A softmax layer at the end of the network\nuses the features generated by the decoder for pixel-wise classification. The decoder fuses feature maps from the parallel encoders\nlocally as well as contextually at multiple scales to generate per-pixel feature maps for final pixel-wise classification resulting in\nsegmented output. We experimentally show the merits of OrthoSeg by demonstrating state-of-the-art accuracy on the ISPRS\nPotsdam 2D Semantic Segmentation dataset. Adaptability is one of the key motivations behind OrthoSeg so that it serves as a useful\narchitectural option for a wide range of problems involving the task of semantic segmentation of coregistered multimodal and/or\nmultispectral imagery. Hence, OrthoSeg is designed to enable independent scaling of parallel encoder networks and decoder network\nto better match application requirements, such as the number of input channels, the effective field-of-view, and model capacity.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.07747",
        "title": "LOG-CAN: LOCAL-GLOBAL CLASS-AWARE NETWORK FOR SEMANTIC SEGMENTATION OF REMOTE SENSING IMAGES\n",
        "abstract": "Remote sensing images are known of having complex back- grounds, high intra-class variance and large variation of scales, which bring challenge to semantic segmentation. We present LoG-CAN, a multi-scale semantic segmenta- tion network with a global class-aware (GCA) module and local class-aware (LCA) modules to remote sensing images. Specifically, the GCA module captures the global represen- tations of class-wise context modeling to circumvent back- ground interference; the LCA modules generate local class representations as intermediate aware elements, indirectly associating pixels with global class representations to reduce variance within a class; and a multi-scale architecture with GCA and LCA modules yields effective segmentation of ob- jects at different scales via cascaded refinement and fusion of features. Through the evaluation on the ISPRS Vaihingen dataset and the ISPRS Potsdam dataset, experimental results indicate that LoG-CAN outperforms the state-of-the-art meth- ods for general semantic segmentation, while significantly reducing network parameters and computation. Code is available at https://github.com/xwmaxwma/rssegmentation.\nIndex Terms\u2014 Semantic segmentation, remote sensing, class representations",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.07916",
        "title": "IMAFD: An Interpretable Multi-stage Approach to Flood Detection from time series Multispectral Data",
        "abstract": "In this paper, we address two critical challenges in the domain of flood detection: the computational expense of large- scale time series change detection and the lack of interpretable decision-making processes on explainable AI (XAI). To overcome these challenges, we proposed an interpretable multi-stage approach to flood detection, IMAFD has been proposed. It provides an automatic, efficient and interpretable solution suitable for large-scale remote sensing tasks and offers insight into the decision-making process. The proposed IMAFD approach combines the analysis of the dynamic time series image sequences to identify images with possible flooding with the static, within-image semantic segmentation. It combines anomaly detection (at both image and pixel level) with semantic segmentation. The flood detection problem is addressed through four stages: (1) at a sequence level: identifying the suspected images (2) at a multi-image level: detecting change within suspected images (3) at an image level: semantic segmentation of images into Land, Water or Cloud class (4) decision making. Our contributions are two folder. First, we efficiently reduced the number of frames to be processed for dense change detection by providing a multi-stage holistic approach to flood detection. Second, the proposed semantic change detection method (stage 3) provides human users with an interpretable decision-making process, while most of the explainable AI (XAI) methods provide post hoc explanations. The evaluation of the proposed IMAFD framework was performed on three datasets, WorldFloods, RavAEn and MediaEval. For all the above datasets, the proposed framework demonstrates a competitive performance compared to other methods offering also interpretability and insight.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2011.00993",
        "title": "Real-time Semantic Segmentation with Context Aggregation Network\n",
        "abstract": "With the increasing demand of autonomous systems, pixelwise semantic seg- mentation for visual scene understanding needs to be not only accurate but also efficient for potential real-time applications. In this paper, we propose Context Aggregation Network, a dual branch convolutional neural network, with sig- nificantly lower computational costs as compared to the state-of-the-art, while maintaining a competitive prediction accuracy. Building upon the existing dual branch architectures for high-speed semantic segmentation, we design a cheap high resolution branch for effective spatial detailing and a context branch with light-weight versions of global aggregation and local distribution blocks, potent to capture both long-range and local contextual dependencies required for ac- curate semantic segmentation, with low computational overheads. We evaluate our method on two semantic segmentation datasets, namely Cityscapes dataset and UAVid dataset. For Cityscapes test set, our model achieves state-of-the-art results with mIOU of 75.9%, at 76 FPS on an NVIDIA RTX 2080Ti and 8 FPS on a Jetson Xavier NX. With regards to UAVid dataset, our proposed network achieves mIOU score of 63.5% with high execution speed (15 FPS).\nKeywords: Semantic segmentation, Real-time, convolutional neural network, context aggregation network",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2105.08788",
        "title": "Self-Supervised Learning for Fine-Grained Visual Categorization",
        "abstract": "Recent research in self-supervised learning (SSL) has shown its capability in learn- ing useful semantic representations from images for classification tasks. Through our work, we study the usefulness of SSL for Fine-Grained Visual Categoriza- tion (FGVC). FGVC aims to distinguish objects of visually similar sub categories within a general category. The small inter-class, but large intra-class variations within the dataset makes it a challenging task. The limited availability of annotated labels for such a fine-grained data encourages the need for SSL, where additional supervision can boost learning without the cost of extra annotations. Our baseline achieves 86.36% top-1 classification accuracy on CUB-200-2011 dataset by utiliz- ing random crop augmentation during training and center crop augmentation during testing. In this work, we explore the usefulness of various pretext tasks, specifically, rotation, pretext invariant representation learning (PIRL), and deconstruction and construction learning (DCL) for FGVC. Rotation as an auxiliary task promotes the model to learn global features, and diverts it from focusing on the subtle details. PIRL that uses jigsaw patches attempts to focus on discriminative local regions, but struggles to accurately localize them. DCL helps in learning local discriminating features and outperforms the baseline by achieving 87.41% top-1 accuracy. The deconstruction learning forces the model to focus on local object parts, while reconstruction learning helps in learning the correlation between the parts. We perform extensive experiments to reason our findings. Our code is available on GitHub1 .",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2011.02193",
        "title": "Weed Density and Distribution Estimation for Precision Agriculture using Semi-Supervised Learning",
        "abstract": "Uncontrolled growth of weeds can severely affect the crop yield and quality. Unrestricted use of herbicide for weed removal alters biodiversity and cause environmental pollution. Instead, identifying weed-infested regions can aid selective chemical treatment of these regions. Advances in analyzing farm images have resulted in solutions to identify weed plants. However, a majority of these approaches are based on supervised learning methods which requires huge amount of manually annotated images. As a result, these supervised approaches are economically infeasible for the individual farmer because of the wide variety of plant species being cultivated. In this paper, we propose a deep learning-based semi-supervised approach for robust estimation of weed density and distribution across farmlands using only limited color images acquired from autonomous robots. This weed density and distribution can be useful in a site-specific weed management system for selective treatment of infected areas using autonomous robots. In this work, the foreground vegetation pixels containing crops and weeds are first identified using a Convolutional Neural Network (CNN) based unsupervised segmentation. Subsequently, the weed infected regions are identified using a fine-tuned CNN, eliminating the need for designing hand-crafted features. The approach is validated on two datasets of different crop/weed species (1) Crop Weed Field Image Dataset (CWFID), which consists of carrot plant images and the (2) Sugar Beets dataset. The proposed method is able to localize weed-infested regions a maximum recall of 0.99 and estimate weed density with a maximum accuracy of 82.13%. Hence, the proposed approach is shown to generalize to different plant species without the need for extensive labeled data.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.04955",
        "title": "Degraded Polygons Raise Fundamental Questions of Neural Network Perception",
        "abstract": "It is well-known that modern computer vision systems often exhibit behaviors mis- aligned with those of humans: from adversarial attacks to image corruptions, deep learning vision models suffer in a variety of settings that humans capably handle. In light of these phenomena, here we introduce another, orthogonal perspective study- ing the human-machine vision gap. We revisit the task of recovering images under degradation, first introduced over 30 years ago in the Recognition-by-Components theory of human vision. Specifically, we study the performance and behavior of neural networks on the seemingly simple task of classifying regular polygons at varying orders of degradation along their perimeters. To this end, we implement the Automated Shape Recoverability Test1 for rapidly generating large-scale datasets of perimeter-degraded regular polygons, modernizing the historically manual cre- ation of image recoverability experiments. We then investigate the capacity of neural networks to recognize and recover such degraded shapes when initialized with different priors. Ultimately, we find that neural networks\u2019 behavior on this simple task conflicts with human behavior, raising a fundamental question of the robustness and learning capabilities of modern computer vision models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.13874",
        "title": "Recently, video moment retrieval and highlight detec- tion (MR/HD) are being spotlighted as the demand for video understanding is drastically increased. The key objective of MR/HD is to localize the moment and estimate clip-wise accordance level, i.e., saliency score, to the given text query. Although the recent transformer-based models brought some advances, we found that these methods do not fully exploit the information of a given query. For example, the relevance between text query and video contents is sometimes neglected when predicting the moment and its saliency. To tackle this issue, we introduce Query-Dependent DETR (QD-DETR), a detection transformer tailored for MR/HD. As we observe the insignificant role of a given query in transformer architec- tures, our encoding module starts with cross-attention layers to explicitly inject the context of text query into video repre- sentation. Then, to enhance the model\u2019s capability of exploit- ing the query information, we manipulate the video-query pairs to produce irrelevant pairs. Such negative (irrelevant) video-query pairs are trained to yield low saliency scores, which in turn, encourages the model to estimate precise ac- cordance between query-video pairs. Lastly, we present an input-adaptive saliency predictor which adaptively defines the criterion of saliency scores for the given video-query pairs. Our extensive studies verify the importance of build- ing the query-dependent representation for MR/HD. Specif- ically, QD-DETR outperforms state-of-the-art methods on QVHighlights, TVSum, and Charades-STA datasets. Codes are available at github.com/wjun0830/QD-DETR.",
        "abstract": "Query-Dependent Video Representation for Moment Retrieval and Highlight Detection",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2307.08145",
        "title": "Self-Attention Based Generative Adversarial Networks For Unsupervised Video Summarization",
        "abstract": "In this paper, we study the problem of producing a comprehensive video summary following an unsupervised approach that relies on adversarial learning. We build on a popular method where a Generative Adversarial Network (GAN) is trained to create representative summaries, indistinguishable from the originals. The introduction of the attention mechanism into the architecture for the selection, encoding and decoding of video frames, shows the efficacy of self-attention and transformer in modeling temporal relationships for video summarization. We propose the SUM-GAN-AED model that uses a self-attention mechanism for frame selection, combined with LSTMs for en- coding and decoding. We evaluate the performance of the SUM- GAN-AED model on the SumMe, TVSum and COGNIMUSE datasets. Experimental results indicate that using a self-attention mechanism as the frame selection mechanism outperforms the state-of-the-art on SumMe and leads to comparable to state-of- the-art performance on TVSum and COGNIMUSE.\nIndex Terms\u2014Unsupervised Video Summarization, Generative Adversarial Networks, key-frame extraction, Long Short-Term Memory, Deep Neural Networks",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.03169",
        "title": "Dynamical decoding of the competition between charge density waves in a kagome superconductor",
        "abstract": "The kagome superconductor CsV3Sb5 hosts a variety of charge density wave (CDW) phases, which play a fundamental role in the formation of other exotic electronic instabilities. However, identifying the precise structure of these CDW phases and their intricate relationships remain the subject of intense debate, due to the lack of static probes that can distinguish the CDW phases with identical spatial periodicity. Here, we unveil the competition between two coexisting 2 \u00d7 2 \u00d7 2 CDWs in CsV3Sb5 harnessing time-resolved X-ray diffraction. By analyzing the light-induced changes in the intensity of CDW superlattice peaks, we demonstrate the presence of both phases, each displaying a significantly different amount of melting upon excitation. The anomalous light-induced sharpening of peak width further shows that the phase that is more resistant to photo-excitation exhibits an increase in domain size at the expense of the other, thereby showcasing a hallmark of phase competition. Our results not only shed light on the interplay between the multiple CDW phases in CsV3Sb5, but also establish a non-equilibrium framework for comprehending complex phase relationships that are challenging to disentangle using static techniques.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.09770",
        "title": "\nHow to Data in Datathons",
        "abstract": "The rise of datathons, also known as data or data science hackathons, has provided a platform to collaborate, learn, and innovate in a short timeframe. Despite their significant potential benefits, organizations often struggle to effectively work with data due to a lack of clear guidelines and best practices for potential issues that might arise. Drawing on our own experiences and insights from organizing \u2265 80 datathon challenges with \u2265 60 partnership organizations since 2016, we provide guidelines and recommendations that serve as a resource for organizers to navigate the data-related complexities of datathons. We apply our proposed framework to 10 case studies.\n",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2111.10533",
        "title": "Temporal-MPI: Enabling Multi-Plane Images for\nDynamic Scene Modelling via Temporal Basis\nLearning",
        "abstract": "Novel view synthesis of static scenes has achieved remarkable advancements in producing photo-realistic results. However, key challenges remain for immersive rendering of dy- namic scenes. One of the seminal image-based rendering method, the multi-plane image (MPI), produces high novel-view synthesis quality for static scenes. But modelling dynamic contents by MPI is not studied. In this paper, we propose a novel Temporal-MPI representation which is able to encode the rich 3D and dynamic variation information throughout the entire video as compact temporal basis and coefficients jointly learned. Time-instance MPI for rendering can be generated efficiently using mini-seconds by linear combinations of temporal basis and coefficients from Temporal-MPI. Thus novel-views at arbitrary time-instance will be able to be rendered via Temporal-MPI in real-time with high visual quality. Our method is trained and evaluated on Nvidia Dynamic Scene Dataset. We show that our proposed Temporal- MPI is much faster and more compact compared with other state-of-the-art dynamic scene modelling methods.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2301.04644",
        "title": "DOES PROGRESS ON IMAGENET TRANSFER TO REAL-WORLD DATASETS?",
        "abstract": "Does progress on ImageNet transfer to real-world datasets? We investigate this question by evaluating ImageNet pre-trained models with varying accuracy (57% - 83%) on six practical image classification datasets. In particular, we study datasets collected with the goal of solving real-world tasks (e.g., classifying images from camera traps or satellites), as opposed to web-scraped benchmarks collected for comparing models. On multiple datasets, models with higher ImageNet accuracy do not consistently yield performance improvements. For certain tasks, interven- tions such as data augmentation improve performance even when architectures do not. We hope that future benchmarks will include more diverse datasets to encourage a more comprehensive approach to improving learning algorithms.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1905.02244",
        "title": "Searching for MobileNetV3",
        "abstract": "\nWe present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design. MobileNetV3 is tuned to mobile phone CPUs through a combination of hardware- aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and net- work design can work together to harness complementary approaches improving the overall state of the art. Through this process we create two new MobileNet models for re- lease: MobileNetV3-Large and MobileNetV3-Small which are targeted for high and low resource use cases. These models are then adapted and applied to the tasks of ob- ject detection and semantic segmentation. For the task of semantic segmentation (or any dense pixel prediction), we propose a new efficient segmentation decoder Lite Reduced Atrous Spatial Pyramid Pooling (LR-ASPP). We achieve new state of the art results for mobile classification, detec- tion and segmentation. MobileNetV3-Large is 3.2% more accurate on ImageNet classification while reducing latency by 20% compared to MobileNetV2. MobileNetV3-Small is 6.6% more accurate compared to a MobileNetV2 model with comparable latency. MobileNetV3-Large detection is over 25% faster at roughly the same accuracy as Mo- bileNetV2 on COCO detection. MobileNetV3-Large LR- ASPP is 34% faster than MobileNetV2 R-ASPP at similar accuracy for Cityscapes segmentation.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2310.16802",
        "title": "FROM MOLECULES TO MATERIALS: PRE-TRAINING LARGE GENERALIZABLE MODELS FOR ATOMIC PROP- ERTY PREDICTION",
        "abstract": "Foundation models have been transformational in machine learning fields such as natural language processing and computer vision. Similar success in atomic property prediction has been limited due to the challenges of training effective models across multiple chemical domains. To address this, we introduce Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that simul- taneously trains on multiple datasets from different chemical domains, treating each dataset as a unique pre-training task within a multi-task framework. Our combined training dataset consists of \u223c120M systems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and generalization by fine-tuning over a diverse set of downstream tasks and datasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP demonstrates an average improvement of 59% over training from scratch and matches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the potential of pre-training strategies that utilize diverse data to advance property prediction across chemical domains, especially for low-data tasks. Please visit https://nima.sh/jmp for further information.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.16259",
        "title": "Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction",
        "abstract": "Recently, the remarkable capabilities of large language models (LLMs) have been illustrated across a variety of research domains such as natural language processing, computer vision, and molecular modeling. We extend this paradigm by utilizing LLMs for material property prediction by introducing our model Materials Informatics Trans- former (MatInFormer). Specifically, we introduce a novel approach that involves learn- ing the grammar of crystallography through the tokenization of pertinent space group information. We further illustrate the adaptability of MatInFormer by incorporating task-specific data pertaining to Metal-Organic Frameworks (MOFs). Through atten- tion visualization, we uncover the key features that the model prioritizes during prop- erty prediction. The effectiveness of our proposed model is empirically validated across\n14 distinct datasets, hereby underscoring its potential for high throughput screening through accurate material property prediction.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.00890",
        "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day",
        "abstract": "Conversational generative AI has demonstrated remarkable promise for empow- ering biomedical practitioners, but current investigations focus on unimodal text. Multimodal conversational AI has seen rapid progress by leveraging billions of image-text pairs from the public web, but such general-domain vision-language models still lack sophistication in understanding and conversing about biomedical images. In this paper, we propose a cost-efficient approach for training a vision- language conversational assistant that can answer open-ended research questions of biomedical images. The key idea is to leverage a large-scale, broad-coverage biomedical figure-caption dataset extracted from PubMed Central, use GPT-4 to self-instruct open-ended instruction-following data from the captions, and then fine-tune a large general-domain vision-language model using a novel curriculum learning method. Specifically, the model first learns to align biomedical vocabulary using the figure-caption pairs as is, then learns to master open-ended conversational semantics using GPT-4 generated instruction-following data, broadly mimicking how a layperson gradually acquires biomedical knowledge. This enables us to train a Large Language and Vision Assistant for BioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med exhibits excellent multimodal con- versational capability and can follow open-ended instruction to assist with inquiries about a biomedical image. On three standard biomedical visual question answering datasets, fine-tuning LLaVA-Med outperforms previous supervised state-of-the-art on certain metrics. To facilitate biomedical multimodal research, we will release our instruction-following data and the LLaVA-Med model.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.11678",
        "title": "Full or Weak annotations?\nAn adaptive strategy for budget-constrained annotation campaigns",
        "abstract": "Annotating new datasets for machine learning tasks is tedious, time-consuming, and costly. For segmentation ap- plications, the burden is particularly high as manual delin- eations of relevant image content are often extremely expen- sive or can only be done by experts with domain-specific knowledge. Thanks to developments in transfer learning and training with weak supervision, segmentation models can now also greatly benefit from annotations of different kinds. However, for any new domain application looking to use weak supervision, the dataset builder still needs to define a strategy to distribute full segmentation and other weak annotations. Doing so is challenging, however, as it is a priori unknown how to distribute an annotation budget for a given new dataset. To this end, we propose a novel ap- proach to determine annotation strategies for segmentation datasets, whereby estimating what proportion of segmen- tation and classification annotations should be collected given a fixed budget. To do so, our method sequentially determines proportions of segmentation and classification annotations to collect for budget-fractions by modeling the expected improvement of the final segmentation model. We show in our experiments that our approach yields annota- tions that perform very close to the optimal for a number of different annotation budgets and datasets.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.12112",
        "title": "positive-Augmented Contrastive Learning for Image and Video Captioning Evaluation",
        "abstract": "\nThe CLIP model has been recently proven to be very effective for a variety of cross-modal tasks, including the evaluation of captions generated from vision-and-language architectures. In this paper, we propose a new recipe for a contrastive-based evaluation metric for image cap- tioning, namely Positive-Augmented Contrastive learning Score (PAC-S), that in a novel way unifies the learning of a contrastive visual-semantic space with the addition of generated images and text on curated data. Experiments spanning several datasets demonstrate that our new metric achieves the highest correlation with human judgments on both images and videos, outperforming existing reference- based metrics like CIDEr and SPICE and reference-free metrics like CLIP-Score. Finally, we test the system-level correlation of the proposed metric when considering pop- ular image captioning approaches, and assess the impact of employing different cross-modal features. Our source code and trained models are publicly available at: https: //github.com/aimagelab/pacscore.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03320",
        "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output",
        "abstract": "\nWe present InternLM-XComposer-2.5 (IXC-2.5), a ver- satile large-vision language model that supports long- contextual input and output. IXC-2.5 excels in various text-image comprehension and composition applications, achieving GPT-4V level capabilities with merely 7B LLM backend. Trained with 24K interleaved image-text contexts, it can seamlessly extend to 96K long contexts via RoPE ex- trapolation. This long-context capability allows IXC-2.5 to excel in tasks requiring extensive input and output con- texts. Compared to its previous 2.0 version, InternLM- XComposer-2.5 features three major upgrades in vision- language comprehension: (1) Ultra-High Resolution Un- derstanding, (2) Fine-Grained Video Understanding, and (3) Multi-Turn Multi-Image Dialogue. In addition to com- prehension, IXC-2.5 extends to two compelling applications using extra LoRA parameters for text-image composition: (1) Crafting Webpages and (2) Composing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28 benchmarks, outperforming existing open-source state-of- the-art models on 16 benchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on 16 key tasks. The InternLM-XComposer-2.5 is publicly available at https://github.com/InternLM/InternLM- XComposer.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03243",
        "title": "Visual Grounding with Attention-Driven Constraint Balancing",
        "abstract": " Unlike Object Detection, Visual Grounding task necessitates the detection of an object described by complex free-form language. To simultaneously model such complex semantic and visual representations, recent state-of-the-art studies adopt transformer-based models to fuse features from both modalities, further introducing various modules that modulate visual features to align with the language expressions and elim- inate the irrelevant redundant information. However, their loss function, still adopting common Object Detection losses, solely governs the bound- ing box regression output, failing to fully optimize for the above objec- tives. To tackle this problem, in this paper, we first analyze the attention mechanisms of transformer-based models. Building upon this, we further propose a novel framework named Attention-Driven Constraint Balanc- ing (AttBalance) to optimize the behavior of visual features within language-relevant regions. Extensive experimental results show that our method brings impressive improvements. Specifically, we achieve con- stant improvements over five different models evaluated on four different benchmarks. Moreover, we attain a new state-of-the-art performance by integrating our method into QRNet.\n",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.04979",
        "title": "CoCo: A Coupled Contrastive Framework for Unsupervised Domain Adaptive Graph Classification",
        "abstract": "Although graph neural networks (GNNs) have achieved impressive achievements in graph classi- fication, they often need abundant task-specific la- bels, which could be extensively costly to acquire. A credible solution is to explore additional labeled graphs to enhance unsupervised learning on the target domain. However, how to apply GNNs to domain adaptation remains unsolved owing to the insufficient exploration of graph topology and the significant domain discrepancy. In this paper, we propose Coupled Contrastive Graph Representa- tion Learning (CoCo), which extracts the topolog- ical information from coupled learning branches and reduces the domain discrepancy with cou- pled contrastive learning. CoCo contains a graph convolutional network branch and a hierarchi- cal graph kernel network branch, which explore graph topology in implicit and explicit manners. Besides, we incorporate coupled branches into a holistic multi-view contrastive learning frame- work, which not only incorporates graph repre- sentations learned from complementary views for enhanced understanding, but also encourages the similarity between cross-domain example pairs with the same semantics for domain alignment. Extensive experiments on popular datasets show that our CoCo outperforms these competing base- lines in different settings generally.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.06619",
        "title": "TransVG++: End-to-End Visual Grounding with\nLanguage Conditioned Vision Transformer",
        "abstract": "In this work, we explore neat yet effective Transformer-based frameworks for visual grounding. The previous methods generally address the core problem of visual grounding, i.e., multi-modal fusion and reasoning, with manually-designed mechanisms. Such heuristic designs are not only complicated but also make models easily overfit specific data distributions. To avoid this, we first propose TransVG, which establishes multi-modal correspondences by Transformers and localizes referred regions by directly regressing box coordinates. We empirically show that complicated fusion modules can be replaced by a simple stack of Transformer encoder layers with higher performance. However, the core fusion Transformer in TransVG is stand-alone against uni-modal encoders, and thus should be trained from scratch on limited visual grounding data, which makes it hard to be optimized and leads to sub-optimal performance. To this end, we further introduce TransVG++ to make two-fold improvements. For one thing, we upgrade our framework to a purely Transformer-based one by leveraging Vision Transformer (ViT) for vision feature encoding. For another, we devise Language Conditioned Vision Transformer that removes external fusion modules and reuses the uni-modal ViT for vision-language fusion at the intermediate layers. We conduct extensive experiments on five prevalent datasets, and report a series of state-of-the-art records.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1608.00272",
        "title": "Modeling Context in Referring Expressions",
        "abstract": "Humans refer to objects in their environments all the time, especially in dialogue with other people. We explore generating and com- prehending natural language referring expressions for objects in images. In particular, we focus on incorporating better measures of visual con- text into referring expression models and find that visual comparison to other objects within an image helps improve performance significantly. We also develop methods to tie the language generation process together, so that we generate expressions for all objects of a particular category jointly. Evaluation on three recent datasets - RefCOCO, RefCOCO+, and RefCOCOg1, shows the advantages of our methods for both refer- ring expression generation and comprehension.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2311.00278",
        "title": "RE-SCORING USING IMAGE-LANGUAGE SIMILARITY FOR FEW-SHOT OBJECT DETECT",
        "abstract": "Few-shot object detection, which focuses on detecting novel objects with few labels, is an emerging challenge in the community. Recent studies show that adapting a pre-trained model or modified loss function can improve performance. In this paper, we explore leveraging the power of Con- trastive Language-Image Pre-training (CLIP) and hard negative classification loss in low data setting. Specifically, we propose Re-scoring using Image-language Similarity for Few-shot object detection (RISF) which extends Faster R-CNN by introducing Calibration Module using CLIP (CM-CLIP) and Background Negative Re-scale Loss (BNRL). The former adapts CLIP, which performs zero-shot classification, to re-score the classification scores of a detector using image-class similarities, the latter is modified classification loss considering the punishment for fake backgrounds as well as confusing categories on a generalized few-shot object detection dataset. Extensive experiments on MS- COCO and PASCAL VOC show that the proposed RISF substantially outperforms the state-of-the-art approaches. The code will be available.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03253",
        "title": "STF: SENTENCE TRANSFORMER FINE-TUNING FOR TOPIC CATEGORIZATION WITH LIMITED DATA \u2217",
        "abstract": "Nowadays, topic classification from tweets attracts several researchers\u2019 attention. Different classification systems have been suggested thanks to these research efforts. Nevertheless, they are confronted major challenge owing to the low performance metrics because of the limited labeled data. We propose, Sentence Transformers Fine-tuning (STF), a topic detection system that leverages pre-trained Sentence Transformers models and Fine-tuning to classify topics from tweets accurately. Moreover, extensive parameter sensitivity analyses were established to fine-tune STF parameters\u2019 for our topic classification task to achieve the best performance results. Experiments on two benchmark datasets demonstrated that: (1) the proposed STF can be effectively used for classifying tweet topics and outperform the latest state-of-the-art approaches; (2) the proposed STF does not require a huge amount of labeled tweets to achieve good accuracy, which is the lack in the popular of the state-of-the-art approaches. Our main contribution is the achievement of promising results in tweet topic classification by applying pre-trained sentence transformers language models",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.15624",
        "title": "Semantic Gaussians: Open-Vocabulary Scene Understanding with 3D Gaussian Splatting",
        "abstract": "Open-vocabulary 3D scene understanding presents a signif- icant challenge in computer vision, with wide-ranging applications in embodied agents and augmented reality systems. Previous approaches have adopted Neural Radiance Fields (NeRFs) to analyze 3D scenes. In this paper, we introduce Semantic Gaussians, a novel open-vocabulary scene understanding approach based on 3D Gaussian Splatting. Our key idea is distilling pre-trained 2D semantics into 3D Gaussians. We design a versatile projection approach that maps various 2D semantic features from pre-trained image encoders into a novel semantic component of 3D Gaussians, without the additional training required by NeRFs. We fur- ther build a 3D semantic network that directly predicts the semantic component from raw 3D Gaussians for fast inference. We explore several applications of Semantic Gaussians: semantic segmentation on ScanNet- 20, where our approach attains a 4.2% mIoU and 4.0% mAcc improve- ment over prior open-vocabulary scene understanding counterparts; ob- ject part segmentation, scene editing, and spatial-temporal segmentation with better qualitative results over 2D and 3D baselines, highlighting its versatility and effectiveness on supporting diverse downstream tasks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1912.08830",
        "title": "ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language",
        "abstract": "We introduce the task of 3D object localization in RGB-D scans using natural language descriptions. As input, we assume a point cloud of a scanned 3D scene along with a free-form description of a spec- ified target object. To address this task, we propose ScanRefer, learn- ing a fused descriptor from 3D object proposals and encoded sentence embeddings. This fused descriptor correlates language expressions with geometric features, enabling regression of the 3D bounding box of a tar- get object. We also introduce the ScanRefer dataset, containing 51,583 descriptions of 11,046 objects from 800 ScanNet [9] scenes. ScanRefer is the first large-scale effort to perform object localization via natural language expression directly in 3D 1.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0001",
        "title": "Calculation of prompt diphoton production cross sections at Tevatron and\n  LHC energies",
        "abstract": "A fully differential calculation in perturbative quantum chromodynamics is\n presented for the production of massive photon pairs at hadron colliders. All\n next-to-leading order perturbative contributions from quark-antiquark,\n gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n all-orders resummation of initial-state gluon radiation valid at\n next-to-next-to-leading logarithmic accuracy. The region of phase space is specified in which the calculation is most reliable. Good agreement is\n demonstrated with data from the Fermilab Tevatron, and predictions are made for\n more detailed tests with CDF and DO data. Predictions are shown for\n distributions of diphoton pairs produced at the energy of the Large Hadron\n Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\n boson are contrasted with those produced from QCD processes at the LHC, showing\n that enhanced sensitivity to the signal can be obtained with judicious\n selection of events.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0002",
        "title": "Sparsity-certifying Graph Decompositions",
        "abstract": "We describe a new algorithm, the $(k,\\ell)$-pebble game with colors, and use\n it obtain a characterization of the family of $(k,\\ell)$-sparse graphs and\n algorithmic solutions to a family of problems concerning tree decompositions of\n graphs. Special instances of sparse graphs appear in rigidity theory and have\n received increased attention in recent years. In particular, our colored\n pebbles generalize and strengthen the previous results of Lee and Streinu and\n give a new proof of the Tutte-Nash-Williams characterization of arboricity. We\n also present a new decomposition that certifies sparsity based on the\n $(k,\\ell)$-pebble game with colors. Our work also exposes connections between\n pebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\n Westermann and Hendrickson.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0003",
        "title": "The evolution of the Earth-Moon system based on the dark matter field\n  fluid model",
        "abstract": "The evolution of Earth-Moon system is described by the dark matter field\n fluid model proposed in the Meeting of Division of Particle and Field 2004,\n American Physical Society. The current behavior of the Earth-Moon system agrees\n with this model very well and the general pattern of the evolution of the\n Moon-Earth system described by this model agrees with geological and fossil\n evidence. The closest distance of the Moon to Earth was about 259000 km at 4.5\n billion years ago, which is far beyond the Roche's limit. The result suggests\n that the tidal friction may not be the primary cause for the evolution of the\n Earth-Moon system. The average dark matter field fluid constant derived from\n Earth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts\n that the Mars's rotation is also slowing with the angular acceleration rate\n about -4.38 x 10^(-22) rad s^(-2).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0004",
        "title": "A determinant of Stirling cycle numbers counts unlabeled acyclic\n  single-source automata",
        "abstract": "We show that a determinant of Stirling cycle numbers counts unlabeled acyclic\n single-source automata. The proof involves a bijection from these automata to\n certain marked lattice paths and a sign-reversing involution to evaluate the\n determinant.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0005",
        "title": "From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\alpha}$",
        "abstract": "In this paper we show how to compute the $\\Lambda_{\\alpha}$ norm, $\\alpha\\ge\n 0$, using the dyadic grid. This result is a consequence of the description of\n the Hardy spaces $H^p(R^N)$ in terms of dyadic and special atoms.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0049",
        "title": "An algorithm for the classification of smooth Fano polytopes",
        "abstract": "We present an algorithm that produces the classification list of smooth Fano\n d-polytopes for any given d. The input of the algorithm is a single number,\n namely the positive integer d. The algorithm has been used to classify smooth\n Fano d-polytopes for d<=7. There are 7622 isomorphism classes of smooth Fano\n 6-polytopes and 72256 isomorphism classes of smooth Fano 7-polytopes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0050",
        "title": "Intelligent location of simultaneously active acoustic emission sources:\n  Part II",
        "abstract": "Part I describes an intelligent acoustic emission locator, while Part II\n discusses blind source separation, time delay estimation and location of two\n continuous acoustic emission sources.\n  Acoustic emission (AE) analysis is used for characterization and location of\n developing defects in materials. AE sources often generate a mixture of various\n statistically independent signals. A difficult problem of AE analysis is\n separation and characterization of signal components when the signals from\n various sources and the mode of mixing are unknown. Recently, blind source\n separation (BSS) by independent component analysis (ICA) has been used to solve\n these problems. The purpose of this paper is to demonstrate the applicability\n of ICA to locate two independent simultaneously active acoustic emission\n sources on an aluminum band specimen. The method is promising for\n non-destructive testing of aircraft frame structures by acoustic emission\n analysis.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0051",
        "title": "Visualizing Teleportation",
        "abstract": "A novel way of picturing the processing of quantum information is described,\n allowing a direct visualization of teleportation of quantum states and\n providing a simple and intuitive understanding of this fascinating phenomenon.\n The discussion is aimed at providing physicists a method of explaining\n teleportation to non-scientists. The basic ideas of quantum physics are first\n explained in lay terms, after which these ideas are used with a graphical\n description, out of which teleportation arises naturally.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0052",
        "title": "Quantum Field Theory on Curved Backgrounds. II. Spacetime Symmetries",
        "abstract": "We study space-time symmetries in scalar quantum field theory (including\n interacting theories) on static space-times. We first consider Euclidean\n quantum field theory on a static Riemannian manifold, and show that the\n isometry group is generated by one-parameter subgroups which have either\n self-adjoint or unitary quantizations. We analytically continue the\n self-adjoint semigroups to one-parameter unitary groups, and thus construct a\n unitary representation of the isometry group of the associated Lorentzian\n manifold. The method is illustrated for the example of hyperbolic space, whose\n Lorentzian continuation is Anti-de Sitter space.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0053",
        "title": "A Global Approach to the Theory of Special Finsler Manifolds",
        "abstract": "The aim of the present paper is to provide a global presentation of the\n theory of special Finsler manifolds. We introduce and investigate globally (or\n intrinsically, free from local coordinates) many of the most important and most\n commonly used special Finsler manifolds: locally Minkowskian, Berwald,\n Landesberg, general Landesberg, $P$-reducible, $C$-reducible,\n semi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent,\n $C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of\n the second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like,\n $R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant\n curvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global\n definitions of these special Finsler manifolds are introduced. Various\n relationships between the different types of the considered special Finsler\n manifolds are found. Many local results, known in the literature, are proved\n globally and several new results are obtained. As a by-product, interesting\n identities and properties concerning the torsion tensor fields and the\n curvature tensor fields are deduced. Although our investigation is entirely\n global, we provide; for comparison reasons, an appendix presenting a local\n counterpart of our global approach and the local definitions of the special\n Finsler spaces considered.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.0054",
        "title": "The Hardy-Lorentz Spaces $H^{p,q}(R^n)$",
        "abstract": "In this paper we consider the Hardy-Lorentz spaces $H^{p,q}(R^n)$, with\n $0<p\\le 1$, $0<q\\le \\infty$. We discuss the atomic decomposition of the\n elements in these spaces, their interpolation properties, and the behavior of\n singular integrals and other operators acting on them.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.07883",
        "title": "Combinatorial Pure Exploration of Causal Bandits",
        "abstract": "The combinatorial pure exploration of causal bandits is the following online\n learning task: given a causal graph with unknown causal inference\n distributions, in each round we choose a subset of variables to intervene or do\n no intervention, and observe the random outcomes of all random variables, with\n the goal that using as few rounds as possible, we can output an intervention\n that gives the best (or almost best) expected outcome on the reward variable\n $Y$ with probability at least $1-\\delta$, where $\\delta$ is a given confidence\n level. We provide the first gap-dependent and fully adaptive pure exploration\n algorithms on two types of causal models -- the binary generalized linear model\n (BGLM) and general graphs. For BGLM, our algorithm is the first to be designed\n specifically for this setting and achieves polynomial sample complexity, while\n all existing algorithms for general graphs have either sample complexity\n exponential to the graph size or some unreasonable assumptions. For general\n graphs, our algorithm provides a significant improvement on sample complexity,\n and it nearly matches the lower bound we prove. Our algorithms achieve such\n improvement by a novel integration of prior causal bandit algorithms and prior\n adaptive pure exploration algorithms, the former of which utilize the rich\n observational feedback in causal bandits but are not adaptive to reward gaps,\n while the latter of which have the issue in reverse.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2207.06049",
        "title": "Liouville-type theorems for the Lane-Emden equation in the half-space\n  and cones",
        "abstract": "We prove that 0 the only classical solution of the Lane-Emden equation in the\n half-space which is stable outside a compact set. We also consider weak\n solutions and the case of general cones.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0708.3956",
        "title": "The asymptotic behaviour of recurrence coefficients for orthogonal\n  polynomials with varying exponential weights",
        "abstract": "We consider orthogonal polynomials $\\{p_{n,N}(x)\\}_{n=0}^{\\infty}$ on the\n real line with respect to a weight $w(x)=e^{-NV(x)}$ and in particular the\n asymptotic behaviour of the coefficients $a_{n,N}$ and $b_{n,N}$ in the three\n term recurrence $x \\pi_{n,N}(x) = \\pi_{n+1,N}(x) + b_{n,N} \\pi_{n,N}(x) +\n a_{n,N} \\pi_{n-1,N}(x)$. For one-cut regular $V$ we show, using the Deift-Zhou\n method of steepest descent for Riemann-Hilbert problems, that the diagonal\n recurrence coefficients $a_{n,n}$ and $b_{n,n}$ have asymptotic expansions as\n $n \\to \\infty$ in powers of $1/n^2$ and powers of $1/n$, respectively.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2302.06551",
        "title": "Primes in tuples and Romanoff's theorem",
        "abstract": "We obtain a lower bound for a number of primes in tuples. As applications, we\n obtain a lower bound for the Romanoff type representation functions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2305.15374",
        "title": "ASPER: Answer Set Programming Enhanced Neural Network Models for Joint\n  Entity-Relation Extraction",
        "abstract": "A plethora of approaches have been proposed for joint entity-relation (ER)\n extraction. Most of these methods largely depend on a large amount of manually\n annotated training data. However, manual data annotation is time consuming,\n labor intensive, and error prone. Human beings learn using both data (through\n induction) and knowledge (through deduction). Answer Set Programming (ASP) has\n been a widely utilized approach for knowledge representation and reasoning that\n is elaboration tolerant and adept at reasoning with incomplete information.\n This paper proposes a new approach, ASP-enhanced Entity-Relation extraction\n (ASPER), to jointly recognize entities and relations by learning from both data\n and domain knowledge. In particular, ASPER takes advantage of the factual\n knowledge (represented as facts in ASP) and derived knowledge (represented as\n rules in ASP) in the learning process of neural network models. We have\n conducted experiments on two real datasets and compare our method with three\n baselines. The results show that our ASPER model consistently outperforms the\n baselines.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.10664",
        "title": "Nonadiabatic transitions during a passage near a critical point",
        "abstract": "The passage through a critical point of a many-body quantum system leads to\n abundant nonadiabatic excitations. Here, we explore a regime, in which the\n critical point is not crossed although the system is passing slowly very close\n to it. We show that the leading exponent for the excitation probability then\n can be obtained by standard arguments of the Dykhne formula but the exponential\n prefactor is no longer simple, and behaves as a power law on the characteristic\n transition rate. We derive this prefactor for the nonlinear Landau-Zener (nLZ)\n model by adjusting the Dykhne's approach. Then, we introduce an exactly\n solvable model of the transition near a critical point in the Stark ladder. We\n derive the number of the excitations for it without approximations, and find\n qualitatively similar results for the excitation scaling.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1907.08698",
        "title": "Leveraging Knowledge Bases And Parallel Annotations For Music Genre\n  Translation",
        "abstract": "Prevalent efforts have been put in automatically inferring genres of musical\n items. Yet, the propose solutions often rely on simplifications and fail to\n address the diversity and subjectivity of music genres. Accounting for these\n has, though, many benefits for aligning knowledge sources, integrating data and\n enriching musical items with tags. Here, we choose a new angle for the genre\n study by seeking to predict what would be the genres of musical items in a\n target tag system, knowing the genres assigned to them within source tag\n systems. We call this a translation task and identify three cases: 1) no common\n annotated corpus between source and target tag systems exists, 2) such a large\n corpus exists, 3) only few common annotations exist. We propose the related\n solutions: a knowledge-based translation modeled as taxonomy mapping, a\n statistical translation modeled with maximum likelihood logistic regression; a\n hybrid translation modeled with maximum a posteriori logistic regression with\n priors given by the knowledge-based translation. During evaluation, the\n solutions fit well the identified cases and the hybrid translation is\n systematically the most effective w.r.t. multilabel classification metrics.\n This is a first attempt to unify genre tag systems by leveraging both\n representation and interpretation diversity.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/physics/0410192",
        "title": "Coherent control of optical four-wave mixing by two-color\n  $\\omega$-$3\\omega$ ultrashort laser pulses",
        "abstract": "A theoretical investigation on the quantum control of optical coherent\n four-wave mixing interactions in two-level systems driven by two intense\n synchronized femtosecond laser pulses of central angular frequencies $\\omega$\n and $3\\omega$ is reported. By numerically solving the full Maxwell-Bloch\n equations beyond the slowly-varying envelope and rotating-wave approximations\n in the time domain, the nonlinear coupling to the optical field at frequency\n $5\\omega$ is found to depend critically on the initial relative phase $\\phi$ of\n the two propagating pulses; the coupling is enhanced when the pulses interfere\n constructively in the center ($\\phi=0$), while it is nearly suppressed when\n they are out of phase ($\\phi=\\pi$). The tuning of the initial absolute phase of\n the different frequency components of synchronously propapagating\n $\\omega$-$3\\omega$ femtosecond pulses can serve as a means to control coherent\n anti-Stokes Raman scattering (CARS) processes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1810.00446",
        "title": "Local-Ising type magnetic order and metamagnetism in the rare-earth\n  pyrogermanate Er$_2$Ge$_2$O$_7$",
        "abstract": "The recent discoveries of proximate quantum spin-liquid compounds and their\n potential application in quantum computing informs the search for new candidate\n materials for quantum spin-ice and spin-liquid physics. While the majority of\n such work has centered on members of the pyrochlore family due to their\n inherently frustrated linked tetrahedral structure, the rare-earth\n pyrogermanates also show promise for possible frustrated magnetic behavior.\n With the familiar stoichiometry $RE_2$Ge$_2$O$_7$, these compounds generally\n have tetragonal symmetry with a rare-earth sublattice built of a spiral of\n alternating edge and corner sharing rare-earth site triangles. Studies on\n Dy$_2$Ge$_2$O$_7$ and Ho$_2$Ge$_2$O$_7$ have shown tunable low temperature\n antiferromagnetic order, a high frustration index and spin-ice like dynamics.\n Here we use neutron diffraction to study magnetic order in Er$_2$Ge$_2$O$_7$\n (space group $P4_{1}2_{1}2$ ) and find the lowest yet Ne\\'el temperature in the\n pyrogermanates of 1.15 K. Using neutron powder diffraction we find the magnetic\n structure to order with $k = (0,0,0)$ ordering vector, magnetic space group\n symmetry $P4_{1}^{'}2_{1}2^{'}$ and a refined Er moment of $m = 8.1 \\mu_B$ -\n near the expected value for the Er$^{3+}$ free ion. Provocatively, the magnetic\n structure exhibits similar 'local-Ising' behavior to that seen in the\n pyrocholres where the Er moment points up or down along the short Er-Er bond.\n Upon applying a magnetic field we find a first order metamagnetic transition at\n $\\sim$ 0.35 T to a lower symmetry $P2_{1}^{'}2_{1}^{'}2$ structure. This\n magnetic transition involves an inversion of Er moments aligned antiparallel to\n the applied field describing a class I spin-flip type transition, indicating a\n strong local anisotropy at the Er site - reminiscent of that seen in the\n spin-ice pyrochlores.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1003.0434",
        "title": "The limit of F_p-Betti numbers of a tower of finite covers with amenable\n  fundamental groups",
        "abstract": "We prove an analogue of the Approximation Theorem of L^2-Betti numbers by\n Betti numbers for arbitrary coefficient fields and virtually torsionfree\n amenable groups. The limit of Betti numbers is identified as the dimension of\n some module over the Ore localization of the group ring.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2304.01143",
        "title": "Use Your Head: Improving Long-Tail Video Recognition",
        "abstract": "This paper presents an investigation into long-tail video recognition. We\n demonstrate that, unlike naturally-collected video datasets and existing\n long-tail image benchmarks, current video benchmarks fall short on multiple\n long-tailed properties. Most critically, they lack few-shot classes in their\n tails. In response, we propose new video benchmarks that better assess\n long-tail recognition, by sampling subsets from two datasets: SSv2 and VideoLT.\n  We then propose a method, Long-Tail Mixed Reconstruction, which reduces\n overfitting to instances from few-shot classes by reconstructing them as\n weighted combinations of samples from head classes. LMR then employs label\n mixing to learn robust decision boundaries. It achieves state-of-the-art\n average class accuracy on EPIC-KITCHENS and the proposed SSv2-LT and\n VideoLT-LT. Benchmarks and code at: tobyperrett.github.io/lmr",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1804.03707",
        "title": "A Tamper-Free Semi-Universal Communication System for Deletion Channels",
        "abstract": "We investigate the problem of reliable communication between two legitimate\n parties over deletion channels under an active eavesdropping (aka jamming)\n adversarial model. To this goal, we develop a theoretical framework based on\n probabilistic finite-state automata to define novel encoding and decoding\n schemes that ensure small error probability in both message decoding as well as\n tamper detecting. We then experimentally verify the reliability and\n tamper-detection property of our scheme.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2207.03023",
        "title": "Superior mechanical properties by exploiting size-effects and multiscale\n  interactions in hierarchically architected foams",
        "abstract": "Protective applications in extreme environments demand thermally stable\n materials with superior modulus, strength, and specific energy absorption (SEA)\n at lightweight. However, these properties typically have a trade-off.\n Hierarchically architected materials--such as the architected vertically\n aligned carbon nanotube (VACNT) foams--offer the potential to overcome these\n trade-offs to achieve synergistic enhancement in mechanical properties. Here,\n we adopt a full-factorial design of experiments (DOE) approach to optimize\n multitier design parameters to achieve synergistic enhancement in SEA,\n strength, and modulus at lightweight in VACNT foams with mesoscale cylindrical\n architecture. We exploit the size effects from geometrically-confined synthesis\n and the highly interactive morphology of CNTs to enable higher-order design\n parameter interactions that intriguingly break the diameter-to-thickness\n (D/t)-dependent scaling laws found in common tubular architected materials. We\n show that exploiting complementary hierarchical mechanisms in architected\n material design can lead to unprecedented synergistic enhancement of mechanical\n properties and performance desirable for extreme protective applications.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1905.10534",
        "title": "On the regularity of minima of non-autonomous functionals",
        "abstract": "We consider regularity issues for minima of non-autonomous functionals in the\n Calculus of Variations exhibiting non-uniform ellipticity features. We provide\n a few sharp regularity results for local minimizers that also cover the case of\n functionals with nearly linear growth. The analysis is carried out provided\n certain necessary approximation-in-energy conditions are satisfied. These are\n related to the occurrence of the so-called Lavrentiev phenomenon that that\n non-autonomous functionals might exhibit, and which is a natural obstruction to\n regularity. In the case of vector valued problems we concentrate on higher\n gradient integrability of minima. Instead, in the scalar case, we prove local\n Lipschitz estimates. We also present an approach via a variant of Moser's\n iteration technique that allows to reduce the analysis of several non-uniformly\n elliptic problems to that for uniformly elliptic ones.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2105.08089",
        "title": "A Measure of Research Taste",
        "abstract": "Researchers are often evaluated by citation-based metrics. Such metrics can\n inform hiring, promotion, and funding decisions. Concerns have been expressed\n that popular citation-based metrics incentivize researchers to maximize the\n production of publications. Such incentives may not be optimal for scientific\n progress. Here we present a citation-based measure that rewards both\n productivity and taste: the researcher's ability to focus on impactful\n contributions. The presented measure, CAP, balances the impact of publications\n and their quantity, thus incentivizing researchers to consider whether a\n publication is a useful addition to the literature. CAP is simple,\n interpretable, and parameter-free. We analyze the characteristics of CAP for\n highly-cited researchers in biology, computer science, economics, and physics,\n using a corpus of millions of publications and hundreds of millions of\n citations with yearly temporal granularity. CAP produces qualitatively\n plausible outcomes and has a number of advantages over prior metrics. Results\n can be explored at https://cap-measure.org/",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2204.04521",
        "title": "Benchmarking for Public Health Surveillance tasks on Social Media with a\n  Domain-Specific Pretrained Language Model",
        "abstract": "A user-generated text on social media enables health workers to keep track of\n information, identify possible outbreaks, forecast disease trends, monitor\n emergency cases, and ascertain disease awareness and response to official\n health correspondence. This exchange of health information on social media has\n been regarded as an attempt to enhance public health surveillance (PHS).\n Despite its potential, the technology is still in its early stages and is not\n ready for widespread application. Advancements in pretrained language models\n (PLMs) have facilitated the development of several domain-specific PLMs and a\n variety of downstream applications. However, there are no PLMs for social media\n tasks involving PHS. We present and release PHS-BERT, a transformer-based PLM,\n to identify tasks related to public health surveillance on social media. We\n compared and benchmarked the performance of PHS-BERT on 25 datasets from\n different social medial platforms related to 7 different PHS tasks. Compared\n with existing PLMs that are mainly evaluated on limited tasks, PHS-BERT\n achieved state-of-the-art performance on all 25 tested datasets, showing that\n our PLM is robust and generalizable in the common PHS tasks. By making PHS-BERT\n available, we aim to facilitate the community to reduce the computational cost\n and introduce new baselines for future works across various PHS-related tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.15983",
        "title": "Effects of center-of-mass correction and nucleon anomalous magnetic\n  moments on nuclear charge radii",
        "abstract": "Effects of the center-of-mass correction together with the nucleon\n electromagnetic form factors on the nuclear charge radius are systematically\n studied with a relativistic Hartree-Bogoliubov model. Both one- and two-body\n parts of the CM correction are taken into account. It is found that the one-\n and two-body CM corrections, and the spin-orbit effect originating from the\n nucleon anomalous magnetic moments are all of the same order in magnitude, and\n that they give sizable impacts on the charge radius from light to heavy nuclei.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1502.04479",
        "title": "Searching for IMBHs in Galactic globular clusters through radial\n  velocities of individual stars",
        "abstract": "I present an overview of our ongoing project aimed at building a new\n generation of velocity dispersion profiles ad rotation curves for a\n representative sample of Galactic globular clusters, from the the radial\n velocity of hundreds individual stars distributed at different distances from\n the cluster center. The innermost portion of the profiles will be used to\n constrain the possibile presence of intermediate-mass black holes. The adopted\n methodology consists in combining spectroscopic observations acquired with\n three different instruments at the ESO-VLT: the adaptive-optics assisted,\n integral field unit (IFU) spectrograph SINFONI for the innermost and highly\n crowded cluster cores, the multi-IFU spectrograph KMOS for the intermediate\n regions, and the multi-fiber instrument FLAMES/GIRAFFE-MEDUSA for the\n outskirts. The case of NGC 6388, representing the pilot project that motivated\n the entire program, is described in some details.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/9710108",
        "title": "Three-particle States in Nonrelativistic Four-fermion Model",
        "abstract": "On a nonrelativistic contact four-fermion model we have shown that the simple\n Lambda-cut-off prescription together with definite fine-tuning of the Lambda\n dependency of \"bare\"quantities lead to self-adjoint semi-bounded Hamiltonian in\n one-, two- and three-particle sectors. The fixed self-adjoint extension and\n exact solutions in two-particle sector completely define three-particle\n problem. The renormalized Faddeev equations for the bound states with Fredholm\n properties are obtained and analyzed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2008.11998",
        "title": "Characterization of exact one-query quantum algorithms (ii): for partial\n  functions",
        "abstract": "The query model (or black-box model) has attracted much attention from the\n communities of both classical and quantum computing. Usually, quantum\n advantages are revealed by presenting a quantum algorithm that has a better\n query complexity than its classical counterpart. For example, the well-known\n quantum algorithms including Deutsch-Jozsa algorithm, Simon algorithm and\n Grover algorithm all show a considerable advantage of quantum computing from\n the viewpoint of query complexity. Recently we have considered in (Phys. Rev.\n A. {\\bf 101}, 02232 (2020)) the problem: what functions can be computed by an\n exact one-query quantum algorithm? This problem has been addressed for total\n Boolean functions but still open for partial Boolean functions. Thus, in this\n paper we continue to characterize the computational power of exact one-query\n quantum algorithms for partial Boolean functions by giving several necessary\n and sufficient conditions. By these conditions, we construct some new functions\n that can be computed exactly by one-query quantum algorithms but have essential\n difference from the already known ones. Note that before our work, the known\n functions that can be computed by exact one-query quantum algorithms are all\n symmetric functions, whereas the ones constructed in this papers are generally\n asymmetric.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0509149",
        "title": "Ultraluminous Starbursts from SMBH-induced outflows",
        "abstract": "I argue that there are two modes of global star formation. Disks and smaller\n spheroids form stars relatively inefficiently as a consequence of\n supernova-triggered negative feedback via a sequence of ministarbursts (S\n mode), whereas massive spheroids formed rapidly with high efficiency via the\n impact of AGN jet-triggered positive feedback (J mode) that generates and\n enhances ultraluminous starbursts. Supermassive black hole growth by accretion\n is favoured in the gas-rich protospheroid environment as mergers build up the\n mass of the host galaxy and provide a centrally concentrated gas supply.\n Quasi-spherical outflows arise and provide the source of porosity as the\n energetic jets from the accreting central SMBH are isotropised by the\n inhomogeneous interstellar medium in the protospheroid core. Super-Eddington\n outflows occur and help generate both the SMBH at high redshift and the strong\n positive feedback on protospheroid star formation that occurs as dense\n interstellar clouds are overpressured and collapse. SMBH form before the bulk\n of spheroid stars, and the correlation between spheroid velocity dispersion and\n supermassive black hole mass arises as AGN-triggered outflows limit the gas\n reservoir for spheroid star formation. The super-Eddington phase plausibly\n triggers a top-heavy IMF in the region of influence of the SMBH. The\n Compton-cooled Eddington-limited outflow phase results in a spheroid core whose\n phase space density scales as the inverse 5/2 power of the core mass, and whose\n mass scales as the 3/2 power of SMBH mass. This latter scaling suggests that\n SMBH growth (and hence spheroid formation) is anti-hierarchical.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1908.01287",
        "title": "BCD-Net for Low-dose CT Reconstruction: Acceleration, Convergence, and\n  Generalization",
        "abstract": "Obtaining accurate and reliable images from low-dose computed tomography (CT)\n is challenging. Regression convolutional neural network (CNN) models that are\n learned from training data are increasingly gaining attention in low-dose CT\n reconstruction. This paper modifies the architecture of an iterative regression\n CNN, BCD-Net, for fast, stable, and accurate low-dose CT reconstruction, and\n presents the convergence property of the modified BCD-Net. Numerical results\n with phantom data show that applying faster numerical solvers to model-based\n image reconstruction (MBIR) modules of BCD-Net leads to faster and more\n accurate BCD-Net; BCD-Net significantly improves the reconstruction accuracy,\n compared to the state-of-the-art MBIR method using learned transforms; BCD-Net\n achieves better image quality, compared to a state-of-the-art iterative NN\n architecture, ADMM-Net. Numerical results with clinical data show that BCD-Net\n generalizes significantly better than a state-of-the-art deep (non-iterative)\n regression NN, FBPConvNet, that lacks MBIR modules.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.01502",
        "title": "Oscillating-charged Andreev Bound States and Their Appearance in UTe$_2$",
        "abstract": "In a superconductor with a sublattice degree of freedom, we find\n unconventional Andreev bound states whose charge density oscillates in sign\n between the two sublattices. The appearance of these oscillating-charged\n Andreev bound states is characterized by a Zak phase, rather than a\n conventional topological invariant. In contrast to conventional Andreev bound\n states, for oscillating-charged Andreev bound states the proportionality\n between the electron-like spectral function, the local density of states and\n the tunneling conductance is broken. We examine the possible appearance of\n these novel Andreev bound states in UTe$_2$ and locally noncentrosymmetric\n superconductors.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1501.07832",
        "title": "How does a flexible chain of active particles swell?",
        "abstract": "We study the swelling of a flexible linear chain composed of active particles\n by analytical theory and computer simulation. Three different situations are\n considered: a free chain, a chain confined to an external harmonic trap, and a\n chain dragged at one end. First we consider an ideal chain with harmonic\n springs and no excluded volume between the monomers. The Rouse model of\n polymers is generalized to the case of self-propelled monomers and solved\n analytically. The swelling, as characterized by the spatial extension of the\n chain, scales with the monomer number defining a Flory exponent $\\nu$ which is\n $\\nu =1/2, 0, 1$ in the three different situations. As a result, we find that\n activity does not change the Flory exponent but affects the prefactor of the\n scaling law. This can be quantitatively understood by mapping the system onto\n an equilibrium chain with a higher effective temperature such that the chain\n swells under an increase of the self-propulsion strength. We then use computer\n simulations to study the effect of self-avoidance on active polymer swelling.\n In the three different situations, the Flory exponent is now $\\nu = 3/4, 1/4,\n 1$ and again unchanged under self-propulsion. However, the chain extension\n behaves non-monotonic in the self-propulsion strength.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0303363",
        "title": "Recurrence spectrum in smooth dynamical systems",
        "abstract": "We prove that for conformal expanding maps the return time does have constant\n multifractal spectrum. This is the counterpart of the result by Feng and Wu in\n the symbolic setting.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0304204",
        "title": "Electron-Ion Recombination Rate Coefficients and Photoionization Cross\n  Sections for Astrophysically Abundant Elements. VII. Relativistic\n  calculations for O VI and O VII for UV and X-ray modeling",
        "abstract": "Aimed at ionization balance and spectral analysis of UV and X-ray sources, we\n present self-consistent sets of photoionization cross sections, recombination\n cross sections, and rate coefficients for Li-like O VI and He-like O VII.\n Relativistic fine structure is considered through the Breit-Pauli R-matrix\n (BPRM) method in the close coupling approximation, implementing the unified\n treatment for total electron-ion recombination subsuming both radiative and\n di-electronic recombination processes. Self-consistency is ensured by using an\n identical wavefunction expansion for the inverse processes of photoionization\n and photo-recombination. Radiation damping of resonances, important for H-like\n and He-like core ions, is included. Compared to previous LS coupling results\n without radiative decay of low-n (<= 10) resonances, the presents results show\n significant reduction in O VI recombination rates at high temperatures. In\n addition to the total rates, level-specific photoionization cross sections and\n recombination rates are presented for all fine structure levels n (lSLJ) up to\n n <= 10, to enable accurate computation of recombination-cascade matrices and\n spectral formation of prominent UV and X-ray lines such as the 1032,1038 A\n doublet of O VI, and the `triplet' forbidden, intercombination, and resonance\n X-ray lines of O VII at 22.1, 21.8, and 21.6 \\ang respectively. Altogether,\n atomic parameters for 98 levels of O VI and 116 fine structure levels of O VII\n are theoretically computed. These data should provide a reasonably complete set\n of photoionization and recombination rates in collisional or radiative\n equilibrium.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1007.4250",
        "title": "Extremal Charged Rotating Dilaton Black Holes in Odd Dimensions",
        "abstract": "Employing higher order perturbation theory, we find a new class of charged\n rotating black hole solutions of Einstein-Maxwell-dilaton theory with general\n dilaton coupling constant. Starting from the Myers-Perry solutions, we use the\n electric charge as the perturbative parameter, and focus on extremal black\n holes with equal-magnitude angular momenta in odd dimensions. We perform the\n perturbations up to 4th order for black holes in 5 dimensions and up to 3rd\n order in higher odd dimensions. We calculate the physical properties of these\n black holes and study their dependence on the charge and the dilaton coupling\n constant.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0303172",
        "title": "On the early evolution of the Galactic Halo",
        "abstract": "It is shown that the low metallicity tail of the stellar metallicity\n distribution predicted by simple Outflow models for the Milky Way halo depends\n sensitively on whether Instantaneous Recycling is adopted or relaxed. In both\n cases, current - and still preliminary - data suggest a ``G-dwarf problem'' for\n the halo (reminiscent of the local disk). We suggest that the problem can be\n solved by introducing a (physically motivated) early infall phase. We point out\n several important implications of such a modification, concerning: the putative\n Pop. III (super)massive stars, the number of stars expected at very low\n metallicities, the questions of primary nitrogen and of the dispersion in\n abundance ratios of halo stars.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1504.05321",
        "title": "Instance Optimal Learning",
        "abstract": "We consider the following basic learning task: given independent draws from\n an unknown distribution over a discrete support, output an approximation of the\n distribution that is as accurate as possible in $\\ell_1$ distance (i.e. total\n variation or statistical distance). Perhaps surprisingly, it is often possible\n to \"de-noise\" the empirical distribution of the samples to return an\n approximation of the true distribution that is significantly more accurate than\n the empirical distribution, without relying on any prior assumptions on the\n distribution. We present an instance optimal learning algorithm which optimally\n performs this de-noising for every distribution for which such a de-noising is\n possible. More formally, given $n$ independent draws from a distribution $p$,\n our algorithm returns a labelled vector whose expected distance from $p$ is\n equal to the minimum possible expected error that could be obtained by any\n algorithm that knows the true unlabeled vector of probabilities of distribution\n $p$ and simply needs to assign labels, up to an additive subconstant term that\n is independent of $p$ and goes to zero as $n$ gets large. One conceptual\n implication of this result is that for large samples, Bayesian assumptions on\n the \"shape\" or bounds on the tail probabilities of a distribution over discrete\n support are not helpful for the task of learning the distribution.\n  As a consequence of our techniques, we also show that given a set of $n$\n samples from an arbitrary distribution, one can accurately estimate the\n expected number of distinct elements that will be observed in a sample of any\n size up to $n \\log n$. This sort of extrapolation is practically relevant,\n particularly to domains such as genomics where it is important to understand\n how much more might be discovered given larger sample sizes, and we are\n optimistic that our approach is practically viable.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2211.02065",
        "title": "Finite-time Landauer principle beyond weak coupling",
        "abstract": "Landauer's principle gives a fundamental limit to the thermodynamic cost of\n erasing information. Its saturation requires a reversible isothermal process,\n and hence infinite time. We develop a finite-time version of Landauer's\n principle for a bit encoded in the occupation of a single fermionic mode, which\n can be strongly coupled to a reservoir. By solving the exact non-equilibrium\n dynamics, we optimize erasure processes (taking both the fermion's energy and\n system-bath coupling as control parameters) in the slow driving regime through\n a geometric approach to thermodynamics. We find analytic expressions for the\n thermodynamic metric and geodesic equations, which can be solved numerically.\n Their solution yields optimal processes that allow us to characterize a\n finite-time correction to Landauer's bound, fully taking into account\n non-markovian and strong coupling effects.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1410.3071",
        "title": "Instabilities, breathers and rogue waves in optics",
        "abstract": "Optical rogue waves are rare yet extreme fluctuations in the value of an\n optical field. The terminology was first used in the context of an analogy\n between pulse propagation in optical fibre and wave group propagation on deep\n water, but has since been generalized to describe many other processes in\n optics. This paper provides an overview of this field, concentrating primarily\n on propagation in optical fibre systems that exhibit nonlinear breather and\n soliton dynamics, but also discussing other optical systems where extreme\n events have been reported. Although statistical features such as long-tailed\n probability distributions are often considered the defining feature of rogue\n waves, we emphasise the underlying physical processes that drive the appearance\n of extreme optical structures.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1212.6367",
        "title": "Marian Smoluchowski: A story behind one photograph",
        "abstract": "We discuss the photograph procured from the archives of the V. Stefanyk Lviv\n National Scientific Library of Ukraine dated by 1904 which shows Marian\n Smoluchowski together with professors and graduate students of the Philosophy\n department of the Lviv University. The personalia includes both the professors\n and the graduates depicted on the photograph with the emphasis on the graduates\n as being much less known and studied. The photograph originates from the\n collection of the Shevchenko Scientific Society, therefore a brief historical\n background on the activities of physicists in this society around that period\n of time is provided as well.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0709.4265",
        "title": "Multi-symmetry and Multi-band Superconductivity in Filled-skutterudites\n  PrOs$_4$Sb$_{12}$ and PrRu$_4$Sb$_{12}$",
        "abstract": "Thermal conductivity measurements were performed on single crystal samples of\n the superconducting filled skutterudite compounds PrOs$_4$Sb$_{12}$ and\n PrRu$_4$Sb$_{12}$ both as a function of temperature and magnetic field applied\n perpendicular to the heat current. In zero magnetic field, the low temperature\n electronic thermal conductivity of PrRu$_4$Sb$_{12}$ is vanishingly small,\n consistent with a fully-gapped Fermi surface. For PrOs$_4$Sb$_{12}$, however,\n we find clear evidence for residual electronic conduction as the temperature\n tends to zero Kelvin which is consistent with the presence of nodes in the\n superconducting energy gap. The field dependence of the electronic conductivity\n for both compounds shows a rapid rise immediately above H$_{c1}$ and\n significant structure over the entire vortex state. In the fully gapped\n superconductor PrRu$_4$Sb$_{12}$, this is interpreted in terms of multi-band\n effects. In PrOs$_4$Sb$_{12}$, we consider the Doppler shift of nodal\n quasiparticles at low fields and multiband effects at higher fields.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2311.18047",
        "title": "Validation of Collision Detection and Avoidance Methods for Urban Air\n  Mobility through Simulation",
        "abstract": "Urban Air Mobility is a new concept of regional aviation that has been\n growing in popularity as a solution to the issue of ever-increasing ground\n traffic. Electric vehicles with vertical take-off and landing capabilities are\n being developed by numerous market companies as a result of the push toward\n environmentally sustainable aviation. The next stage in the eVTOL development\n process would be to define the concept of operation of these conceptual\n aircraft and then to integrate them with the existing airspace once they are\n airborne. In addition to coordinating with conventional air traffic and other\n Urban Air Mobility (UAM) vehicles, collision avoidance with uncooperative\n airspace users has to be addressed. Birds and drones of all sizes could be\n dangerous for these low-flying aircraft. Innovative collision detection and\n avoidance techniques need to be employed due to the uncooperative nature of\n these airspace users and different performance characteristics of urban air\n mobility vehicles compared to classical fixed-wing aircraft. The aim of this\n study is to validate one such system by means of fast-time solutions. This\n system uses a decision tree and safety envelopes to prevent collisions with\n non-cooperative airspace members. The system is designed to work with different\n aircraft configurations used for Urban Air Mobility (UAM) operations. Various\n scenarios are modelled by varying intruder type, location, flight path among\n others. Changes in flight time and closest point of approach are assessed to\n evaluate the system with regard to safety and efficiency.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2001.04348",
        "title": "Leveraging Multi-Method Evaluation for Multi-Stakeholder Settings",
        "abstract": "In this paper, we focus on recommendation settings with multiple stakeholders\n with possibly varying goals and interests, and argue that a single evaluation\n method or measure is not able to evaluate all relevant aspects in such a\n complex setting. We reason that employing a multi-method evaluation, where\n multiple evaluation methods or measures are combined and integrated, allows for\n getting a richer picture and prevents blind spots in the evaluation outcome.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2004.06721",
        "title": "Daily growth rate of scientific production on Covid-19. Analysis in\n  databases and open access repositories",
        "abstract": "The scientific community is facing one of its greatest challenges in solving\n a global health problem: COVID-19 pandemic. This situation has generated an\n unprecedented volume of publications. What is the volume, in terms of\n publications, of research on COVID-19? The general objective of this research\n work is to obtain a global vision of the daily growth of scientific production\n on COVID-19 in different databases (Dimensions, Web of Science Core Collection,\n Scopus-Elsevier, Pubmed and eight repositories). In relation to the results\n obtained, Dimensions indexes a total of 9435 publications (69% with peer review\n and 2677 preprints) well above Scopus (1568) and WoS (718). This is a classic\n biliometric phenomenon of exponential growth (R2 = 0.92). The global growth\n rate is 500 publications and the production doubles every 15 days. In the case\n of Pubmed the weekly growth is around 1000 publications. Of the eight\n repositories analysed, Pubmed Central, Medrxiv and SSRN are the leaders.\n Despite their enormous contribution, the journals continue to be the core of\n scientific communication. Finally, it has been established that three out of\n every four publications on the COVID-19 are available in open access. The\n information explosion demands a serious and coordinated response from\n information professionals, which places us at the centre of the information\n pandemic.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1505.04306",
        "title": "Search for production of vector-like quark pairs and of four top quarks\n  in the lepton-plus-jets final state in $pp$ collisions at $\\sqrt{s}=8$ TeV\n  with the ATLAS detector",
        "abstract": "A search for pair production of vector-like quarks, both up-type ($T$) and\n down-type ($B$), as well as for four-top-quark production, is presented. The\n search is based on $pp$ collisions at $\\sqrt{s}=8$ TeV recorded in 2012 with\n the ATLAS detector at the CERN Large Hadron Collider and corresponding to an\n integrated luminosity of 20.3 fb$^{-1}$. Data are analysed in the\n lepton-plus-jets final state, characterised by an isolated electron or muon\n with high transverse momentum, large missing transverse momentum and multiple\n jets. Dedicated analyses are performed targeting three cases: a $T$ quark with\n significant branching ratio to a $W$ boson and a $b$-quark ($T\\bar{T} \\to\n Wb$+X), and both a $T$ quark and a $B$ quark with significant branching ratio\n to a Higgs boson and a third-generation quark ($T\\bar{T} \\to Ht$+X and\n $B\\bar{B} \\to Hb$+X respectively). No significant excess of events above the\n Standard Model expectation is observed, and 95% CL lower limits are derived on\n the masses of the vector-like $T$ and $B$ quarks under several branching ratio\n hypotheses assuming contributions from $T \\to Wb$, $Zt$, $Ht$ and $B \\to Wt$,\n $Zb$, $Hb$ decays. The 95% CL observed lower limits on the $T$ quark mass range\n between 715 GeV and 950 GeV for all possible values of the branching ratios\n into the three decay modes, and are the most stringent constraints to date.\n Additionally, the most restrictive upper bounds on four-top-quark production\n are set in a number of new physics scenarios.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1311.0913",
        "title": "Bidding Games and Efficient Allocations",
        "abstract": "Richman games are zero-sum games, where in each turn players bid in order to\n determine who will play next [Lazarus et al.'99]. We extend the theory to\n impartial general-sum two player games called \\emph{bidding games}, showing the\n existence of pure subgame-perfect equilibria (PSPE). In particular, we show\n that PSPEs form a semilattice, with a unique and natural \\emph{Bottom\n Equilibrium}.\n  Our main result shows that if only two actions available to the players in\n each node, then the Bottom Equilibrium has additional properties: (a) utilities\n are monotone in budget; (b) every outcome is Pareto-efficient; and (c) any\n Pareto-efficient outcome is attained for some budget.\n  In the context of combinatorial bargaining, we show that a player with a\n fraction of X% of the total budget prefers her allocation to X% of the possible\n allocations. In addition, we provide a polynomial-time algorithm to compute the\n Bottom Equilibrium of a binary bidding game.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1305.4270",
        "title": "On the equivalence of several definitions of compact infra-solvmanifolds",
        "abstract": "We show the equivalence of several definitions of compact infra-solvmanifolds\n that appear in various math literatures.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1504.05783",
        "title": "Automated parameters for troubled-cell indicators using outlier\n  detection",
        "abstract": "In Vuik and Ryan (2014) we studied the use of troubled-cell indicators for\n discontinuity detection in nonlinear hyperbolic partial differential equations\n and introduced a new multiwavelet technique to detect troubled cells. We found\n that these methods perform well as long as a suitable, problem-dependent\n parameter is chosen. This parameter is used in a threshold which decides\n whether or not to detect an element as a troubled cell. Until now, these\n parameters could not be chosen automatically. The choice of the parameter has\n impact on the approximation: it determines the strictness of the troubled-cell\n indicator. An inappropriate choice of the parameter will result in detection\n (and limiting) of too few or too many elements. The optimal parameter is chosen\n such that the minimal number of troubled cells is detected and the resulting\n approximation is free of spurious oscillations. In this paper we will see that\n for each troubled-cell indicator the sudden increase or decrease of the\n indicator value with respect to the neighboring values is important for\n detection. Indication basically reduces to detecting the outliers of a vector\n (one dimension) or matrix (two dimensions). This is done using Tukey's boxplot\n approach to detect which coefficients in a vector are straying far beyond\n others (Tukey, 1977). We provide an algorithm that can be applied to various\n troubled-cell indication variables. Using this technique the problem-dependent\n parameter that the original indicator requires is no longer necessary as the\n parameter will be chosen automatically.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0009207",
        "title": "The Steinhaus tiling problem and the range of certain quadratic forms",
        "abstract": "We give a short proof of the fact that there are no measurable subsets of\n Euclidean space (in dimension d > 2), which, no matter how translated and\n rotated, always contain exactly one integer lattice point. In dimension d=2\n (the original Steinhaus problem) the question remains open.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2312.04579",
        "title": "zkDFL: An efficient and privacy-preserving decentralized federated\n  learning with zero-knowledge proof",
        "abstract": "Federated learning (FL) has been widely adopted in various fields of study\n and business. Traditional centralized FL systems suffer from serious issues. To\n address these concerns, decentralized federated learning (DFL) systems have\n been introduced in recent years. With the help of blockchains, they attempt to\n achieve more integrity and efficiency. However, privacy preservation remains an\n uncovered aspect of these systems. To tackle this, as well as to scale the\n blockchain-based computations, we propose a zero-knowledge proof (ZKP)-based\n aggregator (zkDFL). This allows clients to share their large-scale model\n parameters with a trusted centralized server without revealing their individual\n data to other clients. We utilize blockchain technology to manage the\n aggregation algorithm via smart contracts. The server performs a ZKP algorithm\n to prove to the clients that the aggregation is done according to the accepted\n algorithm. Additionally, the server can prove that all inputs from clients have\n been used. We evaluate our approach using a public dataset related to the\n wearable Internet of Things. As demonstrated by numerical evaluations, zkDFL\n introduces verifiability of the correctness of the aggregation process and\n enhances the privacy protection and scalability of DFL systems, while the gas\n cost has significantly declined.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1912.00787",
        "title": "Fluctuations of the Gromov-Prohorov sample model",
        "abstract": "In this paper, we study the fluctuations of observables of metric measure\n spaces which are random discrete approximations $X_n$ of a fixed arbitrary\n (complete, separable) metric measure space $X=(\\mathcal{X},d,\\mu)$. These\n observables $\\Phi(X_n)$ are polynomials in the sense of\n Greven-Pfaffelhuber-Winter, and we show that for a generic model space $X$,\n they yield asymptotically normal random variables. However, if $X$ is a compact\n homogeneous space, then the fluctuations of the observables are much smaller,\n and after an adequate rescaling, they converge towards probability\n distributions which are not Gaussian. Conversely, we prove that if all the\n fluctuations of the observables $\\Phi(X_n)$ are smaller than in the generic\n case, then the measure metric space $X$ is compact homogeneous. The proofs of\n these results rely on the Gromov reconstruction principle, and on an adaptation\n of the method of cumulants and mod-Gaussian convergence developed by\n F\\'eray-M\\'eliot-Nikeghbali.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1604.07677",
        "title": "Interplanetary Type IV Bursts",
        "abstract": "We study the characteristics of moving type IV radio bursts which extend to\n the hectometric wavelengths (interplanetary type IV or type IV IP bursts) and\n their relationship with energetic phenomena on the Sun. Our dataset comprises\n 48 interplanetary type IV bursts observed with Wind/WAVES in the 13.825 MHz-20\n kHz frequency range. The dynamic spectra of the RSTN, the Nancay Decametric\n Array (DAM), the ARTEMIS-IV, the Culgoora, Hiraiso and Izmiran Radio\n Spectrographs were used to track the evolution of the events in the low corona.\n These were supplemented with SXR flux data from the GOES and CME data from the\n SOHO/LASCO. Positional information of the coronal bursts was obtained by the\n NRH. We examined the relationship of the type IV events with coronal radio\n bursts, CMEs and SXR flares. The majority of the events (45) were characterized\n as compact; their duration was on average 106 minutes. This type of events was,\n mostly, associated with M-and X-class flares (40 out of 45) and fast CMEs; 32\n of these events had CMEs faster than 1000 km/s. Furthermore, in 43 compact\n events the CME was, possibly, subjected to reduced aerodynamic drag as it was\n propagating in the wake of a previous CME. A minority (three) of long lived\n type IV IP bursts was detected, with duration from 960 minutes to 115 hours.\n These events are referred to as extended or long duration and appear to\n replenish their energetic electron content, possibly from electrons escaping\n from the corresponding coronal type IV bursts. The latter were found to persist\n on the disk, for tens of hours to days. Prominent among them was the unusual\n interplanetary type IV burst of 18--23 May 2002, which is the longest event in\n the Wind/WAVES catalog. The three extended events were, usually, accompanied by\n a number of flares, of GOES class C in their majority, and of CMEs, many of\n which were slow and narrow.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.06020",
        "title": "Hurwitz moduli varieties parameterizing Galois covers of an algebraic\n  curve",
        "abstract": "Given a smooth, projective curve $Y$, a finite group $G$ and a positive\n integer $n$ we study smooth, proper families $X\\to Y\\times S\\to S$ of Galois\n covers of $Y$ with Galois group isomorphic to $G$ branched in $n$ points,\n parameterized by algebraic varieties $S$. When $G$ is with trivial center we\n prove that the Hurwitz space $H^G_n(Y)$ is a fine moduli variety for this\n moduli problem and construct explicitly the universal family. For arbitrary $G$\n we prove that $H^G_n(Y)$ is a coarse moduli variety. For families of pointed\n Galois covers of $(Y,y_0)$ we prove that the Hurwitz space $H^G_n(Y,y_0)$ is a\n fine moduli variety, and construct explicitly the universal family, for\n arbitrary group $G$. We use classical tools of algebraic topology and of\n complex algebraic geometry.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0709.0047",
        "title": "Quantum Informational Dark Energy: Dark energy from forgetting",
        "abstract": "We suggest that dark energy has a quantum informational origin. Landauer's\n principle associated with the erasure of quantum information at a cosmic\n horizon implies the non-zero vacuum energy having effective negative pressure.\n Assuming the holographic principle, the minimum free energy condition, and the\n Gibbons-Hawking temperature for the cosmic event horizon we obtain the\n holographic dark energy with the parameter $d\\simeq 1$, which is consistent\n with the current observational data. It is also shown that both the\n entanglement energy and the horizon energy can be related to Landauer's\n principle.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2108.10562",
        "title": "A LOFAR-uGMRT spectral index study of distant radio halos",
        "abstract": "Context. Radio halos are megaparsec-scale diffuse radio sources{ mostly}\n located at the centres of merging galaxy clusters. The common mechanism invoked\n to explain their origin is the re-acceleration of relativistic particles caused\n by large-scale turbulence. Aims. Current re-acceleration models predict that a\n significant number of halos at high redshift should be characterised by very\n steep spectra ($\\alpha<-1.5$) because of increasing inverse Compton energy\n losses. In this paper, we investigate the spectral index properties of a sample\n of nine clusters selected from the second Planck Sunyaev-Zel'dovich catalogue\n showing diffuse radio emission with the Low Frequency Array (LOFAR) in the\n 120-168 MHz band. This is the first time that radio halos discovered at low\n frequencies are followed up at higher frequencies. Methods. We analysed\n upgraded Giant Metrewave Radio Telescope (uGMRT) observations in Bands 3 and 4,\n that is, 250-500 and 550-900 MHz respectively. These observations were combined\n with existing LOFAR data to obtain information on the spectral properties of\n the diffuse radio emission. Results. We find diffuse radio emission in the\n uGMRT observations for five of the nine high-$z$ radio halos previously\n discovered with LOFAR. For those, we measure spectral indices in the range of\n $-1$ to $-1.4$. For the uGMRT non-detections, we estimated that the halos\n should have a spectral index steeper than $-1.5$. We also confirm the presence\n of one candidate relic. Conclusions. Despite the small number of clusters, we\n find evidence that about half of the massive and merging clusters at high\n redshift host radio halos with a very steep spectrum. This is in line with\n theoretical predictions, although larger statistical samples are necessary to\n test models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2404.04881",
        "title": "Constraining Axion-Like Particles Dark Matter in Coma Berenices with\n  FAST",
        "abstract": "Axions and axion-like particles (ALPs) appear in many extensions of the\n Standard Model and are being investigated as promising dark matter (DM)\n candidates. One viable methodology for their detection involves the\n investigation of the line-like radio emissions from the dwarf spheroidal\n galaxy, potentially originating from the radiative decay of ALPs or the\n conversion of ALPs in the magnetic field. In this work, we constrain the\n properties of ALPs using the 2-hour radio observation of Coma Berenices through\n the Five-hundred-meter Aperture Spherical radio Telescope (FAST). The $\\rm\n 95\\%$ upper limits of the ALP-photon coupling are calculated for the ALP decay\n and conversion scenarios, respectively. Note that the sensitive ALP masses for\n FAST range from $\\sim \\mu \\rm eV$ to tens of $\\mu \\rm eV$, where ALP can\n explain the DM abundance naturally. However, our limits are weaker than those\n of the CAST helioscope, which can provide an independent and complementary\n check on the ALP non-detection for ground experiments. Furthermore, we evaluate\n the expected sensitivity on the ALP of FAST with its full designed bandwidth\n (70 $\\rm MHz$ - 3 $\\rm GHz$) for 100 hours of observation time. Our results\n indicate that, even with the exceptional sensitivity of the FAST, it is\n challenging to surpass the existing experimental constraints on ALP DM using\n radio observation of dSphs, unless the possible enhancements of ALP signals by\n compact stars in dSphs are considered.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1503.08967",
        "title": "Authenticated Semi-quantum Direct Communication Protocols using Bell\n  States",
        "abstract": "This study presents the first two authenticated semi-quantum direct\n communication (ASQDC) protocols without using any classical channel. By\n pre-sharing the master secret key between two communicants, a sender with\n advanced quantum devices can transmit a secret message to a receiver who can\n only perform classical operations without any information leakage. The receiver\n is then capable of verifying the message up to the single qubit level, i.e., a\n one-qubit modification of the transmitted quantum sequence can be detected with\n a probability close to 1. Moreover, the proposed protocols are resistant to\n several well-known attacks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/9605245",
        "title": "Production of scalar $K\\bar K$ molecules in $\\phi$ radiative decays",
        "abstract": "The potentialities of the production of the scalar $K\\bar K$ molecules in the\n $\\phi$ radiative decays are considered beyond the narrow resonance width\n approximation. It is shown that $BR(\\phi\\rightarrow\\gamma\n f_0(a_0)\\rightarrow\\gamma\\pi\\pi(\\pi\\eta))\\approx (1\\div 2)\\times 10^{-5}\\\n ,\\BR(\\phi\\rightarrow\\gamma (f_0+a_0)\\rightarrow\\gamma K^+K^-)\\alt 10^{-6}$ and\n $BR(\\phi\\rightarrow\\gamma (f_0+a_0) \\to \\gamma K^0\\bar K^0)\\alt 10^{-8}$. The\n mass spectra in the $\\pi\\pi\\ ,\\ \\pi\\eta\\ ,\\ K^+K^-\\ ,\\ K^0\\bar K^0$ channels\n are calculated. The imaginary part of the amplitude $\\phi\\rightarrow\\gamma\n f_0(a_0)$ is calculated analytically. It is obtained the phase of the scalar\n resonance production amplitude that causes the interference patterns in the\n reaction $e^+e^-\\rightarrow\\gamma \\pi^+\\pi^-$ in the $\\phi$ meson mass region.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2008.09962",
        "title": "On the number of distinct roots of a lacunary polynomial over finite\n  fields",
        "abstract": "We obtain new upper bounds on the number of distinct roots of lacunary\n polynomials over finite fields. Our focus will be on polynomials for which\n there is a large gap between consecutive exponents in the monomial expansion.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1806.01238",
        "title": "Center-Outward Distribution Functions, Quantiles, Ranks, and Signs in\n  $\\mathbb{R}^d$",
        "abstract": "Univariate concepts as quantile and distribution functions involving ranks\n and signs, do not canonically extend to $\\mathbb{R}^d, d\\geq 2$. Palliating\n that has generated an abundant literature. Chapter 1 shows that, unlike the\n many definitions that have been proposed so far, the measure\n transportation-based ones introduced in Chernozhukov et al. (2017) enjoy all\n the properties that make univariate quantiles and ranks successful tools for\n semiparametric statistical inference.\n  We therefore propose a new center-outward definition of multivariate\n distribution and quantile functions, along with their empirical counterparts,\n for which we obtain a Glivenko-Cantelli result. Our approach is geometric and,\n contrary to the Monge-Kantorovich one in Chernozhukov et al. (2017), does not\n require any moment assumptions. The resulting ranks and signs are strictly\n distribution-free, and maximal invariant under the action of a data-driven\n class of (order-preserving) transformations generating the family of absolutely\n continuous distributions; that property is the theoretical foundation of the\n semiparametric efficiency preservation property of ranks. The corresponding\n quantiles are equivariant under the same transformations.\n  The empirical proposed distribution functions are defined at observed values\n only. A continuous extension to the entire $\\mathbb{R}^d$, yielding continuous\n empirical quantile contours while preserving the monotonicity and\n Glivenko-Cantelli features is desirable. Such extension requires solving a\n nontrivial problem of smooth interpolation under cyclical monotonicity\n constraints. A complete solution of that problem is given in Chapter 2; we show\n that the resulting distribution and quantile functions are Lipschitz, and\n provide a sharp lower bound for the Lipschitz constants. A numerical study of\n empirical center-outward quantile contours and their consistency is conducted.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0211582",
        "title": "Quantum states and optics in a {\\it p}-type heterojunction with lateral\n  surface quantum dot or antidot superlattice subjected to perpendicular\n  magnetic field",
        "abstract": "The studies of quantum states and optics in a {\\it p}-type heterojunction\n with lateral surface quantum dot (antidot) superlattice and in the presence of\n perpendicular magnetic field are performed. For the first time the Azbel'--\n Hofstadter problem is solved for holes in a complicated valence band described\n by the $4 \\times 4$ Luttinger Hamiltonian. The set of magnetic subbands is\n obtained for separate hole levels in a wide interval of magnetic field. We\n found remarkable differences between hole spectra and the Hofstadter\n \"butterfly\" for electrons. The influence of the spin-orbit interaction onto\n wavefunctions and energy spectrum has been investigated. The probabilities of\n optical transitions between quantum states in the valence band and donors\n located in the monolayer inside the heterojunction are calculated. The set of\n parameters (superlattice periods, amplitude of periodic potential, magnitude of\n magnetic field, etc.) required for experimental observation of splitted hole\n Landau levels is determined.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1505.05336",
        "title": "Investigating Earth shadowing effect with DAMA/LIBRA-phase1",
        "abstract": "In the present paper the results obtained in the investigation of possible\n diurnal effects for low-energy single-hit scintillation events of\n DAMA/LIBRA-phase1 (1.04 ton $\\times$ yr exposure) have been analysed in terms\n of an effect expected in case of Dark Matter (DM) candidates inducing nuclear\n recoils and having high cross-section with ordinary matter, which implies low\n DM local density in order to fulfill the DAMA/LIBRA DM annual modulation\n results. This effect is due to the different Earth depths crossed by those DM\n candidates during the sidereal day.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2003.12895",
        "title": "Memorizing Gaussians with no over-parameterizaion via gradient decent on\n  neural networks",
        "abstract": "We prove that a single step of gradient decent over depth two network, with\n $q$ hidden neurons, starting from orthogonal initialization, can memorize\n $\\Omega\\left(\\frac{dq}{\\log^4(d)}\\right)$ independent and randomly labeled\n Gaussians in $\\mathbb{R}^d$. The result is valid for a large class of\n activation functions, which includes the absolute value.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2107.00752",
        "title": "Global embedding of BTZ spacetime using generalized method of symmetric\n  embeddings construction",
        "abstract": "It is often easier to study pseudo-Riemannian manifolds by presenting them as\n surfaces in some ambient space. We propose an algorithm for construction of\n explicit isometric embeddings of pseudo-Riemannian manifolds with symmetries\n into an ambient space of higher dimension. While most of the existing methods\n are based on Gauss-Codazzi-Mainardi-Peterson equations, we do not use them and\n instead concentrate on a system of equations which connects the metric on the\n manifold and the embedding function of the surface. Our algorithm is based on\n the group theoretical method of separation of variables that we developed\n earlier (arXiv:1202.1204). The algorithm makes this method more convenient and\n simple to use. It allowed us to simplify the construction of many known\n embeddings as well as obtain some new ones. In particular, we obtain explicit\n global embeddings of spinning BTZ black hole in 7-dimensional flat space.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1503.09031",
        "title": "Optimal Actuator and Observation Location for Time-Varying Systems on a\n  Finite-Time Horizon",
        "abstract": "The choice of the location of controllers and observations is of great\n importance for designing control systems and improving the estimations in\n various practical problems. For time-varying systems in Hilbert spaces, the\n existence and convergence of the optimal location based on linear-quadratic\n control on a finite-time horizon is studied. The optimal location of\n observations for improving the estimation of the state at the final time, based\n on Kalman filter, is considered as the dual problem to the LQoptimal problem of\n the control locations. Further, the existence and convergence of optimal\n locations of observations for improving the estimation at the initial time,\n based on Kalman smoother is discussed. The obtained results are applied to a\n linear advection-diffusion model.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1004.0657",
        "title": "A very young component in the pre-eminent starburst region of the Small\n  Magellanic Cloud",
        "abstract": "We present a study of the compact H II region N66A in the SMC pre-eminent\n starburst region N66/NGC346. Despite extensive research on various components\n of the N66/NGC346 complex, few studies have so far focused on N66A, which is a\n special object in the whole complex and therefore deserves scrutiny. The study\n of this compact H II region and its fellow objects seems important in the\n framework of massive star formation in the Magellanic Clouds. This analysis is\n based mainly on our optical ESO NTT observations, both imaging and\n spectroscopy, coupled with archive HST ACS data and Spitzer infrared images\n (IRAC 3.6, 4.5, 5.8, and 8.0 microns). We derive a number of physical\n characteristics of the compact H II region N66A. Moreover, we present the\n spectral classification of the main exciting star of N66A for the first time\n using spectroscopy. Its spectral features indicate a main sequence massive star\n of type O8. We compare this result with that based on the stellar Lyman\n continuum flux estimated from the ionized gas H-beta flux. The compact H II\n region belongs to a rare class of H II regions in the Magellanic Clouds, called\n High-excitation Blobs (HEBs). N66A most probably represents a very young\n massive star formation event in the N66 complex, which has a range of ages.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2001.08063",
        "title": "Algorithms for Tensor Network Contraction Ordering",
        "abstract": "Contracting tensor networks is often computationally demanding. Well-designed\n contraction sequences can dramatically reduce the contraction cost. We explore\n the performance of simulated annealing and genetic algorithms, two common\n discrete optimization techniques, to this ordering problem. We benchmark their\n performance as well as that of the commonly-used greedy search on physically\n relevant tensor networks. Where computationally feasible, we also compare them\n with the optimal contraction sequence obtained by an exhaustive search. We find\n that the algorithms we consider consistently outperform a greedy search given\n equal computational resources, with an advantage that scales with tensor\n network size. We compare the obtained contraction sequences and identify signs\n of highly non-local optimization, with the more sophisticated algorithms\n sacrificing run-time early in the contraction for better overall performance.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0301146",
        "title": "A covariant formalism for Chern-Simons gravity",
        "abstract": "Chern--Simons type Lagrangians in $d=3$ dimensions are analyzed from the\n point of view of their covariance and globality. We use the transgression\n formula to find out a new fully covariant and global Lagrangian for\n Chern--Simons gravity: the price for establishing globality is hidden in a\n bimetric (or biconnection) structure. Such a formulation allows to calculate\n from a global and simpler viewpoint the energy-momentum complex and the\n superpotential both for Yang--Mills and gravitational examples.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2304.08710",
        "title": "Quantum Algorithm for Unsupervised Anomaly Detection",
        "abstract": "Anomaly detection, an important branch of machine learning, plays a critical\n role in fraud detection, health care, intrusion detection, military\n surveillance, etc. As one of the most commonly used unsupervised anomaly\n detection algorithms, the Local Outlier Factor algorithm (LOF algorithm) has\n been extensively studied. This algorithm contains three steps, i.e.,\n determining the k-distance neighborhood for each data point x, computing the\n local reachability density of x, and calculating the local outlier factor of x\n to judge whether x is abnormal. The LOF algorithm is computationally expensive\n when processing big data sets. Here we present a quantum LOF algorithm\n consisting of three parts corresponding to the classical algorithm.\n Specifically, the k-distance neighborhood of x is determined by amplitude\n estimation and minimum search; the local reachability density of each data\n point is calculated in parallel based on the quantum multiply-adder; the local\n outlier factor of each data point is obtained in parallel using amplitude\n estimation. It is shown that our quantum algorithm achieves exponential speedup\n on the dimension of the data points and polynomial speedup on the number of\n data points compared to its classical counterpart. This work demonstrates the\n advantage of quantum computing in unsupervised anomaly detection.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.04191",
        "title": "Classification of maximally non-self-dual modular categories of small\n  dimension",
        "abstract": "We prove that a non-pointed maximally non-self-dual (MNSD) modular category\n of Frobenius-Perron (FP) dimension less than $2025$ has at most two possible\n types, and all these types can be realized except those of FP dimension $675$,\n $729$ and $1125$. We also prove that all these modular categories are\n group-theoretical except the modular categories of dimension $675$. Our result\n shows that a non-group-theoretical MNSD modular category of smallest FP\n dimension may be the category of FP dimension $675$, and non-pointed MNSD\n modular category of smallest FP dimension is the category of FP dimension\n $243$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2009.13483",
        "title": "Accidental and symmetry-protected bound states in the continuum in\n  planar photonic-crystal structures, studied by the resonant-state expansion",
        "abstract": "The resonant-state expansion (RSE) provides a precise and computationally\n cheap tool to find resonant states in complex systems using the optical modes\n of a simpler system as a basis. We apply the RSE to a photonic crystal slab in\n order to identify and analyze its bound states in the continuum (BICs). We show\n that the RSE is a useful and reliable method for not only finding the BICs but\n also for differentiating between accidental and symmetry-protected BICs, as\n well as for understanding their formation from the basis modes and evolution\n with structural and material parameters of the system. The high efficiency of\n the RSE allows us to track the properties of BICs and other high-quality\n optical modes, covering the full parameter space of the system in a reasonable\n time frame.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0910.2784",
        "title": "Anomaly at finite density and chiral fermions on lattice",
        "abstract": "Using both perturbation theory in the Euclidean formalism as well as the\n non-perturbative Fujikawa's method, we verify that the chiral anomaly equation\n remains unaffected in continuum QCD in the presence of nonzero chemical\n potential, \\mu. We extend our considerations to lattice fermions with exact\n chiral symmetry and discuss the consequences for the recent Bloch-Wettig\n proposal for the Dirac operator at finite chemical potential. We propose a new\n simpler method of incorporating \\mu.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0307035",
        "title": "Elementary modifications and line configurations in P^2",
        "abstract": "Associated to an arrangement of projective hyperplanes A is the module D(A),\n which consists of derivations tangent to A. We study D(A) when A is a\n configuration of lines in the projective plane. In this setting, we relate the\n deletion/restriction construction used in the study of hyperplane arrangements\n to elementary modifications of bundles. This allows us to obtain bounds on the\n Castelnuovo-Mumford regularity of D(A). We also give simple combinatorial\n conditions for the associated bundle to be stable, and describe its jump lines.\n These regularity bounds and stability considerations impose constraints on\n Terao's conjecture.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/quant-ph/0207096",
        "title": "Measurement of qutrits",
        "abstract": "We proposed the procedure of measuring the unknown state of the three-level\n system - the qutrit, which was realized as the arbitrary polarization state of\n the single-mode biphoton field. This procedure is accomplished for the set of\n the pure states of qutrits; this set is defined by the properties of SU(2)\n transformations, that are done by the polarization transformers.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1101.4281",
        "title": "On Why-Questions in Physics",
        "abstract": "The aim of this paper is to introduce a mathematical logic based approach\n investigating why-type questions in physics.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1804.02594",
        "title": "Causal limit on quantum communication",
        "abstract": "The capacity of a channel is known to be equivalent to the highest rate at\n which it can generate entanglement. Analogous to entanglement, the notion of a\n causality measure characterises the temporal aspect of quantum correlations.\n Despite holding an equally fundamental role in physics, temporal quantum\n correlations have yet to find their operational significance in quantum\n communication. Here we uncover a connection between quantum causality and\n channel capacity. We show the amount of temporal correlations between two ends\n of the noisy quantum channel, as quantified by a causality measure, implies a\n general upper bound on its channel capacity. The expression of this new bound\n is simpler to evaluate than most previously known bounds. We demonstrate the\n utility of this bound by applying it to a class of shifted depolarizing\n channels, which results in improvement over previously calculated bounds for\n this class of channels.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.10399",
        "title": "Multilingual Normalization of Temporal Expressions with Masked Language\n  Models",
        "abstract": "The detection and normalization of temporal expressions is an important task\n and preprocessing step for many applications. However, prior work on\n normalization is rule-based, which severely limits the applicability in\n real-world multilingual settings, due to the costly creation of new rules. We\n propose a novel neural method for normalizing temporal expressions based on\n masked language modeling. Our multilingual method outperforms prior rule-based\n systems in many languages, and in particular, for low-resource languages with\n performance improvements of up to 33 F1 on average compared to the state of the\n art.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2310.18519",
        "title": "Practical trainable temporal post-processor for multi-state quantum\n  measurement",
        "abstract": "We develop and demonstrate a trainable temporal post-processor (TPP)\n harnessing a simple but versatile machine learning algorithm to provide optimal\n processing of quantum measurement data subject to arbitrary noise processes,\n for the readout of an arbitrary number of quantum states. We demonstrate the\n TPP on the essential task of qubit state readout, which has historically relied\n on temporal processing via matched filters in spite of their applicability only\n for specific noise conditions. Our results show that the TPP can reliably\n outperform standard filtering approaches under complex readout conditions, such\n as high power readout. Using simulations of quantum measurement noise sources,\n we show that this advantage relies on the TPP's ability to learn optimal linear\n filters that account for general quantum noise correlations in data, such as\n those due to quantum jumps, or correlated noise added by a phase-preserving\n quantum amplifier. We show that the transformation described by the TPP can be\n expressed via an efficient semi-analytic form, providing a linearly-scaling\n generalization of matched filtering to an arbitrary number of states under the\n most general noise conditions of the readout signal emanating from the\n measurement chain. The TPP can be efficiently, autonomously, and reliably\n trained on measurement data, and requires only linear operations, making it\n ideal for FPGA implementations in cQED for real-time processing of measurement\n data from general quantum systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2310.19954",
        "title": "Dynamic, viscoelasticity-driven shape change of elastomer bilayers",
        "abstract": "Thin bilayers made of elastic sheets with different strain recoveries can be\n used for dynamic shape morphing through ambient stimuli, such as temperature,\n mass diffusion, and light. As a fundamentally different approach to designing\n temporal shape change, constituent polymer molecular features (rather than\n external fields) are leveraged, specifically the viscoelasticity of gelatin\n bilayers, to achieve dynamic three-dimensional (3D) curls and helical twists.\n After stretching and releasing, the acquired 3D shape recovers its original\n flat shape on a timescale originating from the polymer viscoelasticity. The\n bilayer time-dependent curvature can be accurately predicted from hyperelastic\n and viscoelastic functions using finite element analysis (FEA). FEA reveals the\n nonlinear shape dynamics in space and time in quantitative agreement with\n experiments. The findings present a new frontier in dynamic biomimetic\n shape-morphing by exploiting intrinsic material properties in contrast with\n state-of-the-art methods relying on external field variations, moving one step\n closer to acquiring autonomous shape-shifting capabilities of biological\n systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1907.07633",
        "title": "A Database of Groups with Equivalent Character Tables",
        "abstract": "Two groups are said to have the same character table if a permutation of the\n rows and a permutation of the columns of one table produces the other table.\n The problem of determining when two groups have the same character table is\n computationally intriguing. We have constructed a database containing for all\n finite groups of order less than 2000 (excluding those of order 1024), a\n partitioning of groups into classes having the same character table. To handle\n the 408,641,062 groups of order 1536 and other orders with a large number of\n groups we utilized high-throughput computing together with a new algorithmic\n approach to the problem. Our approach involved using graph isomorphism software\n to construct canoncial graphs that correspond to the character table of a group\n and then hashing the graphs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1511.02208",
        "title": "The HI supershell GS 118+01-44 and its role in the interstellar medium",
        "abstract": "We carry out a multiwavelength study to characterize the HI supershell\n designated GS 118+01-44, and to analyse its possible origin. A multiwavlength\n study has been carried out to study the supershell and its environs. We\n performed an analysis of the HI, CO, radio continuum, and infrared emission\n distributions. The Canadian Galactic Plane Survey (CGPS) HI data reveals that\n GS 118+01-44 is centred at (l, b) = (117.7, 1.4) with a systemic velocity of\n -44.3 km/s. According to Galactic rotation models this structure is located at\n 3.0 +- 0.6 kpc from the Sun. There are several HII regions and three supernova\n remnants (SNRs) catalogued in the region. On the other hand, the analysis of\n the temperature spectral index distribution shows that in the region there is a\n predominance of non-thermal emission. Infrared emission shows that cool\n temperatures dominate the area of the supershell. Concerning the origin of the\n structure, we found that even though several OB stars belonging to Cas OB5 are\n located in the interior of GS 118+01-44, an analysis of the energy injected by\n these stars through their stellar winds indicates that they do not have\n sufficient energy to create GS 118+01-44. Therefore, an additional energy\n source is needed to explain the genesis of GS 118+01-44. On the other hand, the\n presence of several HII regions and young stellar object candidates in the\n edges of GS 118+01-44 shows that the region is still active in forming new\n stars.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1510.05465",
        "title": "BEER analysis of Kepler and CoRoT light curves: IV. Discovery of four\n  new low-mass white dwarf companions in the Kepler data",
        "abstract": "We report the discovery of four short-period eclipsing systems in the Kepler\n light curves, consisting of an A-star primary and a low-mass white dwarf (WD)\n secondary (dA+WD) - KIC 4169521, KOI-3818, KIC 2851474, and KIC 9285587. The\n systems show BEaming, Ellipsoidal and Reflection (BEER) phase modulations\n together with primary and secondary eclipses. These add to the 6 Kepler and 18\n WASP short-period eclipsing dA+WD binaries that were previously known. The\n light curves, together with follow-up spectroscopic observations, allow us to\n derive the masses, radii, and effective temperatures of the two components of\n the four systems. The orbital periods, of 1.17-3.82 days, and WD masses, of\n 0.19-0.22 Msun, are similar to those of the previously known systems. The WD\n radii of KOI-3818, KIC 2851474, and KIC 9285587 are 0.026, 0.035, and 0.026\n Rsun, respectively, the smallest WD radii derived so far for short-period\n eclipsing dA+WD binaries. These three binaries extend the previously known\n population to older systems with cooler and smaller WD secondaries. KOI-3818\n displays evidence for a fast-rotating primary and a minute but significant\n eccentricity of ~0.0015. These features are probably the outcome of the\n mass-transfer process.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2104.06479",
        "title": "Primordial giant planet obliquity driven by a circumplanetary disk",
        "abstract": "Detached circumplanetary disks are unstable to tilting as a result of the\n stellar tidal potential. We examine how a tilted circumplanetary disk affects\n the evolution of the spin axis of an oblate planet. The disk is evolved using\n time-dependent equations for linear wave-like warp evolution, including terms\n representing the effect of the tidal potential and planetary oblateness. For a\n disk with a sufficiently large mass, we find that the planet spin quickly\n aligns to the misaligned disk. The tilt of the planetary spin axis then\n increases on the same timescale as the disk. This can be an efficient mechanism\n for generating primordial obliquity in giant planets. We suggest that directly\n imaged exoplanets at large orbital radii, where the disk mass criterion is more\n likely to be satisfied, could have significant obliquities due to the tilt\n instability of their circumplanetary disks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/gr-qc/0702131",
        "title": "Focusing of branes in warped backgrounds",
        "abstract": "Branes are embedded surfaces in a given background (bulk) spacetime. Assuming\n a warped bulk, we investigate, in analogy with the case for geodesics, the\n notion of {\\em focusing} of families of such embedded, extremal 3--branes in a\n five dimensional background . The essential tool behind our analysis, is the\n well-known generalised Raychaudhuri equations for surface congruences. In\n particular, we find explicit solutions of these equations, which seem to show\n that families of 3--branes can focus along lower dimensional submanifolds\n depending on where the initial expansions are specified. We conclude with\n comments on the results obtained and possibilities about future work along\n similar lines.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1508.06577",
        "title": "BMS invariance and the membrane paradigm",
        "abstract": "The Bondi-van der Burg-Metzner-Sachs (BMS) group is the asymptotic symmetry\n group of asymptotically flat spacetime. It is infinite dimensional and entails\n an infinite number of conservation laws. According to the black hole membrane\n paradigm, null infinity (in asymptotically flat spacetime) and black hole event\n horizons behave like fluid membranes. The fluid dynamics of the membrane is\n governed by an infinite set of symmetries and conservation laws. Our main\n result is to point out that the infinite set of symmetries and conserved\n charges of the BMS group and the membrane paradigm are the same. This\n relationship has several consequences. First, it sheds light on the physical\n interpretation of BMS conservation laws. Second, it generalizes the BMS\n conservation laws to arbitrary subregions of arbitrary null surfaces. Third, it\n clarifies the identification of the superrotation subgroup of the BMS group. We\n briefly comment on the black hole information problem.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/9807153",
        "title": "Effects of dimerization and interchain one-particle hopping in a weakly\n  coupled dimerized chain system at quarter filling",
        "abstract": "Effects of the intrachain dimerization and the interchain one-particle\n hopping, $t_{b}$, in a quasi-one-dimensional dimerized chain system at quarter\n filling have been studied, based on the perturbative renormalization group\n (PRG) approach. Based on the results, we discuss difference in the low-energy\n properties between TMTTF and TMTSF compounds.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1310.3680",
        "title": "Magnetic fields during the formation of supermassive black holes",
        "abstract": "Observations of quasars at $\\rm z> 6$ report the existence of a billion solar\n mass black holes. Comprehending their formation in such a short time scale is a\n matter of ongoing research. One of the most promising scenarios to assemble\n supermassive black holes is a monolithic collapse of protogalactic gas clouds\n in atomic cooling halos with $\\rm T_{vir} \\geq 10^{4} K$. In this article, we\n study the amplification and impact of magnetic fields during the formation of\n seed black holes in massive primordial halos. We perform high resolution\n cosmological magnetohydrodynamics simulations for four distinct halos and\n follow their collapse for a few free-fall times until the simulations reach a\n peak density of $\\rm 7 \\times 10^{-10} g/cm^{3}$. Our findings show that\n irrespective of the initial seed field, the magnetic field strength reaches a\n saturated state in the presence of strong accretion shocks. Under such\n conditions, the growth time becomes very short and amplification occurs rapidly\n within a small fraction of the free-fall time. We find that the presence of\n such strong magnetic fields provides additional support against gravity and\n helps in suppressing fragmentation. Massive clumps of a few hundred solar\n masses are formed at the end of our simulations and high accretion rates of\n $\\rm 1 M_{\\odot}/yr$ are observed. We expect that in the presence of such\n accretion rates, the clumps will grow to form supermassive stars of $\\rm \\sim\n 10^{5} M_{\\odot}$. Overall, the role of the magnetic fields seems supportive\n for the formation of massive black holes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1607.04112",
        "title": "Magnetic phase diagrams in the H-T plane of the magnetically strongest\n  sigma-phase Fe-V compounds",
        "abstract": "Magnetization measurements were performed on two sigma-phase samples of\n Fe(100-x)V(x) (x=35.5, 34.1) vs. temperature, T, and in DC magnetic field, of\n various amplitudes. Using three characteristic temperatures, magnetic phase\n diagrams in the H-T plane have been designed testifying to a re-entrant\n character of magnetism. The ground magnetic state, a spin glass (SG), was\n evidenced to be composed of two sub phases: one with a weak irreversibility and\n the other with a strong irreversibility. Two critical lines were reconstructed\n within the SG state. Both of them show a crossover from the Gabay-Toulouse\n behavior (low field) to a linear and/or quasi-Almeida-Touless behavior. A\n strong difference in the effect of the applied magnetic field on the SG phase\n in the two samples was revealed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2312.08363",
        "title": "On the Computational Hardness of Quantum One-Wayness",
        "abstract": "There is a large body of work studying what forms of computational hardness\n are needed to realize classical cryptography. In particular, one-way functions\n and pseudorandom generators can be built from each other, and thus require\n equivalent computational assumptions to be realized. Furthermore, the existence\n of either of these primitives implies that $\\rm{P} \\neq \\rm{NP}$, which gives a\n lower bound on the necessary hardness.\n  One can also define versions of each of these primitives with quantum output:\n respectively one-way state generators and pseudorandom state generators. Unlike\n in the classical setting, it is not known whether either primitive can be built\n from the other. Although it has been shown that pseudorandom state generators\n for certain parameter regimes can be used to build one-way state generators,\n the implication has not been previously known in full generality. Furthermore,\n to the best of our knowledge, the existence of one-way state generators has no\n known implications in complexity theory.\n  We show that pseudorandom states compressing $n$ bits to $\\log n + 1$ qubits\n can be used to build one-way state generators and pseudorandom states\n compressing $n$ bits to $\\omega(\\log n)$ qubits are one-way state generators.\n This is a nearly optimal result since pseudorandom states with fewer than $c\n \\log n$-qubit output can be shown to exist unconditionally. We also show that\n any one-way state generator can be broken by a quantum algorithm with classical\n access to a $\\rm{PP}$ oracle.\n  An interesting implication of our results is that a $t(n)$-copy one-way state\n generator exists unconditionally, for every $t(n) = o(n/\\log n)$. This\n contrasts nicely with the previously known fact that $O(n)$-copy one-way state\n generators require computational hardness. We also outline a new route towards\n a black-box separation between one-way state generators and quantum bit\n commitments.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0109373",
        "title": "Coincidences of high density peaks in UVES spectra of QSO pairs",
        "abstract": "We present preliminary results of an investigation of the clustering\n properties of high matter density peaks between redshift ~2 and ~3, as traced\n by Lyman limit and Damped Ly-alpha systems in spectra of close QSO pairs and\n groups.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0905.1730",
        "title": "The puzzle of apparent linear lattice artifacts in the 2d non-linear\n  sigma-model and Symanzik's solution",
        "abstract": "Lattice artifacts in the 2d O(n) non-linear sigma-model are expected to be of\n the form O(a^2), and hence it was (when first observed) disturbing that some\n quantities in the O(3) model with various actions show parametrically stronger\n cutoff dependence, apparently O(a), up to very large correlation lengths. In a\n previous letter we described the solution to this puzzle. Based on the\n conventional framework of Symanzik's effective action, we showed that there are\n logarithmic corrections to the O(a^2) artifacts which are especially large,\n (ln(a))^3, for n=3 and that such artifacts are consistent with the data. In\n this paper we supply the technical details of this computation. Results of\n Monte Carlo simulations using various lattice actions for O(3) and O(4) are\n also presented.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2404.05782",
        "title": "Dynamical stability and chaos in artificial neural network trajectories\n  along training",
        "abstract": "The process of training an artificial neural network involves iteratively\n adapting its parameters so as to minimize the error of the network's\n prediction, when confronted with a learning task. This iterative change can be\n naturally interpreted as a trajectory in network space -- a time series of\n networks -- and thus the training algorithm (e.g. gradient descent optimization\n of a suitable loss function) can be interpreted as a dynamical system in graph\n space. In order to illustrate this interpretation, here we study the dynamical\n properties of this process by analyzing through this lens the network\n trajectories of a shallow neural network, and its evolution through learning a\n simple classification task. We systematically consider different ranges of the\n learning rate and explore both the dynamical and orbital stability of the\n resulting network trajectories, finding hints of regular and chaotic behavior\n depending on the learning rate regime. Our findings are put in contrast to\n common wisdom on convergence properties of neural networks and dynamical\n systems theory. This work also contributes to the cross-fertilization of ideas\n between dynamical systems theory, network theory and machine learning",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0610342",
        "title": "$C^*$-algebras of inverse semigroups: amenability and weak containment",
        "abstract": "We argue that weak containment is an appropriate notion of amenability for\n inverse semigroups. Given an inverse semigroup $S$ and a homomorphism $\\phi$ of\n $S$ onto a group $G$, we show, under an assumption on $\\ker(\\phi)$, that $S$\n has weak containment if and only if $G$ is amenable and $\\ker(\\phi)$ has weak\n containment. Using Fell bundle amenability, we find a related result for\n inverse semigroups with zero. We show that all graph inverse semigroups have\n weak containment and that Nica's inverse semigroup $\\mcT_{G,P}$ of a\n quasi-lattice ordered group $(G,P)$ has weak containment if and only if $(G,P)$\n is amenable.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0905.2588",
        "title": "Effect of dipole-dipole charge interactions on dust coagulation",
        "abstract": "This study examines the effect that dipole-dipole charge interactions between\n fractal aggregates have on the growth of dust grains. Aggregates in a plasma or\n radiative environment will have charge distributed over their extended surface,\n which leads to a net dipole moment for the charged grains. A self-consistent\n N-body code is used to model the dynamics of interacting charged aggregates.\n The aggregates are free to rotate due to collisions and dipole-dipole\n electrostatic interactions. These rotations are important in determining the\n growth rate and subsequent geometry (fractal dimension) of the grains. In\n contrast to previous studies which have only taken charge-dipole interactions\n into account, like-charged grains are found to coagulate more efficiently than\n neutral grains due to preferential incorporation of small aggregates into\n mid-sized aggregate structures. The charged aggregates tend to be more compact\n than neutral aggregates, characterized by slightly higher fractal dimensions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1705.09995",
        "title": "Subject Specific Stream Classification Preprocessing Algorithm for\n  Twitter Data Stream",
        "abstract": "Micro-blogging service Twitter is a lucrative source for data mining\n applications on global sentiment. But due to the omnifariousness of the\n subjects mentioned in each data item; it is inefficient to run a data mining\n algorithm on the raw data. This paper discusses an algorithm to accurately\n classify the entire stream in to a given number of mutually exclusive\n collectively exhaustive streams upon each of which the data mining algorithm\n can be run separately yielding more relevant results with a high efficiency.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2205.02402",
        "title": "Quasi-periodic behaviour in the $\\gamma$-ray light curve of the blazar\n  PKS 0405-385",
        "abstract": "We analyze the quasi-periodic oscillation (QPO) of the historical light curve\n of FSRQs PKS 0405-385 detected by the Fermi LAT from August 2008 to November\n 2021. To identify and determine the QPO signal of PKS 0405-385 in the\n $\\gamma$-ray light curve, we use four time series analysis techniques based on\n frequency and time domains, i.e., the Lomb-Scargle periodogram (LSP), the\n weighted wavelet z-transform (WWZ), the REDFIT and the epoch folding. The\n results show that PKS 0405-385 has a quasi-periodic behavior of $\\sim$2.8 yr\n with the significance of $\\sim$4.3$\\sigma$ in Fermi long-term monitoring.\n Remarkably, we also performed QPO analysis in the G-band light curve observed\n from October 2014 to October 2021 using LSP and WWZ technology, and the results\n ($\\sim$4$\\sigma$ of significance) are consistent with the periodic detection in\n $\\gamma$-ray. This may imply that the optical emission is radiated by an\n electron population same as the \\gr\\ emission. In discussing the possible\n mechanism of quasi-periodic behavior, either the helical motion within a jet or\n the supermassive black hole binary system provides a viable explanation for the\n QPO of 2.8 yr, and the relevant parameters have been estimated.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/physics/9910047",
        "title": "Theory of the tune shift due to linear coupling",
        "abstract": "The presence of skew quadrupole fields will linearly couple the x and y\n motions. The x and y motions can then be written as the sum of two normal modes\n >. This paper presents analytical perturbation theory results for the tunes of\n the normal modes. The results for the normal mode tunes are first found correct\n to lowest order in the skew quadrupole fields. The results are then carried one\n step further to include the next higher order terms in the skew quadrupole\n fields. These analytical results show that for the higher order shift in the\n tune, the important harmonics of the skew quadrupole field are the harmonics\n near the sum of the tunes. However the harmonics closest to the sum of the\n tunes do not contribute to the higher order tune splitting, the seperation of\n the tunes, as they shift the two tunes about equally.This results in a lack of\n a dominant harmonic for the higher order part of the tune splitting, which\n complicates the understanding and correction of the higher order part of the\n tune splitting.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1306.1345",
        "title": "A Note on Graphs of Linear Rank-Width 1",
        "abstract": "We prove that a connected graph has linear rank-width 1 if and only if it is\n a distance-hereditary graph and its split decomposition tree is a path. An\n immediate consequence is that one can decide in linear time whether a graph has\n linear rank-width at most 1, and give an obstruction if not. Other immediate\n consequences are several characterisations of graphs of linear rank-width 1. In\n particular a connected graph has linear rank-width 1 if and only if it is\n locally equivalent to a caterpillar if and only if it is a vertex-minor of a\n path [O-joung Kwon and Sang-il Oum, Graphs of small rank-width are pivot-minors\n of graphs of small tree-width, arxiv:1203.3606] if and only if it does not\n contain the co-K_2 graph, the Net graph and the 5-cycle graph as vertex-minors\n [Isolde Adler, Arthur M. Farley and Andrzej Proskurowski, Obstructions for\n linear rank-width at most 1, arxiv:1106.2533].",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2204.10916",
        "title": "Revealing Occlusions with 4D Neural Fields",
        "abstract": "For computer vision systems to operate in dynamic situations, they need to be\n able to represent and reason about object permanence. We introduce a framework\n for learning to estimate 4D visual representations from monocular RGB-D, which\n is able to persist objects, even once they become obstructed by occlusions.\n Unlike traditional video representations, we encode point clouds into a\n continuous representation, which permits the model to attend across the\n spatiotemporal context to resolve occlusions. On two large video datasets that\n we release along with this paper, our experiments show that the representation\n is able to successfully reveal occlusions for several tasks, without any\n architectural changes. Visualizations show that the attention mechanism\n automatically learns to follow occluded objects. Since our approach can be\n trained end-to-end and is easily adaptable, we believe it will be useful for\n handling occlusions in many video understanding tasks. Data, code, and models\n are available at https://occlusions.cs.columbia.edu/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/0002240",
        "title": "Heavy quark mass expansion and intrinsic charm in light hadrons",
        "abstract": "We review the technique of heavy quark mass expansion of various operators\n made of heavy quark fields using a semiclassical approximation. It corresponds\n to an operator product expansion in the form of series in the inverse heavy\n quark mass. This technique applied recently to the axial current is used to\n estimate the charm content of the \\eta, \\eta' mesons and the intrinsic charm\n contribution to the proton spin. The derivation of heavy quark mass expansion\n for Qbar \\gamma_5 Q is given here in detail and the expansions of the scalar,\n vector and tensor current and of a contribution to the energy-momentum tensor\n are presented as well. The obtained results are used to estimate the intrinsic\n charm contribution to various observables.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/quant-ph/0401162",
        "title": "Quantum Circuits for Incompletely Specified Two-Qubit Operators",
        "abstract": "While the question ``how many CNOT gates are needed to simulate an arbitrary\n two-qubit operator'' has been conclusively answered -- three are necessary and\n sufficient -- previous work on this topic assumes that one wants to simulate a\n given unitary operator up to global phase. However, in many practical cases\n additional degrees of freedom are allowed. For example, if the computation is\n to be followed by a given projective measurement, many dissimilar operators\n achieve the same output distributions on all input states. Alternatively, if it\n is known that the input state is |0>, the action of the given operator on all\n orthogonal states is immaterial. In such cases, we say that the unitary\n operator is incompletely specified; in this work, we take up the practical\n challenge of satisfying a given specification with the smallest possible\n circuit. In particular, we identify cases in which such operators can be\n implemented using fewer quantum gates than are required for generic completely\n specified operators.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.05565",
        "title": "Towards Generalized Robot Assembly through Compliance-Enabled Contact\n  Formations",
        "abstract": "Contact can be conceptualized as a set of constraints imposed on two bodies\n that are interacting with one another in some way. The nature of a contact,\n whether a point, line, or surface, dictates how these bodies are able to move\n with respect to one another given a force, and a set of contacts can provide\n either partial or full constraint on a body's motion. Decades of work have\n explored how to explicitly estimate the location of a contact and its dynamics,\n e.g., frictional properties, but investigated methods have been computationally\n expensive and there often exists significant uncertainty in the final\n calculation. This has affected further advancements in contact-rich tasks that\n are seemingly simple to humans, such as generalized peg-in-hole insertions. In\n this work, instead of explicitly estimating the individual contact dynamics\n between an object and its hole, we approach this problem by investigating\n compliance-enabled contact formations. More formally, contact formations are\n defined according to the constraints imposed on an object's available\n degrees-of-freedom. Rather than estimating individual contact positions, we\n abstract out this calculation to an implicit representation, allowing the robot\n to either acquire, maintain, or release constraints on the object during the\n insertion process, by monitoring forces enacted on the end effector through\n time. Using a compliant robot, our method is desirable in that we are able to\n complete industry-relevant insertion tasks of tolerances <0.25mm without prior\n knowledge of the exact hole location or its orientation. We showcase our method\n on more generalized insertion tasks, such as commercially available\n non-cylindrical objects and open world plug tasks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2307.08384",
        "title": "Efficient Quantum State Preparation with Walsh Series",
        "abstract": "A new approximate Quantum State Preparation (QSP) method is introduced,\n called the Walsh Series Loader (WSL). The WSL approximates quantum states\n defined by real-valued functions of single real variables with a depth\n independent of the number $n$ of qubits. Two approaches are presented: the\n first one approximates the target quantum state by a Walsh Series truncated at\n order $O(1/\\sqrt{\\epsilon})$, where $\\epsilon$ is the precision of the\n approximation in terms of infidelity. The circuit depth is also\n $O(1/\\sqrt{\\epsilon})$, the size is $O(n+1/\\sqrt{\\epsilon})$ and only one\n ancilla qubit is needed. The second method represents accurately quantum states\n with sparse Walsh series. The WSL loads $s$-sparse Walsh Series into $n$-qubits\n with a depth doubly-sparse in $s$ and $k$, the maximum number of bits with\n value $1$ in the binary decomposition of the Walsh function indices. The\n associated quantum circuit approximates the sparse Walsh Series up to an error\n $\\epsilon$ with a depth $O(sk)$, a size $O(n+sk)$ and one ancilla qubit. In\n both cases, the protocol is a Repeat-Until-Success (RUS) procedure with a\n probability of success $P=\\Theta(\\epsilon)$, giving an averaged total time of\n $O(1/\\epsilon^{3/2})$ for the WSL (resp. $O(sk/\\epsilon)$ for the sparse WSL).\n Amplitude amplification can be used to reduce by a factor\n $O(1/\\sqrt{\\epsilon})$ the total time dependency with $\\epsilon$ but increases\n the size and depth of the associated quantum circuits, making them linearly\n dependent on $n$. These protocols give overall efficient algorithms with no\n exponential scaling in any parameter. They can be generalized to any\n complex-valued, multi-variate, almost-everywhere-differentiable function. The\n Repeat-Until-Success Walsh Series Loader is so far the only method which\n prepares a quantum state with a circuit depth and an averaged total time\n independent of the number of qubits.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2107.14450",
        "title": "Stiff equation of state for a holographic nuclear matter as instanton\n  gas",
        "abstract": "In a holographic model, which was used to investigate the color\n superconducting phase of QCD, a dilute gas of instantons is introduced to study\n the nuclear matter. The free energy of the nuclear matter is computed as a\n function of the baryon chemical potential in the probe approximation. Then the\n equation of state is obtained at low temperature. Using the equation of state\n for the nuclear matter, the Tolman-Oppenheimer-Volkov equations for a cold\n compact star are solved. We find the mass-radius relation of the star, which is\n similar to the one for quark star. This similarity implies that the instanton\n gas given here is a kind of self-bound matter.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1502.03069",
        "title": "The Anomalous Scaling Exponents of Turbulence in General Dimension from\n  Random Geometry",
        "abstract": "We propose an exact analytical formula for the anomalous scaling exponents of\n inertial range structure functions in incompressible fluid turbulence. The\n formula is a gravitational Knizhnik-Polyakov-Zamolodchikov (KPZ)-type relation,\n and is valid in any number of space dimensions. It incorporates intermittency\n by gravitationally dressing the Kolmogorov linear scaling via a coupling to a\n random geometry. The formula has one real parameter $\\gamma$ that depends on\n the number of space dimensions. The scaling exponents satisfy the convexity\n inequality, and the supersonic bound constraint. They agree with the\n experimental and numerical data in two and three space dimensions, and with\n numerical data in four space dimensions. Intermittency increases with $\\gamma$,\n and in the infinite $\\gamma$ limit the scaling exponents approach the value\n one, as in Burgers turbulence. At large $n$ the $n$th order exponent scales as\n $\\sqrt{n}$. We discuss the relation between fluid flows and black hole geometry\n that inspired our proposal.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1610.10023",
        "title": "Quasi-Prufer extensions of rings",
        "abstract": "We introduce quasi-Prufer extensions of rings in order to relativize the\n notion of quasi-Prufer domains and to take into account some contexts recently\n introduced in the literature. We also introduce almost-Prufer ring extensions.\n Characterizations and properties are given. In particular, we examine the\n relationship with the finite fibers property.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1203.1020",
        "title": "Relaxation Oscillations in New IS-LM Model",
        "abstract": "In this paper, we create new version of IS-LM model. The original IS-LM model\n has two main deficiencies: assumptions of constant price level and of strictly\n exogenous money supply. New IS-LM model eliminates these deficiencies. In the\n second section, we prove the existence of relaxation oscillations in this new\n IS-LM model.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1106.3488",
        "title": "Proceedings 15th International Refinement Workshop",
        "abstract": "Refinement is one of the cornerstones of a formal approach to software\n engineering: the process of developing a more detailed design or implementation\n from an abstract specification through a sequence of mathematically-based steps\n that maintain correctness with respect to the original specification.\n  The aim of this BCS FACS Refinement Workshop, is to bring together people who\n are interested in the development of more concrete designs or executable\n programs from abstract specifications using formal notations, tool support for\n formal software development, and practical experience with formal refinement\n methodologies.\n  The purpose of the workshop is to provide a forum for the exchange of ideas,\n and discussion of common ground and key differences.\n  This 15th workshop continued a 20 year tradition in refinement workshops run\n under the auspices of the British Computer Society (BCS) FACS special interest\n group. After the first seven editions had been held in the UK, in 1998 it was\n combined with the Australasian Refinement Workshop to form the International\n Refinement Workshop, hosted at The Australian National University. Six more\n editions have followed in a variety of locations, all with electronic published\n proceedings and associated journal special issues.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2103.12669",
        "title": "Log canonical models of foliated surfaces",
        "abstract": "We study log canonical models of foliated surfaces of general type. In\n particular, we show that log canonical models of general type and their minimal\n partial du Val resolutions are bounded. Moreover, we show the valuative\n criteria of separatedness and properness and a property related to\n local-closedness for the moduli functor $\\mathcal{S}_P^{sm}$ which parametrizes\n the stable smoothable foliated surface pairs. On the way, we also show a result\n on the invariance of plurigenera.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2009.13672",
        "title": "$\\mathrm{e}^+$$\\mathrm{e}^-$ Beam-beam Parameter Study for a TeV-scale\n  PWFA Linear Collider",
        "abstract": "We perform a beam-beam parameter study for a TeV-scale PWFA (particle-driven\n plasma wakefield acceleration) $\\mathrm{e}^+$$\\mathrm{e}^-$ linear collider\n using GUINEA-PIG simulations. The study shows that the total luminosity follows\n the $1/\\sqrt{\\sigma_z}$-scaling predicted by beamstrahlung theory, where\n $\\sigma_z$ is the rms beam length, which is advantageous for PWFA, as short\n beam lengths are preferred. We also derive a parameter set for a 3 TeV PWFA\n linear collider with main beam parameters optimised for luminosity and\n luminosity spread introduced by beamstrahlung.\n  Lastly, the study also compare the performance for scenarios with reduced\n positron beam charge at 3 TeV and 14 TeV with CLIC parameters.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1004.3497",
        "title": "Interactions of Phonons and Rotons with Interfaces in Superfluid Helium",
        "abstract": "We solve the problem of beams of phonons and rotons incident on, and\n interacting with, solid surfaces. Phonons and rotons are the quasiparticles of\n superfluid helium and have a unique dispersion curve. The dispersion curve\n controls the transmission, reflection and mode change of these quasiparticles\n at the interface with another medium. We develop a non-local hydrodynamic\n theory in a consistent and unified way. The structure of the solutions in the\n quantum fluid is discussed. The creation probabilities of all quasiparticles\n are derived when any one of them is incident on the interface. The dependencies\n on frequency and angular are analysed and the backward reflection and\n refraction for $R^-$ rotons are discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.08710",
        "title": "Extending \\textit{ab initio} plasma-surface simulations to\n  experimentally relevant scales",
        "abstract": "The physical processes at the interface of a low-temperature plasma and a\n solid are extremely complex. They involve a huge number of elementary processes\n in the plasma, in the solid as well as charge, momentum and energy transfer\n across the interface. In the majority of plasma simulations these surface\n processes are either neglected or treated via phenomenological parameters.\n However, those parameters are known only in some cases, so such an approach is\n very inaccurate and does not have predictive capability. Therefore,\n improvements are highly needed. In this paper we briefly summarize relevant\n theoretical methods from solid state and surface physics that are able to\n contribute to an improved simulation of plasma-surface interaction in the near\n future. Full \\textit{ab initio} quantum simulations are feasible only for\n extremely short times and/or small system sizes. A substantial simplification\n is achieved when electronic quantum effects are not treated explicitly. Then\n one arrives at semi-classical molecular dynamics (MD) simulations for the heavy\n particles that have become the main workhorse in surface science simulations.\n Using microscopically founded potentials and force fields as an input, these MD\n simulations approach the quality of \\textit{ab initio} simulations, in many\n cases. However, despite their simplified nature, these simulations require a\n time step that is of the order or below one femtosecond making it prohibitive\n to reach experimentally relevant scales of minutes. To bridge this gap in\n length and time scales without compromising the first principles character of\n the simulations, many physical and computational strategies have been put\n forward in surface science. This paper presents a brief overview on different\n methods and their underlying physical ideas, and we compare their strengths and\n weaknesses.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1804.09906",
        "title": "A comparison of the R_h=ct and LCDM cosmologies using the Cosmic\n  Distance Duality Relation",
        "abstract": "The cosmic distance duality (CDD) relation (based on the Etherington\n reciprocity theorem) plays a crucial role in a wide assortment of cosmological\n measurements. Attempts at confirming it observationally have met with mixed\n results, though the general consensus appears to be that the data do support\n its existence in nature. A common limitation with past approaches has been\n their reliance on a specific cosmological model, or on measurements of the\n luminosity distance to Type Ia SNe, which introduces a dependence on the\n presumed cosmology in spite of beliefs to the contrary. Confirming that the CDD\n is actually realized in nature is crucial because its violation would require\n exotic new physics. In this paper, we study the CDD using the observed angular\n size of compact quasar cores and a Gaussian Process reconstruction of the HII\n galaxy Hubble diagram---without pre-assuming any particular background\n cosmology. In so doing, we confirm at a very high level of confidence that the\n angular-diameter and luminosity distances do indeed satisfy the CDD. We then\n demonstrate the potential power of this result by utilizing it in a comparative\n test of two competing cosmological models---the R_h=ct universe and LCDM---and\n show that R_h=ct is favoured by the CDD data with a likelihood ~82.3% compared\n with ~17.7% for the standard model.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1604.08589",
        "title": "Interpreting the subtle spectral variations of the 11.2 and 12.7 {\\mu}m\n  polycyclic aromatic hydrocarbon bands",
        "abstract": "We report new properties of the 11 and 12.7 {\\mu}m emission complexes of\n polycyclic aromatic hydrocarbons (PAHs) by applying a Gaussian-based\n decomposition technique. Using high-resolution \\textit{Spitzer} Space Telescope\n data, we study in detail the spectral and spatial characteristics of the 11 and\n 12.7 {\\mu}m emission bands in maps of reflection nebulae NGC 7023 and NGC 2023\n (North and South) and the star-forming region M17. Profile variations are\n observed in both the 11 and 12.7 {\\mu}m emission bands. We identify a neutral\n contribution to the traditional 11.0 {\\mu}m PAH band and a cationic\n contribution to the traditional 11.2 {\\mu}m band, the latter of which affects\n the PAH class of the 11.2 {\\mu}m emission in our sample. The peak variations of\n the 12.7 {\\mu}m complex are explained by the competition between two underlying\n blended components. The spatial distributions of these components link them to\n cations and neutrals. We conclude that the 12.7 {\\mu}m emission originates in\n both neutral and cationic PAHs, lending support to the use of the 12.7/11.2\n intensity ratio as a charge proxy.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0803.0786",
        "title": "On the independent points in the sky for the search of periodic\n  gravitational wave",
        "abstract": "We investigate the independent points in the sky require to search the\n periodic gravitational wave, assuming the noise power spectral density to be\n flat. We have made an analysis with different initial azimuth of the Earth for\n a week data set. The analysis shows significant difference in the independent\n points in the sky for the search. We numerically obtain an approximate relation\n to make trade-off between computational cost and sensitivities. We also discuss\n the feasibility of the coherent search in small frequency band in reference to\n advanced LIGO.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.06749",
        "title": "Event-Triggered Optimal Formation Tracking Control Using Reinforcement\n  Learning for Large-Scale UAV Systems",
        "abstract": "Large-scale UAV switching formation tracking control has been widely applied\n in many fields such as search and rescue, cooperative transportation, and UAV\n light shows. In order to optimize the control performance and reduce the\n computational burden of the system, this study proposes an event-triggered\n optimal formation tracking controller for discrete-time large-scale UAV systems\n (UASs). And an optimal decision - optimal control framework is completed by\n introducing the Hungarian algorithm and actor-critic neural networks (NNs)\n implementation. Finally, a large-scale mixed reality experimental platform is\n built to verify the effectiveness of the proposed algorithm, which includes\n large-scale virtual UAV nodes and limited physical UAV nodes. This compensates\n for the limitations of the experimental field and equipment in realworld\n scenario, ensures the experimental safety, significantly reduces the\n experimental cost, and is suitable for realizing largescale UAV formation light\n shows.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1407.4955",
        "title": "Correlations between weights and overlap in ensembles of weighted\n  multiplex networks",
        "abstract": "Multiplex networks describe a large number of systems ranging from social\n networks to the brain. These multilayer structure encode information in their\n structure. This information can be extracted by measuring the correlations\n present in the multiplex networks structure, such as the overlap of the links\n in different layers. Many multiplex networks are also weighted, and the weights\n of the links can be strongly correlated with the structural properties of the\n multiplex network. For example in multiplex network formed by the citation and\n collaboration networks between PRE scientists it was found that the statistical\n properties of citations to co-authors are different from the one of citations\n to non-co-authors, i.e. the weights depend on the overlap of the links. Here we\n present a theoretical framework for modelling multiplex weighted networks with\n different types of correlations between weights and overlap. To this end, we\n use the framework of canonical network ensembles, and the recently introduced\n concept of multilinks, showing that null models of a large variety of network\n structures can be constructed in this way. In order to provide a concrete\n example of how this framework apply to real data we consider a multiplex\n constructed from gene expression data of healthy and cancer tissues.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1608.06157",
        "title": "The Spin-Half {\\it XXZ} Antiferromagnet on the Square Lattice Revisited:\n  A High-Order Coupled Cluster Treatment",
        "abstract": "We use the coupled cluster method (CCM) to study the ground-state properties\n and lowest-lying triplet excited state of the spin-half {\\it XXZ}\n antiferromagnet on the square lattice. The CCM is applied to it to high orders\n of approximation by using an efficient computer code that has been written by\n us and which has been implemented to run on massively parallelized computer\n platforms. We are able therefore to present precise data for the basic\n quantities of this model over a wide range of values for the anisotropy\n parameter $\\Delta$ in the range $-1 \\leq \\Delta < \\infty$ of interest,\n including both the easy-plane $(-1 < \\Delta < 1)$ and easy-axis $(\\Delta > 1)$\n regimes, where $\\Delta \\rightarrow \\infty$ represents the Ising limit. We\n present results for the ground-state energy, the sublattice magnetization, the\n zero-field transverse magnetic susceptibility, the spin stiffness, and the\n triplet spin gap. Our results provide a useful yardstick against which other\n approximate methods and/or experimental studies of relevant antiferromagnetic\n square-lattice compounds may now compare their own results. We also focus\n particular attention on the behaviour of these parameters for the easy-axis\n system in the vicinity of the isotropic Heisenberg point ($\\Delta = 1$), where\n the model undergoes a phase transition from a gapped state (for $\\Delta > 1$)\n to a gapless state (for $\\Delta \\leq 1$), and compare our results there with\n those from spin-wave theory (SWT). Interestingly, the nature of the criticality\n at $\\Delta=1$ for the present model with spins of spin quantum number\n $s=\\frac{1}{2}$ that is revealed by our CCM results seems to differ\n qualitatively from that predicted by SWT, which becomes exact only for its\n near-classical large-$s$ counterpart.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1402.4792",
        "title": "An accurate and efficient Lagrangian sub-grid model",
        "abstract": "A computationally efficient model is introduced to account for the sub-grid\n scale velocities of tracer particles dispersed in statistically homogeneous and\n isotropic turbulent flows. The model embeds the multi-scale nature of turbulent\n temporal and spatial correlations, that are essential to reproduce\n multi-particle dispersion. It is capable to describe the Lagrangian diffusion\n and dispersion of temporally and spatially correlated clouds of particles.\n Although the model neglects intermittent corrections, we show that pair and\n tetrad dispersion results nicely compare with Direct Numerical Simulations of\n statistically isotropic and homogeneous $3D$ turbulence. This is in agreement\n with recent observations that deviations from self-similar pair dispersion\n statistics are rare events.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1503.03452",
        "title": "Design and implementation of an Android application (MobilitApp+) to\n  analyze the mobility patterns of citizens in the Metropolitan Region of\n  Barcelona",
        "abstract": "In our project we have designed an Android application to obtain mobility\n data of the citizens in the metropolitan area of Barcelona. Our implementation\n synchronously obtains in background on the one hand, periodic location updates\n and, on the other hand, the type of activity citizens are doing. At the end of\n the day, all this data is processed and sent to a server where are stored to\n obtain mobility patterns from citizens that could help to improve the current\n transportation infrastructure. MobilitApp is fully functional and stable\n although the results can be improved in some situations. In future releases we\n will implement machine learning technics to obtain significant improvements,\n especially in the activity recognition modules.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2101.03805",
        "title": "A Conflict-Based Search Framework for Multi-Objective Multi-Agent Path\n  Finding",
        "abstract": "Conventional multi-agent path planners typically compute an ensemble of paths\n while optimizing a single objective, such as path length. However, many\n applications may require multiple objectives, say fuel consumption and\n completion time, to be simultaneously optimized during planning and these\n criteria may not be readily compared and sometimes lie in competition with each\n other. The goal of the problem is thus to find a Pareto-optimal set of\n solutions instead of a single optimal solution. Naively applying existing\n multi-objective search algorithms, such as multi-objective A* (MOA*), to\n multi-agent path finding may prove to be inefficient as the dimensionality of\n the search space grows exponentially with the number of agents. This article\n presents an approach named Multi-Objective Conflict-Based Search (MO-CBS) that\n attempts to address this so-called curse of dimensionality by leveraging prior\n Conflict-Based Search (CBS), a well-known algorithm for single-objective\n multi-agent path finding, and principles of dominance from multi-objective\n optimization literature. We also develop several variants of MO-CBS to improve\n its performance. We prove that MO-CBS and its variants can compute the entire\n Pareto-optimal set. Numerical results show that MO-CBS outperforms MOM*, a\n recently developed state-of-the-art multi-objective multi-agent planner.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0708.3295",
        "title": "Recent progress on the manipulation of single atoms in optical tweezers\n  for quantum computing",
        "abstract": "This paper summarizes our recent progress towards using single rubidium atoms\n trapped in an optical tweezer to encode quantum information. We demonstrate\n single qubit rotations on this system and measure the coherence of the qubit.\n We move the quantum bit over distances of tens of microns and show that the\n coherence is reserved. We also transfer a qubit atom between two tweezers and\n show no loss of coherence. Finally, we describe our progress towards\n conditional entanglement of two atoms by photon emission and two-photon\n interferences.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1710.05800",
        "title": "A rapidly expanding Bose-Einstein condensate: an expanding universe in\n  the lab",
        "abstract": "We study the dynamics of a supersonically expanding ring-shaped Bose-Einstein\n condensate both experimentally and theoretically. The expansion redshifts\n long-wavelength excitations, as in an expanding universe. After expansion,\n energy in the radial mode leads to the production of bulk topological\n excitations -- solitons and vortices -- driving the production of a large\n number of azimuthal phonons and, at late times, causing stochastic persistent\n currents. These complex nonlinear dynamics, fueled by the energy stored\n coherently in one mode, are reminiscent of a type of \"preheating\" that may have\n taken place at the end of inflation.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1712.06133",
        "title": "Critical graph of a polynomial quadratic differential related to a\n  Schr\\\"odinger equation with quartic potential",
        "abstract": "In this paper, we study the weak asymptotic in the plane of some wave\n functions resulting from the WKB techniques applied to a Shrodinger equation\n with quartic oscillator and having some boundary condition. In first step, we\n make transformations of our problem to obtain a Heun equation satisfied by the\n polynomial part of the WKB wave functions .Especially , we investigate the\n properties of the Cauchy transform of the root counting measure of a re-scaled\n solutions of the Schrodinger equation, to obtain a quadratic algebraic equation\n of the form $\\mathcal{C}^{2}\\left( z\\right) +r\\left( z\\right) \\mathcal{C}\\left(\n z\\right) +s\\left( z\\right) =0$, where $r,s$ are also polynomials. In second\n step, we discuss the existence of solutions (as Cauchy transform of a signed\n measures) of this algebraic equation.This problem remains to describe the\n critical graph of a related 4-degree polynomial quadratic differential\n $-p\\left( z\\right) dz^{2}$. In particular, we discuss the existence(and their\n number) of finite critical trajectories of this quadratic differential.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1007.4685",
        "title": "Generalized Zeta Function Regularization and the Multiplicative Anomaly",
        "abstract": "A brief survey of the zeta function regularization and multiplicative anomaly\n issues when the associated zeta function of fluctuation operator is the regular\n at the origin (regular case) as well as when it is singular at the origin\n (singular case) is presented. In the singular case, new results for the\n multiplicative anomaly are presented",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1711.10115",
        "title": "The Smallest Shape Spaces. III. Triangles in 2- and 3-d",
        "abstract": "This is an innovative treatise on triangles, resting upon 1) 3-body problem\n techniques including mass-weighted relative Jacobi coordinates. 2) Part I's\n detailed layer-by-layer topological and geometrical study of Kendall-type shape\n spaces - configuration spaces of all possible shapes - which, for triangles,\n are (pieces of) spheres. 3) Hopf mathematics. Triangles are moreover\n prototypical through being the smallest models which carry relative-angle as\n well as length-ratio information. Both 1) and 3) produce insightful new\n versions of Heron's formula, 3)'s simultaneously providing new foundations for\n 2). Medians, and regular triangles bounding between tall and flat triangles,\n also play prominent roles. Right triangles form three kissing cap-circles on\n the shape sphere, from which a shape-theoretic answer to the well-known\n conundrum of what is the probability that a triangle is obtuse very readily\n follows: 3/4. The differential-geometric aspects of this answer moreover\n generalize to numerous variant problems.\n  Hopf mathematics additionally gives a general bundle section interpretation\n to Kendall's iconic spherical blackboard of vertex-unlablelled\n mirror-image-identified triangles, and of its two variants where one of these\n two conditions are dropped. We attribute a monopole to each of these spaces and\n to the full shape sphere, one due to Dirac, one to Iwai and the other two are\n new to this paper. We finally make insightful comparison of triangles in 2-$d$\n with a) Part II's 4 points on the line. b) Triangles in 3-$d$, which are\n particularly significant as the smallest model exhibiting stratification.\n Stratified manifold-sheaf pairs - sheaves adding useful local and global\n structure to general bundles - lie at the heart of Shape Theory's future\n development.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.18531",
        "title": "Difference-in-Discontinuities: Estimation, Inference and Validity Tests",
        "abstract": "This paper investigates the econometric theory behind the newly developed\n difference-in-discontinuities design (DiDC). Despite its increasing use in\n applied research, there are currently limited studies of its properties. The\n method combines elements of regression discontinuity (RDD) and\n difference-in-differences (DiD) designs, allowing researchers to eliminate the\n effects of potential confounders at the discontinuity. We formalize the\n difference-in-discontinuity theory by stating the identification assumptions\n and proposing a nonparametric estimator, deriving its asymptotic properties and\n examining the scenarios in which the DiDC has desirable bias properties when\n compared to the standard RDD. We also provide comprehensive tests for one of\n the identification assumption of the DiDC. Monte Carlo simulation studies show\n that the estimators have good performance in finite samples. Finally, we\n revisit Grembi et al. (2016), that studies the effects of relaxing fiscal rules\n on public finance outcomes in Italian municipalities. The results show that the\n proposed estimator exhibits substantially smaller confidence intervals for the\n estimated effects.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1804.09826",
        "title": "Mirror Symmetry of quantum Yang-Mills vacua and cosmological\n  implications",
        "abstract": "We find an argument related to the existence of a Z_2-symmetry for the\n renormalization group flow derived from the bare Yang-Mills Lagrangian, and\n show that the cancellation of the vacuum energy may arise motivated both from\n the renormalization group flow solutions and the effective Yang-Mills action.\n In the framework of the effective Savvidy's action, two Mirror minima are\n allowed, with exactly equal and hold opposite sign energy densities. At the\n cosmological level, we explore the stability of the electric and magnetic\n attractor solutions, both within and beyond the perturbation theory, and find\n that thanks to these latter the cancellation between the electric and the\n magnetic vacua components is achieved at macroscopic space and time\n separations. This implies the disappearance of the conformal anomaly in the\n classical limit of an effective Yang-Mills theory. In this picture, the\n tunneling probability from the Mirror vacua to the other vacua is exponentially\n suppressed in the quantum non-thermal state --- similarly to what happens for\n electroweak instantonic tunneling solutions. Specifically, we show that, in a\n dynamical Friedmann-Lema\\^itre-Robertson-Walker (FLRW) cosmological background,\n the Nielsen-Olsen argument --- on the instability of uniform chromo-electric\n and chromo-magnetic Mirror vacua --- is subtly violated. The chromo-magnetic\n and chromo-electric uniform vacua are unstable only at asymptotic times, when\n the attractor to a zero energy density is already reached. The two vacua can\n safely decay into one anisotropic vacuum that has zero energy-density. We also\n discover a new surprising pattern of solitonic and anti-solitonic space-like\n solutions, which are sourced by the Yang-Mills dynamics in FLRW. We dub such\n non-perturbative configurations, which are directly related to dynamical\n cancellation mechanism of the vacuum energy, as {\\it chronons}, or\n $\\chi$-solutions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2103.02205",
        "title": "Gradual Fine-Tuning for Low-Resource Domain Adaptation",
        "abstract": "Fine-tuning is known to improve NLP models by adapting an initial model\n trained on more plentiful but less domain-salient examples to data in a target\n domain. Such domain adaptation is typically done using one stage of\n fine-tuning. We demonstrate that gradually fine-tuning in a multi-stage process\n can yield substantial further gains and can be applied without modifying the\n model or learning objective.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1812.01123",
        "title": "Negative differential conductance effect and electrical anisotropy of 2D\n  ZrB2 monolayers",
        "abstract": "Two-dimensional (2D) metal-diboride ZrB2 monolayers was predicted\n theoretically as a stable new electronic material [A. Lopez-Bezanilla, Phys.\n Rev. Mater., 2018, 2, 011002 (R)]. Here, we investigate its electronic\n transport properties along the zigzag (z-ZrB2) and armchair (a-ZrB2)\n directions, using the density functional theory and non-equilibrium Green's\n function methods. Under low biases, the 2D ZrB2 shows a similar electrical\n transport along zigzag and armchair directions as electric current propagates\n mostly via the metallic Zr-Zr bonds. However, it shows an electrical anistropy\n under high biases, and its I-V curves along zigzag and armchair directions\n diverge as the bias voltage is higher than 1.4 V, as more directional B-B\n transmission channels are opened. Importantly, both z-ZrB2 and a-ZrB2 show a\n pronounced negative differential conductance (NDC) effect and hence they can be\n promising for the use in NDC-based nanodevices.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.03081",
        "title": "SD-AETO: Service Deployment Enabled Adaptive Edge Task Offloading in MEC",
        "abstract": "In recent years, edge computing, as an important pillar for future networks,\n has been developed rapidly. Task offloading is a key part of edge computing\n that can provide computing resources for resource-constrained devices to run\n computing-intensive applications, accelerate computing speed and save energy.\n An efficient and feasible task offloading scheme can not only greatly improve\n the quality of experience (QoE) but also provide strong support and assistance\n for 5G/B5G networks, the industrial Internet of Things (IIoT), computing\n networks and so on. To achieve these goals, this paper proposes an adaptive\n edge task offloading scheme assisted by service deployment (SD-AETO) focusing\n on the optimization of the energy utilization ratio (EUR) and the processing\n latency. In the pre-implementation stage of the SD-AETO scheme, a service\n deployment scheme is invoked to assist with task offloading considering each\n service's popularity. The optimal service deployment scheme is obtained by\n using the approximate deployment graph (AD-graph). Furthermore, a task\n scheduling and queue offloading design procedure is proposed to complete the\n SD-AETO scheme based on the task priority. The task priority is generated by\n the corresponding service popularity and task offloading direction. Finally, we\n analyze our SD-AETO scheme and compare it with related approaches, and the\n results show that our scheme has a higher edge offloading rate and lower\n resource consumption for massive task scenarios in the edge network.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/9505058",
        "title": "A Soluble Model of Four-Fermion Interactions in de Sitter Space",
        "abstract": "We consider the theory of four-fermion interactions with N-component fermions\n in de Sitter space. It is found that the effective potential for a composite\n operator in the theory is calculable in the leading order of the 1/N expansion.\n The resulting effective potential is analyzed by varying both the four-fermion\n coupling constant and the curvature of the space-time. The critical curvature\n at which the dynamically generated fermion mass disappears is found to exist\n and is calculated analytically. The dynamical fermion mass is expressed as a\n function of the space-time curvature.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/0210325",
        "title": "Forward-Backward Multiplicity Correlations in Symmetric and Asymmetric\n  High Energy Collisions",
        "abstract": "Forward-backward correlations are explored within the two-component clan\n model of multiparticle production. It is found that existing data are well\n described, and, in hh collisions, that clans must be allowed to leak particles\n from one hemisphere to the other. General formulae given for the symmetric case\n are then extended to the asymmetric one, which is relevant for pA and AB\n collisions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0810.4752",
        "title": "Statistical Learning Theory: Models, Concepts, and Results",
        "abstract": "Statistical learning theory provides the theoretical basis for many of\n today's machine learning algorithms. In this article we attempt to give a\n gentle, non-technical overview over the key ideas and insights of statistical\n learning theory. We target at a broad audience, not necessarily machine\n learning researchers. This paper can serve as a starting point for people who\n want to get an overview on the field before diving into technical details.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1107.5376",
        "title": "On the participant-spectator matter and thermalization of neutron-rich\n  systems in heavy-ion collisions",
        "abstract": "We study the participant-spectator matter at the energy of vanishing flow for\n neutron-rich systems. Our study reveals similar behaviour of\n articipant-spectator for neutron-rich systems as for stable systems and also\n points towards nearly mass independence behaviour of participant-spectator\n matter for neutron-rich systems at the energy of vanishing flow. We also study\n the thermalization reached in the reactions of neutron-rich systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1908.03429",
        "title": "Non-mesonic decay of the $\\eta$-mesic $^{3}\\hspace{-0.03cm}\\mbox{He}$\n  via $pd\\rightarrow(^{3}\\hspace{-0.03cm}\\mbox{He}$-$\\eta)_{bound}\\rightarrow$\n  $^{3}\\hspace{-0.03cm}\\mbox{He} 2\\gamma (6\\gamma$) reaction",
        "abstract": "In this article a theoretical model for the $\\eta$-mesic\n $^{3}\\hspace{-0.03cm}\\mbox{He}$ non-mesonic decay channels is presented. We\n present the resultant relative momentum distribution of bound\n $^{3}\\hspace{-0.03cm}\\mbox{He}$-$\\eta$ as well as in-medium branching ratios of\n $\\eta\\rightarrow 2\\gamma$ and $\\eta\\rightarrow 3\\pi^0$, which are crucial for\n the Monte Carlo simulations of measured processes and thus for the experimental\n data interpretation. As an example we also apply the model for the estimation\n of the detection efficiency of the WASA-at-COSY detector.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1412.8654",
        "title": "Entropic forces in a non-equilibrium system: Flocks of birds",
        "abstract": "When birds come together to form a flock, the distribution of their\n individual velocities narrows around the mean velocity of the flock. We argue\n that, in a broad class of models for the joint distribution of positions and\n velocities, this narrowing generates an entropic force that opposes the\n cohesion of the flock. The strength of this force depends strongly on the\n nature of the interactions among birds: if birds are coupled to a fixed number\n of neighbors, the entropic forces are weak, while if they couple to all other\n birds within a fixed distance, the entropic forces are sufficient to tear a\n flock apart. Similar entropic forces should occur in other non-equilibrium\n systems. For the joint distribution of protein structures and amino-acid\n sequences, these forces favor the occurrence of \"highly designable\" structures.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2003.06954",
        "title": "Bounded-Rational Pursuit-Evasion Games",
        "abstract": "We present a framework that incorporates the idea of bounded rationality into\n dynamic stochastic pursuit-evasion games. The solution of a stochastic game is\n characterized, in general, by its (Nash) equilibria in feedback form. However,\n computing these Nash equilibrium strategies may require extensive computational\n resources. In this paper, the agents are modeled as bounded rational entities\n having limited computational resources. We illustrate the framework by applying\n it to a pursuit-evasion game between two vehicles in a stochastic wind field,\n where both the pursuer and the evader are bounded rational. We show how such a\n game may be analyzed by properly casting it as an iterative sequence of\n finite-state Markov Decision Processes (MDPs). Leveraging tools and algorithms\n from cognitive hierarchy theory (\"level-$k$ thinking\") we compute the solution\n of the ensuing discrete game, while taking into consideration the rationality\n level of each agent. We also present an online algorithm for each agent to\n infer its opponent rationality level.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1610.04185",
        "title": "Le Potier's strange duality, quot schemes, and multiple point formulas\n  for del Pezzo surfaces",
        "abstract": "We study Le Potier's strange duality on del Pezzo surfaces using quot schemes\n to construct independent sections of theta line bundles on moduli spaces of\n sheaves, one of which is the Hilbert scheme of n points. For n at most 7, we\n use multiple point formulas to count the length of the quot scheme, which\n agrees with the dimension of the space of sections on the Hilbert scheme. When\n the surface is the projective plane and n is arbitrary, we use nice resolutions\n of general stable sheaves to show that the quot schemes that arise are finite\n and reduced. Combining our results, we obtain a lower bound on the rank of the\n strange duality map, as well as evidence that the map is injective when n is at\n most 7.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2002.00205",
        "title": "Deep segmental phonetic posterior-grams based discovery of\n  non-categories in L2 English speech",
        "abstract": "Second language (L2) speech is often labeled with the native, phone\n categories. However, in many cases, it is difficult to decide on a categorical\n phone that an L2 segment belongs to. These segments are regarded as\n non-categories. Most existing approaches for Mispronunciation Detection and\n Diagnosis (MDD) are only concerned with categorical errors, i.e. a phone\n category is inserted, deleted or substituted by another. However,\n non-categorical errors are not considered. To model these non-categorical\n errors, this work aims at exploring non-categorical patterns to extend the\n categorical phone set. We apply a phonetic segment classifier to generate\n segmental phonetic posterior-grams (SPPGs) to represent phone segment-level\n information. And then we explore the non-categories by looking for the SPPGs\n with more than one peak. Compared with the baseline system, this approach\n explores more non-categorical patterns, and also perceptual experimental\n results show that the explored non-categories are more accurate with increased\n confusion degree by 7.3% and 7.5% under two different measures. Finally, we\n preliminarily analyze the reason behind those non-categories.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2107.04082",
        "title": "Improved Language Identification Through Cross-Lingual Self-Supervised\n  Learning",
        "abstract": "Language identification greatly impacts the success of downstream tasks such\n as automatic speech recognition. Recently, self-supervised speech\n representations learned by wav2vec 2.0 have been shown to be very effective for\n a range of speech tasks. We extend previous self-supervised work on language\n identification by experimenting with pre-trained models which were learned on\n real-world unconstrained speech in multiple languages and not just on English.\n We show that models pre-trained on many languages perform better and enable\n language identification systems that require very little labeled data to\n perform well. Results on a 26 languages setup show that with only 10 minutes of\n labeled data per language, a cross-lingually pre-trained model can achieve over\n 89.2% accuracy.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2204.08462",
        "title": "CapillaryX: A Software Design Pattern for Analyzing Medical Images in\n  Real-time using Deep Learning",
        "abstract": "Recent advances in digital imaging, e.g., increased number of pixels\n captured, have meant that the volume of data to be processed and analyzed from\n these images has also increased. Deep learning algorithms are state-of-the-art\n for analyzing such images, given their high accuracy when trained with a large\n data volume of data. Nevertheless, such analysis requires considerable\n computational power, making such algorithms time- and resource-demanding. Such\n high demands can be met by using third-party cloud service providers. However,\n analyzing medical images using such services raises several legal and privacy\n challenges and does not necessarily provide real-time results. This paper\n provides a computing architecture that locally and in parallel can analyze\n medical images in real-time using deep learning thus avoiding the legal and\n privacy challenges stemming from uploading data to a third-party cloud\n provider. To make local image processing efficient on modern multi-core\n processors, we utilize parallel execution to offset the resource-intensive\n demands of deep neural networks. We focus on a specific medical-industrial case\n study, namely the quantifying of blood vessels in microcirculation images for\n which we have developed a working system. It is currently used in an\n industrial, clinical research setting as part of an e-health application. Our\n results show that our system is approximately 78% faster than its serial system\n counterpart and 12% faster than a master-slave parallel system architecture.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0612633",
        "title": "Transport properties of n-type ultrananocrystalline diamond films",
        "abstract": "We investigate transport properties of ultrananocrystalline diamond films for\n a broad range of temperatures. Addition of nitrogen during plasma-assisted\n growth increases the conductivity of ultrananocrystalline diamond films by\n several orders of magnitude. We show that films produced at low concentration\n of nitrogen in the plasma are very resistive and electron transport occurs via\n a variable range hopping mechanism while in films produced at high nitrogen\n concentration the electron states become delocalized and the transport\n properties of ultrananocrystalline diamond films can be described using the\n Boltzmann formalism. We discuss the critical concentration of carriers at which\n the metal to insulator transition in ultrananocrystalline diamond films occurs\n and compare our results with available experimental data.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0608121",
        "title": "String Gas Cosmology and Structure Formation",
        "abstract": "It has recently been shown that a Hagedorn phase of string gas cosmology may\n provide a causal mechanism for generating a nearly scale-invariant spectrum of\n scalar metric fluctuations, without the need for an intervening period of de\n Sitter expansion. A distinctive signature of this structure formation scenario\n would be a slight blue tilt of the spectrum of gravitational waves. In this\n paper we give more details of the computations leading to these results.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1909.08160",
        "title": "Left-invariant CR structures on 3-dimensional Lie groups",
        "abstract": "The systematic study of CR manifolds originated in two pioneering 1932 papers\n of \\'Elie Cartan. In the first, Cartan classifies all homogeneous CR\n 3-manifolds, the most well-known case of which is a one-parameter family of\n left-invariant CR structures on $\\mathrm{SU}_2 = S^3$, deforming the standard\n `spherical' structure. In this paper, mostly expository, we illustrate and\n clarify Cartan's results and methods by providing detailed classification\n results in modern language for four 3-dimensional Lie groups. In particular, we\n find that $\\mathrm{SL}_2(\\mathbb{R})$ admits two one-parameter families of\n left-invariant CR structures, called the elliptic and hyperbolic families,\n characterized by the incidence of the contact distribution with the null cone\n of the Killing metric. Low dimensional complex representations of\n $\\mathrm{SL}_2(\\mathbb{R})$ provide CR embedding or immersions of these\n structures. The same methods apply to all other three-dimensional Lie groups\n and are illustrated by descriptions of the left-invariant CR structures for\n $\\mathrm{SU}_2$, the Heisenberg group, and the Euclidean group.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.04394",
        "title": "Threshold-Based Fast Successive-Cancellation Decoding of Polar Codes",
        "abstract": "Fast SC decoding overcomes the latency caused by the serial nature of the SC\n decoding by identifying new nodes in the upper levels of the SC decoding tree\n and implementing their fast parallel decoders. In this work, we first present a\n novel sequence repetition node corresponding to a particular class of bit\n sequences. Most existing special node types are special cases of the proposed\n sequence repetition node. Then, a fast parallel decoder is proposed for this\n class of node. To further speed up the decoding process of general nodes\n outside this class, a threshold-based hard-decision-aided scheme is introduced.\n The threshold value that guarantees a given error-correction performance in the\n proposed scheme is derived theoretically. Analysis and hardware implementation\n results on a polar code of length $1024$ with code rates $1/4$, $1/2$, and\n $3/4$ show that our proposed algorithm reduces the required clock cycles by up\n to $8\\%$, and leads to a $10\\%$ improvement in the maximum operating frequency\n compared to state-of-the-art decoders without tangibly altering the\n error-correction performance. In addition, using the proposed threshold-based\n hard-decision-aided scheme, the decoding latency can be further reduced by\n $57\\%$ at $\\mathrm{E_b}/\\mathrm{N_0} = 5.0$~dB.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0207104",
        "title": "Cosmological Spacetimes from Negative Tension Brane Backgrounds",
        "abstract": "We identify a time-dependent class of metrics with potential applications to\n cosmology, which emerge from negative-tension branes. The cosmology is based on\n a general class of solutions to Einstein-dilaton-Maxwell theory, presented in\n {hep-th/0106120}. We argue that solutions with hyperbolic or planar symmetry\n describe the gravitational interactions of a pair of negative-tension\n $q$-branes. These spacetimes are static near each brane, but become\n time-dependent and expanding at late epoch -- in some cases asymptotically\n approaching flat space. We interpret this expansion as being the spacetime's\n response to the branes' presence. The time-dependent regions provide explicit\n examples of cosmological spacetimes with past horizons and no past naked\n singularities. The past horizons can be interpreted as S-branes. We prove that\n the singularities in the static regions are repulsive to time-like geodesics,\n extract a cosmological `bounce' interpretation, compute the explicit charge and\n tension of the branes, analyse the classical stability of the solution (in\n particular of the horizons) and study particle production, deriving a general\n expression for Hawking's temperature as well as the associated entropy.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0811.2249",
        "title": "Solutions of Polynomial Systems Derived from the Steady Cavity Flow\n  Problem",
        "abstract": "We propose a general algorithm to enumerate all solutions of a\n zero-dimensional polynomial system with respect to a given cost function. The\n algorithm is developed and is used to study a polynomial system obtained by\n discretizing the steady cavity flow problem in two dimensions. The key\n technique on which our algorithm is based is to solve polynomial optimization\n problems via sparse semidefinite programming relaxations (SDPR), which has been\n adopted successfully to solve reaction-diffusion boundary value problems\n recently. The cost function to be minimized is derived from discretizing the\n fluid's kinetic energy. The enumeration algorithm's solutions are shown to\n converge to the minimal kinetic energy solutions for SDPR of increasing order.\n We demonstrate the algorithm with SDPR of first and second order on polynomial\n systems for different scenarios of the cavity flow problem and succeed in\n deriving the $k$ smallest kinetic energy solutions. The question whether these\n solutions converge to solutions of the steady cavity flow problem is discussed,\n and we pose a conjecture for the minimal energy solution for increasing\n Reynolds number.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2109.08408",
        "title": "Finite-Size scaling analysis of many-body localization transition in\n  quasi-periodic spin chains",
        "abstract": "We analyze the finite-size scaling of the average gap-ratio and the\n entanglement entropy across the many-body localization (MBL) transition in one\n dimensional Heisenberg spin-chain with quasi-periodic (QP) potential. By using\n the recently introduced cost-function approach, we compare different scenarios\n for the transition using exact diagonalization of systems up to 22 lattice\n sites. Our findings suggest that the MBL transition in the QP Heisenberg chain\n belongs to the class of Berezinskii-Kosterlitz-Thouless (BKT) transition, the\n same as in the case of uniformly disordered systems as advocated in recent\n studies. Moreover, we observe that the critical disorder strength shows a clear\n sub-linear drift with the system-size as compared to the linear drift seen in\n random disordered models, suggesting that the finite-size effects in the MBL\n transition for the QP systems are less severe than that in the random\n disordered scenario. Moreover, deep in the ergodic regime, we find an\n unexpected double-peak structure of distribution of on-site magnetizations that\n can be traced back to the strong correlations present in the QP potential.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.01315",
        "title": "Minimal model for the flat bands in copper-substituted lead phosphate\n  apatite: Strong diamagnetism from multi-orbital physics",
        "abstract": "The claims that a copper-substituted lead apatite, denoted as\n CuPb$_9$(PO$_4$)$_6$OH$_2$, could be a room-temperature superconductor have led\n to an intense research activity. While other research groups did not confirm\n these claims, and the hope of realizing superconductivity in this compound has\n all but vanished, other findings have emerged which motivate further work on\n this material. In fact, Density Functional Theory (DFT) calculations indicate\n the presence of two nearly flat bands near the Fermi level, which are known to\n host strongly correlated physics. In order to facilitate the theoretical study\n of the intriguing physics associated with these two flat bands, we propose a\n minimal tight-binding model which reproduces their main features. We then\n calculate the orbital magnetic susceptibility of our two-band model and find a\n large diamagnetic response which arises due to the multi-orbital nature of the\n bands and which could provide an explanation for the strong diamagnetism\n reported in experiments.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0103136",
        "title": "Superbranes and Super Born-Infeld Theories from Nonlinear Realizations",
        "abstract": "We describe, on a few instructive examples, a systematic way of deducing the\n superfield equations of motion of superbranes in the approach of partial\n breaking of global supersymmetry (PBGS) from the nonlinear-realizations\n formalism. For D-branes these equations simultaneously represent the\n appropriate supersymmetric Born-Infeld theories. We also discuss how to\n construct an off-shell superfield action for the $N=2, d=4$ Dirac-Born-Infeld\n theory corresponding to the partial supersymmetry breaking $N=4 \\to N=2$ in\n $d=4$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1201.5254",
        "title": "Functionality in single-molecule devices: Model calculations and\n  applications of the inelastic electron tunneling signal in molecular\n  junctions",
        "abstract": "We analyze how functionality could be obtained within single-molecule devices\n by using a combination of non-equilibrium Green's functions and ab-initio\n calculations to study the inelastic transport properties of single-molecule\n junctions. First we apply a full non-equilibrium Green's function technique to\n a model system with electron-vibration coupling. We show that the features in\n the inelastic electron tunneling spectra (IETS) of the molecular junctions are\n virtually independent of the nature of the molecule-lead contacts. Since the\n contacts are not easily reproducible from one device to another, this is a very\n useful property. The IETS signal is much more robust versus modifications at\n the contacts and hence can be used to build functional nanodevices. Second, we\n consider a realistic model of a organic conjugated molecule. We use ab-initio\n calculations to study how the vibronic properties of the molecule can be\n controlled by an external electric field which acts as a gate voltage. The\n control, through the gate voltage, of the vibron frequencies and (more\n importantly) of the electron-vibron coupling enables the construction of\n functionality: non-linear amplification and/or switching is obtained from the\n IETS signal within a single-molecule device.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0807.2130",
        "title": "Direct observation of the e3ffect of isotope-induced disorder on the\n  exciton binding energy in LiHxD1-x mixed crystals",
        "abstract": "The results of a quantitative study of the renormalization of the binding\n energy of the Wannier-Mott exciton by the isotope effect are presented.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2010.10568",
        "title": "On the diversity of asymmetries in gapped protoplanetary disks",
        "abstract": "Protoplanetary disks with large inner dust cavities are thought to host\n massive planetary or substellar companions. These disks show asymmetries and\n rings in the millimeter continuum, caused by dust trapping in pressure bumps,\n and potentially vortices or horseshoes. The origin of the asymmetries and their\n diversity remains unclear. We present a comprehensive study of 16 disks for\n which the gas surface density profile has been constrained by CO isotopologue\n data. We compare the azimuthal extents of the dust continuum profiles with the\n local gas surface density in each disk, and find that the asymmetries\n correspond to higher Stokes numbers or low gas surface density. We discuss\n which asymmetric structures can be explained by a horseshoe, a vortex or spiral\n density waves. Second, we reassess the gas gap radii from the $^{13}$CO maps,\n which are about a factor 2 smaller than the dust ring radii, suggesting that\n companions in these disks are in the brown dwarf mass regime ($\\sim 15-50\n M_{\\rm Jup}$) or in the Super-Jovian mass regime ($\\sim 3-15 M_{\\rm Jup}$) on\n eccentric orbits. This is consistent with the estimates from contrast curves on\n companion mass limits. These curves rule out (sub)stellar companions ($q>$0.05)\n for the majority of the sample at the gap location, but it remains possible at\n even smaller radii. Third, we find that spiral arms in scattered light images\n are primarily detected around high luminosity stars with disks with wide gaps,\n which can be understood by the dependence of the spiral arm pitch angle on disk\n temperature and companion mass.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1106.4538",
        "title": "Chiral Nonet Mixing in pi pi Scattering",
        "abstract": "Pion pion scattering is studied in a generalized linear sigma model which\n contains two scalar nonets (one of quark-antiquark type and the other of\n diquark-antidiquark type) and two corresponding pseudoscalar nonets. An\n interesting feature concerns the mixing of the four isosinglet scalar mesons\n which yield poles in the scattering amplitude. Some realism is introduced by\n enforcing exact unitarity via the K-matrix method.\n  It is shown that a reasonable agreement with experimental data is obtained up\n to about 1 GeV. The poles in the unitarized scattering amplitude are studied in\n some detail. The lowest pole clearly represents the sigma meson (or f0(600))\n with a mass and decay width around 500 MeV. The second pole invites comparison\n with the f0(980) which has a mass around 1 GeV and decay width around 100 MeV.\n The third and fourth poles, resemble some of the isosinglet state in the\n complicated 1-2 GeV region. Some comparison is made to the situation in the\n usual SU(3) linear sigma model with a single scalar nonet.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1707.03071",
        "title": "Bright triplet excitons in lead halide perovskites",
        "abstract": "Nanostructured semiconductors emit light from electronic states known as\n excitons[1]. According to Hund's rules[2], the lowest energy exciton in organic\n materials should be a poorly emitting triplet state. Analogously, the lowest\n exciton level in all known inorganic semiconductors is believed to be optically\n inactive. These 'dark' excitons (into which the system can relax) hinder\n light-emitting devices based on semiconductor nanostructures. While strategies\n to diminish their influence have been developed[3-5], no materials have been\n identified in which the lowest exciton is bright. Here we show that the lowest\n exciton in quasi-cubic lead halide perovskites is optically active. We first\n use the effective-mass model and group theory to explore this possibility,\n which can occur when the strong spin-orbit coupling in the perovskite\n conduction band is combined with the Rashba effect [6-10]. We then apply our\n model to CsPbX3 (X=Cl,Br,I) nanocrystals[11], for which we measure size- and\n composition-dependent fluorescence at the single-nanocrystal level. The bright\n character of the lowest exciton immediately explains the anomalous\n photon-emission rates of these materials, which emit 20 and 1,000 times\n faster[12] than any other semiconductor nanocrystal at room[13-16] and\n cryogenic[17] temperatures, respectively. The bright exciton is further\n confirmed by detailed analysis of the fine structure in low-temperature\n fluorescence spectra. For semiconductor nanocrystals[18], which are already\n used in lighting[19,20], lasers[21,22], and displays[23], these optically\n active excitons can lead to materials with brighter emission and enhanced\n absorption. More generally, our results provide criteria for identifying other\n semiconductors exhibiting bright excitons with potentially broad implications\n for optoelectronic devices.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1906.05248",
        "title": "Multitask Learning for Network Traffic Classification",
        "abstract": "Traffic classification has various applications in today's Internet, from\n resource allocation, billing and QoS purposes in ISPs to firewall and malware\n detection in clients. Classical machine learning algorithms and deep learning\n models have been widely used to solve the traffic classification task. However,\n training such models requires a large amount of labeled data. Labeling data is\n often the most difficult and time-consuming process in building a classifier.\n To solve this challenge, we reformulate the traffic classification into a\n multi-task learning framework where bandwidth requirement and duration of a\n flow are predicted along with the traffic class. The motivation of this\n approach is twofold: First, bandwidth requirement and duration are useful in\n many applications, including routing, resource allocation, and QoS\n provisioning. Second, these two values can be obtained from each flow easily\n without the need for human labeling or capturing flows in a controlled and\n isolated environment. We show that with a large amount of easily obtainable\n data samples for bandwidth and duration prediction tasks, and only a few data\n samples for the traffic classification task, one can achieve high accuracy. We\n conduct two experiment with ISCX and QUIC public datasets and show the efficacy\n of our approach.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.08025",
        "title": "Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using\n  Self-Imagination",
        "abstract": "The potential of Vision-Language Models (VLMs) often remains underutilized in\n handling complex text-based problems, particularly when these problems could\n benefit from visual representation. Resonating with humans' ability to solve\n complex text-based problems by (1) creating a visual diagram from the problem\n and (2) deducing what steps they need to take to solve it, we propose\n Self-Imagine. We leverage a single Vision-Language Model (VLM) to generate a\n structured representation of the question using HTML, then render the HTML as\n an image, and finally use the same VLM to answer the question using both the\n question and the image. Our approach does not require any additional training\n data or training. We evaluate our approach on three mathematics tasks and nine\n general-purpose reasoning tasks using state-of-the-art (LLAVA-1.5 and GEMINI\n PRO) VLMs. Our approach boosts the performance of LLAVA-1.5 and GEMINI PRO on\n all math tasks (on average GSM8K: +3.1%; ASDIV: +3.2%; SVAMP: +6.9%) and the\n majority of the general-purpose reasoning tasks by 3.2% to 6.0% on average.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1804.05464",
        "title": "On Gradient-Based Learning in Continuous Games",
        "abstract": "We formulate a general framework for competitive gradient-based learning that\n encompasses a wide breadth of multi-agent learning algorithms, and analyze the\n limiting behavior of competitive gradient-based learning algorithms using\n dynamical systems theory. For both general-sum and potential games, we\n characterize a non-negligible subset of the local Nash equilibria that will be\n avoided if each agent employs a gradient-based learning algorithm. We also shed\n light on the issue of convergence to non-Nash strategies in general- and\n zero-sum games, which may have no relevance to the underlying game, and arise\n solely due to the choice of algorithm. The existence and frequency of such\n strategies may explain some of the difficulties encountered when using gradient\n descent in zero-sum games as, e.g., in the training of generative adversarial\n networks. To reinforce the theoretical contributions, we provide empirical\n results that highlight the frequency of linear quadratic dynamic games (a\n benchmark for multi-agent reinforcement learning) that admit global Nash\n equilibria that are almost surely avoided by policy gradient.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.06445",
        "title": "SGX-MR-Prot: Efficient and Developer-Friendly Access-Pattern Protection\n  in Trusted Execution Environments",
        "abstract": "Trusted Execution Environments, such as Intel SGX, use hardware supports to\n ensure the confidentiality and integrity of applications against a compromised\n cloud system. However, side channels like access patterns remain for\n adversaries to exploit and obtain sensitive information. Common approaches use\n oblivious programs or primitives, such as ORAM, to make access patterns\n oblivious to input data, which are challenging to develop. This demonstration\n shows a prototype SGX-MR-Prot for efficiently protecting access patterns of\n SGX-based data-intensive applications and minimizing developers' efforts.\n SGX-MR-Prot uses the MapReduce framework to regulate application dataflows to\n reduce the cost of access-pattern protection and hide the data oblivious\n details from SGX developers. This demonstration will allow users to intuitively\n understand the unique contributions of the framework-based protection approach\n via interactive exploration and visualization.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.15771",
        "title": "First search for the absorption of fermionic dark matter with the\n  PandaX-4T experiment",
        "abstract": "Compared with the signature of dark matter elastic scattering off nuclei, the\n absorption of fermionic dark matter by nuclei opens up a new searching channel\n for light dark matter with a characteristic monoenergetic signal. In this\n Letter, we explore the $95.0$-day data from the PandaX-4T commissioning run and\n report the first dedicated searching results of the fermionic dark matter\n absorption signal through a neutral current process. No significant signal was\n found, and the lowest limit on the dark matter-nucleon interaction cross\n section is set to be $1.5\\times10^{-50}$ cm$^2$ for a fermionic dark matter\n mass of $40$ MeV/$c^2$ with 90\\% confidence level.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.03624",
        "title": "The role of anharmonicity in single-molecule spin-crossover",
        "abstract": "We exploit the system-bath paradigm to investigate anharmonicity effects of\n vibrations on spin-crossover (SCO) in a single molecule. Focusing on weak\n coupling, we use the linear response approximation to deal with the vibrational\n bath and propagate the Redfield master equation to obtain the equilibrium high\n spin fraction. We take both the anharmonicity in the bath potentials and the\n nonlinearity in the spin-vibration coupling into account and find a strong\n interplay between these two effects. Further, we show that the SCO in a single\n molecule is always a gradual transition and the anharmonicity-induced phonon\n drag greatly affects the transition behavior.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1007.2432",
        "title": "Chiral Interactions of Histidine in a Hydrated Vermiculite",
        "abstract": "Recent work suggests a link between chiral asymmetry in the amino acid\n iso-valine extracted from the Murchison meteorite and the extent of hydrous\n alteration. We present the results of neutron scattering experiments on an\n exchanged, 1-dimensionally ordered n-propyl ammonium vermiculite clay. The\n vermiculite gel has a (001) d-spacing of order 5nm at the temperature and\n concentration of the experiments and the d-spacing responds sensitively to\n changes in concentration, temperature and electronic environment. The data show\n that isothermal addition of D-histidine or L-histidine solutions produces\n shifts in the d-spacing that are different for each enantiomer. This chiral\n specificity is of interest for the question of whether clays could have played\n an important role in the origin of biohomochirality.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.00864",
        "title": "Nonlinear analysis of charge-pump phase-locked loop: the hold-in and\n  pull-in ranges",
        "abstract": "In this paper a fairly complete mathematical model of CP-PLL, which reliable\n enough to serve as a tool for credible analysis of dynamical properties of\n these circuits, is studied. We refine relevant mathematical definitions of the\n hold-in and pull-in ranges related to the local and global stability. Stability\n analysis of the steady state for the charge-pump phase locked loop is\n non-trivial: straight-forward linearization of available CP-PLL models may lead\n to incorrect conclusions, because the system is not smooth near the steady\n state and may experience overload. In this work necessary details for local\n stability analysis are presented and the hold-in range is computed. An upper\n estimate of the pull-in range is obtained via the analysis of limit cycles. The\n study provided an answer to Gardner's conjecture on the similarity of transient\n responses of CP-PLL and equivalent classical PLL and to conjectures on the\n infinite pull-in range of CP-PLL with proportionally-integrating filter.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/gr-qc/0303090",
        "title": "Gauge Invariant Variables in Two-Parameter Nonlinear Perturbations",
        "abstract": "The procedure to find gauge invariant variables for two-parameter nonlinear\n perturbations in general relativity is considered. For each order metric\n perturbation, we define the variable which is defined by the appropriate\n combination with lower order metric perturbations. Under the gauge\n transformation, this variable is transformed in the manner similar to the gauge\n transformation of the linear order metric perturbation. We confirm this up to\n third order. This implies that gauge invariant variables for higher order\n metric perturbations can be found by using a procedure similar to that for\n linear order metric perturbations. We also derive gauge invariant combinations\n for the perturbation of an arbitrary physical variable, other than the\n spacetime metric, up to third order.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2008.01569",
        "title": "Doubly-hidden scalar heavy molecules and tetraquarks states from QCD at\n  NLO",
        "abstract": "Alerted by the recent LHCb discovery of exotic hadrons in the range (6.2 --\n 6.9) GeV, we present new results for the doubly-hidden scalar heavy $(\\bar QQ)\n (Q\\bar Q)$ charm and beauty molecules using the inverse Laplace transform sum\n rule (LSR) within stability criteria and including the Next-to-Leading Order\n (NLO) factorized perturbative and $\\langle G^3\\rangle$ gluon condensate\n corrections. We also critically revisit and improve existing Lowest Order (LO)\n QCD spectral sum rules (QSSR) estimates of the $({ \\bar Q \\bar Q})(QQ)$\n tetraquarks analogous states. In the example of the anti-scalar-scalar\n molecule, we separate explicitly the contributions of the factorized and\n non-factorized contributions to LO of perturbative QCD and to the\n $\\langle\\alpha_sG^2\\rangle$ gluon condensate contributions in order to disprove\n some criticisms on the (mis)uses of the sum rules for four-quark currents. We\n also re-emphasize the importance to include PT radiative corrections for heavy\n quark sum rules in order to justify the (ad hoc) definition and value of the\n heavy quark mass used frequently at LO in the literature. Our LSR results for\n tetraquark masses summarized in Table II are compared with the ones from ratio\n of moments (MOM) at NLO and results from LSR and ratios of MOM at LO (Table\n IV). The LHCb broad structure around (6.2 --6.7) GeV can be described by the\n $\\overline{\\eta}_{c}{\\eta}_{c}$, $\\overline{J/\\psi}{J/\\psi}$ and\n $\\overline{\\chi}_{c1}{\\chi}_{c1}$ molecules or/and their analogue tetraquark\n scalar-scalar, axial-axial and vector-vector lowest mass ground states. The\n peak at (6.8--6.9) GeV can be likely due to a $\\overline{\\chi}_{c0}{\\chi}_{c0}$\n molecule or/and a pseudoscalar-pseudoscalar tetraquark state. Similar analysis\n is done for the scalar beauty states whose masses are found to be above the\n $\\overline\\eta_b\\eta_b$ and $\\overline\\Upsilon(1S)\\Upsilon(1S)$ thresholds.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/9906317",
        "title": "Next-to-Leading Order QCD corrections to the Lifetime Difference of\n  $B_s$ Mesons",
        "abstract": "In this talk we present a calculation of the dacay rate difference in the\n neutral $B_s-\\bar{B}_s$ system, $\\Delta \\Gamma_{B_s}$, in next-to-leading order\n (NLO) QCD. We find a sizeable decrease compared to leading-order (LO)\n estimates: $ (\\Delta \\Gamma/\\Gamma)_{B_s} = (f_{B_s}/210 MeV)^2 [0.006 B(m_b) +\n 0.150 B_S(m_b) - 0.0063]$ in terms of the bag parameters $B$ and $B_S$ in the\n NDR scheme. We put special emphasize on the theoretical and physical\n implications of this quantity.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1703.04413",
        "title": "Topological Conjugacy of Non-hyperbolic Linear Flows",
        "abstract": "The topological equivalence classification for linear flows on $\\mathbb{R}^n$\n had been completely solved by Kuiper and independently Ladis in 1973. However,\n Ladis' proof was published in a Russian journal which isn't easily available,\n Kuiper's proof is more topological and a little bit subtle. Aiming at\n topological conjugacy classification, mainly based on the ideas of Kuiper, we\n introduce other techniques and try to present an elementary and self-contained\n proof just using linear algebra and elementary topology.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2307.03413",
        "title": "Unsupervised Hyperspectral and Multispectral Images Fusion Based on the\n  Cycle Consistency",
        "abstract": "Hyperspectral images (HSI) with abundant spectral information reflected\n materials property usually perform low spatial resolution due to the hardware\n limits. Meanwhile, multispectral images (MSI), e.g., RGB images, have a high\n spatial resolution but deficient spectral signatures. Hyperspectral and\n multispectral image fusion can be cost-effective and efficient for acquiring\n both high spatial resolution and high spectral resolution images. Many of the\n conventional HSI and MSI fusion algorithms rely on known spatial degradation\n parameters, i.e., point spread function, spectral degradation parameters,\n spectral response function, or both of them. Another class of deep\n learning-based models relies on the ground truth of high spatial resolution HSI\n and needs large amounts of paired training images when working in a supervised\n manner. Both of these models are limited in practical fusion scenarios. In this\n paper, we propose an unsupervised HSI and MSI fusion model based on the cycle\n consistency, called CycFusion. The CycFusion learns the domain transformation\n between low spatial resolution HSI (LrHSI) and high spatial resolution MSI\n (HrMSI), and the desired high spatial resolution HSI (HrHSI) are considered to\n be intermediate feature maps in the transformation networks. The CycFusion can\n be trained with the objective functions of marginal matching in single\n transform and cycle consistency in double transforms. Moreover, the estimated\n PSF and SRF are embedded in the model as the pre-training weights, which\n further enhances the practicality of our proposed model. Experiments conducted\n on several datasets show that our proposed model outperforms all compared\n unsupervised fusion methods. The codes of this paper will be available at this\n address: https: //github.com/shuaikaishi/CycFusion for reproducibility.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1809.05612",
        "title": "On the Homology of the Space of Curves Immersed in The Sphere with\n  Curvature Constrained to a Prescribed Interval",
        "abstract": "While the topology of the space of all smooth immersed curves on the\n $2$-sphere $\\mathbb{S}^2$ that start and end at given points in given\n directions is well known, it is an open problem to understand the homotopy type\n of its subspaces consisting of the curves whose geodesic curvatures are\n constrained to a prescribed proper open interval. In this article we prove\n that, under certain circumstances for endpoints and end directions, these\n subspaces are not homotopically equivalent to the whole space. Moreover, we\n give an explicit construction of exotic generators for some homotopy and\n cohomology groups. It turns out that the dimensions of these generators depend\n on endpoints and end directions. A version of the h-principle is used to prove\n these results.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1609.01368",
        "title": "Product BMO, little BMO and Riesz Commutators in the Bessel setting",
        "abstract": "In this paper, we study the product BMO space, little bmo space and their\n connections with the corresponding commutators associated with Bessel operators\n studied by Weinstein, Huber, and by Muckenhoupt-Stein. We first prove that the\n product BMO space in the Bessel setting can be used to prove the boundedness of\n the iterated commutators with the Bessel Riesz transforms. We next study the\n little $\\rm bmo$ space in this Bessel setting and obtain the equivalent\n characterization of this space in terms of commutators. We further show that in\n analogy with the classical setting, the little $\\rm bmo$ space is a proper\n subspace of the product $\\rm BMO$ space. These extend the previous related\n results studied by Cotlar-Sadosky and Ferguson-Sadosky on the bidisc to the\n Bessel setting.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ex/0106103",
        "title": "Test of CPT and Lorentz invariance from muonium spectroscopy",
        "abstract": "Following a suggestion of Kostelecky et al. we have evaluated a test of CPT\n and Lorentz invariance from the microwave spectroscopy of muonium. Hamiltonian\n terms beyond the standard model violating CPT and Lorentz invariance would\n contribute frequency shifts $\\delta\\nu_{12}$ and $\\delta\\nu_{34}$ to $\\nu_{12}$\n and $\\nu_{34}$, the two transitions involving muon spin flip, which were\n precisely measured in ground state muonium in a strong magnetic field of 1.7 T.\n The shifts would be indicated by anti-correlated oscillations in $\\nu_{12}$ and\n $\\nu_{34}$ at the earth's sidereal frequency. No time dependence was found in\n $\\nu_{12}$ or $\\nu_{34}$ at the level of 20 Hz, limiting the size of some CPT\n and Lorentz violating parameters at the level of $2\\times10^{-23}$ GeV,\n representing Planck scale sensitivity and an order of magnitude improvement in\n sensitivity over previous limits for the muon.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1103.3167",
        "title": "Fidelity decay in interacting two-level boson systems: Freezing and\n  revivals",
        "abstract": "We study the fidelity decay in the $k$-body embedded ensembles of random\n matrices for bosons distributed in two single-particle states, considering the\n reference or unperturbed Hamiltonian as the one-body terms and the diagonal\n part of the $k$-body embedded ensemble of random matrices, and the perturbation\n as the residual off-diagonal part of the interaction. We calculate the\n ensemble-averaged fidelity with respect to an initial random state within\n linear response theory to second order on the perturbation strength, and\n demonstrate that it displays the freeze of the fidelity. During the freeze, the\n average fidelity exhibits periodic revivals at integer values of the Heisenberg\n time $t_H$. By selecting specific $k$-body terms of the residual interaction,\n we find that the periodicity of the revivals during the freeze of fidelity is\n an integer fraction of $t_H$, thus relating the period of the revivals with the\n range of the interaction $k$ of the perturbing terms. Numerical calculations\n confirm the analytical results.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.06028",
        "title": "Compact active vibration isolation and tilt stabilization for a portable\n  high-precision atomic gravimeter",
        "abstract": "In high-precision atomic gravimeters, a rest mass is needed to provide a\n gravity reference, which is typically the retro-reflecting mirror of the Raman\n laser beams that addresses the two hyperfine ground states of the specific\n free-falling atomic test mass. We constructed a compact active feedback control\n system for the retro-reflecting mirror that provides vibration isolation in the\n vertical axis as well as two rotation stabilization in the horizontal plane.\n The active feedback control provides vertical vibration reduction of up to a\n factor of 300 in the frequency range of 0.03 to 10 Hz and tilt stabilization of\n approximately $\\pm$ 1 $\\mu$rad in the noisy lab environment. This system has\n enabled high-precision gravity measurements on a portable gravimeter with\n sensitivity reaching $6.4\\times 10^{-8}$ g/$\\sqrt{\\text{Hz}}$ and resolution of\n $2.8\\times 10^{-9}$ g after an integration time of 4000 s.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1701.06037",
        "title": "The Hessian of quantized Ding functionals and its asymptotic behavior",
        "abstract": "We compute the Hessian of quantized Ding functionals and give an elementary\n proof for the convexity of quantized Ding functionals along Bergman geodesics\n from the view point of projective geometry. We study also the asymptotic\n behavior of the Hessian using the Berezin-Toeplitz quantization.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1612.00103",
        "title": "Review on Hadron Spectroscopy",
        "abstract": "I review some of the lattice results on spectroscopy and resonances in the\n past years. For the conventional hadron spectrum computations, focus has been\n put on the isospin breaking effects, QED effects, and simulations near the\n physical pion mass point. I then go through several single-channel scattering\n studies within L\\\"uscher formalism, a method that has matured over the past few\n years. The topics cover light mesons and also the charmed mesons, with the\n latter case intimately related to the recently discovered exotic $XYZ$\n particles. Other possible related formalisms that are available on the market\n are also discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.06118",
        "title": "CHITNet: A Complementary to Harmonious Information Transfer Network for\n  Infrared and Visible Image Fusion",
        "abstract": "Current infrared and visible image fusion (IVIF) methods go to great lengths\n to excavate complementary features and design complex fusion strategies, which\n is extremely challenging. To this end, we rethink the IVIF outside the box,\n proposing a complementary to harmonious information transfer network (CHITNet).\n It reasonably transfers complementary information into harmonious one, which\n integrates both the shared and complementary features from two modalities.\n Specifically, to skillfully sidestep aggregating complementary information in\n IVIF, we design a mutual information transfer (MIT) module to mutually\n represent features from two modalities, roughly transferring complementary\n information into harmonious one. Then, a harmonious information acquisition\n supervised by source image (HIASSI) module is devised to further ensure the\n complementary to harmonious information transfer after MIT. Meanwhile, we also\n propose a structure information preservation (SIP) module to guarantee that the\n edge structure information of the source images can be transferred to the\n fusion results. Moreover, a mutual promotion training paradigm (MPTP) with\n interaction loss is adopted to facilitate better collaboration among MIT,\n HIASSI and SIP. In this way, the proposed method is able to generate fused\n images with higher qualities. Extensive experimental results demonstrate the\n superiority of our CHITNet over state-of-the-art algorithms in terms of visual\n quality and quantitative evaluations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2011.10211",
        "title": "Portable Magnetic Particle Spectrometer (MPS) for Future Rapid and\n  Wash-free Bioassays",
        "abstract": "Nowadays, there is an increasing demand for more accessible routine\n diagnostics for patients with respect to high accuracy, ease of use, and low\n cost. However, the quantitative and high accuracy bioassays in large hospitals\n and laboratories usually require trained technicians and equipment that is both\n bulky and expensive. In addition, the multi-step bioassays and long turnaround\n time could severely affect the disease surveillance and control especially in\n pandemics such as influenza and COVID-19. In view of this, a portable,\n quantitative bioassay device will be valuable in regions with scarce medical\n resources and help relieve burden on local healthcare systems. Herein, we\n introduce the MagiCoil diagnostic device, an inexpensive, portable,\n quantitative and rapid bioassay platform based on magnetic particle\n spectrometer (MPS) technique. MPS detects the dynamic magnetic responses of\n magnetic nanoparticles (MNPs) and uses the harmonics from oscillating MNPs as\n metrics for sensitive and quantitative bioassays. This device does not require\n trained technicians to operate and employs a fully automatic, one-step,\n wash-free assay with user friendly smartphone interface. Using a\n streptavidin-biotin binding system as a model, we show that the detection limit\n of the current portable device for streptavidin is 64 nM (equal to 5.12 pmole).\n In addition, this MPS technique is very versatile and allows for the detection\n of different diseases just by changing the surface modifications on MNPs.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2402.15478",
        "title": "Transformers are Expressive, But Are They Expressive Enough for\n  Regression?",
        "abstract": "Transformers have become pivotal in Natural Language Processing,\n demonstrating remarkable success in applications like Machine Translation and\n Summarization. Given their widespread adoption, several works have attempted to\n analyze the expressivity of Transformers. Expressivity of a neural network is\n the class of functions it can approximate. A neural network is fully expressive\n if it can act as a universal function approximator. We attempt to analyze the\n same for Transformers. Contrary to existing claims, our findings reveal that\n Transformers struggle to reliably approximate smooth functions, relying on\n piecewise constant approximations with sizable intervals. The central question\n emerges as: \"Are Transformers truly Universal Function Approximators?\" To\n address this, we conduct a thorough investigation, providing theoretical\n insights and supporting evidence through experiments. Theoretically, we prove\n that Transformer Encoders cannot approximate smooth functions. Experimentally,\n we complement our theory and show that the full Transformer architecture cannot\n approximate smooth functions. By shedding light on these challenges, we\n advocate a refined understanding of Transformers' capabilities.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0005189",
        "title": "On the quantum model of gravitational electrodynamics",
        "abstract": "It is shown that application of dynamic flows concept in 4-dimensional\n Euclidean space makes possible to form Minkowski space and to formulate the\n generalized variational problem of electrodynamics and gravi- dynamics. It is\n shown that 1-dimensional (cylindrical) factorization of 4-dimensional Euclidean\n space provides a quantization of ths model.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2008.09808",
        "title": "On the emergent System Mass Function: the contest between accretion and\n  fragmentation",
        "abstract": "We propose a new model for the evolution of a star cluster's System Mass\n Function (SMF). The model involves both turbulent fragmentation and competitive\n accretion. Turbulent fragmentation creates low-mass seed proto-systems (i.e.\n single and multiple protostars). Some of these low-mass seed proto-systems then\n grow by competitive accretion to produce the high-mass power-law tail of the\n SMF. Turbulent fragmentation is relatively inefficient, in the sense that the\n creation of low-mass seed proto-systems only consumes a fraction, $\\sim 23\\%$\n (at most $\\sim 50\\%$), of the mass available for star formation. The remaining\n mass is consumed by competitive accretion. Provided the accretion rate onto a\n proto-system is approximately proportional to its mass ($dm/dt \\propto m$), the\n SMF develops a power-law tail at high masses with the Salpeter slope ($\\sim\n -2.3$). If the rate of supply of mass accelerates, the rate of proto-system\n formation also accelerates, as appears to be observed in many clusters.\n However, even if the rate of supply of mass decreases, or ceases and then\n resumes, the SMF evolves homologously, retaining the same overall shape, and\n the high-mass power-law tail simply extends to ever higher masses until the\n supply of gas runs out completely. The Chabrier SMF can be reproduced very\n accurately if the seed proto-systems have an approximately log-normal mass\n distribution with median mass $\\sim 0.11 {\\rm M}_{_\\odot}$ and logarithmic\n standard deviation $\\sigma_{\\log_{10}(M/{\\rm M}_\\odot)}\\sim 0.47$).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1407.2192",
        "title": "An ensemble Kushner-Stratonovich-Poisson filter for recursive estimation\n  in nonlinear dynamical systems",
        "abstract": "Despite the numerous applications that may be expeditiously modelled by\n counting processes, stochastic filtering strategies involving Poisson-type\n observations still remain somewhat poorly developed. In this work, we propose a\n Monte Carlo stochastic filter for recursive estimation in the context of\n linear/nonlinear dynamical systems with Poisson-type measurements. A key aspect\n of the present development is the filter-update scheme, derived from an\n ensemble approximation of the time-discretized nonlinear filtering equation,\n modified to account for Poisson-type measurements. Specifically, the additive\n update through a gain-like correction term, empirically approximated from the\n innovation integral in the filtering equation, eliminates the problem of\n particle collapse encountered in many conventional particle filters. Through a\n few numerical demonstrations, the versatility of the proposed filter is brought\n forth, first with application to filtering problems with diffusive or\n Poisson-type measurements and then to an automatic control problem wherein the\n extremization of the associated cost functional is achieved simply by an\n appropriate redefinition of the innovation process.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0303032",
        "title": "Selection criteria for targets of asteroseismic campaigns",
        "abstract": "Various dedicated satellite projects are underway or in advanced stages of\n planning to perform high-precision, long duration time series photometry of\n stars, with the purpose of using the frequencies of stellar oscillations to put\n new constraints on the internal structure of stars. It is known (cf. Brown, et\n al. 1994) that the effectiveness of oscillation frequencies in constraining\n stellar model parameters is significantly higher if classical parameters such\n as effective temperature, and luminosity are known with high precision. In\n order to optimize asteroseismic campaigns it is therefore useful to select\n targets from among candidates for which good spectroscopic and astrometric data\n already exists. This paper presents selection criteria, as well as\n redeterminations of stellar luminosity and reddening for stars satisfying these\n criteria.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2101.10093",
        "title": "Single-Crystal NMR Spectroscopy",
        "abstract": "Single-crystal (SC) NMR spectroscopy is a solid-state NMR method that has\n been used since the early days of NMR to study the magnitude and orientation of\n tensorial nuclear spin interactions in solids. This review first presents the\n field of SC NMR instrumentation, then provides a survey of software for\n analysis of SC NMR data, and finally it highlights selected applications of SC\n NMR in various fields of research. The aim of the last part is not to provide a\n complete review of all SC NMR literature but to provide examples that\n demonstrate interesting applications of SC NMR.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1306.0930",
        "title": "Stationary States and Asymptotic Behaviour of Aggregation Models with\n  Nonlinear Local Repulsion",
        "abstract": "We consider a continuum aggregation model with nonlinear local repulsion\n given by a degenerate power-law diffusion with general exponent. The steady\n states and their properties in one dimension are studied both analytically and\n numerically, suggesting that the quadratic diffusion is a critical case. The\n focus is on finite-size, monotone and compactly supported equilibria. We also\n investigate numerically the long time asymptotics of the model by simulations\n of the evolution equation. Issues such as metastability and local/ global\n stability are studied in connection to the gradient flow formulation of the\n model.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2102.05593",
        "title": "Quantum Variational Optimization of Ramsey Interferometry and Atomic\n  Clocks",
        "abstract": "We discuss quantum variational optimization of Ramsey interferometry with\n ensembles of $N$ entangled atoms, and its application to atomic clocks based on\n a Bayesian approach to phase estimation. We identify best input states and\n generalized measurements within a variational approximation for the\n corresponding entangling and decoding quantum circuits. These circuits are\n built from basic quantum operations available for the particular sensor\n platform, such as one-axis twisting, or finite range interactions. Optimization\n is defined relative to a cost function, which in the present study is the\n Bayesian mean square error of the estimated phase for a given prior\n distribution, i.e. we optimize for a finite dynamic range of the\n interferometer. In analogous variational optimizations of optical atomic\n clocks, we use the Allan deviation for a given Ramsey interrogation time as the\n relevant cost function for the long-term instability. Remarkably, even\n low-depth quantum circuits yield excellent results that closely approach the\n fundamental quantum limits for optimal Ramsey interferometry and atomic clocks.\n The quantum metrological schemes identified here are readily applicable to\n atomic clocks based on optical lattices, tweezer arrays, or trapped ions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1402.2369",
        "title": "Discovery of new low-excitation planetary nebulae",
        "abstract": "We report a multi-wavelength study of four new planetary nebula (PN)\n candidates selected from the INT/WFC Photometric Ha Survey of the Northern\n Galactic Plane (IPHAS) and Deep Sky Hunter (DSH) catalogues. We present\n mid-resolution optical spectra of these PNs. The PN status of our sample was\n confirmed by optical narrow-band images and mid-resolution spectra. Based on\n the locations of these objects in the log (Ha/[N II]) versus log (Ha/[S II])\n diagnostic diagram, we conclude that these sources are evolved lowexcitation\n PNs. The optical and infrared appearances of these newly discovered PNs are\n discussed. Three of the new nebulae studied here are detected in infrared and\n have low infrared-to-radio flux ratios, probably suggesting that they are\n evolved. Furthermore, we derive the dynamical ages and distances of these\n nebulae and study the spectral energy distribution for one of them with\n extensive infrared archival data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2204.07470",
        "title": "Explaining the 96 GeV Di-photon Anomaly in a Generic 2HDM Type-III",
        "abstract": "Motivated by results recently reported by the CMS Collaboration about an\n excess in the di-photon spectrum at about 96 GeV, especially when combined with\n another long-standing anomaly at the same value in the $b\\bar b$ invariant mass\n spectrum in four-jet events collected at LEP, we show that a possible\n explanation to both phenomena can be found at 1$\\sigma$ level in a generic\n 2-Higgs Doublet Model (2HDM) of Type-III in presence of a specific Yukawa\n texture, wherein Lepton Flavour Violating (LFV) (neutral) currents are induced\n at tree level. Bounds from Higgs data play a major role in limiting the\n parameter space of this scenario, yet we find solutions with $m_H = 125$ GeV\n and $m_h = 96$ GeV consistent with current theoretical and experimental bounds.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1902.07904",
        "title": "Filamentous Active Matter: Band Formation, Bending, Buckling, and\n  Defects",
        "abstract": "Motor proteins drive persistent motion and self-organisation of cytoskeletal\n filaments. However, state-of-the-art microscopy techniques and continuum\n modelling approaches focus on large length and time scales. Here, we perform\n component-based computer simulations of polar filaments and molecular motors\n linking microscopic interactions and activity to self-organisation and dynamics\n from the two-filament level up to the mesoscopic domain level. Dynamic filament\n crosslinking and sliding, and excluded-volume interactions promote formation of\n bundles at small densities, and of active polar nematics at high densities. A\n buckling-type instability sets the size of polar domains and the density of\n topological defects. We predict a universal scaling of the active diffusion\n coefficient and the domain size with activity, and its dependence on parameters\n like motor concentration and filament persistence length. Our results provide a\n microscopic understanding of cytoplasmic streaming in cells and help to develop\n design strategies for novel engineered active materials.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.15324",
        "title": "Topological superconductivity enhanced by exceptional points",
        "abstract": "Majorana zero modes (MZMs) emerge as edge states in topological\n superconductors and are promising for topological quantum computation, but\n their detection has so far been elusive. Here we show that non-Hermiticity can\n be used to obtain dramatically more robust MZMs. The enhanced properties appear\n as a result of an extreme instability of exceptional points to\n superconductivity, such that even a vanishingly small superconducting order\n parameter already opens a large energy gap, produces well-localized MZMs, and\n leads to strong superconducting pair correlations. Our work thus illustrates\n the large potential of enhancing topological superconductivity using\n non-Hermitian exceptional points.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1911.09426",
        "title": "KPZ statistics of second class particles in ASEP via mixing",
        "abstract": "We consider the asymmetric simple exclusion process on $\\mathbb{Z}$ with a\n single second class particle initially at the origin. The first class particles\n form two rarefaction fans which come together at the origin, where the large\n time density jumps from $0$ to $1$. We are interested in $X(t)$, the position\n of the second class particle at time $t$. We show that, under the KPZ $1/3$\n scaling, $X(t)$ is asymptotically distributed as the difference of two\n independent, $\\mathrm{GUE}$-distributed random variables.The key part of the\n proof is to show that $X(t)$ equals, up to a negligible term, the difference of\n a random number of holes and particles, with the randomness built up by ASEP\n itself. This provides a KPZ analogue to the 1994 result of Ferrari and Fontes\n \\cite{FF94b}, where this randomness comes from the initial data and leads to\n Gaussian limit laws.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2104.01120",
        "title": "Linear Systems can be Hard to Learn",
        "abstract": "In this paper, we investigate when system identification is statistically\n easy or hard, in the finite sample regime. Statistically easy to learn linear\n system classes have sample complexity that is polynomial with the system\n dimension. Most prior research in the finite sample regime falls in this\n category, focusing on systems that are directly excited by process noise.\n Statistically hard to learn linear system classes have worst-case sample\n complexity that is at least exponential with the system dimension, regardless\n of the identification algorithm. Using tools from minimax theory, we show that\n classes of linear systems can be hard to learn. Such classes include, for\n example, under-actuated or under-excited systems with weak coupling among the\n states. Having classified some systems as easy or hard to learn, a natural\n question arises as to what system properties fundamentally affect the hardness\n of system identifiability. Towards this direction, we characterize how the\n controllability index of linear systems affects the sample complexity of\n identification. More specifically, we show that the sample complexity of\n robustly controllable linear systems is upper bounded by an exponential\n function of the controllability index. This implies that identification is easy\n for classes of linear systems with small controllability index and potentially\n hard if the controllability index is large. Our analysis is based on recent\n statistical tools for finite sample analysis of system identification as well\n as a novel lower bound that relates controllability index with the least\n singular value of the controllability Gramian.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0806.0787",
        "title": "Power reductivity over an arbitrary base",
        "abstract": "Our starting point is Mumford's conjecture, on representations of Chevalley\n groups over fields, as it is phrased in the preface of \"Geometric Invariant\n Theory\". After extending the conjecture appropriately, we show that it holds\n over an arbitrary commutative base ring. We thus obtain the first fundamental\n theorem of invariant theory (often referred to as Hilbert's fourteenth problem)\n over an arbitrary Noetherian ring. We also prove results on the Grosshans\n graded deformation of an algebra in the same generality. We end with tentative\n finiteness results for rational cohomology over the integers.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2006.04393",
        "title": "The Gaia-ESO Survey: an extremely Li-rich giant in the globular cluster\n  NGC 1261",
        "abstract": "Lithium rich stars in globular clusters are rare. In fact, only 14 have been\n found so far, in different evolutionary phases from dwarfs to giants. Different\n mechanisms have been proposed to explain this enhancement, but it is still an\n open problem. Using spectra collected within the Gaia-ESO Survey, obtained with\n the GIRAFFE spectrograph at the ESO Very Large Telescope, we present the\n discovery of the first Li-rich star in the cluster NGC 1261, the second star\n known in the red giant branch bump phase. The star shows an extreme Li\n overabundance of A(Li)_LTE=3.92\\pm0.14, corresponding to A(Li)_NLTE=3.40 dex.\n We propose that the Li enhancement is caused by fresh Li production through an\n extra mixing process (sometimes referred to as {\\em cool bottom burning}) or\n could be a pre-existing Li overabundance resulting from binary mass transfer,\n likely from a red giant branch star, because of the low barium abundance. To\n unambiguously explain the Li enhancement in globular cluster stars, however, a\n reliable determination of the abundance of key species like Be, 6Li, 12C/13C,\n and several s-process elements is required, as well as detailed modeling of\n chromospheric activity indicators.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1406.4497",
        "title": "A Chandra-HETG VIEW OF MCG +8-11-11",
        "abstract": "We present a spectral analysis of the 118 ks High Energy Transmission\n Gratings (HETG) observation of the X-ray bright Seyfert 1.5 galaxy MCG\n +8-11-11, in conjunction with 100 ks of archival Suzaku data, aimed at\n investigating the signatures of warm absorption and Compton reflection reported\n from previous Suzaku and XMM-Newton studies of the source. Contrary to previous\n results, we find that warm absorption is not required by the data. Instead, we\n report upper limits on absorption lines that are below previous (marginal)\n detections. Fe Ka line emission is clearly detected and is likely resolved with\n sigma ~ 0.02 keV with the HETG data. We applied self-consistent, broadband\n spectral-fitting models to the HETG and Suzaku data to investigate this and\n other signatures of distant absorption and reflection. Utilizing in particular\n the MYTorus model, we find that the data are consistent with reprocessing by a\n distant, neutral torus that is Compton thick and out of the line-of-sight.\n However, we do not find compelling evidence of a relativistically-broadened\n Fe-K emission line, which is often expected from type 1 AGN. This is consistent\n with some, although not all, previous studies of MCG +8-11-11. A well-measured\n edge is identified by the HETG near 0.5 keV, indicating neutral absorption in\n the line of sight that is consistent with galactic absorption; however, the\n absorption may be partially intrinsic to the source. The HETG data are\n consistent with the presence of a soft excess, a feature that may be missed by\n considering the Suzaku data alone.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.09534",
        "title": "Learning-Based Compress-and-Forward Schemes for the Relay Channel",
        "abstract": "The relay channel, consisting of a source-destination pair along with a\n relay, is a fundamental component of cooperative communications. While the\n capacity of a general relay channel remains unknown, various relaying\n strategies, including compress-and-forward (CF), have been proposed. In CF, the\n relay forwards a quantized version of its received signal to the destination.\n Given the correlated signals at the relay and destination, distributed\n compression techniques, such as Wyner--Ziv coding, can be harnessed to utilize\n the relay-to-destination link more efficiently. Leveraging recent advances in\n neural network-based distributed compression, we revisit the relay channel\n problem and integrate a learned task-aware Wyner--Ziv compressor into a\n primitive relay channel with a finite-capacity out-of-band relay-to-destination\n link. The resulting neural CF scheme demonstrates that our compressor recovers\n binning of the quantized indices at the relay, mimicking the optimal asymptotic\n CF strategy, although no structure exploiting the knowledge of source\n statistics was imposed into the design. The proposed neural CF, employing\n finite order modulation, operates closely to the rate achievable in a primitive\n relay channel with a Gaussian codebook. We showcase the advantages of\n exploiting the correlated destination signal for relay compression through\n various neural CF architectures that involve end-to-end training of the\n compressor and the demodulator components. Our learned task-oriented\n compressors provide the first proof-of-concept work toward interpretable and\n practical neural CF relaying schemes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.07685",
        "title": "The residue-counts of $x^2+a/x$ modulo a prime",
        "abstract": "For a prime $p>3$ and $a\\in \\Bbb Z$ with $p\\nmid a$ let $V_p(x^2+\\frac ax)$\n be the residue-counts of $x^2+\\frac ax$ modulo $p$ as $x$ runs over\n $1,2,\\ldots,p-1$. In this paper, we obtain an explicit formula for\n $V_p(x^2+\\frac ax)$, which is concerned with cubic residues and binary\n quadratic forms.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1512.07593",
        "title": "Regularity of distributions of Wigner integrals",
        "abstract": "Wigner integrals and the corresponding Wigner chaos were introduced by P.\n Biane and R. Speicher in 1998 as a non-commutative counterpart of classical\n Wiener-It\\^o integrals and the corresponding Wiener-It\\^o chaos, respectively,\n in free probability.\n  In the classical case, a famous result of I. Shigekawa states that\n non-trivial elements in the finite Wiener-It\\^o chaos have an absolutely\n continuous distribution. We provide here a first contribution to such\n regularity questions for Wigner integrals by showing that the distribution of\n non-trivial elements in the finite Wigner chaos cannot have atoms. This answers\n a question of I. Nourdin and G. Peccati.\n  For doing so, we establish the notion of directional gradients in the context\n of the free Malliavin calculus. These directional gradients bridge between free\n Malliavin calculus and the theory of non-commutative derivations as initiated\n by D. Voiculescu and Y. Dabrowski. Methods recently invented by R. Speicher, M.\n Weber, and the author for treating similar questions in the case of finitely\n many variables are extended, such that they apply to directional gradients.\n This approach also excludes zero-divisors for the considered elements in the\n finite Wigner chaos.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2109.05515",
        "title": "One-dimensional purely Lee-Huang-Yang fluids dominated by quantum\n  fluctuations in two-component Bose-Einstein condensates",
        "abstract": "Lee-Huang-Yang (LHY) fluids are an exotic quantum matter dominated purely by\n quantum fluctuations. Recently, the three-dimensional LHY fluids were observed\n in ultracold atoms experiments, while their low-dimensional counterparts have\n not been well known. Herein, based on the Gross-Pitaevskii equation of\n one-dimensional LHY quantum fluids in two-component Bose-Einstein condensates,\n we reveal analytically and numerically the formation, properties, and dynamics\n of matter-wave structures therein. Considering a harmonic trap, approximate\n analytical results are obtained based on variational approximation, and\n higher-order nonlinear localized modes with nonzero nodes are constructed\n numerically. Stability regions of all the LHY nonlinear localized modes are\n identified by linear-stability analysis and direct perturbed numerical\n simulations. Movements and oscillations of single localized mode, and\n collisions between two modes, under the influence of different initial kicks\n are also studied in dynamical evolutions. The predicted results are available\n to quantum-gas experiments, providing a new insight into LHY physics in\n low-dimensional settings.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2207.03769",
        "title": "Laser-guided lightning",
        "abstract": "Electric currents circulating between charged clouds and the earth surface\n during lightning discharges are responsible for considerable damages and\n casualties. It is therefore important to develop better protection methods in\n addition to the traditional Franklin rod. Here we present the first\n demonstration that filaments formed by short and intense laser pulses can guide\n lightning discharges over considerable distances. We believe that this\n experimental breakthrough will lead to progress in lightning protection and\n lightning physics. An experimental campaign was carried out on the S\\\"antis\n Mountain in Northeastern Switzerland during the Summer of 2021 with a high\n repetition rate terawatt laser. The guiding of an upward negative lightning\n leader over a distance of 50 m was recorded by two separate high-speed cameras.\n The guiding of negative lightning leaders by laser filaments was corroborated\n in three other instances by VHF interferometric measurements, and the number of\n X-ray bursts detected during guided lightning events was significantly\n increased. While this research field has been very active for more than 20\n years with many research groups around the world working to achieve this goal,\n this result demonstrates lightning guiding by lasers, which may lead to the\n development of a laser lightning rod. This work paves the way for new\n atmospheric applications of ultrashort lasers and represents a significant step\n forward in the development of a laser based lightning protection for airports,\n launchpads or large infrastructures.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1903.03233",
        "title": "Some extremal results on K_{s,t}-free graphs",
        "abstract": "For graphs $H$ and $F$, let $\\text{ex}(n,H,F)$ be the maximum possible number\n of copies of $H$ in an $F$-free graph on $n$ vertices. The study of this\n function, which generalizes the well-known Tur\\'{a}n number of graphs, was\n systematically studied by Alon and Shikhelman recently. In this paper, we show\n that for any $m$ and $t\\ge 2m-3\\ge3$,\n \\[\\text{ex}(n,K_{m},K_{2,t})=\\Theta(n^{\\frac{3}{2}}).\\] This result improves\n some results of Alon and Shikhelman (J. Combin. Theory Ser. B, 121:146-172,\n 2016). We also study the $k$-partite $K_{s,t}$-free graph, we show that for any\n $k\\ge3$ and $t\\ge(k-1)(s-1)!+1$, \\[\\text{ex}_{\\chi\\le\n k}(n,K_{s,t})\\ge\\frac{k-1}{2k}n^{2-1/s}+o(n^{2-1/s}).\\] Moreover, we give a new\n construction of $3$-partite $K_{2,2t+1}$-free graphs with many edges.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0405140",
        "title": "VERA Observation of the W49N H2O Maser Outburst in 2003 October",
        "abstract": "We report on a strong outburst of the W49N H2O maser observed with VERA.\n Single-dish monitoring with VERA 20 m telescopes detected a strong outburst of\n the maser feature at V_LSR = -30.7 km/s in 2003 October. The outburst had a\n duration of ~100 days and a peak intensity of 7.9 x 10^4 Jy, being one of the\n strongest outbursts in W49N observed so far. VLBI observations with the VERA\n array were also carried out near to the maximum phase of the outburst, and the\n outburst spot was identified in the VLBI map. While the map was in good\n agreement with previous studies, showing three major concentrations of maser\n spots, we found a newly formed arc-like structure in the central maser\n concentration, which may be a shock front powered by a forming star or a star\n cluster. The outburst spot was found to be located on the arc-like structure,\n indicating a possible connection of the present outburst to a shock phenomenon.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1801.02252",
        "title": "Spaces with polynomial hulls that contain no analytic discs",
        "abstract": "Extensions of the notions of polynomially and rationally convex hulls are\n introduced. Using these notions, a generalization of a result of Duval and\n Levenberg on polynomially convex hulls containing no analytic discs is\n presented. As a consequence it is shown that there exists a Cantor set $X$ in\n ${\\mathbb C}^3$ with a nontrivial polynomially convex hull that contains no\n analytic discs. Using this Cantor set, it is shown that there exist arcs and\n curves in ${\\mathbb C}^4$ with nontrivial polynomially convex hulls that\n contain no analytic discs. This answers a question raised a few years ago by\n Bercovici and can be regarded as a partial answer to a question raised by\n Wermer over 60 years ago. More generally, it is shown that every uncountable,\n compact subspace of a Euclidean space can be embedded as a subspace $X$ of\n ${\\mathbb C}^N$, for some N, in such a way as to have a nontrivial polynomially\n convex hull that contains no analytic discs. In the case when the topological\n dimension of the space is at most one, $X$ can be chosen so as to have the\n stronger property that $P(X)$ has a dense set of invertible elements.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1511.06571",
        "title": "A cut-cell finite volume - finite element coupling approach for\n  fluid-structure interaction in compressible flow",
        "abstract": "We present a loosely coupled approach for the solution of fluid-structure\n interaction problems between a compressible flow and a deformable structure.\n The method is based on staggered Dirichlet-Neumann partitioning. The interface\n motion in the Eulerian frame is accounted for by a conservative cut-cell\n Immersed Boundary method. The present approach enables sub-cell resolution by\n considering individual cut-elements within a single fluid cell, which\n guarantees an accurate representation of the time-varying solid interface. The\n cut-cell procedure inevitably leads to non-matching interfaces, demanding for a\n special treatment. A Mortar method is chosen in order to obtain a conservative\n and consistent load transfer. We validate our method by investigating\n two-dimensional test cases comprising a shock-loaded rigid cylinder and a\n deformable panel. Moreover, the aeroelastic instability of a thin plate\n structure is studied with a focus on the prediction of flutter onset. Finally,\n we propose a three-dimensional fluid-structure interaction test case of a\n flexible inflated thin shell interacting with a shock wave involving large and\n complex structural deformations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.01921",
        "title": "Causal Scoring Medical Image Explanations: A Case Study On Ex-vivo\n  Kidney Stone Images",
        "abstract": "On the promise that if human users know the cause of an output, it would\n enable them to grasp the process responsible for the output, and hence provide\n understanding, many explainable methods have been proposed to indicate the\n cause for the output of a model based on its input. Nonetheless, little has\n been reported on quantitative measurements of such causal relationships between\n the inputs, the explanations, and the outputs of a model, leaving the\n assessment to the user, independent of his level of expertise in the subject.\n To address this situation, we explore a technique for measuring the causal\n relationship between the features from the area of the object of interest in\n the images of a class and the output of a classifier. Our experiments indicate\n improvement in the causal relationships measured when the area of the object of\n interest per class is indicated by a mask from an explainable method than when\n it is indicated by human annotators. Hence the chosen name of Causal\n Explanation Score (CaES)",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/9704056",
        "title": "Pseudoscalar Conversion and Gamma-Rays from Supernovae",
        "abstract": "A light pseudoscalar coupled to two photons would be copiously emitted by the\n core of a supernova and part of this flux would be converted to gamma-rays by\n the galactic magnetic field. Measurements on the SN1987A gamma-ray flux by the\n Gamma-Ray Spectrometer on the Solar Maximum Mission satellite imply stringents\n bounds on such process. The improved generation of satellite-borne detectors,\n like EGRET or the projegeneration of satellite-borne detectors, like EGRET or\n the project GLAST, could be able to detect a pseudoscalar-to-photon signal from\n a nearby supernova.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2006.02794",
        "title": "Generalized Ordered Set Partitions",
        "abstract": "In this paper, we consider ordered set partitions obtained by imposing\n conditions on the size of the lists, and such that the first $r$ elements are\n in distinct blocks, respectively. We introduce a generalization of the Lah\n numbers. For this new combinatorial sequence we derive its exponential\n generating function, some recurrence relations, and combinatorial identities.\n We prove and present results using combinatorial arguments, generating\n functions, the symbolic method and Riordan arrays. For some specific cases we\n provide a combinatorial interpretation for the inverse matrix of the\n generalized Lah numbers by means of two families of posets.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1302.0703",
        "title": "Two Particle-Hole Excitations in Charged Current Quasielastic\n  Antineutrino--Nucleus Scattering",
        "abstract": "We evaluate the quasielastic and multinucleon contributions to the\n antineutrino nucleus scattering cross section and compare our results with the\n recent MiniBooNE data. We use a local Fermi gas model that includes RPA\n correlations and gets the multinucleon part from a systematic many body\n expansion of the $W$ boson selfenergy in the nuclear medium. The same model had\n been quite successful for the neutrino cross section and contains no new\n parameters. We have also analysed the relevance of 2p2h events for the\n antineutrino energy reconstruction.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.05887",
        "title": "Bottleneck Matching in the Plane",
        "abstract": "We present an algorithm for computing a bottleneck matching in a set of\n $n=2\\ell$ points in the plane, which runs in $O(n^{\\omega/2}\\log n)$\n deterministic time, where $\\omega\\approx 2.37$ is the exponent of matrix\n multiplication.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1711.01582",
        "title": "A symmetrizable extension of polyconvex thermoelasticity and\n  applications to zero-viscosity limits and weak-strong uniqueness",
        "abstract": "We embed the equations of polyconvex thermoviscoelasticity into an augmented,\n symmetrizable, hyperbolic system and derive a relative entropy identity in the\n extended variables. Following the relative entropy formulation, we prove the\n convergence from thermoviscoelasticity with Newtonian viscosity and Fourier\n heat conduction to smooth solutions of the system of adiabatic thermoelasticity\n as both parameters tend to zero. Also, convergence from thermoviscoelasticity\n to smooth solutions of thermoelasticity in the zero-viscosity limit. Finally,\n we establish a weak-strong uniqueness result for the equations of adiabatic\n thermoelasticity in the class of entropy weak solutions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2204.13553",
        "title": "A Synthetic Roman Space Telescope High-Latitude Time-Domain Survey:\n  Supernovae in the Deep Field",
        "abstract": "NASA will launch the Nancy Grace Roman Space Telescope (Roman) in the second\n half of this decade, which will allow for a generation-defining measurement of\n dark energy through multiple probes, including Type Ia supernovae (SNe Ia). To\n improve decisions on survey strategy, we have created the first simulations of\n realistic Roman images that include artificial SNe Ia injected as point sources\n in the images. Our analysis combines work done on Roman simulations for weak\n gravitational lensing studies as well as catalog-level simulations of SN\n samples. We have created a time series of images over two years containing\n $\\sim$ 1,050 SNe Ia, covering a 1 square degree subarea of a planned 5 square\n degree deep survey. We have released these images publicly for community use\n along with input catalogs of all injected sources. We create secondary products\n from these images by generating coadded images and demonstrating recovery of\n transient sources using image subtraction. We perform first-use analyses on\n these images in order to measure galaxy-detection efficiency, point\n source-detection efficiency, and host-galaxy association biases. The simulated\n images can be found here:\n https://roman.ipac.caltech.edu/sims/SN_Survey_Image_sim.html.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/math/0612795",
        "title": "Locality of continuous Hamiltonian flows and Lagrangian intersections\n  with the conormal of open subsets",
        "abstract": "In this paper, we prove that if a continuous Hamiltonian flow fixes the\n points in an open subset $U$ of a symplectic manifold $(M,\\omega)$, then its\n associated Hamiltonian is constant at each moment on $U$. As a corollary, we\n prove that the Hamiltonian of compactly supported continuous Hamiltonian flows\n is unique both on a compact $M$ with smooth boundary $\\del M$ and on a\n non-compact manifold bounded at infinity. An essential tool for the proof of\n the locality is the Lagrangian intersection theorem for the conormals of open\n subsets proven by Kasturirangan and the author, combined with Viterbo's scheme\n that he introduced in the proof of uniqueness of the Hamiltonian on a closed\n manifold \\cite{viterbo2}. We also prove the converse of the theorem which\n localizes a previously known global result in symplectic topology.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.05908",
        "title": "The Temporal and Spatial Behaviors of CME Occurrence Rate at Different\n  Latitudes",
        "abstract": "The statistical study of the Coronal Mass Ejections (CMEs) is a hot topic in\n solar physics. To further reveal the temporal and spatial behaviors of the CMEs\n at different latitudes and heights, we analyzed the correlation and phase\n relationships between the occurrence rate of CMEs, the Coronal Brightness Index\n (CBI), and the 10.7-cm solar radio flux (F10.7). We found that the occurrence\n rate of the CMEs correlates with CBI relatively stronger at high latitudes\n (>=60) than at low latitudes (<=50). At low latitudes, the occurrence rate of\n the CMEs correlates relatively weaker with CBI than F10.7. There is a\n relatively stronger correlation relationship between CMEs, F10.7, and CBI\n during Solar Cycle 24(SC24) than Solar Cycle 23 (SC23). During SC23, the\n high-latitude CME occurrence rate lags behind F10.7 by three months, and during\n SC24, the low-latitude CME occurrence rate leads to the low-latitude CBI by one\n month. The correlation coefficient values turn out to be larger when the very\n faint CMEsare removed from the samples of the CDAW catalog. Based on our\n results, we may speculate that the source regions of the high/low-latitude CMEs\n may vary in height, and the process of magnetic energy accumulation and\n dissipation is from the lower to the upper atmosphere of the Sun. The temporal\n offsets between different indicators could help us better understand the\n physical processes responsible for the solar-terrestrial interactions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0407610",
        "title": "Dynamical Mass Estimates for Two Luminous Young Stellar Clusters in\n  Messier 83",
        "abstract": "Using new data from the UVES spectrograph on the ESO Very Large Telescope and\n archive images from the Hubble Space Telescope, we have measured projected\n velocity dispersions and structural parameters for two bright young star\n clusters in the nearby spiral galaxy NGC 5236. One cluster is located near the\n nuclear starburst of NGC 5236, at a projected distance of 440 pc from the\n centre, while the other is located in the disk of the galaxy at a projected\n galactocentric distance of 2.3 kpc. We estimate virial masses for the two\n clusters of (4.2+/-0.7)x10^5 Msun and (5.2+/-0.8)x10^5 Msun and ages (from\n broad-band photometry) of 10^(7.1+/-0.2} years and 10^(8.0+/-0.1) years,\n respectively. Comparing the observed mass-to-light (M/L) ratios with simple\n stellar population models, we find that the data for both clusters are\n consistent with a Kroupa-type stellar mass function (MF). In particular, we\n rule out any MF with a significantly lower M/L ratio than the Kroupa MF, such\n as a Salpeter-like MF truncated at a mass of 1 Msun or higher. These clusters\n provide a good illustration of the fact that massive, globular cluster-like\n objects (\"super star clusters\") can form at the present epoch even in the disks\n of seemingly normal, undisturbed spiral galaxies.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.00604",
        "title": "Monaural Speech Enhancement using Deep Neural Networks by Maximizing a\n  Short-Time Objective Intelligibility Measure",
        "abstract": "In this paper we propose a Deep Neural Network (DNN) based Speech Enhancement\n (SE) system that is designed to maximize an approximation of the Short-Time\n Objective Intelligibility (STOI) measure. We formalize an approximate-STOI cost\n function and derive analytical expressions for the gradients required for DNN\n training and show that these gradients have desirable properties when used\n together with gradient based optimization techniques. We show through\n simulation experiments that the proposed SE system achieves large improvements\n in estimated speech intelligibility, when tested on matched and unmatched\n natural noise types, at multiple signal-to-noise ratios. Furthermore, we show\n that the SE system, when trained using an approximate-STOI cost function\n performs on par with a system trained with a mean square error cost applied to\n short-time temporal envelopes. Finally, we show that the proposed SE system\n performs on par with a traditional DNN based Short-Time Spectral Amplitude\n (STSA) SE system in terms of estimated speech intelligibility. These results\n are important because they suggest that traditional DNN based STSA SE systems\n might be optimal in terms of estimated speech intelligibility.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.14042",
        "title": "Pressure-dependent structure of BaZrO$_3$ crystals as determined by\n  Raman Spectroscopy",
        "abstract": "The structure of dielectric perovskite BaZrO$_3$, long known to be cubic at\n room temperature without any structural phase transition with variation of\n temperature, has been recently disputed to have different ground state\n structures with lower symmetries involving octahedra rotation. The\n pressure-dependent Raman scattering measurements can identify the hierarchy of\n energetically-adjacent polymorphs, helping in turn understand its ground state\n structure at atmospheric pressure. Here, Raman scattering spectra of\n high-quality BaZrO$_3$ single crystals grown by the optical floating zone\n method are investigated in a pressure range from 1 atm to 42 GPa. First, based\n on the analyses of the infrared and Raman spectra measured at the atmosphere,\n it is found that all observed vibrational modes can be assigned according to\n the cubic $Pm\\bar{3}m$ structure. In addition, by applying pressure, two\n structural phase transitions are found at 8.4 and 19.2 GPa, one from the cubic\n to the rhombohedral $R\\bar{3}c$ phase and the other from the rhombohedral to\n the tetragonal $I4/mcm$ phase. Based on the two pressure-induced structural\n phase transitions, the true ground state structure of BaZrO$_3$ at room\n temperature and ambient pressure is corroborated to be cubic while the\n rhombohedral phase is the closest second.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0905.2411",
        "title": "Color Distributions, Number and Mass Densities of Massive Galaxies at\n  1.5 < z < 3: Comparing Observations with Merger Simulations",
        "abstract": "We present a comparison between the observed color distribution, number and\n mass density of massive galaxies at 1.5 < z < 3 and a model by Hopkins et al.\n that relates the quasar and galaxy population on the basis of gas-rich mergers.\n In order to test the hypothesis that quiescent red galaxies are formed after a\n gas-rich merger involving quasar activity, we confront photometry of massive (M\n > 4x10^10 Msun) galaxies extracted from the FIRES, GOODS-South, and MUSYC\n surveys, together spanning an area of 496 arcmin^2, with synthetic photometry\n from hydrodynamical merger simulations. As in the Hopkins et al. (2006b) model,\n we use the observed quasar luminosity function to estimate the merger rate. We\n find that the synthetic U-V and V-J colors of galaxies that had a quasar phase\n in their past match the colors of observed galaxies that are best characterized\n by a quiescent stellar population. At z ~ 2.6, the observed number and mass\n density of quiescent red galaxies with M > 4x10^10 Msun is consistent with the\n model in which every quiescent massive galaxy underwent a quasar phase in the\n past. At z ~ 1.9, 2.8 times less quiescent galaxies are observed than predicted\n by the model as descendants of higher redshift quasars. The merger model also\n predicts a large number of galaxies undergoing merger-driven star formation. We\n find that the predicted number and mass density accounts for 30-50% of the\n observed massive star-forming galaxies. However, their colors do not match\n those of observed star-forming galaxies. In particular, the colors of dusty red\n galaxies are not reproduced by the simulations. Several possible origins of\n this discrepancy are discussed. The observational constraints on the validity\n of the model are currently limited by cosmic variance and uncertainties in\n stellar population synthesis and radiative transfer.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1701.05379",
        "title": "ALPs Effective Field Theory and Collider Signatures",
        "abstract": "We study the leading effective interactions between the Standard Model fields\n and a generic singlet CP-odd (pseudo)Goldstone boson. Two possible frameworks\n for electroweak symmetry breaking are considered: linear and non-linear. For\n the latter case, the basis of leading effective operators is determined and\n compared with that for the linear expansion. Associated phenomenological\n signals at colliders are explored for both scenarios, deriving new bounds and\n analyzing future prospects, including LHC and High Luminosity LHC\n sensitivities. Mono-$Z$, mono-$W$, $W$-photon plus missing energy and on-shell\n top final states are most promising signals expected in both frameworks. In\n addition, non-standard Higgs decays and mono-Higgs signatures are especially\n prominent and expected to be dominant in non-linear realizations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1904.01127",
        "title": "Cyberthreat Detection from Twitter using Deep Neural Networks",
        "abstract": "To be prepared against cyberattacks, most organizations resort to security\n information and event management systems to monitor their infrastructures.\n These systems depend on the timeliness and relevance of the latest updates,\n patches and threats provided by cyberthreat intelligence feeds. Open source\n intelligence platforms, namely social media networks such as Twitter, are\n capable of aggregating a vast amount of cybersecurity-related sources. To\n process such information streams, we require scalable and efficient tools\n capable of identifying and summarizing relevant information for specified\n assets. This paper presents the processing pipeline of a novel tool that uses\n deep neural networks to process cybersecurity information received from\n Twitter. A convolutional neural network identifies tweets containing\n security-related information relevant to assets in an IT infrastructure. Then,\n a bidirectional long short-term memory network extracts named entities from\n these tweets to form a security alert or to fill an indicator of compromise.\n The proposed pipeline achieves an average 94% true positive rate and 91% true\n negative rate for the classification task and an average F1-score of 92% for\n the named entity recognition task, across three case study infrastructures.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1805.08697",
        "title": "Cepheids in Eclipsing Binaries. What and How We Can Learn About Them",
        "abstract": "Eclipsing binary systems with pulsating components offer a unique possibility\n to accurately measure the most important parameters of pulsating stars, to\n study their evolution, and to test the pulsation theory. I will show what we\n can learn about the pulsating stars from the analysis of such systems and how\n we can do it. Special attention will be paid to the mass, radius, p-factor, and\n distance determination. Although the core of the method is based on the\n observations of double-lined eclipsing spectroscopic binaries, with the help of\n the pulsation theory, it is possible to measure absolute parameters for\n single-lined binaries also.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.15489",
        "title": "A Flexible Cryptographic Infrastructure for High-security SDR-based\n  Systems",
        "abstract": "Military software defined radio (SDR) systems are a major factor in future\n network-centric operations due to their flexibility and support for more\n capable radio communications systems. The inherent nature of software-based\n systems requires a more complex auxiliary infrastructure and multiple\n independent levels of security compared with typical systems: Secure booting of\n the SDR device, cryptographically signed software, real time operating platform\n software as well as radio applications. This technology raises new challenges\n with respect to the management. The largest impact on SDR deployments is due to\n the auxiliary cryptographic infrastructure for the security of the software\n life cycle and the cyclic update of the keys. Compared to conventional radio\n devices, the SDR system with the cryptographic infrastructure described in this\n paper reaches a higher security level and is more flexible. The advantage is\n the possibility to deploy trunked radio system and further waveforms, such as\n coalition wideband, which will be standardized in the future. Also it is\n possible to update cryptographic mechanisms. In this work, we analyze the\n requirements for a high secure SDR deployment and model the life cycle of the\n components of a deployed SDR node based on the Joint Program Executive Office\n (JPEO) Software Communication Architecture (SCA).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1410.7441",
        "title": "Diagonality and idempotents with applications to problems in operator\n  theory and frame theory",
        "abstract": "We prove that a nonzero idempotent is zero-diagonal if and only if it is not\n a Hilbert-Schmidt perturbation of a projection, along with other useful\n equivalences. Zero-diagonal operators are those whose diagonal entries are\n identically zero in some basis.\n  We also prove that any bounded sequence appears as the diagonal of some\n idempotent operator, thereby providing a characterization of inner products of\n dual frame pairs in infinite dimensions. Furthermore, we show that any\n absolutely summable sequence whose sum is a positive integer appears as the\n diagonal of a finite rank idempotent.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.02572",
        "title": "Artificial intelligence real-time prediction and physical interpretation\n  of atomic binding energies in nano-scale metal clusters",
        "abstract": "Single atomic sites often determine the functionality and performance of\n materials, such as catalysts, semi-conductors or enzymes. Computing and\n understanding the properties of such sites is therefore a crucial component of\n the rational materials design process. Because of complex electronic effects at\n the atomic level, atomic site properties are conventionally derived from\n computationally expensive first-principle calculations, as this level of theory\n is required to achieve relevant accuracy. In this study, we present a widely\n applicable machine learning (ML) approach to compute atomic site properties\n with high accuracy in real time. The approach works well for complex\n non-crystalline atomic structures and therefore opens up the possibility for\n high-throughput screenings of nano-materials, amorphous systems and materials\n interfaces. Our approach includes a robust featurization scheme to transform\n atomic structures into features which can be used by common machine learning\n models. Performing a genetic algorithm (GA) based feature selection, we show\n how to establish an intuitive physical interpretation of the structure-property\n relations implied by the ML models. With this approach, we compute atomic site\n stabilities of metal nanoparticles ranging from 3-55 atoms with mean absolute\n errors in the range of 0.11-0.14 eV in real time. We also establish the\n chemical identity of the site as most important factor in determining atomic\n site stabilities, followed by structural features like bond distances and\n angles. Both, the featurization and GA feature selection functionality are\n published in open-source python modules. With this method, we enable the\n efficient rational design of highly specialized real-world nano-catalysts\n through data-driven materials screening.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0507176",
        "title": "Simulating field-aligned diffusion of a cosmic ray gas",
        "abstract": "The macroscopic behaviour of cosmic rays in turbulent magnetic fields is\n discussed. An implementation of anisotropic diffusion of cosmic rays with\n respect to the magnetic field in a non-conservative, high-order,\n finite-difference magnetohydrodynamic code is discussed. It is shown that the\n standard implementation fails near singular X-points of the magnetic field,\n which are common if the field is random. A modification to the diffusion model\n for cosmic rays is described and the resulting telegraph equation (implemented\n by solving a dynamic equation for the diffusive flux of cosmic rays) is used;\n it is argued that this modification may better describe the physics of cosmic\n ray diffusion. The present model reproduces several processes important for the\n propagation and local confinement of cosmic rays, including spreading\n perpendicular to the local large-scale magnetic field, controlled by the\n random-to-total magnetic field ratio, and the balance between cosmic ray\n pressure and magnetic tension. Cosmic ray diffusion is discussed in the context\n of a random magnetic field produced by turbulent dynamo action. It is argued\n that energy equipartition between cosmic rays and other constituents of the\n interstellar medium do not necessarily imply that cosmic rays play a\n significant role in the balance of forces.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1207.5442",
        "title": "Security Analysis of a Password-Based Authentication Protocol Proposed\n  to IEEE 1363",
        "abstract": "In recent years, several protocols for password-based authenticated key\n exchange have been proposed. These protocols aim to be secure even though the\n sample space of passwords may be small enough to be enumerated by an off-line\n adversary. In Eurocrypt 2000, Bellare, Pointcheval and Rogaway (BPR) presented\n a model and security definition for authenticated key exchange. They claimed\n that in the ideal-cipher model (random oracles), the two-flow protocol at the\n core of Encrypted Key Exchange (EKE) is secure. Bellare and Rogaway suggested\n several instantiations of the ideal cipher in their proposal to the IEEE\n P1363.2 working group. Since then there has been an increased interest in\n proving the security of password-based protocols in the ideal-cipher model. For\n example, Bresson, Chevassut, and Pointcheval have recently showed that the\n One-Encryption-Key-Exchange (OEKE) protocol is secure in the ideal cipher\n model. In this paper, we present examples of real (NOT ideal) ciphers\n (including naive implementations of the instantiations proposed to IEEE\n P1363.2) that would result in broken instantiations of the idealised AuthA\n protocol and OEKE protocol. Our result shows that the AuthA protocol can be\n instantiated in an insecure way, and that there are no well defined (let alone\n rigorous) ways to distinguish between secure and insecure instantiations. Thus,\n without a rigorous metric for ideal-ciphers, the value of provable security in\n ideal cipher model is limited.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2012.13958",
        "title": "Impurities in systems of noninteracting trapped fermions",
        "abstract": "We study the properties of spin-less non-interacting fermions trapped in a\n confining potential in one dimension but in the presence of one or more\n impurities which are modelled by delta function potentials. We use a method\n based on the single particle Green's function. For a single impurity placed in\n the bulk, we compute the density of the Fermi gas near the impurity. Our\n results, in addition to recovering the Friedel oscillations at large distance\n from the impurity, allow the exact computation of the density at short\n distances. We also show how the density of the Fermi gas is modified when the\n impurity is placed near the edge of the trap in the region where the\n unperturbed system is described by the Airy gas. Our method also allows us to\n compute the effective potential felt by the impurity both in the bulk and at\n the edge. In the bulk this effective potential is shown to be a universal\n function only of the local Fermi wave vector, or equivalently of the local\n fermion density. When the impurity is placed near the edge of the Fermi gas,\n the effective potential can be expressed in terms of Airy functions. For an\n attractive impurity placed far outside the support of the fermion density, we\n show that an interesting transition occurs where a single fermion is pulled out\n of the Fermi sea and forms a bound state with the impurity. This is a quantum\n analogue of the well-known Baik-Ben Arous-P\\'ech\\'e (BBP) transition, known in\n the theory of spiked random matrices. The density at the location of the\n impurity plays the role of an order parameter. We also consider the case of two\n impurities in the bulk and compute exactly the effective force between them\n mediated by the background Fermi gas.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2210.11098",
        "title": "The definable content of homological invariants II: \\v{C}ech cohomology\n  and homotopy classification",
        "abstract": "This is the second installment in a series of papers applying descriptive set\n theoretic techniques to both analyze and enrich classical functors from\n homological algebra and algebraic topology. In it, we show that the \\v{C}ech\n cohomology functors $\\check{\\mathrm{H}}^n$ on the category of locally compact\n separable metric spaces each factor into (i) what we term their definable\n version, a functor $\\check{\\mathrm{H}}^n_{\\mathrm{def}}$ taking values in the\n category $\\mathsf{GPC}$ of groups with a Polish cover (a category first\n introduced in this work's predecessor), followed by (ii) a forgetful functor\n from $\\mathsf{GPC}$ to the category of groups. These definable cohomology\n functors powerfully refine their classical counterparts: we show that they are\n complete invariants, for example, of the homotopy types of mapping telescopes\n of $d$-spheres or $d$-tori for any $d\\geq 1$, and, in contrast, that there\n exist uncountable families of pairwise homotopy inequivalent mapping telescopes\n of either sort on which the classical cohomology functors are constant. We then\n apply the functors $\\check{\\mathrm{H}}^n_{\\mathrm{def}}$ to show that a seminal\n problem in the development of algebraic topology, namely Borsuk and Eilenberg's\n 1936 problem of classifying, up to homotopy, the maps from a solenoid\n complement $S^3\\backslash\\Sigma$ to the $2$-sphere, is essentially hyperfinite\n but not smooth.\n  In the course of this work, we record Borel definable versions of a number of\n classical results bearing on both the combinatorial and homotopical\n formulations of \\v{C}ech cohomology; in aggregate, this work may be regarded as\n laying foundations for the descriptive set theoretic study of the homotopy\n relation on the space of maps from a locally compact Polish space to a\n polyhedron, a relation which embodies a substantial variety of classification\n problems arising throughout mathematics.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.13486",
        "title": "Hardness of almost embedding simplicial complexes in $\\mathbb{R}^d$, II",
        "abstract": "A map $f: K \\to \\mathbb{R}^d$ of a simplicial complex is an almost embedding\n if $f(\\sigma) \\cap f(\\tau) = \\varnothing$ whenever $\\sigma, \\tau$ are disjoint\n simplices of $K$. Fix integers $d,k \\geqslant 2$ such that $k+2 \\leqslant d\n \\leqslant\\frac{3k}2+1$. Assuming that the \"preimage of a cycle is a cycle\" we\n prove $\\mathbf{NP}$-hardness of the algorithmic problem of recognition of\n almost embeddability of finite $k$-dimensional complexes in $\\mathbb{R}^d$.\n Assuming that $\\mathbf{P} \\ne \\mathbf{NP}$ (and that the \"preimage of a cycle\n is a cycle\") we prove that the embedding obstruction is incomplete for\n $k$-dimensional complexes in $\\mathbb{R}^d$ using configuration spaces. Our\n proof generalizes the Skopenkov-Tancer proof of this result for $d =\n \\frac{3k}{2} + 1$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1912.01471",
        "title": "Exploring Supersymmetric CP Violation after LHC Run 2 with Electric\n  Dipole Moments and B Observables",
        "abstract": "We consider the prospects for measuring distinctive signatures of the\n CP-violating phases in the minimal supersymmetric extension of the Standard\n Model (MSSM) in light of the limits on sparticle masses from searches at the\n LHC. We use the CPsuperH code to evaluate model predictions and scan the\n parameter space using a geometric approach that maximizes CP-violating\n observables subject to the current upper limits on electric dipole moments\n (EDMs). We focus on the possible CP-violating asymmetry $A_{\\rm CP}$ in $b \\to\n s \\gamma$ decay and on a possible CP-violating contribution to the $B_s -\n \\overline{B}_s$ mass difference $\\Delta M^{NP}_{B_s}$, as well as future\n measurements of the EDMs of the proton, neutron and electron. We find that the\n current LHC and EDM limits are consistent with values of $A_{\\rm CP}$, $\\Delta\n M^{NP}_{B_s}$ and the proton EDM that are measurable with the Belle-II\n detector, LHCb and a proposed measurement of the proton EDM using a storage\n ring, respectively. Measurement of a non-zero proton EDM would constrain\n $A_{\\rm CP}$ significantly, but it and a CP-violating contribution to $\\Delta\n M^{NP}_{B_s}$ could still be measurable, along with neutron and electron EDMs.\n A more accurate measurement of $A_{\\rm CP}$ with the current central value\n would favour stop and chargino masses within reach of future LHC runs as well\n as a potentially measurable value of $\\Delta M^{NP}_{B_s}$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0605097",
        "title": "Decoherence and Quantum Walks: anomalous diffusion and ballistic tails",
        "abstract": "The common perception is that strong coupling to the environment will always\n render the evolution of the system density matrix quasi-classical (in fact,\n diffusive) in the long time limit. We present here a counter-example, in which\n a particle makes quantum transitions between the sites of a d-dimensional\n hypercubic lattice whilst strongly coupled to a bath of two-level systems which\n  'record' the transitions. The long-time evolution of an initial wave packet\n is found to be most unusual: the mean square displacement of the particle\n density matrix shows long-range ballitic behaviour, but simultaneously a kind\n of weakly-localised behaviour near the origin. This result may have important\n implications for the design of quantum computing algorithms, since it describes\n a class of quantum walks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2106.04857",
        "title": "Positivity of the Poincar\\'e bundle on the moduli space of vector\n  bundles and its applications",
        "abstract": "We prove that the normalized Poincar\\'e bundle on the moduli space of stable\n rank $r$ vector bundles with a fixed determinant on a smooth projective curve\n $X$ induces a family of nef vector bundles on the moduli space. Two\n applications follow. We show that when the genus of $X$ is large, the derived\n category of $X$ is embedded into the derived category of the moduli space for\n arbitrary rank and coprime degree, which extends the results of Narasimhan,\n Fonarev-Kuznetsov, and Belmans-Mukhopadhyay. As the second application, we\n construct a family of ACM bundles on the moduli space. A key ingredient of our\n proof is the investigation of birational geometry of the moduli spaces of\n parabolic bundles.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0809.3081",
        "title": "Undetermined states: how to find them and their applications",
        "abstract": "We investigate the undetermined sets consisting of two-level, multi-partite\n pure quantum states, whose reduced density matrices give absolutely no\n information of their original states. Two approached of finding these quantum\n states are proposed. One is to establish the relation between codewords of the\n stabilizer quantum error correction codes (SQECCs) and the undetermined states.\n The other is to study the local complementation rules of the graph states. As\n an application, the undetermined states can be exploited in the quantum secret\n sharing scheme. The security is guaranteed by their undetermineness.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.02671",
        "title": "On the convergence of conditional gradient method for unbounded\n  multiobjective optimization problems",
        "abstract": "This paper focuses on developing a conditional gradient algorithm for\n multiobjective optimization problems with an unbounded feasible region. We\n employ the concept of recession cone to establish the well-defined nature of\n the algorithm. The asymptotic convergence property and the iteration-complexity\n bound are established under mild assumptions. Numerical examples are provided\n to verify the algorithmic performance.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.08092",
        "title": "Bayesian Mixture Modelling with Ranked Set Samples",
        "abstract": "We consider the Bayesian estimation of the parameters of a finite mixture\n model from independent order statistics arising from imperfect ranked set\n sampling designs. As a cost-effective method, ranked set sampling enables us to\n incorporate easily attainable characteristics, as ranking information, into\n data collection and Bayesian estimation. To handle the special structure of the\n ranked set samples, we develop a Bayesian estimation approach exploiting the\n Expectation-Maximization (EM) algorithm in estimating the ranking parameters\n and Metropolis within Gibbs Sampling to estimate the parameters of the\n underlying mixture model. Our findings show that the proposed RSS-based\n Bayesian estimation method outperforms the commonly used Bayesian counterpart\n using simple random sampling. The developed method is finally applied to\n estimate the bone disorder status of women aged 50 and older.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1502.01504",
        "title": "Feedback based Reputation on top of the Bitcoin Blockchain",
        "abstract": "The ability to assess the reputation of a member in a web community is a need\n addressed in many different ways according to the many different stages in\n which the nature of communities has evolved over time. In the case of\n reputation of goods/services suppliers, the solutions available to prevent the\n feedback abuse are generally reliable but centralized under the control of few\n big Internet companies. In this paper we show how a decentralized and\n distributed feedback management system can be built on top of the Bitcoin\n blockchain",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/9505072",
        "title": "Self-Similarity and Localization",
        "abstract": "The localized eigenstates of the Harper equation exhibit universal\n self-similar fluctuations once the exponentially decaying part of a wave\n function is factorized out. For a fixed quantum state, we show that the whole\n localized phase is characterized by a single strong coupling fixed point of the\n renormalization equations. This fixed point also describes the generalized\n Harper model with next nearest neighbor interaction below a certain threshold.\n Above the threshold, the fluctuations in the generalized Harper model are\n described by a strange invariant set of the renormalization equations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1001.4244",
        "title": "A centerless representation of the Virasoro algebra associated with the\n  unitary circular ensemble",
        "abstract": "We consider the 2-dimensional Toda lattice tau functions\n $\\tau_n(t,s;\\eta,\\theta)$ deforming the probabilities $\\tau_n(\\eta,\\theta)$\n that a randomly chosen matrix from the unitary group U(n), for the Haar\n measure, has no eigenvalues within an arc $(\\eta,\\theta)$ of the unit circle.\n We show that these tau functions satisfy a centerless Virasoro algebra of\n constraints, with a boundary part in the sense of Adler, Shiota and van\n Moerbeke. As an application, we obtain a new derivation of a differential\n equation due to Tracy and Widom, satisfied by these probabilities, linking it\n to the Painleve VI equation.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0610477",
        "title": "Reconstructing compositions",
        "abstract": "We consider the problem of reconstructing compositions of an integer from\n their subcompositions, which was raised by Raykova (albeit disguised as a\n question about layered permutations). We show that every composition w of n\\ge\n 3k+1 can be reconstructed from its set of k-deletions, i.e., the set of all\n compositions of n-k contained in w. As there are compositions of 3k with the\n same set of k-deletions, this result is best possible.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2110.04471",
        "title": "Provably Efficient Black-Box Action Poisoning Attacks Against\n  Reinforcement Learning",
        "abstract": "Due to the broad range of applications of reinforcement learning (RL),\n understanding the effects of adversarial attacks against RL model is essential\n for the safe applications of this model. Prior theoretical works on adversarial\n attacks against RL mainly focus on either observation poisoning attacks or\n environment poisoning attacks. In this paper, we introduce a new class of\n attacks named action poisoning attacks, where an adversary can change the\n action signal selected by the agent. Compared with existing attack models, the\n attacker's ability in the proposed action poisoning attack model is more\n restricted, which brings some design challenges. We study the action poisoning\n attack in both white-box and black-box settings. We introduce an adaptive\n attack scheme called LCB-H, which works for most RL agents in the black-box\n setting. We prove that the LCB-H attack can force any efficient RL agent, whose\n dynamic regret scales sublinearly with the total number of steps taken, to\n choose actions according to a policy selected by the attacker very frequently,\n with only sublinear cost. In addition, we apply LCB-H attack against a popular\n model-free RL algorithm: UCB-H. We show that, even in the black-box setting, by\n spending only logarithm cost, the proposed LCB-H attack scheme can force the\n UCB-H agent to choose actions according to the policy selected by the attacker\n very frequently.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1711.03250",
        "title": "Switchable Ferroelectric Photovoltaic Effects in Epitaxial Thin Films of\n  h-RFeO3 having Narrow Optical Band Gaps",
        "abstract": "Ferroelectric photovoltaics (FPVs) have drawn much attention owing to their\n high stability, environmental safety, anomalously high photovoltages, coupled\n with reversibly switchable photovoltaic responses. However, FPVs suffer from\n extremely low photocurrents, which is primarily due to their wide band gaps.\n Here, we present a new class of FPVs by demonstrating switchable ferroelectric\n photovoltaic effects using hexagonal ferrite (h-RFeO3) thin films having narrow\n band gaps of ~1.2 eV, where R denotes rare-earth ions. FPVs with narrow band\n gaps suggests their potential applicability as photovoltaic and optoelectronic\n devices. The h-RFeO3 films further exhibit reasonably large ferroelectric\n polarizations, which possibly reduces a rapid recombination rate of the\n photo-generated electron-hole pairs. The power conversion efficiency (PCE) of\n h-RFeO3 thin-film devices is sensitive on the magnitude of polarization. In the\n case of h-TmFeO3 (h-TFO) thin film, the measured PCE is twice as large as that\n of the BiFeO3 thin film, a prototypic FPV. We have further shown that the\n switchable photovoltaic effect dominates over the unswitchable internal field\n effect arising from the net built-in potential. This work thus demonstrates a\n new class of FPVs towards high-efficiency solar cell and optoelectronic\n applications.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1407.8239",
        "title": "Conductance behavior in nanowires with spin-orbit interaction -- A\n  numerical study",
        "abstract": "We consider electronic transport through semiconducting nanowires (W) with\n spin-orbit interaction (SOI), in a hybrid N-W-N setup where the wire is\n contacted by normal-metal leads (N). We investigate the conductance behavior of\n the system as a function of gate and bias voltage, magnetic field, wire length,\n temperature, and disorder. The transport calculations are performed numerically\n and are based on standard recursive Green's function techniques. In particular,\n we are interested in understanding if and how it is possible to deduce the\n strength of the SOI from the transport behavior. This is a very relevant\n question since so far no clear experimental observation in that direction has\n been produced. We find that the smoothness of the electrostatic potential\n profile between the contacts and the wire plays a crucial role, and we show\n that in realistic regimes the N-W-N setup may mask the effects of SOI, and a\n trivial behavior with apparent vanishing SOI is observed. We identify an\n optimal parameter regime, with neither too smooth nor too abrupt potentials,\n where the signature of SOI is best visible, with and without Fabry-Perot\n oscillations, and is most resilient to disorder and temperature effects.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1009.0910",
        "title": "Fundamental solitons in discrete lattices with a delayed nonlinear\n  response",
        "abstract": "The formation of unstaggered localized modes in dynamical lattices can be\n supported by the interplay of discreteness and nonlinearity with a finite\n relaxation time. In rapidly responding nonlinear media, on-site discrete\n solitons are stable, and their broad inter-site counterparts are marginally\n stable, featuring a virtually vanishing real instability eigenvalue. The\n solitons become unstable in the case of the slowly relaxing nonlinearity. The\n character of the instability alters with the increase of the delay time, which\n leads to a change in the dynamics of unstable discrete solitons. They form\n robust localized breathers in rapidly relaxing media, and decay into\n oscillatory diffractive pattern in the lattices with a slow nonlinear response.\n Marginally stable solitons can freely move across the lattice.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.12680",
        "title": "On a universal characterisation of $p$-typical Witt vectors",
        "abstract": "For a prime $p$ and a commutative ring $R$ with unity, let $W(R)$ denote the\n ring of $p$-typical Witt vectors. The ring $W(R)$ is endowed with a\n Verschiebung operator $W(R)\\xrightarrow{V}W(R)$ and a Teichm\\\"{u}ller map\n $R\\xrightarrow{\\langle \\ \\rangle}W(R)$. One of the properties satisfied by $V,\n \\langle \\ \\rangle$ is that the map $R \\to W(R)$ given by $x\\mapsto V\\langle\n x^p\\rangle - p\\langle x \\rangle$ is an additive map. In this paper we show that\n for $p\\neq 2$, this property essentially characterises the functor $W$. Unlike\n other characterisations, this only uses the group structure on $W(R)$ and hence\n is suitable for generalising to the non-commutative setup. We give a\n conjectural characterisation of Hesselholt's functor of $p$-typical Witt\n vectors using a universal property for $p\\neq 2$. Moreover we provide evidence\n for this conjecture.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1602.06019",
        "title": "Unraveling nonadiabatic ionization and Coulomb potential effects in\n  strong-field photoelectron holography",
        "abstract": "Strong field photoelectron holography has been proposed as a means for\n interrogating the spatial and temporal information of electrons and ions in a\n dynamic system. After ionization, part of the electron wave packet may directly\n go to the detector (the reference wave), while another part may be driven back\n to the ion where it scatters off (the signal wave). The interference hologram\n of the two waves may be used to retrieve the target information. However,\n unlike conventional optical holography, the propagations of electron wave\n packets are affected by the Coulomb potential as well as by the laser field. In\n addition, electrons are emitted over the whole laser pulse duration, thus\n multiple interferences may occur. In this work, we used a generalized\n quantum-trajectory Monte Carlo method to investigate the effect of Coulomb\n potential and the nonadiabatic subcycle ionization on the photoelectron\n hologram. We showed that photoelectron hologram can be well described only when\n the nonadiabatic effect in ionization is accounted for, and Coulomb potential\n can be neglected only in the tunnel ionization regime. Our results help\n establishing photoelectron holography for probing spatial and dynamic\n properties of atoms and molecules.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1408.1927",
        "title": "A Search of The Four-Color Theorem and its Higher Dimensional\n  Generalization",
        "abstract": "Four-Color Theorem has secret in its logical proof and actual operating. In\n this paper we will give a proof of Four-Color Theorem based on Kuratowski's\n Theorem using some induction argument and give a description of the most\n complicated coloring map, a simple proof of Kuratowski's Theorem using Euler\n charateristic is also presented. We also conjecture the higher dimensional\n generalization of Four-Color Theorem.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/gr-qc/0412135",
        "title": "Varying Couplings in Electroweak Theory",
        "abstract": "We extend the theory of Kimberly and Magueijo for the spacetime variation of\n the electroweak couplings in the unified Glashow-Salam-Weinberg model of the\n electroweak interaction to include quantum corrections. We derive the effective\n quantum-corrected dilaton evolution equations in the presence of a background\n cosmological matter density that is composed of weakly interacting and\n non-weakly-interacting non-relativistic dark-matter components.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1505.02331",
        "title": "The Atiyah-Bott formula for the cohomology of the moduli space of\n  bundles on a curve",
        "abstract": "This paper is a companion of the paper \"Weil's conjecture for function\n fields\" by J. Lurie and the author. We present a different exposition of\n essentially the same algebro-geometric proof of the Atiyah-Bott for the\n cohomology of Bun(G), which subsequently leads to the proof of the Tamagawa\n number formula for the volume of the automorphic space for function fields.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.06752",
        "title": "High energy nuclear physics meets Machine Learning",
        "abstract": "Though being seemingly disparate and with relatively new intersection, high\n energy nuclear physics and machine learning have already begun to merge and\n yield interesting results during the last few years. It's worthy to raise the\n profile of utilizing this novel mindset from machine learning in high energy\n nuclear physics, to help more interested readers see the breadth of activities\n around this intersection. The aim of this mini-review is to introduce to the\n community the current status and report an overview of applying machine\n learning for high energy nuclear physics, to present from different aspects and\n examples how scientific questions involved in high energy nuclear physics can\n be tackled using machine learning.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2102.06295",
        "title": "Realizations of Isostatic Material Frameworks",
        "abstract": "This paper studies the set of equivalent realizations of isostatic frameworks\n in two dimensions, and algorithms for finding all such realizations. We show\n that an isostatic framework has an even number of equivalent realizations that\n preserve edge lengths and connectivity. We enumerate the complete set of\n equivalent realizations for a toy framework with pinned boundary in two\n dimensions and study the impact of boundary length on the emergence of these\n realizations. To ameliorate the computational complexity of finding a solution\n to a large multivariate quadratic system corresponding to the constraints;\n alternative methods - based on constraint reduction and distance-based covering\n map or Cayley parameterization of the search space - are presented. The\n application of these methods is studied on atomic clusters, a model\n two-dimensional glasses, and jamming.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1911.09664",
        "title": "Time dependence of few-body F\\\"{o}rster interactions among ultracold\n  Rydberg atoms",
        "abstract": "Rubidium Rydberg atoms in either $|m_j|$-sublevel of the $36p_{3/2}$ state\n can exchange energy via Stark-tuned F\\\"{o}rster resonances, including two-,\n three-, and four-body dipole-dipole interactions. Three-body interactions of\n this type were first reported and categorized by Faoro, \\textit{et al.}~[Nat.\\\n Commun.\\ \\textbf{6}, 8173 (2015)] and their Borromean nature was confirmed by\n Tretyakov, \\textit{et al.}~[Phys.\\ Rev.\\ Lett. \\textbf{119}, 173402 (2017)]. We\n report the time dependence of the $N$-body F\\\"{o}rster resonance $N\\times\n 36p_{3/2,|m_j|=1/2}\\rightarrow 36s_{1/2}+37s_{1/2}+(N-2)\\times\n 36p_{3/2,|m_j|=3/2}$, for $N=2,3$, and 4, by measuring the fraction of\n initially excited atoms that end up in the $37s_{1/2}$ state as a function of\n time. The essential features of these interactions are captured in an\n analytical model that includes only the many-body matrix elements and\n neighboring atom distribution. A more sophisticated simulation reveals the\n importance of beyond-nearest-neighbor interactions and of always-resonant\n interactions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1008.0023",
        "title": "Supertropical matrix algebra III: Powers of matrices and generalized\n  eigenspaces",
        "abstract": "We investigate powers of supertropical matrices, with special attention to\n the role of the coefficients of the supertropical characteristic polynomial\n (especially the supertropical trace) in controlling the rank of a power of a\n matrix. This leads to a Jordan-type decomposition of supertropical matrices,\n together with a generalized eigenspace decomposition of a power of an arbitrary\n supertropical matrix.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2107.13539",
        "title": "On square-free and radical factorizations and existence of some divisors",
        "abstract": "We discuss various square-free and radical factorizations and existence of\n some divisors in monoids in the context of: atomicity, ascending chain\n condition for principal ideals, a pre-Schreier property, a greatest common\n divisor property and a greatest common divisor for sets property.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0210322",
        "title": "Connections, local subgroupoids,and a holonomy Lie groupoid of a line\n  bundle gerbe",
        "abstract": "Our main aim is to associate a holonomy Lie groupoid to the connective\n structure of an abelian gerbe. The construction has analogies with a procedure\n for the holonomy Lie groupoid of a foliation, in using a locally Lie groupoid\n and a globalisation procedure. We show that path connections and 2-holonomy on\n line bundles may be formulated using the notion of a connection pair on a\n double category, due to Brown-Spencer, but now formulated in terms of double\n groupoids using the thin fundamental groupoids introduced by\n Caetano-Mackaay-Picken. To obtain a locally Lie groupoid to which globalisation\n applies, we use methods of local subgroupoids as developed by Brown-$\\dot{\\rm\n I}$\\c{c}en-Mucuk.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1703.10642",
        "title": "Deep Neural Network Optimized to Resistive Memory with Nonlinear\n  Current-Voltage Characteristics",
        "abstract": "Artificial Neural Network computation relies on intensive vector-matrix\n multiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array\n showed a feasibility of implementing such operations with high energy\n efficiency, thus there are many works on efficiently utilizing emerging NVM\n crossbar array as analog vector-matrix multiplier. However, its nonlinear I-V\n characteristics restrain critical design parameters, such as the read voltage\n and weight range, resulting in substantial accuracy loss. In this paper,\n instead of optimizing hardware parameters to a given neural network, we propose\n a methodology of reconstructing a neural network itself optimized to resistive\n memory crossbar arrays. To verify the validity of the proposed method, we\n simulated various neural network with MNIST and CIFAR-10 dataset using two\n different specific Resistive Random Access Memory (RRAM) model. Simulation\n results show that our proposed neural network produces significantly higher\n inference accuracies than conventional neural network when the synapse devices\n have nonlinear I-V characteristics.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2103.16065",
        "title": "General local energy-preserving integrators for solving multi-symplectic\n  Hamiltonian PDEs",
        "abstract": "In this paper we propose and investigate a general approach to constructing\n local energy-preserving algorithms which can be of arbitrarily high order in\n time for solving Hamiltonian PDEs. This approach is based on the temporal\n discretization using continuous Runge-Kutta-type methods, and the spatial\n discretization using pseudospectral methods or Gauss--Legendre collocation\n methods. The local energy conservation law of our new schemes is analyzed in\n detail. The effectiveness of the novel local energy-preserving integrators is\n demonstrated by coupled nonlinear Schr\\\"odinger equations and 2D nonlinear\n Schr\\\"odinger equations with external fields. Our new schemes are compared with\n some classical multi-symplectic and symplectic schemes in numerical\n experiments. The numerical results show the remarkable \\emph{long-term}\n behaviour of our new schemes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1411.2520",
        "title": "Local-global compatibility for regular algebraic cuspidal automorphic\n  representation when $\\ell \\neq p$",
        "abstract": "We prove the compatibility of local and global Langlands correspondences for\n $GL_n$ up to semisimplification for the Galois representations constructed by\n Harris-Lan-Taylor-Thorne and Scholze. More precisely, let $r_p(\\pi)$ denote an\n $n$-dimensional $p$-adic representation of the Galois group of a CM field $F$\n attached to a regular algebraic cuspidal automorphic representation $\\pi$ of\n $GL_n(\\mathbb{A}_F)$. We show that the restriction of $r_p(\\pi)$ to the\n decomposition group of a place $v\\nmid p$ of $F$ corresponds up to\n semisimplification to $rec(\\pi_v)$, the image of $\\pi_v$ under the local\n Langlands correspondence. Furthermore, we can show that the monodromy of the\n associated Weil-Deligne representation of $.r_p(\\pi)|_{G_{F_v}}$ is `more\n nilpotent' than the monodromy of $rec(\\pi_v)$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2103.06292",
        "title": "Relative depolarization of the black hole photon ring in GRMHD models of\n  Sgr A* and M87*",
        "abstract": "Using general relativistic magnetohydrodynamic simulations of accreting black\n holes, we show that a suitable subtraction of the linear polarization per pixel\n from total intensity images can enhance the photon ring features. We find that\n the photon ring is typically a factor of $\\simeq 2$ less polarized than the\n rest of the image. This is due to a combination of plasma and general\n relativistic effects, as well as magnetic turbulence. When there are no other\n persistently depolarized image features, adding the subtracted residuals over\n time results in a sharp image of the photon ring. We show that the method works\n well for sample, viable GRMHD models of Sgr A* and M87*, where measurements of\n the photon ring properties would provide new measurements of black hole mass\n and spin, and potentially allow for tests of the \"no-hair\" theorem of general\n relativity.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2003.09473",
        "title": "Exploring the nature and synchronicity of early cluster formation in the\n  Large Magellanic Cloud V: Multiple Populations in ancient Globular Clusters",
        "abstract": "We examine four ancient Large Magellanic Cloud (LMC) globular clusters (GCs)\n for evidence of multiple stellar populations using the Advanced Camera for\n Surveys and Wide Field Camera 3 on the Hubble Space Telescope Programme\n GO-14164. NGC 1466, NGC 1841, and NGC 2257 all show evidence for a redder,\n secondary population along the main-sequence. Reticulum does not show evidence\n for the presence of a redder population, but this GC has the least number of\n stars and Monte Carlo simulations indicate that the sample of main sequence\n stars is too small to robustly infer whether a redder population exists in this\n cluster. The second, redder, population of the other three clusters constitutes\n $\\sim30-40\\%$ of the total population along the main-sequence. This brings the\n total number of ancient LMC GCs with known split or broadened main-sequences to\n five. However, unlike for Hodge 11 and NGC 2210 (see arXiv:1904.01434), none of\n the clusters show evidence for multiple populations in the horizontal branch.\n We also do not find evidence of a second population along the Red Giant Branch\n (RGB).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2103.08171",
        "title": "Stochastic Integrals and Gelfand Integration in Fr\\'echet Spaces",
        "abstract": "We provide a detailed analysis of the Gelfand integral on Fr\\'echet spaces,\n showing among other things a Vitali theorem, dominated convergence and a Fubini\n result. Furthermore, the Gelfand integral commutes with linear operators. The\n Skorohod integral is conveniently expressed in terms of a Gelfand integral on\n Hida distribution space, which forms our prime motivation and example. We\n extend several results of Skorohod integrals to a general class of pathwise\n Gelfand integrals. For example, we provide generalizations of the\n Hida-Malliavin derivative and extend the integration-by-parts formula in\n Malliavin Calculus. A Fubini-result is also shown, based on the commutative\n property of Gelfand integrals with linear operators. Finally, our studies give\n the motivation for two existing definitions of stochastic Volterra integration\n in Hida space.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1309.6168",
        "title": "Lumped Parameter Modeling of a Quantum Optics Circuit and Decisive Test\n  for Time-Symmetric Physics",
        "abstract": "This paper showed how a simple lumped parameter model of a circuit can yield\n correct quantum mechanical predictions of its behavior, even when there is\n quantum entanglement between components of that circuit. It addresses an\n important example, the circuit of the original Bell's Theorem experiments for\n ideal polarizers. Correct predictions emerge from two alternative simple but\n time-symmetric models based on classical Markov Random Field across space time.\n Exact agreement here does not violate Bell's Theorem itself, because the\n interplay between initial and final outcomes in these calculations does not\n fall within the CHSH definition of time forwards causality. Both models raise\n interesting questions for future research. The final section discusses several\n possible directions for following up on these results, both in lumped system\n modeling and in more general approaches. The final section proposed a new\n experiment with three-photon entanglement which could tell us which is true,\n local realistic MRF models and time-symmetric physics, or conventional\n predictions assuming the usual collapse of the wave function. The appendix\n worked out what the conventional predictions would be for the proposed\n experiment, and also gives a simple master equation version of the collapse\n assumption which does not involve metaphysical observers. Section A.4 gives the\n prediction for the new models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2001.09703",
        "title": "Unconstrained Biometric Recognition: Summary of Recent SOCIA Lab.\n  Research",
        "abstract": "The development of biometric recognition solutions able to work in visual\n surveillance conditions, i.e., in unconstrained data acquisition conditions and\n under covert protocols has been motivating growing efforts from the research\n community. Among the various laboratories, schools and research institutes\n concerned about this problem, the SOCIA: Soft Computing and Image Analysis\n Lab., of the University of Beira Interior, Portugal, has been among the most\n active in pursuing disruptive solutions for obtaining such extremely ambitious\n kind of automata. This report summarises the research works published by\n elements of the SOCIA Lab. in the last decade in the scope of biometric\n recognition in unconstrained conditions. The idea is that it can be used as\n basis for someone wishing to entering in this research topic.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1708.04748",
        "title": "When the cookie meets the blockchain: Privacy risks of web payments via\n  cryptocurrencies",
        "abstract": "We show how third-party web trackers can deanonymize users of\n cryptocurrencies. We present two distinct but complementary attacks. On most\n shopping websites, third party trackers receive information about user\n purchases for purposes of advertising and analytics. We show that, if the user\n pays using a cryptocurrency, trackers typically possess enough information\n about the purchase to uniquely identify the transaction on the blockchain, link\n it to the user's cookie, and further to the user's real identity. Our second\n attack shows that if the tracker is able to link two purchases of the same user\n to the blockchain in this manner, it can identify the user's entire cluster of\n addresses and transactions on the blockchain, even if the user employs\n blockchain anonymity techniques such as CoinJoin. The attacks are passive and\n hence can be retroactively applied to past purchases. We discuss several\n mitigations, but none are perfect.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/q-bio/0508039",
        "title": "Stimulus-invariant processing and spectrotemporal reverse correlation in\n  primary auditory cortex",
        "abstract": "The spectrotemporal receptive field (STRF) provides a versatile and\n integrated, spectral and temporal, functional characterization of single cells\n in primary auditory cortex (AI). In this paper, we explore the origin of, and\n relationship between, different ways of measuring and analyzing an STRF. We\n demonstrate that STRFs measured using a spectrotemporally diverse array of\n broadband stimuli -- such as dynamic ripples, spectrotemporally white noise,\n and temporally orthogonal ripple combinations (TORCs) -- are very similar,\n confirming earlier findings that the STRF is a robust linear descriptor of the\n cell. We also present a new deterministic analysis framework that employs the\n Fourier series to describe the spectrotemporal modulations contained in the\n stimuli and responses. Additional insights into the STRF measurements,\n including the nature and interpretation of measurement errors, is presented\n using the Fourier transform, coupled to singular-value decomposition (SVD), and\n variability analyses including bootstrap. The results promote the utility of\n the STRF as a core functional descriptor of neurons in AI.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/quant-ph/0110120",
        "title": "Optimal Evaluation of Generalized Euler Angles with Applications to\n  Classical and Quantum Control",
        "abstract": "Given two linearly independent matrices in $so(3)$, $Z_1$ and $Z_2$, every\n rotation matrix $X_f \\in SO(3)$ can be written as the product of alternate\n elements from the one dimensional subgroups corresponding to $Z_1$ and $Z_2$,\n namely $X_f=e^{Z_1 t_1}e^{Z_2 t_2}e^{Z_1t_3} \\cdot \\cdot \\cdot e^{Z_1t_s}$. The\n parameters $t_i$, $i=1,...,s$ are called {\\it generalized Euler angles}.\n  In this paper, we evaluate the minimum number of factors required for the\n factorization of $X_f \\in SO(3)$, as a function of $X_f$, and provide an\n algorithm to determine the generalized Euler angles explicitly. The results can\n be applied to the bang bang control with minimum number of switches of some\n classical control systems and of two level quantum systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1903.06335",
        "title": "Orthogonal multiple flag varieties of finite type II : even degree case",
        "abstract": "Let $G$ be the split orthogonal group of degree $2n$ over an arbitrary\n infinite field $\\mathbb{F}$ of chararcteristic not $2$. In this paper, we\n classify multiple flag varieties $G/P_1\\times\\cdots\\times G/P_k$ of finite\n type. Here a multiple flag variety is said to be of finite type if it has a\n finite number of $G$-orbits with respect to the diagonal action of $G$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1508.06713",
        "title": "Encoding the Factorisation Calculus",
        "abstract": "Jay and Given-Wilson have recently introduced the Factorisation (or SF-)\n calculus as a minimal fundamental model of intensional computation. It is a\n combinatory calculus containing a special combinator, F, which is able to\n examine the internal structure of its first argument. The calculus is\n significant in that as well as being combinatorially complete it also exhibits\n the property of structural completeness, i.e. it is able to represent any\n function on terms definable using pattern matching on arbitrary normal forms.\n In particular, it admits a term that can decide the structural equality of any\n two arbitrary normal forms.\n  Since SF-calculus is combinatorially complete, it is clearly at least as\n powerful as the more familiar and paradigmatic Turing-powerful computational\n models of Lambda Calculus and Combinatory Logic. Its relationship to these\n models in the converse direction is less obvious, however. Jay and Given-Wilson\n have suggested that SF-calculus is strictly more powerful than the\n aforementioned models, but a detailed study of the connections between these\n models is yet to be undertaken.\n  This paper begins to bridge that gap by presenting a faithful encoding of the\n Factorisation Calculus into the Lambda Calculus preserving both reduction and\n strong normalisation. The existence of such an encoding is a new result. It\n also suggests that there is, in some sense, an equivalence between the former\n model and the latter. We discuss to what extent our result constitutes an\n equivalence by considering it in the context of some previously defined\n frameworks for comparing computational power and expressiveness.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1904.02399",
        "title": "Riemannian Normalizing Flow on Variational Wasserstein Autoencoder for\n  Text Modeling",
        "abstract": "Recurrent Variational Autoencoder has been widely used for language modeling\n and text generation tasks. These models often face a difficult optimization\n problem, also known as the Kullback-Leibler (KL) term vanishing issue, where\n the posterior easily collapses to the prior, and the model will ignore latent\n codes in generative tasks. To address this problem, we introduce an improved\n Wasserstein Variational Autoencoder (WAE) with Riemannian Normalizing Flow\n (RNF) for text modeling. The RNF transforms a latent variable into a space that\n respects the geometric characteristics of input space, which makes posterior\n impossible to collapse to the non-informative prior. The Wasserstein objective\n minimizes the distance between the marginal distribution and the prior directly\n and therefore does not force the posterior to match the prior. Empirical\n experiments show that our model avoids KL vanishing over a range of datasets\n and has better performances in tasks such as language modeling, likelihood\n approximation, and text generation. Through a series of experiments and\n analysis over latent space, we show that our model learns latent distributions\n that respect latent space geometry and is able to generate sentences that are\n more diverse.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2003.01869",
        "title": "Exactly solvable two-terminal heat engine with asymmetric Onsager\n  coefficients: Origin of the power-efficiency bound",
        "abstract": "An engine producing a finite power at the ideal (Carnot) efficiency is a\n dream engine, which is not prohibited by the thermodynamic second law. Some\n years ago, a two-terminal heat engine with {\\em asymmetric} Onsager\n coefficients in the linear response regime was suggested by Benenti, Saito, and\n Casati [Phys. Rev. Lett. {\\bf 106}, 230602 (2011)], as a prototypical system to\n make such a dream come true with non-divergent system parameter values.\n However, such a system has never been realized in spite of many trials. Here,\n we introduce an exactly solvable two-terminal Brownian heat engine with the\n asymmetric Onsager coefficients in the presence of a Lorenz (magnetic) force.\n Nevertheless, we show that the dream engine regime cannot be accessible even\n with the asymmetric Onsager coefficients, due to an instability keeping the\n engine from reaching its steady state. This is consistent with recent trade-off\n relations between the engine power and efficiency, where the (cyclic)\n steady-state condition is implicitly presumed. We conclude that the\n inaccessibility to the dream engine originates from the steady-state constraint\n on the engine.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.08660",
        "title": "Ziv-Zakai-type error bounds for general statistical models",
        "abstract": "I propose Ziv-Zakai-type lower bounds on the Bayesian error for estimating a\n parameter $\\beta:\\Theta \\to \\mathbb R$ when the parameter space $\\Theta$ is\n general and $\\beta(\\theta)$ need not be a linear function of $\\theta$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1704.00128",
        "title": "Bifurcation results for problems with fractional Trudinger-Moser\n  nonlinearity",
        "abstract": "By using a suitable topological argument based on cohomological linking and\n by exploiting a Trudinger-Moser inequality in fractional spaces recently\n obtained, we prove existence of multiple solutions for a problem involving the\n nonlinear fractional laplacian and a related critical exponential nonlinearity.\n This extends results in the literature for the N-Laplacian operator.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1410.5005",
        "title": "Theoretical Calculations for Predicted States of Heavy Quarkonium via\n  Non-Relativistic Frame Work",
        "abstract": "In this paper, we calculate the mass spectra of heavy quarkonium by using\n matrix Numerov's method to make the predictions of F and G states for further\n experiments. The method gives a very reasonable result which is in a good\n agreement with other methods and with recently published theoretical data. From\n the yielded wave functions we calculate the root mean square radius r_ms and\n \\b{eta} coefficients of heavy quarkonium",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.10275",
        "title": "MoRF: Mobile Realistic Fullbody Avatars from a Monocular Video",
        "abstract": "We present a system to create Mobile Realistic Fullbody (MoRF) avatars. MoRF\n avatars are rendered in real-time on mobile devices, learned from monocular\n videos, and have high realism. We use SMPL-X as a proxy geometry and render it\n with DNR (neural texture and image-2-image network). We improve on prior work,\n by overfitting per-frame warping fields in the neural texture space, allowing\n to better align the training signal between different frames. We also refine\n SMPL-X mesh fitting procedure to improve the overall avatar quality. In the\n comparisons to other monocular video-based avatar systems, MoRF avatars achieve\n higher image sharpness and temporal consistency. Participants of our user study\n also preferred avatars generated by MoRF.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2305.08639",
        "title": "Abelian quotients for groups generated by cubed half-twists",
        "abstract": "Below we construct non-cyclic and torsion-free abelian quotients for\n subgroups of braid groups generated by cube powers of half-twists. In the case\n of 3 and 4 strands we compute the abelianization of these groups. Also, we get\n abelianizations of level-3 congruence subgroups of braid groups on 3 and 4\n strands. Moreover, we construct non-cyclic and torsion-free abelian quotients\n for level-3 congruence subgroups of braid groups. The constructions are based\n on the original construction of Dennis Johnson \\cite{DJ}, who computed an\n abelian quotient of the Torelli group.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0207111",
        "title": "Higher dimensional geometries related to fuzzy odd-dimensional spheres",
        "abstract": "We study $SO(m)$ covariant Matrix realizations of $ \\sum_{i=1}^{m} X_i^2 = 1\n $ for even $m$ as candidate fuzzy odd spheres following hep-th/0101001. As for\n the fuzzy four sphere, these Matrix algebras contain more degrees of freedom\n than the sphere itself and the full set of variables has a geometrical\n description in terms of a higher dimensional coset. The fuzzy $S^{2k-1} $ is\n related to a higher dimensional coset $ {SO(2k) \\over U(1) \\times U(k-1)}$.\n These cosets are bundles where base and fibre are hermitian symmetric spaces.\n  The detailed form of the generators and relations for the Matrix algebras\n related to the fuzzy three-spheres suggests Matrix actions which admit the\n fuzzy spheres as solutions. These Matrix actions are compared with the BFSS,\n IKKT and BMN Matrix models as well as some others. The geometry and\n combinatorics of fuzzy odd spheres lead to some remarks on the transverse\n five-brane problem of Matrix theories and the exotic scaling of the entropy of\n 5-branes with the brane number.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2101.07935",
        "title": "A quantitative model for a nanoscale switch accurately predicts thermal\n  actuation behavior",
        "abstract": "Manipulation of temperature can be used to actuate DNA origami nano-hinges\n containing gold nanoparticles. We develop a physical model of this system that\n uses partition function analysis of the interaction between the nano-hinge and\n nanoparticle to predict the probability that the nano-hinge is open at a given\n temperature. The model agrees well with experimental data and predicts\n experimental conditions that allow the actuation temperature of the nano-hinge\n to be tuned over a range of temperatures from $30$${}^{\\circ}\\mathrm{C}$ to\n $45$${}^{\\circ}\\mathrm{C}$. Additionally, the model reveals surprising physical\n constraints on the system. This combination of physical insight and predictive\n potential is likely to inform future designs that integrate nanoparticles into\n dynamic DNA origami structures. Furthermore, our modeling approach could be\n expanded to consider the incorporation, stability, and actuation of other types\n of functional elements or actuation mechanisms integrated into nucleic acid\n devices.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1707.03620",
        "title": "A universe with no ordinal-definable, stationary, co-stationary subset\n  of $\\omega_1$",
        "abstract": "It is shown that the existence of a measurable cardinal is equiconsistent to\n a model of ZFC in which there is no ordinal-definable, stationary, costationary\n subset of $\\omega_1$",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1605.06434",
        "title": "Molecular Dynamics Simulations of Compression-Tension Asymmetry in\n  Plasticity of Fe Nanopillars",
        "abstract": "Tension-compression asymmetry is a notable feature of plasticity in bcc\n single crystals. Recent experiments reveal striking differences in the\n plasticity of bcc nanopillars for tension and compression. Here we present\n results from molecular dynamics simulations of nanopillars of bcc Fe in tension\n and compression. We find that a totally different deformation mechanism applies\n in each cases: dislocation glide in compression and twinning in tension. This\n difference explains experimentally-observed asymmetry in the nanopillar\n morphology.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0906.4488",
        "title": "Search for 14.4 keV solar axions emitted in the M1-transition of 57Fe\n  nuclei with CAST",
        "abstract": "We have searched for 14.4 keV solar axions or more general axion-like\n particles (ALPs), that may be emitted in the M1 nuclear transition of 57Fe, by\n using the axion-to-photon conversion in the CERN Axion Solar Telescope (CAST)\n with evacuated magnet bores (Phase I). From the absence of excess of the\n monoenergetic X-rays when the magnet was pointing to the Sun, we set\n model-independent constraints on the coupling constants of pseudoscalar\n particles that couple to two photons and to a nucleon g_{a\\gamma} |-1.19\n g_{aN}^{0}+g_{aN}^{3}|<1.36\\times 10^{-16} GeV^{-1} for m_{a}<0.03 eV at the\n 95% confidence level.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2006.16280",
        "title": "The Assembly History of M87 Through Radial Variations in Chemical\n  Abundances of its Field Star And Globular Cluster Populations",
        "abstract": "We present an extensive study of spectroscopically-derived chemical\n abundances for M87 and its globular cluster (GC) system. Using observations\n from the Mitchell spectrograph at McDonald, LRIS at Keck, and Hectospec on the\n MMT, we derive new metallicity gradients from $\\sim 2$ to $140$ kpc. We use a\n novel hierarchical statistical framework to simultaneously separate the GC\n system into subpopulations while measuring the metallicity gradients of those\n subpopulations. We create physically-motivated spectral stacks of the GC\n subpopulations by leveraging the output of this statistical framework to\n perform the first application of abundance tagging in a massive ETG to better\n constrain the origins of the GC subpopulations and, thus, the assembly history\n of M87. We find a metal-poor, $\\alpha$-enhanced population of GCs in both in\n the inner and outer halo unanticipated by current cosmological simulations of\n galaxy evolution. We use the remarkably flat metallicity gradients we find for\n both the metal-rich and metal-poor GC subpopulations in the inner halo as\n tentative evidence that some amount of the metal-poor GCs formed directly in\n the halo of M87 at high redshift.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1007.4937",
        "title": "Broad emission lines for negatively spinning black holes",
        "abstract": "We present an extended scheme for the calculation of the profiles of emission\n lines from accretion discs around rotating black holes. The scheme includes\n discs with angular momenta which are parallel and antiparallel with respect to\n the black hole's angular momentum, as both configurations are assumed to be\n stable (King et al., 2005). We discuss line shapes for such discs and present a\n code for modelling observational data with this scheme in X-ray data analysis\n programs. Based on a Green's function approach, an arbitrary radius dependence\n of the disc emissivity and arbitrary limb darkening laws can be easily taken\n into account, while the amount of precomputed data is significantly reduced\n with respect to other available models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1904.08925",
        "title": "The impact of proportional transaction costs on systematically generated\n  portfolios",
        "abstract": "The effect of proportional transaction costs on systematically generated\n portfolios is studied empirically. The performance of several portfolios (the\n index tracking portfolio, the equally-weighted portfolio, the entropy-weighted\n portfolio, and the diversity-weighted portfolio) in the presence of dividends\n and transaction costs is examined under different configurations involving the\n trading frequency, constituent list size, and renewing frequency. Moreover, a\n method to smooth transaction costs is proposed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1103.3452",
        "title": "The characteristics of thermalization of boost-invariant plasma from\n  holography",
        "abstract": "We report on the approach towards the hydrodynamic regime of boost-invariant\n N=4 super Yang-Mills plasma at strong coupling starting from various\n far-from-equilibrium states at tau=0. The results are obtained through\n numerical solution of Einstein's equations for the dual geometries, as\n described in detail in the companion article arXiv:1203.0755. Despite the very\n rich far-from-equilibrium evolution, we find surprising regularities in the\n form of clear correlations between initial entropy and total produced entropy,\n as well as between initial entropy and the temperature at thermalization,\n understood as the transition to a hydrodynamic description. For 29 different\n initial conditions that we consider, hydrodynamics turns out to be definitely\n applicable for proper times larger than 0.7 in units of inverse temperature at\n thermalization. We observe a sizable anisotropy in the energy-momentum tensor\n at thermalization, which is nevertheless entirely due to hydrodynamic effects.\n This suggests that effective thermalization in heavy ion collisions may occur\n significantly earlier than true thermalization.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1207.4244",
        "title": "Cloaking and imaging at the same time",
        "abstract": "In this letter, we propose a conceptual device to perform subwavelength\n imaging with positive refraction. The key to this proposal is that a drain is\n no longer a must for some cases. What's more, this device is an isotropic\n omnidirectional cloak with a perfect electric conductor hiding region and shows\n versatile illusion optical effects. Numerical simulations are performed to\n verify the functionalities.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2111.12420",
        "title": "CircuitFlow: A Domain Specific Language for Dataflow Programming (with\n  appendices)",
        "abstract": "Dataflow applications, such as machine learning algorithms, can run for days,\n making it desirable to have assurances that they will work correctly. Current\n tools are not good enough: too often the interactions between tasks are not\n type-safe, leading to undesirable run-time errors. This paper presents a new\n declarative Haskell Embedded DSL (eDSL) for dataflow programming: CircuitFlow.\n Defined as a Symmetric Monoidal Preorder (SMP) on data that models dependencies\n in the workflow, it has a strong mathematical basis, refocusing on how data\n flows through an application, resulting in a more expressive solution that not\n only catches errors statically, but also achieves competitive run-time\n performance. In our preliminary evaluation, CircuitFlow outperforms the\n industry-leading Luigi library of Spotify by scaling better with the number of\n inputs. The innovative creation of CircuitFlow is also of note, exemplifying\n how to create a modular eDSL whose semantics necessitates effects, and where\n storing complex type information for program correctness is paramount.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0912.5193",
        "title": "Ranking relations using analogies in biological and information networks",
        "abstract": "Analogical reasoning depends fundamentally on the ability to learn and\n generalize about relations between objects. We develop an approach to\n relational learning which, given a set of pairs of objects\n $\\mathbf{S}=\\{A^{(1)}:B^{(1)},A^{(2)}:B^{(2)},\\ldots,A^{(N)}:B ^{(N)}\\}$,\n measures how well other pairs A:B fit in with the set $\\mathbf{S}$. Our work\n addresses the following question: is the relation between objects A and B\n analogous to those relations found in $\\mathbf{S}$? Such questions are\n particularly relevant in information retrieval, where an investigator might\n want to search for analogous pairs of objects that match the query set of\n interest. There are many ways in which objects can be related, making the task\n of measuring analogies very challenging. Our approach combines a similarity\n measure on function spaces with Bayesian analysis to produce a ranking. It\n requires data containing features of the objects of interest and a link matrix\n specifying which relationships exist; no further attributes of such\n relationships are necessary. We illustrate the potential of our method on text\n analysis and information networks. An application on discovering functional\n interactions between pairs of proteins is discussed in detail, where we show\n that our approach can work in practice even if a small set of protein pairs is\n provided.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1703.05324",
        "title": "Velocity-Density Correlations from the cosmicflows-3 Distance Catalog\n  and the 2MASS Redshift Survey",
        "abstract": "The peculiar velocity of a mass tracer is on average aligned with the dipole\n modulation of the surrounding mass density field. We present a first\n measurement of the correlation between radial peculiar velocities of objects in\n the cosmicflows-3 catalog and the dipole moment of the 2MRS galaxy distribution\n in concentric spherical shells centered on these objects. Limiting the analysis\n to cosmicflows-3 objects with distances of $100 \\rm Mpc h^{-1}$, the\n correlation function is detected at a confidence level $> 4\\sigma$. The\n measurement is found consistent with the standard $\\Lambda$CDM model at $<\n 1.7\\sigma$ level. We formally derive the constraints\n $0.32<\\Omega^{0.55}\\sigma_8<0.48$ ($68\\% $ confidence level) or equivalently\n $0.34<\\Omega^{0.55}/b<0.52$, where $b$ is the galaxy bias factor. Deeper and\n improved peculiar velocity catalogs will substantially reduce the\n uncertainties, allowing tighter constraints from this type of correlations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0601507",
        "title": "p-adic cohomology",
        "abstract": "This is a survey of some recent developments concerning the p-adic cohomology\n of algebraic varieties over fields of positive characteristic and local fields\n of mixed characteristic, plus some related areas like p-adic Hodge theory.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1912.05626",
        "title": "Impact of Source to Drain Tunneling on the Ballistic Performance of Ge,\n  GaSb, and GeSn Nanowire p-MOSFETs",
        "abstract": "We investigated the effect of material choice and orientation in limiting\n source to drain tunneling (SDT) in nanowire (NW) p-MOSFETs. Si, Ge, GaSb, and\n Ge0.96Sn0.04 nanowire MOSFETs (NWFETs) were simulated using rigorous ballistic\n quantum transport simulations. To properly account for the non-parabolicity and\n anisotropy of the valence band the k.p method was used. For each material, a\n set of six different transport/confinement directions were simulated to\n identify the direction with the highest ON-current (ION ). For Ge, GaSb, and\n GeSn [001]/110/-110 oriented NWFETs showed the best ON-state performance,\n compared to other orientations. Our simulation results show that, despite\n having a higher percentage of SDT in OFF-state than silicon, GaSb\n [001]/110/-110 NWFET can outperform Si NWFETs. We further examined the role of\n doping in limiting SDT and demonstrated that the ON-state performance of Ge and\n GeSn NWFETs could be improved by reducing the doping in the source/drain (S/D)\n extension regions. Finally, we analyzed the impact of increased injection\n velocity in [ [001]/110/-110 oriented GaSb and GeSn NWFETs, as a result of the\n application of uniaxial compressive stress, and showed that when compared at a\n fixed OFF-current (IOFF) with unstrained NWFETs, uniaxial compressive stress\n deteriorates the ON-state performancedue to an increase in OFF-state SDT\n current component.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1004.5323",
        "title": "Geometrization of Trace Formulas",
        "abstract": "Following our joint work arXiv:1003.4578 with Robert Langlands, we make the\n first steps toward developing geometric methods for analyzing trace formulas in\n the case of the function field of a curve defined over a finite field. We also\n suggest a conjectural framework of geometric trace formulas for curves defined\n over the complex field, which exploits the categorical version of the geometric\n Langlands correspondence.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2002.05220",
        "title": "Importance of non-flow background on the chiral magnetic wave search",
        "abstract": "An observable sensitive to the chiral magnetic wave (CMW) is the charge\n asymmetry dependence of the $\\pi^{-}$ and $\\pi^{+}$ anisotropic flow\n difference, $\\Delta v_{n}(A_{\\rm ch})$. We show that, due to non-flow\n correlations, the flow measurements by the Q-cumulant method using all charged\n particles as reference introduce a trivial linear term to $\\Delta v_{n}(A_{\\rm\n ch})$. The trivial slope contribution to the triangle flow difference $\\Delta\n v_{3}(A_{\\rm ch})$ can be negative if the non-flow is dominated by back-to-back\n pairs. This can explain the observed negative $\\Delta v_{3}(A_{\\rm ch})$ slope\n in the preliminary STAR data. We further find that the non-flow correlations\n give rise to additional backgrounds to the slope of $\\Delta v_{2}(A_{\\rm ch})$\n from the competition among different pion sources and from the larger\n multiplicity dilution to $\\pi^{+}$ ($\\pi^{-}$) at positive (negative) $A_{\\rm\n ch}$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1701.05305",
        "title": "Random Forest Missing Data Algorithms",
        "abstract": "Random forest (RF) missing data algorithms are an attractive approach for\n dealing with missing data. They have the desirable properties of being able to\n handle mixed types of missing data, they are adaptive to interactions and\n nonlinearity, and they have the potential to scale to big data settings.\n Currently there are many different RF imputation algorithms but relatively\n little guidance about their efficacy, which motivated us to study their\n performance. Using a large, diverse collection of data sets, performance of\n various RF algorithms was assessed under different missing data mechanisms.\n Algorithms included proximity imputation, on the fly imputation, and imputation\n utilizing multivariate unsupervised and supervised splitting---the latter class\n representing a generalization of a new promising imputation algorithm called\n missForest. Performance of algorithms was assessed by ability to impute data\n accurately. Our findings reveal RF imputation to be generally robust with\n performance improving with increasing correlation. Performance was good under\n moderate to high missingness, and even (in certain cases) when data was missing\n not at random.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2302.12002",
        "title": "Master's Thesis: Out-of-distribution Detection with Energy-based Models",
        "abstract": "Today, deep learning is increasingly applied in security-critical situations\n such as autonomous driving and medical diagnosis. Despite its success, the\n behavior and robustness of deep networks are not fully understood yet, posing a\n significant risk. In particular, researchers recently found that neural\n networks are overly confident in their predictions, even on data they have\n never seen before. To tackle this issue, one can differentiate two approaches\n in the literature. One accounts for uncertainty in the predictions, while the\n second estimates the underlying density of the training data to decide whether\n a given input is close to the training data, and thus the network is able to\n perform as expected.In this thesis, we investigate the capabilities of EBMs at\n the task of fitting the training data distribution to perform detection of\n out-of-distribution (OOD) inputs. We find that on most datasets, EBMs do not\n inherently outperform other density estimators at detecting OOD data despite\n their flexibility. Thus, we additionally investigate the effects of\n supervision, dimensionality reduction, and architectural modifications on the\n performance of EBMs. Further, we propose Energy-Prior Network (EPN) which\n enables estimation of various uncertainties within an EBM for classification,\n bridging the gap between two approaches for tackling the OOD detection problem.\n We identify a connection between the concentration parameters of the Dirichlet\n distribution and the joint energy in an EBM. Additionally, this allows\n optimization without a held-out OOD dataset, which might not be available or\n costly to collect in some applications. Finally, we empirically demonstrate\n that Energy-Prior Network (EPN) is able to detect OOD inputs, datasets shifts,\n and adversarial examples. Theoretically, EPN offers favorable properties for\n the asymptotic case when inputs are far from the training data.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0705.4335",
        "title": "Effective Theory for Trapped Few-Fermion Systems",
        "abstract": "We apply the general principles of effective field theories to the\n construction of effective interactions suitable for few- and many-body\n calculations in a no-core shell model framework. We calculate the spectrum of\n systems with three and four two-component fermions in a harmonic trap. In the\n unitary limit, we find that three-particle results are within 10% of known\n semi-analytical values even in small model spaces. The method is very general,\n and can be readily extended to other regimes, more particles, different species\n (e.g., protons and neutrons in nuclear physics), or more-component fermions (as\n well as bosons). As an illustration, we present calculations of the\n lowest-energy three-fermion states away from the unitary limit and find a\n possible inversion of parity in the ground state in the limit of trap size\n large compared to the scattering length. Furthermore, we investigate the lowest\n positive-parity states for four fermions, although we are limited by the\n dimensions we can currently handle in this case.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0711.2322",
        "title": "Relativistic corrections to the static potential at O(1/m) and O(1/m^2)",
        "abstract": "We investigate the relativistic corrections to the static potential, i.e. the\n O(1/m) potential and the O(1/m^2) velocity-dependent potentials, in SU(3)\n lattice gauge theory. They are important ingredients of potential\n nonrelativistic QCD for heavy quarkonium. Utilizing the multi-level algorithm,\n we obtain remarkably clean signals of these potentials up to r=0.9 fm. We\n observe long range nonperturbative contributions to these corrections.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1311.6120",
        "title": "The circle method and bounds for $L$-functions - IV: Subconvexity for\n  twists of $GL(3)$ $L$-functions - B",
        "abstract": "Let $\\pi$ be a $SL(3,\\mathbb Z)$ Hecke-Maass cusp form satisfying the\n Ramanujan conjecture and the Selberg-Ramanujan conjecture, and let $\\chi$ be a\n primitive Dirichlet character modulo $M$, which we assume to be prime for\n simplicity. We will prove the following subconvex bound $$\n L\\left(\\tfrac{1}{2},\\pi\\otimes\\chi\\right)\\ll_{\\pi,\\varepsilon}\n M^{\\frac{3}{4}-\\frac{1}{1612}+\\varepsilon}. $$",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1304.3597",
        "title": "Percolation on interdependent networks with a fraction of antagonistic\n  interactions",
        "abstract": "Recently, the percolation transition has been characterized on interacting\n networks both in presence of interdependent and antagonistic interactions. Here\n we characterize the phase diagram of the percolation transition in two Poisson\n interdependent networks with a percentage q of antagonistic nodes. We show that\n this system can present a bistability of the steady state solutions, and both\n first, and second order phase transitions. In particular, we observe a\n bistability of the solutions in some regions of the phase space also for a\n small fraction of antagonistic interactions 0<q<0.4. Moreover, we show that a\n fraction q>q_c=2/3 of antagonistic interactions is necessary to strongly reduce\n the region in phase-space in which both networks are percolating. This last\n result suggests that interdependent networks are robust to the presence of\n antagonistic interactions. Our approach can be extended to multiple networks,\n and to complex boolean rules for regulating the percolation phase transition.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1712.05400",
        "title": "Itinerant quantum multi-criticality of two dimensional Dirac fermions",
        "abstract": "We analyze emergent quantum multi-criticality for strongly interacting,\n massless Dirac fermions in two spatial dimensions ($d=2$) within the framework\n of Gross-Neveu-Yukawa models, by considering the competing order parameters\n that give rise to fully gapped (insulating or superconducting) ground states.\n We focus only on those competing orders, which can be rotated into each other\n by generators of an exact or emergent chiral symmetry of massless Dirac\n fermions, and break $O(S_1)$ and $O(S_2)$ symmetries in the ordered phase.\n Performing a renormalization group analysis by using the $\\epsilon=(3-d)$\n expansion scheme, we show that all the coupling constants in the critical\n hyperplane flow toward a new attractive fixed point, supporting an\n \\emph{enlarged} $O(S_1+S_2)$ chiral symmetry. Such a fixed point acts as an\n exotic quantum multi-critical point (MCP), governing the \\emph{continuous}\n semimetal-insulator as well as insulator-insulator (for example antiferromagnet\n to valence bond solid) quantum phase transitions. In comparison with the lower\n symmetric semimetal-insulator quantum critical points, possessing either\n $O(S_1)$ or $O(S_2)$ chiral symmetry, the MCP displays enhanced correlation\n length exponents, and anomalous scaling dimensions for both fermionic and\n bosonic fields. We discuss the scaling properties of the ratio of bosonic and\n fermionic masses, and the increased dc resistivity at the MCP. By computing the\n scaling dimensions of different local fermion bilinears in the particle-hole\n channel, we establish that most of the four fermion operators or generalized\n density-density correlation functions display faster power law decays at the\n MCP compared to the free fermion and lower symmetric itinerant quantum critical\n points. Possible generalization of this scenario to higher dimensional Dirac\n fermions is also outlined.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1210.6120",
        "title": "An effective approach to the solution of a system of nonlinear\n  differential equations in partial derivatives",
        "abstract": "There are few approaches to the solution of a system of nonlinear\n differential equations in partial derivatives, for example $\\cite{NK87} -\n \\cite{EK98}$. In our paper we propose an approach that was used to solve the\n Navier-Stokes equations in three dimensional space. This solution is described\n in details in article \"Existence, uniqueness and smoothness of solution for 3D\n Navier-Stokes equations with any smooth initial velocity\" $\\cite{TT12}$. The\n authors expect that it can be successfully applied to other systems of\n nonlinear differential equations in partial derivatives.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1904.06830",
        "title": "ContactDB: Analyzing and Predicting Grasp Contact via Thermal Imaging",
        "abstract": "Grasping and manipulating objects is an important human skill. Since\n hand-object contact is fundamental to grasping, capturing it can lead to\n important insights. However, observing contact through external sensors is\n challenging because of occlusion and the complexity of the human hand. We\n present ContactDB, a novel dataset of contact maps for household objects that\n captures the rich hand-object contact that occurs during grasping, enabled by\n use of a thermal camera. Participants in our study grasped 3D printed objects\n with a post-grasp functional intent. ContactDB includes 3750 3D meshes of 50\n household objects textured with contact maps and 375K frames of synchronized\n RGB-D+thermal images. To the best of our knowledge, this is the first\n large-scale dataset that records detailed contact maps for human grasps.\n Analysis of this data shows the influence of functional intent and object size\n on grasping, the tendency to touch/avoid 'active areas', and the high frequency\n of palm and proximal finger contact. Finally, we train state-of-the-art image\n translation and 3D convolution algorithms to predict diverse contact patterns\n from object shape. Data, code and models are available at\n https://contactdb.cc.gatech.edu.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0702559",
        "title": "Cellular Dynamical Mean Field Theory of the Periodic Anderson Model",
        "abstract": "We develop a cluster dynamical mean field theory of the periodic Anderson\n model in three dimensions, taking a cluster of two sites as a basic reference\n frame. The mean field theory displays the basic features of the Doniach phase\n diagram: a paramagnetic Fermi liquid state, an antiferromagnetic state and a\n transition between them.\n  In contrast with spin density wave theories, the transition is accompanied by\n a large increase of the effective mass everywhere on the Fermi surface and a\n substantial change of the Fermi surface shape across the transition. To\n understand the nature and the origin of the phases near the transition, we\n investigate the paramagnetic solution underlying the antiferromagnetic state,\n and identify the transition as a point where the $f$ electrons decouple from\n the conduction electrons undergoing an orbitally selective Mott transition.\n This point turns out to be intimately related to the two impurity Kondo model\n quantum critical point. In this regime, non local correlations become important\n and result in significant changes in the photoemission spectra and the de\n Haas-van Alphen frequencies. The transition involves considerable $f$ spectral\n weight transfer from the Fermi level to its immediate vicinity, rather than to\n the Hubbard bands as in single site DMFT.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1406.3734",
        "title": "Critical Behavior of the SDW Transition in Underdoped Ba(Fe1-xCox)2As2\n  (x <=0.05): 75As NMR Investigation",
        "abstract": "We investigate the nature of the SDW (Spin Density Wave) transition in the\n underdoped regime of an iron-based high Tc superconductor Ba(Fe1-xCox)2As2 by\n 75As NMR, with primary focus on a composition with x = 0.02 (T_SDW = 99 K).We\n demonstrate that critical slowing down toward the three dimensional SDW\n transition sets in at the tetragonal to orthorhombic structural phase\n transition, Ts = 105 K, suggesting strong interplay between structural\n distortion and spin correlations. In the critical regime between Ts and T_SDW,\n the dynamical structure factor of electron spins S(q,Wn) measured with the\n longitudinal NMR relaxation rate 1/T1 exhibits a divergent behavior obeying a\n power law, 1/T1~S(q, Wn)~(T/T_SDW-1)^a with the critical exponent a ~ 0.33.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.11672",
        "title": "The local balance laws for energy, momentum and entropy: how they came\n  into being, and what was their destiny",
        "abstract": "The historical process of the genesis of the extensive or substance-like\n quantities took place in two steps. First, global conservation or\n non-conservation was discovered. Only later did it become possible to formulate\n the balance locally in the form of a continuity equation. This process can be\n clearly seen in energy, momentum, and entropy. After a long and intricate\n history, the quantitative description of the local balance has been achieved\n for all of the three quantities in a surprisingly short period of time around\n the turn of the 19th to the 20th century. The new ideas could have simplified\n considerably the teaching of energy, momentum, and entropy. However, in all\n three cases, today's language of physics remained essentially the same as it\n was at the time when a local balancing was not yet possible.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0509662",
        "title": "Killing vector fields with twistor derivative",
        "abstract": "Motivated by the possible characterization of Sasakian manifolds in terms of\n twistor forms, we give the complete classification of compact Riemannian\n manifolds carrying a Killing vector field whose covariant derivative (viewed as\n a 2-form) is a twistor form.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.07669",
        "title": "On the convergence of partial sums with respect to Vilenkin system on\n  the martingale Hardy spaces",
        "abstract": "In this paper we derive characterizations of boundedness of the subsequences\n of partial sums with respect to Vilenkin system on the martingale Hardy spaces\n when $ 0<p<1 $. Moreover, we find necessary and sufficient conditions for the\n modulus of continuity of $f\\in H_{p}$ martingales, which provide convergence of\n subsequences of partial sums on the martingale Hardy spaces. It is also proved\n that these results are the best possible in a special sense. As applications,\n both some well-known and new results are pointed out.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0410496",
        "title": "3-D Photoionization Structure and Distances of Planetary Nebulae II.\n  Menzel 1",
        "abstract": "We present the results of a spatio-kinematic study of the planetary nebula\n Menzel 1 using spectro-photometric mapping and a 3-D photoionization code. We\n create several 2-D emission line images from our long-slit spectra, and use\n these to derive the line fluxes for 15 lines, the Halpha/Hbeta extinction map,\n and the [SII] line ratio density map of the nebula. We use our photoionization\n code constrained by these data to derive the three-dimensional nebular\n structure and ionizing star parameters of Menzel 1 by simultaneously fitting\n the integrated line intensities, the density map, and the observed morphologies\n in several lines, as well as the velocity structure. Using theoretical\n evolutionary tracks of intermediate and low mass stars, we derive a mass for\n the central star of 0.63+-0.05 Msolar. We also derive a distance of 1050+_150\n pc to Menzel 1.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0903.4299",
        "title": "Token Ring Project",
        "abstract": "Ring topology is a simple configuration used to connect processes that\n communicate among themselves. A number of network standards such as token ring,\n token bus, and FDDI are based on the ring connectivity. This article will\n develop an implementation of a ring of processes that communicate among\n themselves via pipe links. The processes are nodes in the ring. Each process\n reads from its standard input and writes in its standard output. N-1 process\n redirects the its standard output to a standard input of the process through a\n pipe. When the ring-structure is designed, the project can be extended to\n simulate networks or to implement algorithms for mutual exclusion.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1301.6639",
        "title": "Defects, Super-Poincar\\'{e} line bundle and Fermionic T-duality",
        "abstract": "Topological defects are interfaces joining two conformal field theories, for\n which the energy momentum tensor is continuous across the interface. A class of\n the topological defects is provided by the interfaces separating two bulk\n systems each described by its own Lagrangian, where the two descriptions are\n related by a discrete symmetry.\n  In this paper we elaborate on the cases in which the discrete symmetry is a\n bosonic or a fermionic T- duality. We review how the equations of motion\n imposed by the defect encode the general bosonic T- duality transformations for\n toroidal compactifications. We generalize this analysis in some detail to the\n case of topological defects allowed in coset CFTs, in particular to those\n cosets where the gauged group is either an axial or vector U(1). This is\n discussed in both the operator and Lagrangian approaches. We proceed to\n construct a defect encoding a fermionic T-duality. We show that the fermionic\n T-duality is implemented by the Super-Poincar\\'{e} line bundle. The observation\n that the exponent of the gauge invariant flux on a defect is a kernel of the\n Fourier-Mukai transform of the Ramond-Ramond fields, is generalized to a\n fermionic T-duality. This is done via a fiberwise integration on\n supermanifolds.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2301.01662",
        "title": "Unimodular approaches to the cosmological constant problem",
        "abstract": "We review selected aspects of unimodular gravity and we discuss its viability\n as a solution of the old cosmological constant problem. In unimodular gravity\n the cosmological constant is promoted to a global degree of freedom. We\n highlight the importance of correctly setting up its initial data in order to\n achieve a resolution of the cosmological constant problem on a semi-classical\n level. We review recent path integral analysis of quantum aspects of unimodular\n gravity to note that the semi-classical findings carry over to the quantum\n level as well. We point out that a resolution of the problem inherently relies\n on a global constraint on the space-time four-volume. This makes the theory\n closely related to the vacuum energy sequester, which operates in a similar\n way. We discuss possible avenues of extending unimodular gravity that preserve\n the resolution of the cosmological constant problem.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2402.05219",
        "title": "Photochemically-induced acousto-optics in gases",
        "abstract": "Acousto-optics consists of launching acoustic waves in a medium (usually a\n crystal) in order to modulate its refractive index and create a tunable optical\n grating. In this article, we present the theoretical basis of a new scheme to\n generate acousto-optics in a gas, where the acoustic waves are initiated by the\n localized absorption (and thus gas heating) of spatially-modulated UV light, as\n was demonstrated in Y. Michine and H. Yoneda, Commun. Phys. 3, 24 (2020). We\n identify the chemical reactions initiated by the absorption of UV light via the\n photodissociation of ozone molecules present in the gas, and calculate the\n resulting temperature increase in the gas as a function of space and time.\n Solving the Euler fluid equations shows that the modulated, isochoric heating\n initiates a mixed acoustic/entropy wave in the gas, whose high-amplitude\n density (and thus refractive index) modulation can be used to manipulate a\n high-power laser. We calculate that diffraction efficiencies near 100% can be\n obtained using only a few millimeters of gas containing a few percent ozone\n fraction at room temperature, with UV fluences of less than 100 mJ/cm2,\n consistent with the experimental measurements. Our analysis suggests possible\n ways to optimize the diffraction efficiency by changing the buffer gas\n composition. Gases have optics damage thresholds two to three orders of\n magnitude beyond those of solids; these optical elements should therefore be\n able to manipulate kJ-class lasers.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0808.2142",
        "title": "An Abundance of Heterotic Vacua",
        "abstract": "We explicitly construct the largest dataset to date of heterotic vacua\n arising from stable vector bundles on Calabi-Yau threefolds. Focusing on\n elliptically fibered Calabi-Yau manifolds with spectral cover bundles, we show\n that the number of heterotic models with non-zero number of generations is\n finite. We classify these models according to the complex base of their\n Calabi-Yau threefold and to the unification gauge group that they preserve in\n four dimensions. This database of the order of $10^7$ models, which includes\n potential Standard Model candidates, is subjected to some preliminary\n statistical analyses. The additional constraint that there should be three net\n generations of particles gives a dramatic reduction of the number of vacua.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2103.11476",
        "title": "Under pressure: Hydrogel swelling in a granular medium",
        "abstract": "Hydrogels hold promise in agriculture as reservoirs of water in dry soil,\n potentially alleviating the burden of irrigation. However, confinement in soil\n can markedly reduce the ability of hydrogels to absorb water and swell,\n limiting their widespread adoption. Unfortunately, the underlying reason\n remains unknown. By directly visualizing the swelling of hydrogels confined in\n three-dimensional granular media, we demonstrate that the extent of hydrogel\n swelling is determined by the competition between the force exerted by the\n hydrogel due to osmotic swelling and the confining force transmitted by the\n surrounding grains. Furthermore, the medium can itself be restructured by\n hydrogel swelling, as set by the balance between the osmotic swelling force,\n the confining force, and intergrain friction. Together, our results provide\n quantitative principles to predict how hydrogels behave in confinement,\n potentially improving their use in agriculture as well as informing other\n applications such as oil recovery, construction, mechanobiology, and\n filtration.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/physics/0312126",
        "title": "Guiding optical flows by photonic crystal slabs made of dielectric\n  cylinders",
        "abstract": "We investigate the electromagnetic propagation in two-dimensional photonic\n crystals, formed by parallel dielectric cylinders embedded a uniform medium.\n The frequency band structure is computed using the standard plane-wave\n expansion method, while the propagation and scattering of the electromagnetic\n waves are calculated by the multiple scattering theory. It is shown that within\n partial bandgaps, the waves tend to bend away from the forbidden directions.\n Such a property may render novel applications in manipulating optical flows. In\n addition, the relevance with the imaging by flat photonic crystal slabs will\n also be discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1503.06482",
        "title": "Optimal binomial, Poisson, and normal left-tail domination for sums of\n  nonnegative random variables",
        "abstract": "Let $X_1,\\dots,X_n$ be independent nonnegative random variables (r.v.'s),\n with $S_n:=X_1+\\dots+X_n$ and finite values of $s_i:=E X_i^2$ and $m_i:=E\n X_i>0$. Exact upper bounds on $E f(S_n)$ for all functions $f$ in a certain\n class $\\mathcal{F}$ of nonincreasing functions are obtained, in each of the\n following settings: (i) $n,m_1,\\dots,m_n,s_1,\\dots,s_n$ are fixed; (ii) $n$,\n $m:=m_1+\\dots+m_n$, and $s:=s_1+\\dots+s_n$ are fixed; (iii)~only $m$ and $s$\n are fixed. These upper bounds are of the form $E f(\\eta)$ for a certain r.v.\n $\\eta$. The r.v. $\\eta$ and the class $\\mathcal{F}$ depend on the choice of one\n of the three settings. In particular, $(m/s)\\eta$ has the binomial distribution\n with parameters $n$ and $p:=m^2/(ns)$ in setting (ii) and the Poisson\n distribution with parameter $\\lambda:=m^2/s$ in setting (iii). One can also let\n $\\eta$ have the normal distribution with mean $m$ and variance $s$ in any of\n these three settings. In each of the settings, the class $\\mathcal{F}$\n contains, and is much wider than, the class of all decreasing exponential\n functions. As corollaries of these results, optimal in a certain sense upper\n bounds on the left-tail probabilities $P(S_n\\le x)$ are presented, for any real\n $x$. In fact, more general settings than the ones described above are\n considered. Exact upper bounds on the exponential moments $E\\exp\\{hS_n\\}$ for\n $h<0$, as well as the corresponding exponential bounds on the left-tail\n probabilities, were previously obtained by Pinelis and Utev. It is shown that\n the new bounds on the tails are substantially better.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2305.11522",
        "title": "DSFNet: Dual Space Fusion Network for Occlusion-Robust 3D Dense Face\n  Alignment",
        "abstract": "Sensitivity to severe occlusion and large view angles limits the usage\n scenarios of the existing monocular 3D dense face alignment methods. The\n state-of-the-art 3DMM-based method, directly regresses the model's\n coefficients, underutilizing the low-level 2D spatial and semantic information,\n which can actually offer cues for face shape and orientation. In this work, we\n demonstrate how modeling 3D facial geometry in image and model space jointly\n can solve the occlusion and view angle problems. Instead of predicting the\n whole face directly, we regress image space features in the visible facial\n region by dense prediction first. Subsequently, we predict our model's\n coefficients based on the regressed feature of the visible regions, leveraging\n the prior knowledge of whole face geometry from the morphable models to\n complete the invisible regions. We further propose a fusion network that\n combines the advantages of both the image and model space predictions to\n achieve high robustness and accuracy in unconstrained scenarios. Thanks to the\n proposed fusion module, our method is robust not only to occlusion and large\n pitch and roll view angles, which is the benefit of our image space approach,\n but also to noise and large yaw angles, which is the benefit of our model space\n method. Comprehensive evaluations demonstrate the superior performance of our\n method compared with the state-of-the-art methods. On the 3D dense face\n alignment task, we achieve 3.80% NME on the AFLW2000-3D dataset, which\n outperforms the state-of-the-art method by 5.5%. Code is available at\n https://github.com/lhyfst/DSFNet.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1810.02747",
        "title": "Vanishing Theorem for the de Rham Complex of Unitary Local System",
        "abstract": "We will prove a Kodaira-Nakano type of vanishing theorem for the logarithmic\n de Rham complex of unitary local system. We will then study the weight\n filtration on the logarithmic de Rham complex, and prove a stronger statement\n for the associated graded complex.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0303075",
        "title": "Superfield T-duality rules",
        "abstract": "A geometric treatment of T-duality as an operation which acts on differential\n forms in superspace allows us to derive the complete set of T-duality\n transformation rules which relate the superfield potentials of D=10 type IIA\n supergravity with those of type IIB supergravity including Ramond-Ramond\n superfield potentials and fermionic supervielbeins. We show that these rules\n are consistent with the superspace supergravity constraints.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.04344",
        "title": "Physical Security in the Post-quantum Era: A Survey on Side-channel\n  Analysis, Random Number Generators, and Physically Unclonable Functions",
        "abstract": "Over the past decades, quantum technology has seen consistent progress, with\n notable recent developments in the field of quantum computers. Traditionally,\n this trend has been primarily seen as a serious risk for cryptography; however,\n a positive aspect of quantum technology should also be stressed. In this\n regard, viewing this technology as a resource for honest parties rather than\n adversaries, it may enhance not only the security, but also the performance of\n specific cryptographic schemes. While considerable effort has been devoted to\n the design of quantum-resistant and quantum-enhanced schemes, little effort has\n been made to understanding their physical security. Physical security deals\n with the design and implementation of security measures fulfilling the\n practical requirements of cryptographic primitives, which are equally essential\n for classic and quantum ones. This survey aims to draw greater attention to the\n importance of physical security, with a focus on secure key generation and\n storage as well as secure execution. More specifically, the possibility of\n performing side-channel analysis in the quantum world is discussed and compared\n to attacks launched in the classic world. Besides, proposals for quantum random\n number generation and quantum physically unclonable functions are compared to\n their classic counterparts and further analyzed to give a better understanding\n of their features, advantages, and shortcomings. Finally, seen from these three\n perspectives, this survey provides an outlook for future research in this\n direction.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2404.12371",
        "title": "Long-lived oscillations of false and true vacuum states in neutral atom\n  systems",
        "abstract": "Metastable false vacuum states arise in a range of quantum systems and can be\n observed in various dynamical scenarios, including decay, bubble nucleation,\n and long-lived oscillations. False vacuum phenomenology has been examined in\n quantum many-body systems, notably in 1D ferromagnetic Ising spin systems and\n superfluids. In this paper, we study long-lived oscillations of false and true\n vacuum states in 1D antiferromagnetic neutral atom chains with long-range\n Rydberg interactions. We use a staggered local detuning field to achieve\n confinement. Using theoretical and numerical models, we identify novel spectral\n signatures of quasiparticle oscillations distinct to antiferromagnetic neutral\n atom systems and interpret them using a classical energy model of deconfinement\n from Rydberg tails. Finally, we evaluate the experimental accessibility of our\n proposed setup on current neutral-atom platforms and discuss experimental\n feasibility and constraints.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2103.12272",
        "title": "Construction of explicit symplectic integrators in general relativity.\n  III. Reissner-Nordstrom-(anti)-de Sitter black holes",
        "abstract": "We give a possible splitting method to a Hamiltonian for the description of\n charged particles moving around the Reissner-Nordstrom-(anti)-de Sitter black\n hole with an external magnetic field. This Hamiltonian can be separated into\n six analytical solvable pieces, whose solutions are explicit functions of\n proper time. In this case, second- and fourth-order explicit symplectic\n integrators are easily available. They exhibit excellent long-term behavior in\n maintaining the boundness of Hamiltonian errors regardless of ordered or\n chaotic orbits if appropriate step-sizes are chosen. Under some circumstances,\n an increase of positive cosmological constant gives rise to strengthening the\n extent of chaos from the global phase space; namely, chaos of charged particles\n occurs easily for the accelerated expansion of the universe. However, an\n increase of the magnitude of negative cosmological constant does not. The\n different contributions on chaos are because the cosmological constant acts as\n a repulsive force in the Reissner-Nordstrom-de Sitter black hole, but an\n attractive force in the Reissner-Nordstrom-anti-de Sitter black hole.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.08020",
        "title": "Gauge equivalence between 1+1 rational Calogero-Moser field theory and\n  higher rank Landau-Lifshitz equation",
        "abstract": "In this paper we study 1+1 field generalization of the rational $N$-body\n Calogero-Moser model. We show that this model is gauge equivalent to some\n special higher rank matrix Landau-Lifshitz equation. The latter equation is\n described in terms of ${\\rm GL}_N$ rational $R$-matrix, which turns into the\n 11-vertex $R$-matrix in the $N=2$ case. The rational $R$-matrix satisfies the\n associative Yang-Baxter equation, which underlies construction of the Lax pair\n for the Zakharov-Shabat equation. The field analogue of the IRF-Vertex\n transformation is proposed. It allows to compute explicit change of variables\n between the field Calogero-Moser model and the Landau-Lifshitz equation.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.03413",
        "title": "Online Learning and Control Synthesis for Reachable Paths of Unknown\n  Nonlinear Systems",
        "abstract": "In this paper, we present a novel method to drive a nonlinear system to a\n desired state, with limited a priori knowledge of its dynamic model: local\n dynamics at a single point and the bounds on the rate of change of these\n dynamics. This method synthesizes control actions by utilizing locally learned\n dynamics along a trajectory, based on data available up to that moment, and\n known proxy dynamics, which can generate an underapproximation of the unknown\n system's true reachable set. An important benefit to the contributions of this\n paper is the lack of knowledge needed to execute the presented control method.\n We establish sufficient conditions to ensure that a controlled trajectory\n reaches a small neighborhood of any provably reachable state within a short\n time horizon, with precision dependent on the tunable parameters of these\n conditions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1902.03843",
        "title": "A Sundaram type bijection for $\\mathrm{SO}(2k+1)$: vacillating tableaux\n  and pairs consisting of a standard Young tableau and an orthogonal\n  Littlewood-Richardson tableau",
        "abstract": "We present a bijection between vacillating tableaux and pairs consisting of a\n standard Young tableau and an orthogonal Littlewood-Richardson tableau for the\n special orthogonal group $\\mathrm{SO}(2k+1)$. This bijection is motivated by\n the direct-sum-decomposition of the $r$th tensor power of the defining\n representation of $\\mathrm{SO}(2k+1)$. To formulate it, we use Kwon's\n orthogonal Littlewood-Richardson tableaux and introduce new alternative\n tableaux they are in bijection with. Moreover we use a suitably defined descent\n set for vacillating tableaux to determine the quasi-symmetric expansion of the\n Frobenius characters of the isotypic components.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2102.04754",
        "title": "Bayesian Transformer Language Models for Speech Recognition",
        "abstract": "State-of-the-art neural language models (LMs) represented by Transformers are\n highly complex. Their use of fixed, deterministic parameter estimates fail to\n account for model uncertainty and lead to over-fitting and poor generalization\n when given limited training data. In order to address these issues, this paper\n proposes a full Bayesian learning framework for Transformer LM estimation.\n Efficient variational inference based approaches are used to estimate the\n latent parameter posterior distributions associated with different parts of the\n Transformer model architecture including multi-head self-attention, feed\n forward and embedding layers. Statistically significant word error rate (WER)\n reductions up to 0.5\\% absolute (3.18\\% relative) and consistent perplexity\n gains were obtained over the baseline Transformer LMs on state-of-the-art\n Switchboard corpus trained LF-MMI factored TDNN systems with i-Vector speaker\n adaptation. Performance improvements were also obtained on a cross domain LM\n adaptation task requiring porting a Transformer LM trained on the Switchboard\n and Fisher data to a low-resource DementiaBank elderly speech corpus.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0107377",
        "title": "Resonant X-Ray Scattering from the Quadrupolar Ordering Phase of CeB_6",
        "abstract": "We theoretically investigate the origin of the resonant x-ray scattering\n (RXS) signal near the Ce $L_{III}$ absorption edge in the quadrupolar ordering\n phase of CeB$_6$, considering the intersite interaction between the $\\Gamma_8$\n states in the initial state. The anisotropic charge distribution of the $4f$\n states modulates the $5d$ states through the intra-atomic Coulomb interaction\n and thereby generates a large RXS superlattice intensity. The temperature and\n magnetic field dependence indicates that the induced dipolar and octupolar\n orders have little influence on the RXS spectra, in good agreement with the\n recent experiment.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2304.06087",
        "title": "High-Fidelity, Frequency-Flexible Two-Qubit Fluxonium Gates with a\n  Transmon Coupler",
        "abstract": "We propose and demonstrate an architecture for fluxonium-fluxonium two-qubit\n gates mediated by transmon couplers (FTF, for fluxonium-transmon-fluxonium).\n Relative to architectures that exclusively rely on a direct coupling between\n fluxonium qubits, FTF enables stronger couplings for gates using\n non-computational states while simultaneously suppressing the static\n controlled-phase entangling rate ($ZZ$) down to kHz levels, all without\n requiring strict parameter matching. Here we implement FTF with a flux-tunable\n transmon coupler and demonstrate a microwave-activated controlled-Z (CZ) gate\n whose operation frequency can be tuned over a 2 GHz range, adding frequency\n allocation freedom for FTF's in larger systems. Across this range,\n state-of-the-art CZ gate fidelities were observed over many bias points and\n reproduced across the two devices characterized in this work. After optimizing\n both the operation frequency and the gate duration, we achieved peak CZ\n fidelities in the 99.85-99.9\\% range. Finally, we implemented model-free\n reinforcement learning of the pulse parameters to boost the mean gate fidelity\n up to $99.922\\pm0.009\\%$, averaged over roughly an hour between scheduled\n training runs. Beyond the microwave-activated CZ gate we present here, FTF can\n be applied to a variety of other fluxonium gate schemes to improve gate\n fidelities and passively reduce unwanted $ZZ$ interactions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1405.1463",
        "title": "Mixed quantum states in higher categories",
        "abstract": "There are two ways to describe the interaction between classical and quantum\n information categorically: one based on completely positive maps between\n Frobenius algebras, the other using symmetric monoidal 2-categories. This paper\n makes a first step towards combining the two. The integrated approach allows a\n unified description of quantum teleportation and classical encryption in a\n single 2-category, as well as a universal security proof applicable\n simultaneously to both scenarios.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0806.0068",
        "title": "An exploratory analysis of the transient and long term behaviour of\n  small 3D perturbations in the circular cylinder wake",
        "abstract": "An initial-value problem for arbitrary small 3D vorticity perturbations\n imposed on a free shear flow is considered. The viscous perturbation equations\n are then combined in terms of the vorticity and velocity, and are solved by\n means of a combined Laplace-Fourier transform in the plane normal to the basic\n flow. This treatment allows for a simplification of the governing equations\n such that it is possible to observe long transients, that can last hundreds\n time scales. This result would not be possible over an acceptable lapse of time\n by carrying out a direct numerical integration of the linearized Navier-Stokes\n equations. The exploration is done with respect to physical inputs as the angle\n of obliquity, the symmetry of the perturbation and the streamwise damping rate.\n The base flow is an intermediate section of the growing 2D circular cylinder\n wake where the entrainment process is still active. Two Reynolds numbers of the\n order of the critical value for the onset of the first instability are\n considered. The early transient evolution offers very different scenarios for\n which we present a summary for particular cases. For example, for amplified\n perturbations, we have observed two kinds of transients, namely (1) a monotone\n amplification and (2) a sequence of growth - decrease - final growth. In the\n latter case, if the initial condition is an asymmetric oblique or longitudinal\n perturbation, the transient clearly shows an initial oscillatory time scale.\n Furthermore, the more a perturbation is longitudinally confined the more it is\n amplified in time. The long-term behavior of two-dimensional disturbances shows\n excellent agreement with a recent two-dimensional spatio-temporal multiscale\n modal analysis and with laboratory data concerning the frequency and wave\n length of the parallel vortex shedding in the cylinder wake.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.00958",
        "title": "Arbitrarily accurate twin composite $\\pi$ pulse sequences",
        "abstract": "We present three classes of symmetric broadband composite pulse sequences.\n The composite phases are given by analytic formulas (rational fractions of\n $\\pi$) valid for any number of constituent pulses. The transition probability\n is expressed by simple analytic formulas and the order of pulse area error\n compensation grows linearly with the number of pulses. Therefore, any desired\n compensation order can be produced by an appropriate composite sequence; in\n this sense, they are arbitrarily accurate. These composite pulses perform\n equally well or better than previously published ones. Moreover, the current\n sequences are more flexible as they allow total pulse areas of arbitrary\n integer multiples of $\\pi$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1502.08047",
        "title": "$L^2$ estimates for the $\\bar \\partial$ operator",
        "abstract": "This is a survey article about $L^2$ estimates for the $\\bar \\partial$\n operator. After a review of the basic approach that has come to be called the\n \"Bochner-Kodaira Technique\", the focus is on twisted techniques and their\n applications to estimates for $\\bar \\partial$, to $L^2$ extension theorems, and\n to other problems in complex analysis and geometry, including invariant metric\n estimates and the $\\bar \\partial$-Neumann Problem.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1005.2199",
        "title": "On rational homology disk smoothings of valency 4 surface singularities",
        "abstract": "Thanks to the recent work of Bhupal, Stipsicz, Szabo, and the author, one has\n a complete list of resolution graphs of weighted homogeneous complex surface\n singularities admitting a rational homology disk (\"QHD\") smoothing, i.e., one\n with Milnor number 0. They fall into several classes, the most interesting of\n which are the three classes whose resolution dual graph has central vertex with\n valency 4. We give a uniform \"quotient construction\" of the QHD smoothings for\n these classes; it is an explicit Q-Gorenstein smoothing, yielding a precise\n description of the Milnor fibre and its non-abelian fundamental group. This had\n already been done for two of these classes in a previous paper; what is new\n here is the construction of the third class, which is far more difficult. In\n addition, we explain the existence of two different QHD smoothings for the\n first class.\n  We also prove a general formula for the dimension of a QHD smoothing\n component for a rational surface singularity. A corollary is that for the\n valency 4 cases, such a component has dimension 1 and is smooth. Another\n corollary is that \"most\" H-shaped resolution graphs cannot be the graph of a\n singularity with a QHD smoothing. This result, plus recent work of\n Bhupal-Stipsicz, is evidence for a general\n  Conjecture: The only complex surface singularities with a QHD smoothing are\n the (known) weighted homogeneous examples.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0505544",
        "title": "Boxicity and Treewidth",
        "abstract": "In this paper, we relate the seemingly unrelated concepts of treewidth and\n boxicity. Our main result is that, for any graph G, boxicity(G) <= treewidth(G)\n + 2. We also show that this upper bound is (almost) tight. Our result leads to\n various interesting consequences, like bounding the boxicity of many well known\n graph classes, such as chordal graphs, circular arc graphs, AT-free graphs,\n co--comparability graphs etc. All our bounds are shown to be tight up to small\n constant factors. An algorithmic consequence of our result is a linear time\n algorithm to construct a box representation for graphs of bounded treewidth in\n a space of constant dimension. We also show many structural results as a\n consequence. In particular, we show that, if the boxicity of a graph is b >= 3,\n then there exists a simple cycle of length at least b-3 as well as an induced\n cycle of length at least floor of (log(b-2) to the base Delta) + 2, where Delta\n is its maximum degree. We also relate boxicity with the cardinality of minimum\n vertex cover, minimum feedback vertex cover etc. Another structural consequence\n is that, for any fixed planar graph H, there is a constant c(H) such that, if\n boxicity(G) >= c(H) then H is a minor of G.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1911.08491",
        "title": "The Pristine survey X: a large population of low-metallicity stars\n  permeates the Galactic disk",
        "abstract": "The orbits of the least chemically enriched stars open a window on the\n formation of our Galaxy when it was still in its infancy. The common picture is\n that these low-metallicity stars are distributed as an isotropic,\n pressure-supported component since these stars were either accreted from the\n early building blocks of the assembling Milky Way, or were later brought by the\n accretion of faint dwarf galaxies. Combining the metallicities and radial\n velocities from the Pristine and LAMOST surveys and Gaia DR2 parallaxes and\n proper motions for an unprecedented large and unbiased sample of very\n metal-poor stars at $[Fe/H]\\leq-2.5$ we show that this picture is incomplete.\n This sample shows strong statistical evidence (at the $5.0\\sigma$ level) of\n asymmetry in their kinematics, favouring prograde motion. Moreover, we find\n that $31\\%$ of the stars that currently reside in the disk do not venture\n outside of the disk plane throughout their orbit. The discovery of this\n population implies that a significant fraction of stars with iron abundances\n $[Fe/H]\\leq-2.5$ formed within or concurrently with the Milky Way disk and that\n the history of the disk was quiet enough to allow them to retain their\n disk-like orbital properties.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/0009140",
        "title": "Single chargino production at linear colliders",
        "abstract": "We study the single chargino production $e^+ e^- \\to \\tilde \\chi^{\\pm}\n \\mu^{\\mp}$ at linear colliders which occurs through the $\\l_{121}$ R-parity\n violating coupling constant. We focus on the final state containing 4 leptons\n and some missing energy. The largest background is \\susyq and can be reduced\n using the initial beam polarization and some cuts based on the specific\n kinematics of the single chargino production. Assuming the highest allowed\n supersymmetric background, a center of mass energy of $\\sqrt s=500GeV$ and a\n luminosity of ${\\cal L}=500fb^{-1}$, the sensitivities on the $\\l_{121}$\n coupling constant obtained from the single chargino production study improve\n the low-energy experimental limit over a range of $\\Delta m_{\\tilde \\nu}\n \\approx 500GeV$ around the sneutrino resonance, and reach values of $\\sim\n 10^{-4}$ at the $\\tilde \\nu$ pole. The single chargino production also allows\n to reconstruct the $\\tilde \\chi_1^{\\pm}$, $\\tilde \\chi_2^{\\pm}$ and $\\tilde\n \\nu$ masses. The initial state radiation plays a fundamental role in this\n study.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.13620",
        "title": "Optical Continuum Reverberation in the Dwarf Seyfert Nucleus of NGC 4395",
        "abstract": "The nearby dwarf spiral galaxy NGC 4395 contains a broad-lined active\n galactic nucleus (AGN) of exceptionally low luminosity powered by accretion\n onto a central black hole of very low mass ($\\sim10^4-10^5$ M$_\\odot$). In\n order to constrain the size of the optical continuum emission region through\n reverberation mapping, we carried out high-cadence photometric monitoring of\n NGC 4395 in the $griz$ filter bands on two consecutive nights in 2022 April\n using the four-channel MuSCAT3 camera on the Faulkes Telescope North at\n Haleakal\\={a} Observatory. Correlated variability across the $griz$ bands is\n clearly detected, and the $r$, $i$, and $z$ band light curves show lags of\n $8.4^{+1.0}_{-1.1}$, $14.2^{+1.2}_{-1.4}$, and $20.4^{+2.0}_{-2.1}$ minutes\n with respect to the $g$ band when measured using the full-duration light\n curves. When lags are measured for each night separately, the Night 2 data\n exhibit lower cross-correlation amplitudes and shorter lags than the Night 1\n light curves. Using the full-duration lags, we find that the lag-wavelength\n relationship is consistent with the $\\tau\\propto\\lambda^{4/3}$ dependence found\n for more luminous AGN. Combining our results with continuum lags measured for\n other objects, the lag between $g$ and $z$ band scales with optical continuum\n luminosity as $\\tau_{gz} \\propto L^{0.56\\pm0.05}$, similar to the scaling of\n broad-line region size with luminosity, reinforcing recent evidence that\n diffuse continuum emission from the broad-line region may contribute\n substantially to optical continuum variability and reverberation lags.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2109.10316",
        "title": "Direct and clean loading of nanoparticles into optical traps at millibar\n  pressures",
        "abstract": "Nanoparticles levitated by optical fields under vacuum conditions have\n applications in quantum science, the study of nanothermodynamics and precision\n sensing. Existing techniques for loading optical traps require ambient\n conditions, and often involve dispersion in liquids, which can contaminate\n delicate optics and lead to enhanced optical absorption and heating. Here we\n present a clean, dry and generic mechanism for directly loading optical traps\n at pressures down to 1\\,mbar, exploiting Laser Induced Acoustic Desorption. Our\n method allows rapid and efficient trapping, and is also suitable for\n site-selective loading of nanofabricated particles grown on a silicon\n substrate.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2301.01014",
        "title": "Trichotomy Theorem for Prescribed Scalar and Mean Curvatures on Compact\n  Manifolds with Boundaries",
        "abstract": "In this article, we give results of prescribing scalar and mean curvature\n functions for metrics either pointwise conformal or conformally equivalent to a\n Riemannian metric that is equipped on a compact manifold with boundary, with\n dimensions at least $ 3 $. The results are classified by the sign of the first\n eigenvalue of the conformal Laplacian. This leads to a \"Trichotomy Theorem\" in\n terms of both scalar and mean curvature functions, which is a full extension of\n the \"Trichotomy Theorem\" given by Kazdan and Warner. We also discuss\n prescribing Gauss and geodesic curvature problems on compact Riemann surfaces\n with boundary for metrics either pointwise conformal or conformally equivalent\n to the original metric, provided that the Euler characteristic is negative. The\n key step is a general version of monotone iteration scheme which handle the\n zeroth order nonlinear term on the boundary conditions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.03219",
        "title": "$L^{q}$-error estimates for approximation of irregular functionals of\n  random vectors",
        "abstract": "Avikainen showed that, for any $p,q \\in [1,\\infty)$, and any function $f$ of\n bounded variation in $\\mathbb{R}$, it holds that\n $\\mathbb{E}[|f(X)-f(\\widehat{X})|^{q}] \\leq C(p,q)\n \\mathbb{E}[|X-\\widehat{X}|^{p}]^{\\frac{1}{p+1}}$, where $X$ is a\n one-dimensional random variable with a bounded density, and $\\widehat{X}$ is an\n arbitrary random variable. In this article, we will provide multi-dimensional\n versions of this estimate for functions of bounded variation in\n $\\mathbb{R}^{d}$, Orlicz--Sobolev spaces, Sobolev spaces with variable\n exponents, and fractional Sobolev spaces. The main idea of our arguments is to\n use the Hardy--Littlewood maximal estimates and pointwise characterizations of\n these function spaces. We apply our main results to analyze the numerical\n approximation for some irregular functionals of the solution of stochastic\n differential equations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2112.03961",
        "title": "Edge Clique Covers in Graphs with Independence Number Two: a Special\n  Case",
        "abstract": "The edge clique cover number $ecc(G)$ of a graph $G$ is the size of the\n smallest set of complete subgraphs whose union covers all edges of $G$. It has\n been conjectured that all the simple graphs with independence number two\n satisfy $ecc(G)\\leq n$. First, we present a class of graphs containing edges\n difficult to cover but that satisfy the conjecture. Second, we describe a large\n class of graphs $G$ such that $ecc(G)\\leq \\frac{3}{2}n$. This class is easy to\n characterize.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2111.11761",
        "title": "Confronting quantum-corrected teleparallel cosmology with observations",
        "abstract": "It has been shown that at the semi-classical order, gravitational theories\n with quantum fluctuations can be effectively recast as modified theories of\n gravity with non-minimal gravity-matter couplings. We proceed from an\n observational perspective and see whether such quantum fluctuations can leave\n imprints on the late Universe. Within the teleparallel formulation, we\n investigate a representative model in this general class of modified\n gravitational theories inlaid with quantum fluctuations, and determine the\n cosmological parameters by using compiled late-time data sets. Furthermore, we\n assess the statistical significance of such quantum corrections compared to the\n standard cosmological model. The results mildly favor the inclusion of quantum\n corrections with a negative density parameter supporting a phantom-like dark\n energy. This edge is not sufficient to rule out either models but it supports\n the consideration of quantum corrections in a cosmological setting.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2102.09372",
        "title": "Mobile Apps Prioritizing Privacy, Efficiency and Equity: A Decentralized\n  Approach to COVID-19 Vaccination Coordination",
        "abstract": "In this early draft, we describe a decentralized, app-based approach to\n COVID-19 vaccine distribution that facilitates zero knowledge verification,\n dynamic vaccine scheduling, continuous symptoms reporting, access to aggregate\n analytics based on population trends and more. To ensure equity, our solution\n is developed to work with limited internet access as well. In addition, we\n describe the six critical functions that we believe last mile vaccination\n management platforms must perform, examine existing vaccine management systems,\n and present a model for privacy-focused, individual-centric solutions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.09942",
        "title": "OptiRoute: A Heuristic-assisted Deep Reinforcement Learning Framework\n  for UAV-UGV Collaborative Route Planning",
        "abstract": "Unmanned aerial vehicles (UAVs) are capable of surveying expansive areas, but\n their operational range is constrained by limited battery capacity. The\n deployment of mobile recharging stations using unmanned ground vehicles (UGVs)\n significantly extends the endurance and effectiveness of UAVs. However,\n optimizing the routes of both UAVs and UGVs, known as the UAV-UGV cooperative\n routing problem, poses substantial challenges, particularly with respect to the\n selection of recharging locations. Here in this paper, we leverage\n reinforcement learning (RL) for the purpose of identifying optimal recharging\n locations while employing constraint programming to determine cooperative\n routes for the UAV and UGV. Our proposed framework is then benchmarked against\n a baseline solution that employs Genetic Algorithms (GA) to select rendezvous\n points. Our findings reveal that RL surpasses GA in terms of reducing overall\n mission time, minimizing UAV-UGV idle time, and mitigating energy consumption\n for both the UAV and UGV. These results underscore the efficacy of\n incorporating heuristics to assist RL, a method we refer to as\n heuristics-assisted RL, in generating high-quality solutions for intricate\n routing problems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1409.8165",
        "title": "Theory for Baryon Number and Dark Matter at the LHC",
        "abstract": "We investigate the possibility to test the simplest theory for spontaneous\n baryon number violation at the Large Hadron Collider. In this context the\n baryon number is a local gauge symmetry spontaneously broken at the low scale\n through the Brout-Englert-Higgs mechanism. This theory predicts the existence\n of a leptophobic neutral gauge boson and a fermionic dark matter candidate with\n baryon number. We study the gauge boson and Higgs decays, and explore the\n connection between collider signatures and constraints coming from dark matter\n experiments. We point out an upper bound on the symmetry breaking scale using\n the relic density constraints which tells us that this model can be tested or\n ruled out at current or future collider experiments.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1505.01738",
        "title": "Radiative Neutrino Mass Models",
        "abstract": "In this short review, we see some typical models in which light neutrino\n masses are generated at the loop level. These models involve new Higgs bosons\n whose Yukawa interactions with leptons are constrained by the neutrino\n oscillation data. Predictions about flavor structures of $\\ell \\to\n \\overline{\\ell}_1 \\ell_2 \\ell_3$ and leptonic decays of new Higgs bosons via\n the constrained Yukawa interactions are briefly summarized in order to utilize\n such Higgs as a probe of $\\nu$ physics.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2210.03102",
        "title": "Ambiguous Images With Human Judgments for Robust Visual Event\n  Classification",
        "abstract": "Contemporary vision benchmarks predominantly consider tasks on which humans\n can achieve near-perfect performance. However, humans are frequently presented\n with visual data that they cannot classify with 100% certainty, and models\n trained on standard vision benchmarks achieve low performance when evaluated on\n this data. To address this issue, we introduce a procedure for creating\n datasets of ambiguous images and use it to produce SQUID-E (\"Squidy\"), a\n collection of noisy images extracted from videos. All images are annotated with\n ground truth values and a test set is annotated with human uncertainty\n judgments. We use this dataset to characterize human uncertainty in vision\n tasks and evaluate existing visual event classification models. Experimental\n results suggest that existing vision models are not sufficiently equipped to\n provide meaningful outputs for ambiguous images and that datasets of this\n nature can be used to assess and improve such models through model training and\n direct evaluation of model calibration. These findings motivate large-scale\n ambiguous dataset creation and further research focusing on noisy visual data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/physics/0211096",
        "title": "Scanning the structure of ill-known spaces: Part 1. Founding principles\n  about mathematical constitution of space",
        "abstract": "Necessary and sufficient conditions allowing a previously unknown space to be\n explored through scanning operators are reexamined with respect to measure\n theory. Generalized conceptions of distances and dimensionality evaluation are\n proposed, together with their conditions of validity and range of application\n to topological spaces. The existence of a Boolean lattice with fractal\n properties originating from nonwellfounded properties of the empty set is\n demonstrated. This lattice provides a substrate with both discrete and\n continuous properties, from which existence of physical universes can be\n proved, up to the function of conscious perception. Spacetime emerges as an\n ordered sequence of mappings of closed 3-D Ponicare sections of a topological\n 4-space provided by the lattice. The possibility of existence of spaces with\n fuzzy dimension or with adjoined parts with decreasing dimensions is raised,\n together with possible tools for their study. The work provides the\n introductory foundations supporting a new theory of space whose physical\n predictions (suppressing the opposition of quantum and relativistic approaches)\n and experimental proofs are presented in details in Parts 2 and 3 of the study.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1912.04787",
        "title": "Deformations of representations of fundamental groups of complex\n  varieties",
        "abstract": "We describe locally the representation varieties of fundamental groups for\n smooth complex varieties at representations coming from the monodromy of a\n variation of mixed Hodge structure. Given such a manifold $X$ and such a linear\n representation $\\rho$ of its fundamental group $\\pi_1(X,x)$, we use the theory\n of Goldman-Millson and pursue our previous work that combines mixed Hodge\n theory with derived deformation theory to construct a mixed Hodge structure on\n the formal local ring $\\widehat{\\mathcal{O}}_\\rho$ to the representation\n variety of $\\pi_1(X,x)$ at $\\rho$. Then we show how a weighted-homogeneous\n presentation of $\\widehat{\\mathcal{O}}_\\rho$ is induced directly from a\n splitting of the weight filtration of its mixed Hodge structure. In this way we\n recover and generalize theorems of Eyssidieux-Simpson ($X$ compact) and of\n Kapovich-Millson ($\\rho$ finite).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2109.04913",
        "title": "Adjoint Differentiation for generic matrix functions",
        "abstract": "We derive a formula for the adjoint $\\overline{A}$ of a square-matrix\n operation of the form $C=f(A)$, where $f$ is holomorphic in the neighborhood of\n each eigenvalue. We then apply the formula to derive closed-form expressions in\n particular cases of interest such as the case when we have a spectral\n decomposition $A=UDU^{-1}$, the spectrum cut-off $C=A_+$ and the Nearest\n Correlation Matrix routine. Finally, we explain how to simplify the computation\n of adjoints for regularized linear regression coefficients.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/0609274",
        "title": "The Standard Model: Alchemy and Astrology",
        "abstract": "An brief unconventional review of Standard Model physics, containing no\n plots.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2001.11108",
        "title": "D2M: Dynamic Defense and Modeling of Adversarial Movement in Networks",
        "abstract": "Given a large enterprise network of devices and their authentication history\n (e.g., device logons), how can we quantify network vulnerability to lateral\n attack and identify at-risk devices? We systematically address these problems\n through D2M, the first framework that models lateral attacks on enterprise\n networks using multiple attack strategies developed with researchers,\n engineers, and threat hunters in the Microsoft Defender Advanced Threat\n Protection group. These strategies integrate real-world adversarial actions\n (e.g., privilege escalation) to generate attack paths: a series of compromised\n machines. Leveraging these attack paths and a novel Monte-Carlo method, we\n formulate network vulnerability as a probabilistic function of the network\n topology, distribution of access credentials and initial penetration point. To\n identify machines at risk to lateral attack, we propose a suite of five fast\n graph mining techniques, including a novel technique called AnomalyShield\n inspired by node immunization research. Using three real-world authentication\n graphs from Microsoft and Los Alamos National Laboratory (up to 223,399\n authentications), we report the first experimental results on network\n vulnerability to lateral attack, demonstrating D2M's unique potential to\n empower IT admins to develop robust user access credential policies.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1908.10529",
        "title": "Semiclassical inverse spectral problem for elastic Love waves in\n  isotropic media",
        "abstract": "We analyze the inverse spectral problem on the half line associated with\n elastic surface waves. Here, we focus on Love waves. Under certain generic\n conditions, we establish uniqueness and present a reconstruction scheme for the\n S- wavespeed with multiple wells from the semiclassical spectrum of these\n waves.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2307.04897",
        "title": "Spin-EPR-pair separation by conveyor-mode single electron shuttling in\n  Si/SiGe",
        "abstract": "Long-ranged coherent qubit coupling is a missing function block for scaling\n up spin qubit based quantum computing solutions. Spin-coherent conveyor-mode\n electron-shuttling could enable spin quantum-chips with scalable and sparse\n qubit-architecture. Its key feature is the operation by only few easily\n tuneable input terminals and compatibility with industrial gate-fabrication.\n Single electron shuttling in conveyor-mode in a 420 nm long quantum bus has\n been demonstrated previously. Here we investigate the spin coherence during\n conveyor-mode shuttling by separation and rejoining an Einstein-Podolsky-Rosen\n (EPR) spin-pair. Compared to previous work we boost the shuttle velocity by a\n factor of 10000. We observe a rising spin-qubit dephasing time with the longer\n shuttle distances due to motional narrowing and estimate the spin-shuttle\n infidelity due to dephasing to be 0.7 % for a total shuttle distance of nominal\n 560 nm. Shuttling several loops up to an accumulated distance of 3.36 $\\mu$m,\n spin-entanglement of the EPR pair is still detectable, giving good perspective\n for our approach of a shuttle-based scalable quantum computing architecture in\n silicon.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2211.09975",
        "title": "Explicit bounds for large gaps between squarefree integers",
        "abstract": "We obtain explicit forms of the current best known asymptotic upper bounds\n for gaps between squarefree integers. In particular we show, for any $x \\ge 2$,\n that every interval of the form $(x, x + 11x^{1/5}\\log x]$ contains a\n squarefree integer. The constant 11 can be improved further, if $x$ is assumed\n to be larger than a (very) large constant.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1511.01566",
        "title": "DEMONIC programming: a computational language for single-particle\n  equilibrium thermodynamics, and its formal semantics",
        "abstract": "Maxwell's Demon, 'a being whose faculties are so sharpened that he can follow\n every molecule in its course', has been the centre of much debate about its\n abilities to violate the second law of thermodynamics. Landauer's hypothesis,\n that the Demon must erase its memory and incur a thermodynamic cost, has become\n the standard response to Maxwell's dilemma, and its implications for the\n thermodynamics of computation reach into many areas of quantum and classical\n computing. It remains, however, still a hypothesis. Debate has often centred\n around simple toy models of a single particle in a box. Despite their\n simplicity, the ability of these systems to accurately represent thermodynamics\n (specifically to satisfy the second law) and whether or not they display\n Landauer Erasure, has been a matter of ongoing argument. The recent\n Norton-Ladyman controversy is one such example.\n  In this paper we introduce a programming language to describe these simple\n thermodynamic processes, and give a formal operational semantics and program\n logic as a basis for formal reasoning about thermodynamic systems. We formalise\n the basic single-particle operations as statements in the language, and then\n show that the second law must be satisfied by any composition of these basic\n operations. This is done by finding a computational invariant of the system. We\n show, furthermore, that this invariant requires an erasure cost to exist within\n the system, equal to kTln2 for a bit of information: Landauer Erasure becomes a\n theorem of the formal system. The Norton-Ladyman controversy can therefore be\n resolved in a rigorous fashion, and moreover the formalism we introduce gives a\n set of reasoning tools for further analysis of Landauer erasure, which are\n provably consistent with the second law of thermodynamics.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1609.09574",
        "title": "Multiple-scale analysis on the radiation within the coupled KdV\n  equations",
        "abstract": "A multiple scale model of the nonlinearly coupled KdV equations is\n established to predict mechanism of interaction of equatorial Rossby waves and\n barotropic waves in certain case. Analytically, predicted precursor radiation\n is a centrosymmetric object and is shown in excellent quantitative agreement\n with numerical simulations; furthermore, the multiple scale model elucidates\n the salient mechanisms of the interaction of solitary waves and the mechanism\n for radiation. While the atmosphere-ocean science community is very interested\n in theoretical studies of tropical wave interactions and in developing reduced\n dynamical models that can explain some key features of equatorial phenomena,\n our analytic predictions quantitively explain formation of radiation during\n interaction in Biello's model beyond qualitative level.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1011.3221",
        "title": "Reflected backward doubly stochastic differential equations with\n  discontinuous generator",
        "abstract": "In this note, we study one-dimensional reflected backward doubly stochastic\n differential equations (RBDSDEs) with one continuous barrier and discontinuous\n generator (left-or right-continuous). By a comparison theorem establish here\n for RBDSDEs, we provide a minimal or a maximal solution to RBDSDEs",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.08957",
        "title": "Effect of Deviations from General Relativity on Searches for\n  Gravitational Wave Microlensing and Type II Strong Lensing",
        "abstract": "As the gravitational wave detector network is upgraded and the sensitivity of\n the detectors improves, novel scientific avenues open for exploration. For\n example, tests of general relativity will become more accurate as smaller\n deviations can be probed. Additionally, the detection of lensed gravitational\n waves becomes more likely. However, these new avenues could also interact with\n each other, and a gravitational wave event presenting deviations from general\n relativity could be mistaken for a lensed one. Here, we explore how\n phenomenological deviations from general relativity or binaries of exotic\n compact objects could impact those lensing searches focusing on a single event.\n We consider strong lensing, millilensing, and microlensing and find that\n certain phenomenological deviations from general relativity may be mistaken for\n all of these types of lensing. Therefore, our study shows that future candidate\n lensing events would need to be carefully examined to avoid a false claim of\n lensing where instead a deviation from general relativity has been seen.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2204.12739",
        "title": "Analysis of the data from photoelectric gas polarimeters",
        "abstract": "We review the tools and procedures for the analysis of the data collected by\n X-ray photoelectric gas polarimeters, like the ones on-board the Imaging X-ray\n Polarimetry Explorer (IXPE). Although many of such tools are in principle\n common with polarimeters working at other energy bands, the peculiar\n characteristics and performance of these devices require a specific approach.\n We will start from the analysis of the raw data read-out from this kind of\n instruments, that is, the image of the track of the photoelectron. We will\n briefly present how such images are processed with highly-specialized\n algorithms to extract all the information collected by the instrument. These\n include energy, time of arrival and, possibly, absorption point of the photon,\n in addition to the initial direction of emission of the photoelectron. The last\n is the quantity relevant for polarimetry, and we will present different methods\n to obtain the polarization degree and angle from it. A simple method, used\n extensively especially during the development phase of X-ray photoelectric gas\n polarimeters, is based on the construction and fitting of the azimuthal\n distribution of the photoelectrons. We will discuss that there are several\n reasons to prefer an analysis based on Stokes parameters, especially when one\n wants to analyze measurements of real, i.e., not laboratory, sources. These are\n quantities commonly used at all wavelengths because they are additive, and then\n operations like background subtraction or the application of calibration are\n trivial to apply. We will summarize how Stokes parameters can be used to adapt\n current spectroscopy software based on forward folding fitting to perform\n spectro-polarimetry. Moreover, we will derive how to properly associate the\n statistical uncertainty on a polarimetry measurement and the relation with\n another statistical indicator, which is in the minimum detectable polarization.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1405.2646",
        "title": "Consecuencias geom\\'etricas y din\\'amicas de la m\\'ultiple adsorci\\'on\n  de Litio y otros alcalinos en poliacenos, poli-parafenilenos y hojuelas de\n  grafeno",
        "abstract": "We study the spontaneous symmetry breaking due to adsorption of Lithium atoms\n on polyacenes and aromatic molecules consistent on carbon rings with edges\n closed by bond of hydrogen atoms. Hartree Fock and DFT calculations were made\n for polyacenes, poly-para-phenyls and carbon sheets of sizes that show\n properties of graphene. As a result, the spontaneous symmetry breaking on\n polyacenes due to the adsorption of multiple pairs of Lithium atoms on opposite\n sides find expla- nation on the Peierls distortion. We also found that there\n are no sponta- neous symmetry breaking due to adsorption of other alkalines in\n polyacenes and the only case showing a distortion of polyacene is when a pair\n of Sodium atoms is adsorbed on it. Although there were previous studies about\n adsorption of metals on lar- ge sheet of carbon, we initially wanted to\n simplify the problem so that allowed us to obtain a better understanding of the\n reasons for symmetry breaking and then extend it to complex structures, for\n which, we found that the Peierls distortion is observable in small flakes, with\n appropriate symmetry, but can not be generalized to larger flakes and neither\n graphene strips as the minimum energy states of these cases do not correspond\n to this distortion. As an application on the methods we have used in the\n present work, a me- chanism for the decomposition reactions of chloromethane,\n dichloromethane and formyl chloride on graphene surface is proposed. For this,\n we calculate the reactions on the graphene surface with a Lithium atom absorbed\n on the center of it at the opposite side and we found intermediate production\n of radicals is reduced.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1606.00268",
        "title": "Certain Chromatic Sums of Some Cycle Related Graph Classes",
        "abstract": "Let $\\mathcal{C} = \\{c_1,c_2, c_3, \\ldots,c_k\\}$ be a certain type of proper\n $k$-colouring of a given graph $G$ and $\\theta(c_i)$ denote the number of times\n a particular colour $c_i$ is assigned to the vertices of $G$. Then, the\n colouring sum of a given graph $G$ with respect to the colouring $\\cC$, denoted\n by $\\omega_{\\cC}(G)$, is defined to be $\\omega(\\cC) =\n \\sum\\limits_{i=1}^{k}i\\,\\theta(c_i)$. The colouring sums such as\n $\\chi$-chromatic sum, $\\chi^+$-chromatic sum, $b$-chromatic sum,\n $b^+$-chromatic sum etc. are some of these types of colouring sums that have\n been studied recently. Motivated by these studies on certain chromatic sums of\n graphs, in this paper, we study certain chromatic sums for some standard cycle\n related graphs.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1307.5000",
        "title": "Weyl composition of symbols in large dimension",
        "abstract": "This paper is concerned with the Weyl composition of symbols in large\n dimension. We specify a class of symbols in order to estimate the Weyl symbol\n of the product of two Weyl $h-$pseudodifferential operators, with constants\n independent of the dimension. The proof includes a regularized and a hybrid\n compositions together with a decomposition formula. We also analyze in this\n context the remainder term of the semiclassical expansion of the Weyl\n composition.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1906.03625",
        "title": "Soft-ranking Label Encoding for Robust Facial Age Estimation",
        "abstract": "Automatic facial age estimation can be used in a wide range of real-world\n applications. However, this process is challenging due to the randomness and\n slowness of the aging process. Accordingly, in this paper, we propose a\n comprehensive framework aimed at overcoming the challenges associated with\n facial age estimation. First, we propose a novel age encoding method, referred\n to as 'Soft-ranking', which encodes two important properties of facial age,\n i.e., the ordinal property and the correlation between adjacent ages.\n Therefore, Soft-ranking provides a richer supervision signal for training deep\n models. Moreover, we also carefully analyze existing evaluation protocols for\n age estimation, finding that the overlap in identity between the training and\n testing sets affects the relative performance of different age encoding\n methods. Finally, since existing face databases for age estimation are\n generally small, deep models tend to suffer from an overfitting problem. To\n address this issue, we propose a novel regularization strategy to encourage\n deep models to learn more robust features from facial parts for age estimation\n purposes. Extensive experiments indicate that the proposed techniques improve\n the age estimation performance; moreover, we achieve state-of-the-art\n performance on the three most popular age databases, $i.e.$, Morph II,\n CLAP2015, and CLAP2016.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1306.4986",
        "title": "Dynamics of thermalization and decoherence of a nanoscale system",
        "abstract": "We study the decoherence and thermalization dynamics of a nanoscale system\n coupled nonperturbatively to a fully quantum-mechanical bath. The system is\n prepared out of equilibrium in a pure state of the complete system. We propose\n a random matrix model and show analytically that there are two robust temporal\n regimes in the approach of the system to equilibrium --- an initial Gaussian\n decay followed by an exponential tail, consistent with numerical results on\n small interacting lattices [S. Genway, A.F. Ho and D.K.K. Lee, Phys. Rev. Lett.\n 105, 260402 (2010)]. Furthermore, the system decays towards a Gibbs ensemble in\n accordance with the eigenstate thermalization hypothesis.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1909.12608",
        "title": "Charge Induced Acceleration Noise in the LISA Gravitational Reference\n  Sensor",
        "abstract": "The presence of free charge on isolated proof-masses, such as those within\n space-borne gravitational reference sensors, causes a number of spurious forces\n which will give rise to associated acceleration noise. A complete discusssion\n of each charge induced force and its linear acceleration noise is presented.\n The resulting charge acceleration noise contributions to the LISA mission are\n evaluated using the LISA Pathfinder performance and design. It is shown that\n one term is largely dominant but that a full budget should be maintained for\n LISA and future missions due to the large number of possible contributions and\n their dependence on different sensor parameters.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.11765",
        "title": "Privacy-Preserving In-Context Learning with Differentially Private\n  Few-Shot Generation",
        "abstract": "We study the problem of in-context learning (ICL) with large language models\n (LLMs) on private datasets. This scenario poses privacy risks, as LLMs may leak\n or regurgitate the private examples demonstrated in the prompt. We propose a\n novel algorithm that generates synthetic few-shot demonstrations from the\n private dataset with formal differential privacy (DP) guarantees, and show\n empirically that it can achieve effective ICL. We conduct extensive experiments\n on standard benchmarks and compare our algorithm with non-private ICL and\n zero-shot solutions. Our results demonstrate that our algorithm can achieve\n competitive performance with strong privacy levels. These results open up new\n possibilities for ICL with privacy protection for a broad range of\n applications.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1705.09934",
        "title": "Probing various formulations of macrorealism for unsharp quantum\n  measurements",
        "abstract": "Standard Leggett and Garg inequalities (SLGIs) were formulated for testing\n the incompatibility between the classical worldview of macrorealism and quantum\n mechanics. In recent times, various other formulations, such as Wigner form of\n LGIs (WLGIs), entropic LGIs (ELGIs) and the no-signaling in time (NSIT)\n condition have also been proposed. It is also recently argued that no set of\n SLGIs can provide the necessary and sufficient conditions for macrorealism but\n a suitable conjunction of NSIT conditions provides the same. In this paper, we\n first provide a comparative study of the various formulations of LGIs for\n testing macrorealism pertaining to the two different unsharp measurements.\n While the violations of WLGIs are more robust than SLGIs and ELGIs for\n spin-POVMs, here we demonstrate that for the case of biased POVMs, the quantum\n violations of both SLGIs and ELGIs provide the same robustness as WLGIs.\n Importantly, the violations of all formulations of LGIs can be achieved for\n \\textit{any non-zero value} of unsharpness parameter. We have also studied the\n connection between LGIs and NSIT conditions. Further, we investigate the role\n of the joint measurability of the POVMs in the violation of LGIs and found that\n there is no generic connection.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1104.2939",
        "title": "Subexponential convergence for information aggregation on regular trees",
        "abstract": "We consider the decentralized binary hypothesis testing problem on trees of\n bounded degree and increasing depth. For a regular tree of depth t and\n branching factor k>=2, we assume that the leaves have access to independent and\n identically distributed noisy observations of the 'state of the world' s.\n Starting with the leaves, each node makes a decision in a finite alphabet M,\n that it sends to its parent in the tree. Finally, the root decides between the\n two possible states of the world based on the information it receives.\n  We prove that the error probability vanishes only subexponentially in the\n number of available observations, under quite general hypotheses. More\n precisely the case of binary messages, decay is subexponential for any decision\n rule. For general (finite) message alphabet M, decay is subexponential for\n 'node-oblivious' decision rules, that satisfy a mild irreducibility condition.\n In the latter case, we propose a family of decision rules with close-to-optimal\n asymptotic behavior.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0708.1616",
        "title": "Robustness of the second law of thermodynamics under generalizations of\n  the maximum entropy method",
        "abstract": "It is shown that the laws of thermodynamics are extremely robust under\n generalizations of the form of entropy. Using the Bregman-type relative\n entropy, the Clausius inequality is proved to be always valid. This implies\n that thermodynamics is highly universal and does not rule out consistent\n generalization of the maximum entropy method.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1711.06740",
        "title": "Information Gathering with Peers: Submodular Optimization with\n  Peer-Prediction Constraints",
        "abstract": "We study a problem of optimal information gathering from multiple data\n providers that need to be incentivized to provide accurate information. This\n problem arises in many real world applications that rely on crowdsourced data\n sets, but where the process of obtaining data is costly. A notable example of\n such a scenario is crowd sensing. To this end, we formulate the problem of\n optimal information gathering as maximization of a submodular function under a\n budget constraint, where the budget represents the total expected payment to\n data providers. Contrary to the existing approaches, we base our payments on\n incentives for accuracy and truthfulness, in particular, {\\em peer-prediction}\n methods that score each of the selected data providers against its best peer,\n while ensuring that the minimum expected payment is above a given threshold. We\n first show that the problem at hand is hard to approximate within a constant\n factor that is not dependent on the properties of the payment function.\n However, for given topological and analytical properties of the instance, we\n construct two greedy algorithms, respectively called PPCGreedy and\n PPCGreedyIter, and establish theoretical bounds on their performance w.r.t. the\n optimal solution. Finally, we evaluate our methods using a realistic crowd\n sensing testbed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2006.02829",
        "title": "The Enclaveless Competition Game",
        "abstract": "For a subset $S$ of vertices in a graph $G$, a vertex $v \\in S$ is an enclave\n of $S$ if $v$ and all of its neighbors are in $S$, where a neighbor of $v$ is a\n vertex adjacent to $v$. A set $S$ is enclaveless if it does not contain any\n enclaves. The enclaveless number $\\Psi(G)$ of $G$ is the maximum cardinality of\n an enclaveless set in $G$. As first observed in 1997 by Slater [J. Res. Nat.\n Bur. Standards 82 (1977), 197--202], if $G$ is a graph with $n$ vertices, then\n $\\gamma(G) + \\Psi(G) = n$ where $\\gamma(G)$ is the well-studied domination\n number of $G$. In this paper, we continue the study of the\n competition-enclaveless game introduced in 2001 by Phillips and Slater [Graph\n Theory Notes N. Y. 41 (2001), 37--41] and defined as follows. Two players take\n turns in constructing a maximal enclaveless set $S$, where one player,\n Maximizer, tries to maximize $|S|$ and one player, Minimizer, tries to\n minimize~$|S|$. The competition-enclaveless game number $\\Psi_g^+(G)$ of $G$ is\n the number of vertices played when Maximizer starts the game and both players\n play optimally. We study among other problems the conjecture that if $G$ is an\n isolate-free graph of order $n$, then $\\Psi_g^+(G) \\ge \\frac{1}{2}n$. We prove\n this conjecture for regular graphs and for claw-free graphs.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2309.07501",
        "title": "Multi-parameter perturbations for the space-periodic heat equation",
        "abstract": "This paper is divided into three parts. The first part focuses on periodic\n layer heat potentials, demonstrating their smooth dependence on regular\n perturbations of the support of integration. In the second part, we present an\n application of the results from the first part. Specifically, we consider a\n transmission problem for the heat equation in a periodic two-phase composite\n material and we show that the solution depends smoothly on the shape of the\n transmission interface, boundary data, and conductivity parameters. Finally, in\n the last part of the paper, we fix all parameters except for the contrast\n parameter and outline a strategy to deduce an explicit expansion of the\n solution using a Neumann-type series.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1808.03533",
        "title": "Measuring azimuthal and radial modes of photons",
        "abstract": "With the emergence of the field of quantum communications, the appropriate\n choice of photonic degrees of freedom used for encoding information is of\n paramount importance. Highly precise techniques for measuring the polarisation,\n frequency, and arrival time of a photon have been developed. However, the\n transverse spatial degree of freedom still lacks a measurement scheme that\n allows the reconstruction of its full transverse structure with a simple\n implementation and a high level of accuracy. Here we show a method to measure\n the azimuthal and radial modes of Laguerre-Gaussian beams with a greater than\n 99% accuracy, using a single phase screen. We compare our technique with\n previous commonly used methods and demonstrate the significant improvements it\n presents for quantum key distribution and state tomography of high-dimensional\n quantum states of light. Moreover, our technique can be readily extended to any\n arbitrary family of spatial modes, such as mutually unbiased bases,\n Hermite-Gauss, and Ince-Gauss. Our scheme will significantly enhance existing\n quantum and classical communication protocols that use the spatial structure of\n light, as well as enable fundamental experiments on spatial-mode entanglement\n to reach their full potential.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.14972",
        "title": "Tropical Positivity and Determinantal Varieties",
        "abstract": "We initiate the study of positive-tropical generators as positive analogues\n of the concept of tropical bases. Applying this to the tropicalization of\n determinantal varieties, we develop criteria for characterizing their positive\n part. We focus on the study of low-rank matrices, in particular matrices of\n rank 2 and 3. Moreover, in the case square-matrices of corank 1, we fully\n classify the signed tropicalization of the determinantal variety, even beyond\n the positive part.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cs/0510071",
        "title": "A Simple Cooperative Diversity Method Based on Network Path Selection",
        "abstract": "Cooperative diversity has been recently proposed as a way to form virtual\n antenna arrays that provide dramatic gains in slow fading wireless\n environments. However most of the proposed solutions require distributed\n space-time coding algorithms, the careful design of which is left for future\n investigation if there is more than one cooperative relay. We propose a novel\n scheme, that alleviates these problems and provides diversity gains on the\n order of the number of relays in the network. Our scheme first selects the best\n relay from a set of M available relays and then uses this best relay for\n cooperation between the source and the destination. We develop and analyze a\n distributed method to select the best relay that requires no topology\n information and is based on local measurements of the instantaneous channel\n conditions. This method also requires no explicit communication among the\n relays. The success (or failure) to select the best available path depends on\n the statistics of the wireless channel, and a methodology to evaluate\n performance for any kind of wireless channel statistics, is provided.\n Information theoretic analysis of outage probability shows that our scheme\n achieves the same diversity-multiplexing tradeoff as achieved by more complex\n protocols, where coordination and distributed space-time coding for M nodes is\n required, such as those proposed in [7]. The simplicity of the technique,\n allows for immediate implementation in existing radio hardware and its adoption\n could provide for improved flexibility, reliability and efficiency in future 4G\n wireless systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1008.3570",
        "title": "Temperature-induced crossovers in the static roughness of a\n  one-dimensional interface",
        "abstract": "At finite temperature and in presence of disorder, a one-dimensional elastic\n interface displays different scaling regimes at small and large lengthscales.\n Using a replica approach and a Gaussian Variational Method (GVM), we explore\n the consequences of a finite interface width $\\xi$ on the small-lengthscale\n fluctuations. We compute analytically the static roughness $B(r)$ of the\n interface as a function of the distance $r$ between two points on the\n interface. We focus on the case of short-range elasticity and random-bond\n disorder. We show that for a finite width $\\xi$ two temperature regimes exist.\n At low temperature, the expected thermal and random-manifold regimes,\n respectively for small and large scales, connect via an intermediate `modified'\n Larkin regime, that we determine. This regime ends at a temperature-independent\n characteristic `Larkin' length. Above a certain `critical' temperature that we\n identify, this intermediate regime disappears. The thermal and random-manifold\n regimes connect at a single crossover lengthscale, that we compute. This is\n also the expected behavior for zero width. Using a directed polymer\n description, we also study via a second GVM procedure and generic scaling\n arguments, a modified toy model that provides further insights on this\n crossover. We discuss the relevance of the two GVM procedures for the roughness\n at large lengthscale in those regimes. In particular we analyze the scaling of\n the temperature-dependent prefactor in the roughness $B(r)\\sim T^{2\n \\text{\\thorn}} r^{2 \\zeta}$ and its corresponding exponent $\\text{\\thorn}$. We\n briefly discuss the consequences of those results for the quasistatic creep law\n of a driven interface, in connection with previous experimental and numerical\n studies.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0511332",
        "title": "VIMOS-IFU survey of z~0.2 massive galaxy clusters. I. Observations of\n  the strong lensing cluster Abell 2667",
        "abstract": "(abridged) We present extensive multi-color imaging and low resolution VIMOS\n Integral Field Unit spectroscopic observations of the X-ray luminous cluster\n Abell 2667 (z=0.233). An extremely bright giant gravitational arc (z=1.0334) is\n easily identified as part of a triple image system and other fainter multiple\n images are also revealed by the HST-WFPC2 images. The VIMOS-IFU observations\n cover a field of view of 54'' x 54'' and enable us to determine the redshift of\n all galaxies down to V=22.5. Furthermore, redshifts could be identified for\n some sources down to V=23.2. In particular we identify 21 cluster members in\n the cluster inner region, from which we derive a velocity dispersion of\n \\sigma=960 km/s, corresponding to a total mass of 7.1 x 10^{13} solar masses\n within a 110 kpc radius. Using the multiple images constraints and priors on\n the mass distribution of cluster galaxy halos we construct a detailed lensing\n mass model leading to a total mass of 2.9 x 10^{13} solar masses within the\n Einstein radius (16 arcsec). The lensing mass and dynamical mass are in good\n agreement although the dynamical one is much less accurate. Comparing these\n measurements with published X-ray analysis, is however less conclusive.\n Although the X-ray temperature matches the dynamical and lensing estimates, the\n published NFW mass model derived from the X-ray measurement with its small\n concentration of c ~3 can not account for the large Einstein radius observed in\n this cluster. A larger concentration of ~6 would however match the strong\n lensing measurements. These results are likely reflecting the complex structure\n of the cluster mass distribution, underlying the importance of panchromatic\n studies from small to large scale in order to better understand cluster\n physics.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1805.06710",
        "title": "The optical characteristics of the dust of sungrazing comet C/2012 S1\n  (ISON) observed at large heliocentric distances",
        "abstract": "We present an analysis of the photometric and spectroscopic data of the comet\n C/2012 S1 (ISON) observed at the heliocentric distances of 6.21\\div 4.81 AU.\n The photometric observations were made with the 60-cm Zeiss-600 telescope\n (ICAMER, peak Terskol, Russia) and the spectroscopic observations were\n performed using the SCORPIO-2 focal reducer mounted in the prime focus of the\n 6-m BTA telescope (SAO RAS, Russia). We analyse the B, V and R-band images to\n describe the dusty cometary coma and to investigate its brightness, colours and\n dust production rate. The spectra cover the wavelength range of 3600\\div 7070\n \\AA. No emissions which are expected in this wavelength region were detected\n above the 3$\\sigma$ level. The continuum shows a reddening effect with the\n normalized gradient of reflectivity along dispersion of (9.3$\\pm$1.1)% per 1000\n \\AA. A dust-loss rate was derived using the obtained values and under the\n different model assumptions. Our simulations clearly indicate that to retrieve\n dust production from the observational Af$\\rho$ parameter is an ambiguous task.\n The result of such a procedure is strongly dependent on dynamical (e.g.\n effective density and cross-section) as well as optical (e.g. scattering\n coefficient and phase function) characteristics of dust grains. A variation of\n the mentioned parameters can lead to dramatic changes in the evaluation of mass\n production. We demonstrate that the dynamic and optical properties are\n interconnected via the microscopic properties of dust grains (effective size\n and porosity).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1912.13155",
        "title": "LHC probes of the 10 TeV scale",
        "abstract": "The usual range of new particle masses, up to a few TeV, searched for at the\n LHC may be substantially extended if ultraheavy diquark particles exist. A\n diquark scalar, $S_{uu}$, that interacts perturbatively with two up quarks may\n be as heavy as 10 TeV and would still produce tens of spectacular events at the\n 14 TeV LHC. It is shown here that an ultraheavy $S_{uu}$ could be discovered\n through final states of very high energy in various channels, especially if the\n diquark can decay into other new heavy particles. Examples include cascade\n decays of $S_{uu}$ via a second scalar produced in pairs, which leads to two\n dijet resonances, or to more exotic signals with top quarks, Higgs bosons,\n electroweak bosons, and high-$p_T$ jets. Another possibility is that the\n diquark decays into a vectorlike quark of multi-TeV mass and a top or up quark.\n Signal events include one or two highly boosted top quarks and a Higgs boson or\n a $Z$, without counterparts containing top antiquarks. Similarly, direct decays\n of the diquark into $tj$ or $tt$ with leptonic top decays involve only\n positively charged leptons.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.10688",
        "title": "Integration of Programmable Diffraction with Digital Neural Networks",
        "abstract": "Optical imaging and sensing systems based on diffractive elements have seen\n massive advances over the last several decades. Earlier generations of\n diffractive optical processors were, in general, designed to deliver\n information to an independent system that was separately optimized, primarily\n driven by human vision or perception. With the recent advances in deep learning\n and digital neural networks, there have been efforts to establish diffractive\n processors that are jointly optimized with digital neural networks serving as\n their back-end. These jointly optimized hybrid (optical+digital) processors\n establish a new \"diffractive language\" between input electromagnetic waves that\n carry analog information and neural networks that process the digitized\n information at the back-end, providing the best of both worlds. Such hybrid\n designs can process spatially and temporally coherent, partially coherent, or\n incoherent input waves, providing universal coverage for any spatially varying\n set of point spread functions that can be optimized for a given task, executed\n in collaboration with digital neural networks. In this article, we highlight\n the utility of this exciting collaboration between engineered and programmed\n diffraction and digital neural networks for a diverse range of applications. We\n survey some of the major innovations enabled by the push-pull relationship\n between analog wave processing and digital neural networks, also covering the\n significant benefits that could be reaped through the synergy between these two\n complementary paradigms.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1011.2064",
        "title": "The mass-loss rates and molecular abundances of S-type AGB stars",
        "abstract": "The S-type stars are believed to have a C/O-ratio close to unity (within a\n few percent). They are considered to represent an intermediate evolutionary\n stage as AGB stars evolve from oxygen-rich M-type stars into carbon stars. As\n possible transition objects the S-type stars could give important clues to the\n mass-loss mechanism(s) and to the chemical evolution along the AGB. Using\n observations of circumstellar radio line emission in combination with a\n detailed radiative transfer analysis, we have estimated mass-loss rates and\n abundances of chemically important molecules (SiO, HCN) for a sample of 40\n S-type AGB stars. The results will be compared to previous results for M-type\n and carbon stars.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1304.2384",
        "title": "Logical Fuzzy Optimization",
        "abstract": "We present a logical framework to represent and reason about fuzzy\n optimization problems based on fuzzy answer set optimization programming. This\n is accomplished by allowing fuzzy optimization aggregates, e.g., minimum and\n maximum in the language of fuzzy answer set optimization programming to allow\n minimization or maximization of some desired criteria under fuzzy environments.\n We show the application of the proposed logical fuzzy optimization framework\n under the fuzzy answer set optimization programming to the fuzzy water\n allocation optimization problem.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1807.07818",
        "title": "Wireless Multi-Sensor Networks for Smart Cities: A Prototype System with\n  Statistical Data Analysis",
        "abstract": "As urbanization proceeds at an astonishing rate, cities have to continuously\n improve their solutions that affect the safety, health and overall wellbeing of\n their residents. Smart city projects worldwide build on advanced sensor,\n information and communication technologies to help dealing with issues like air\n pollution, waste management, traffic optimization, and energy efficiency. The\n paper reports about the prototype of a smart city initiative in Budapest which\n applies various sensors installed on the public lighting system and a\n cloud-based analytical module. While the installed wireless multi-sensor\n network gathers information about a number of stressors, the module integrates\n and statistically processes the data. The module can handle inconsistent,\n missing and noisy data and can extrapolate the measurements in time and space,\n namely, it can create short-term forecasts and smoothed maps, both accompanied\n by reliability estimates. The resulting database uses geometric representations\n and can serve as an information centre for public services.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1903.08799",
        "title": "The pure cohomology of multiplicative quiver varieties",
        "abstract": "To a quiver $Q$ and choices of nonzero scalars $q_i$, non-negative integers\n $\\alpha_i$, and integers $\\theta_i$ labeling each vertex $i$,\n Crawley-Boevey--Shaw associate a \"multiplicative quiver variety\"\n $\\mathcal{M}_\\theta^q(\\alpha)$, a trigonometric analogue of the Nakajima quiver\n variety associated to $Q$, $\\alpha$, and $\\theta$. We prove that the pure\n cohomology, in the Hodge-theoretic sense, of the stable locus\n $\\mathcal{M}_\\theta^q(\\alpha)^s$ is generated as a $\\mathbb{Q}$-algebra by the\n tautological characteristic classes. In particular, the pure cohomology of\n genus $g$ twisted character varieties of $GL_n$ is generated by tautological\n classes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1309.6585",
        "title": "Next-to-leading order QCD corrections to five jet production at the LHC",
        "abstract": "We present theoretical predictions for five jet production in proton-proton\n collisions at next-to-leading order accuracy in QCD. Inclusive as well as\n differential observables are studied for collision energies of 7 and 8 TeV. In\n general the next-to-leading order corrections stabilize the theoretical\n predictions with respect to scale variations. In case of the inclusive jet\n cross sections, we compare with experimental data where possible and find\n reasonable agreement. We observe that the four-to-three and five-to-four jet\n ratios show better perturbative convergence than the known three-to-two ratio\n and are promising candidates for future alpha_s measurements. Furthermore, we\n present a detailed analysis of uncertainties related to parton distribution\n functions. The full colour virtual matrix elements used in the computation were\n obtained with the NJet package, a publicly available library for the evaluation\n of one-loop amplitudes in massless QCD.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1412.3512",
        "title": "The equidistribution of some length three vincular patterns on\n  $S_n(132)$",
        "abstract": "In 2012 B\\'ona showed the rather surprising fact that the cumulative number\n of occurrences of the classical patterns $231$ and $213$ are the same on the\n set of permutations avoiding $132$, beside the pattern based statistics $231$\n and $213$ do not have the same distribution on this set. Here we show that if\n it is required for the symbols playing the role of $1$ and $3$ in the\n occurrences of $231$ and $213$ to be adjacent, then the obtained statistics are\n equidistributed on the set of $132$-avoiding permutations. Actually, expressed\n in terms of vincular patterns, we prove the following more general results: the\n statistics based on the patterns $b-ca$, $b-ac$ and $ba-c$, together with other\n statistics, have the same joint distribution on $S_n(132)$, and so do the\n patterns $bc-a$ and $c-ab$; and up to trivial transformations, these statistics\n are the only based on length three proper (not classical nor adjacent) vincular\n patterns which are equidistributed on a set of permutations avoiding a\n classical length three pattern.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ex/0511002",
        "title": "Prospects for Antineutrino Running at MiniBooNE",
        "abstract": "We outline a program of antineutrino cross-section measurements necessary for\n the next generation of neutrino oscillation experiments, that can be performed\n with one year of data at MiniBooNE. We describe three independent methods of\n constraining wrong-sign (neutrino) backgrounds in an antineutrino beam, and\n their application to the MiniBooNE antineutrino cross section measurements.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1812.11678",
        "title": "Microscopic states of Kerr black holes from boundary-bulk correspondence",
        "abstract": "It was claimed by the author that black holes can be considered as\n topological insulators. They both have boundary modes and those boundary modes\n can be described by an effective BF theory. In this paper, we analyze the\n boundary modes on the horizon of black holes with the methods developed for\n topological insulator. Firstly the BTZ black hole is analysed, and the results\n are compatible with the previous works. Then we generalize those results to\n Kerr black holes. Some new results are obtained: dimensionless right- and\n left-temperature can be defined and have well behaviors both in Schwarzschild\n limit $a\\rightarrow 0$ and extremal limit $a\\rightarrow M$. Upon the Kerr/CFT\n correspondence, we can associate a central charge $c=12 M r_+$ with an\n arbitrary Kerr black hole if a dual CFT exists. We can identify the microstates\n of the Kerr black hole with the quantum states of this scalar field. From this\n identification we can count the number of microstates of the Kerr black hole\n and give the Bekenstein-Hawking area law for the entropy.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2301.08508",
        "title": "Connecting transonic buffet with incompressible low-frequency\n  oscillations on aerofoils",
        "abstract": "Self-sustained low-frequency flow unsteadiness over rigid aerofoils in the\n transonic regime is referred to as transonic buffet. Although the exact\n physical mechanisms underlying this phenomenon are unclear, it is generally\n assumed to be unique to the transonic regime. This assumption is shown to be\n incorrect here by performing large-eddy simulations of flow over a NACA0012\n profile for a wide range of flow conditions. At zero incidence and sufficiently\n high freestream Mach numbers, M, transonic buffet occurs with shock waves\n present in the flow. However, self-sustained oscillations that occur at similar\n frequencies are observed at lower M for which shock waves are absent and the\n entire flow field remains subsonic at all times. At higher incidences, the\n oscillations are sustained at progressively lower M. Oscillations were observed\n for M as low as 0.3, where compressibility effects are small. A spectral proper\n orthogonal decomposition shows that the spatial structure of these oscillations\n (i.e., mode shapes) are essentially the same for all cases. These results\n indicate that buffet on aerofoils does not necessarily require the presence of\n shock waves. Furthermore, the trend seen with increasing incidence angles\n suggests that transonic buffet on aerofoils and low-frequency oscillations\n reported in the incompressible regime (Zaman et al., 1989, J. Fluid Mech., vol.\n 202, pp. 403--442) have similar origins. Thus, models which rely specifically\n on shock waves to explain transonic buffet are incorrect. These insights could\n be useful in understanding the origins of ``transonic\" buffet and reformulating\n mitigation strategies by shifting the focus away from shock waves.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2206.00565",
        "title": "LiYbSe2: Frustrated Magnetism in a New Pyrochlore Lattice",
        "abstract": "Three-dimensionally (3D) frustrated magnets generally exist in the magnetic\n diamond and pyrochlore lattices, in which quantum fluctuations suppress\n magnetic orders and generate highly entangled ground states (GS). LiYbSe2 in a\n previously unreported pyrochlore lattice was discovered from LiCl flux growth.\n Distinct from the quantum spin liquid (QSL) candidate NaYbSe2 hosting a perfect\n triangular lattice of Yb3+, LiYbSe2 crystallizes in the cubic pyrochlore\n structure with space group Fd-3m (No. 227). The Yb3+ ions in LiYbSe2 are\n arranged on a network of corner-sharing tetrahedra, which is particularly\n susceptible to geometrical frustration. According to our temperature-dependent\n magnetic susceptibility measurements, the dominant antiferromagnetic\n interaction in LiYbSe2 is expected to appear around 8 K. However, no long-range\n magnetic order is detected in thermomagnetic measurements above 70 mK. Specific\n heat measurements also show magnetic correlations shifting with applied\n magnetic field with a degree of missing entropy that may be related to the\n slight mixture of Yb3+ on the Li site. Such magnetic frustration of Yb3+ is\n rare in pyrochlore structures. Thus, LiYbSe2 shows promises in intrinsically\n realizing disordered quantum states like QSL in pyrochlore structures.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.06534",
        "title": "K-Tensors: Clustering Positive Semi-Definite Matrices",
        "abstract": "This paper introduces $K$-Tensors, a novel self-consistent clustering\n algorithm designed to cluster positive semi-definite (PSD) matrices by their\n eigenstructures. Clustering PSD matrices is crucial across various fields,\n including computer and biomedical sciences. Traditional clustering methods,\n which often involve matrix vectorization, tend to overlook the inherent PSD\n characteristics, thereby discarding valuable shape and eigenstructural\n information. To preserve this essential shape and eigenstructral information,\n our approach incorporates a unique distance metric that respects the PSD nature\n of the data. We demonstrate that $K$-Tensors is not only self-consistent but\n also reliably converges to a local optimum. Through numerical studies, we\n further validate the algorithm's effectiveness and explore its properties in\n detail.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/0410178",
        "title": "Topological strings and their physical applications",
        "abstract": "We give an introductory review of topological strings and their application\n to various aspects of superstrings and supersymmetric gauge theories. This\n review includes developing the necessary mathematical background for\n topological strings, such as the notions of Calabi-Yau manifold and toric\n geometry, as well as physical methods developed for solving them, such as\n mirror symmetry, large N dualities, the topological vertex and quantum foam. In\n addition, we discuss applications of topological strings to N=1,2\n supersymmetric gauge theories in 4 dimensions as well as to BPS black hole\n entropy in 4 and 5 dimensions. (These are notes from lectures given by the\n second author at the 2004 Simons Workshop in Mathematics and Physics.)",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1009.5456",
        "title": "Shear Banding from lattice kinetic models with competing interactions",
        "abstract": "Soft Glassy Materials, Non Linear Rheology, Lattice Kinetic models,\n frustrated phase separation} We present numerical simulations based on a\n Boltzmann kinetic model with competing interactions, aimed at characterizating\n the rheological properties of soft-glassy materials. The lattice kinetic model\n is shown to reproduce typical signatures of driven soft-glassy flows in\n confined geometries, such as Herschel-Bulkley rheology, shear-banding and\n histeresys. This lends further credit to the present lattice kinetic model as a\n valuable tool for the theoretical/computational investigation of the rheology\n of driven soft-glassy materials under confinement.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.07236",
        "title": "Combating COVID-19 using Generative Adversarial Networks and Artificial\n  Intelligence for Medical Images: A Scoping Review",
        "abstract": "This review presents a comprehensive study on the role of GANs in addressing\n the challenges related to COVID-19 data scarcity and diagnosis. It is the first\n review that summarizes the different GANs methods and the lungs images datasets\n for COVID-19. It attempts to answer the questions related to applications of\n GANs, popular GAN architectures, frequently used image modalities, and the\n availability of source code. This review included 57 full-text studies that\n reported the use of GANs for different applications in COVID-19 lungs images\n data. Most of the studies (n=42) used GANs for data augmentation to enhance the\n performance of AI techniques for COVID-19 diagnosis. Other popular applications\n of GANs were segmentation of lungs and super-resolution of the lungs images.\n The cycleGAN and the conditional GAN were the most commonly used architectures\n used in nine studies each. 29 studies used chest X-Ray images while 21 studies\n used CT images for the training of GANs. For majority of the studies (n=47),\n the experiments were done and results were reported using publicly available\n data. A secondary evaluation of the results by radiologists/clinicians was\n reported by only two studies. Conclusion: Studies have shown that GANs have\n great potential to address the data scarcity challenge for lungs images of\n COVID-19. Data synthesized with GANs have been helpful to improve the training\n of the Convolutional Neural Network (CNN) models trained for the diagnosis of\n COVID-19. Besides, GANs have also contributed to enhancing the CNNs performance\n through the super-resolution of the images and segmentation. This review also\n identified key limitations of the potential transformation of GANs based\n methods in clinical applications.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2010.08862",
        "title": "Mad Science is Provably Hard: Puzzles in Hearthstone's Boomsday Lab are\n  NP-hard",
        "abstract": "We consider the computational complexity of winning this turn (mate-in-1 or\n \"finding lethal\") in Hearthstone as well as several other single turn puzzle\n types introduced in the Boomsday Lab expansion. We consider three natural\n generalizations of Hearthstone (in which hand size, board size, and deck size\n scale) and prove the various puzzle types in each generalization NP-hard.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.05828",
        "title": "Optimized Distillation Profiles for Heavy-Light Spectroscopy",
        "abstract": "It has been demonstrated that distillation profiles can be employed to build\n optimized quarkonium interpolators for spectroscopy calculations in lattice\n QCD. We test their usefulness for heavy-light systems on (3+1)-flavor ensembles\n with mass-degenerate light and a charm quark in the sea in preparation for a\n future $D\\bar{D}$-scattering analysis. The additional cost of light inversions\n naturally leads to the question if knowledge of optimal profiles can be used to\n avoid superfluous computations. We show such optimal profiles for different\n lattice sizes and pion masses and discuss general trends. Furthermore, we\n discuss the handling of momenta in this framework.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1405.2651",
        "title": "Single atom anisotropic magnetoresistance on a topological insulator\n  surface",
        "abstract": "We demonstrate single atom anisotropic magnetoresistance on the surface of a\n topological insulator, arising from the interplay between the helical\n spin-momentum-locked surface electronic structure and the hybridization of the\n magnetic adatom states. Our first-principles quantum transport calculations\n based on density functional theory for Mn on Bi$_2$Se$_3$ elucidate the\n underlying mechanism. We complement our findings with a two dimensional model\n valid for both single adatoms and magnetic clusters, which leads to a proposed\n device setup for experimental realization. Our results provide an explanation\n for the conflicting scattering experiments on magnetic adatoms on topological\n insulator surfaces, and reveal the real space spin texture around the magnetic\n impurity.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1704.08085",
        "title": "Collisions and drag in debris discs with eccentric parent belts",
        "abstract": "Context: High-resolution images of circumstellar debris discs reveal\n off-centred rings that indicate past or ongoing perturbation, possibly caused\n by secular gravitational interaction with unseen stellar or substellar\n companions. The purely dynamical aspects of this departure from radial symmetry\n are well understood. However, the observed dust is subject to additional forces\n and effects, most notably collisions and drag. Aims: To complement the studies\n of dynamics, we therefore aim to understand how new asymmetries are created by\n the addition of collisional evolution and drag forces, and existing ones\n strengthened or overridden. Methods: We augmented our existing numerical code\n \"Analysis of Collisional Evolution\" (ACE) by an azimuthal dimension, the\n longitude of periapse. A set of fiducial discs with global eccentricities\n ranging from 0 to 0.4 is evolved over giga-year timescales. Size distribution\n and spatial variation of dust are analysed and interpreted. The basic impact of\n belt eccentricity on spectral energy distributions (SEDs) and images is\n discussed.\n  Results: We find features imposed on characteristic timescales. First,\n radiation pressure defines size cutoffs that differ between periapse and\n apoapse, resulting in an asymmetric halo. The differences in size distribution\n make the observable asymmetry of the halo depend on wavelength. Second,\n collisional equilibrium prefers smaller grains on the apastron side of the\n parent belt, reducing the effect of pericentre glow and the overall asymmetry.\n Third, Poynting-Robertson drag fills the region interior to an eccentric belt\n such that the apastron side is more tenuous. Interpretation and prediction of\n the appearance in scattered light is problematic when spatial and size\n distribution are coupled.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2111.07877",
        "title": "Bidirectional, Analog Current Source Benchmarked with Gray\n  Molasses-Assisted Stray Magnetic Field Compensation",
        "abstract": "In ultracold-atom and ion experiments, flexible control of the direction and\n amplitude of a uniform magnetic field is necessary. It is achieved almost\n exclusively by controlling the current flowing through coils surrounding the\n experimental chamber. Here, we present the design and characterization of a\n modular, analog electronic circuit that enables three-dimensional control of a\n magnetic field via the amplitude and direction of a current flowing through\n three perpendicular pairs of coils. Each pair is controlled by one module, and\n we are able to continuously change the current flowing thorough the coils in\n the $\\pm$4 A range using analog waveforms such that smooth crossing through\n zero as the current's direction changes is possible. With the electrical\n current stability at the 10$^{-5}$ level, the designed circuit enables\n state-of-the-art ultracold experiments. As a benchmark, we use the circuit to\n compensate stray magnetic fields that hinder efficient sub-Doppler cooling of\n alkali atoms in gray molasses. We demonstrate how such compensation can be\n achieved without actually measuring the stray fields present, thus speeding up\n the process of optimization of various laser cooling stages.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/9905354",
        "title": "Generating and Calculating One-loop Feynman Diagrams with FeynArts,\n  FormCalc, and LoopTools",
        "abstract": "A set of programs is presented for automatically generating and calculating\n Feynman diagrams. Diagrams are generated with FeynArts, then algebraically\n simplified using a combination of Mathematica and FORM implemented in the\n package FormCalc, and finally evaluated numerically using the LoopTools\n package. FormCalc works either in dimensional regularization or in constrained\n differential renormalization, the latter of which is equivalent at the one-loop\n level to regularization by dimensional reduction. FormCalc combines the speed\n of FORM with the powerful instruction set of Mathematica, and the latter\n greatly eases further processing of the results (e.g. selecting or modifying\n terms). The output is in a form well suited for numerical evaluation, which is\n then straightforward using the implementations of the one-loop integrals in\n LoopTools.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.07122",
        "title": "Double-GEM based thermal neutron detector prototype",
        "abstract": "The Helium-3 shortage and the growing interest in neutron science constitute\n a driving factor in developing new neutron detection technologies. In this\n work, we report the development of a double-GEM detector prototype that uses a\n $^{10}$B$_4$C layer as a neutron converter material. GEANT4 simulations were\n performed predicting an efficiency of 3.14(10) %, agreeing within 2.7 $\\sigma$\n with the experimental and analytic detection efficiencies obtained by the\n detector when tested in a 41.8 meV thermal neutron beam. The detector is\n position sensitive, equipped with a 256+256 strip readout connected to\n resistive chains, and achieves a spatial resolution better than 3 mm. The gain\n stability over time was also measured with a fluctuation of about 0.2 %h$^{-1}$\n of the signal amplitude. A simple data acquisition with only 5 electronic\n channels is sufficient to operate this detector.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/physics/0401072",
        "title": "Liquid Xe scintillation calorimetry and Xe optical properties",
        "abstract": "The optical properties of LXe in the vacuum ultra violet (VUV), determining\n the performance of a scintillation calorimeter, are discussed in detail. The\n available data, measured in a wider spectral region from visible to UV light,\n and in a large range of Xe densities, from gas to liquid, are examined. It is\n shown that this information can be used for deriving the LXe optical properties\n in the VUV. A comparison is made with the few direct measurements in LXe for\n VUV light resulting from the LXe excitation by ionizing particles. A useful\n relation is obtained which connects the Rayleigh scattering length to the\n refractive index in LXe.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0907.1559",
        "title": "Holographic entanglement entropy of the BTZ black hole",
        "abstract": "We investigate quantum entanglement of gravitational configurations in 3D AdS\n gravity using the AdS/CFT correspondence. We derive explicit formulas for the\n holographic entanglement entropy (EE) of the BTZ black hole, conical\n singularities and regularized AdS$_{3}$. The leading term in the large\n temperature expansion of the holographic EE of the BTZ black hole reproduces\n exactly its Bekenstein-Hawking entropy S_BH, whereas the subleading term\n behaves as ln S_BH. We also show that the leading term of the holographic EE\n for the BTZ black hole can be obtained from the large temperature expansion of\n the partition function of a broad class of 2D CFTs on the torus. This result\n indicates that black hole EE is not a fundamental feature of the underlying\n theory of quantum gravity but emerges when the semiclassical notion of\n spacetime geometry is used to describe the black hole.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/9709396",
        "title": "Semileptonic B decays to excited charm mesons",
        "abstract": "Exclusive semileptonic B decays to the lightest excited charmed mesons are\n investigated at order $\\Lambda_{QCD}/m_Q$ in the heavy quark effective theory.\n At zero recoil, $\\Lambda_{QCD}/m_Q$ corrections to the matrix elements of the\n weak currents can be written in terms of the leading Isgur-Wise functions for\n the corresponding transition and meson mass splittings. The differential decay\n rates are predicted, including $\\Lambda_{QCD}/m_Q$ corrections with some model\n dependence away from zero recoil. Applications to B decay sum rules and\n factorization are presented.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.01148",
        "title": "Spectral Characterizations of Solvability and Stability for Delay\n  Differential-Algebraic Equations",
        "abstract": "The solvability and stability analysis of linear time invariant systems of\n delay differential-algebraic equations (DDAEs) is analyzed. The behavior\n approach is applied to DDAEs in order to establish characterizations of their\n solvability in terms of spectral conditions. Furthermore, examples are\n delivered to demonstrate that the eigenvalue-based approach to analyze the\n exponential stability of dynamical system is only valid for a special class of\n DDAEs, namely non-advanced. Then, a new concept of weak stability is proposed\n and studied for DDAEs whose matrix coefficients pairwise commute.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1208.4731",
        "title": "Solution of two-center time-dependent Dirac equation in spherical\n  coordinates: Application of the multipole expansion of the electron-nuclei\n  interaction",
        "abstract": "A non-perturbative approach to the solution of the time-dependent, two-center\n Dirac equation is presented with a special emphasis on the proper treatment of\n the potential of the nuclei. In order to account for the full multipole\n expansion of this potential, we express eigenfunctions of the two-center\n Hamiltonian in terms of well-known solutions of the \"monopole\" problem that\n employs solely the spherically-symmetric part of the interaction. When combined\n with the coupled-channel method, such a wavefunction-expansion technique allows\n for an accurate description of the electron dynamics in the field of moving\n ions for a wide range of internuclear distances. To illustrate the\n applicability of the proposed approach, the probabilities of the K- as well as\n L- shell ionization of hydrogen-like ions in the course of nuclear alpha-decay\n and slow ion-ion collisions have been calculated.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1503.05898",
        "title": "Oxygen, {\\alpha}-element and iron abundance distributions in the inner\n  part of the Galactic thin disc",
        "abstract": "We derived elemental abundances in 27 Cepheids, the great majority situated\n within a zone of Galactocentric distances ranging from 5 to 7 kpc. One star of\n our sample, SU Sct, has a Galactocentric distance of about 3 kpc, and thus\n falls in a poorly investigated region of the inner thin disc. Our new results,\n combined with data on abundances in the very central part of our Galaxy taken\n from literature, show that iron, magnesium, silicon, sulfur, calcium and\n titanium LTE abundance radial distributions, as well as NLTE distribution of\n oxygen reveal a plateau-like structure or even positive abundance gradient in\n the region extending from the Galactic center to about 5 kpc.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1106.1232",
        "title": "A reduction from parity games to simple stochastic games",
        "abstract": "Games on graphs provide a natural model for reactive non-terminating systems.\n In such games, the interaction of two players on an arena results in an\n infinite path that describes a run of the system. Different settings are used\n to model various open systems in computer science, as for instance turn-based\n or concurrent moves, and deterministic or stochastic transitions. In this\n paper, we are interested in turn-based games, and specifically in deterministic\n parity games and stochastic reachability games (also known as simple stochastic\n games). We present a simple, direct and efficient reduction from deterministic\n parity games to simple stochastic games: it yields an arena whose size is\n linear up to a logarithmic factor in size of the original arena.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2108.12621",
        "title": "Circular strings in Kerr-$AdS_5$ black holes",
        "abstract": "The quest for extension of holographic correspondence to the case of finite\n temperature naturally includes Kerr-AdS black holes and their field theory\n duals. We probe the five-dimensional Kerr-AdS space time by pulsating strings.\n First we find particular pulsating string solutions and then semi-classically\n quantize the theory. For the string with large values of energy, we use the\n Bohr-Sommerfeld analysis to find the energy of the string as a function of a\n large quantum number. We obtain the wave function of the problem and thoroughly\n study the corrections to the energy, which according to the holographic\n dictionary are related to anomalous dimensions of certain operators in the dual\n gauge theory. The interpretation of results from holographic point of view is\n not straightforward since the dual theory is at finite temperature.\n Nevertheless, near or at conformal point the expressions can be thought of as\n the dispersion relations of stationary states.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1010.3870",
        "title": "Colour fields in gauge invariant quenched SU(3) Lattice QCD",
        "abstract": "he colour fields, created by static sources belonging to different SU(3)\n representations, from the 3 to the 27, are computed in quenched SU(3) lattice\n QCD, in a 24^3 x 48 lattice at beta=6.2 and a=0.07261(85) fm. We utilize the\n technique of generalized Wilson Loops to localize the sources, correlated with\n plaquettes to measure the respective colour fields. We investigate the Casimir\n scaling of the fields, measured in the static potentials by Bali. We also study\n the coherence length, comparing with the dual Ginzburg-Landau approach. With\n the penetration and coherence lengths we determined the Ginzburg-Landau\n dimensionless parameter, this result is consistent with a type II\n superconductor picture, and with an effective dual gluon mass of 0.905 +- 0.163\n GeV.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.12882",
        "title": "LCANets++: Robust Audio Classification using Multi-layer Neural Networks\n  with Lateral Competition",
        "abstract": "Audio classification aims at recognizing audio signals, including speech\n commands or sound events. However, current audio classifiers are susceptible to\n perturbations and adversarial attacks. In addition, real-world audio\n classification tasks often suffer from limited labeled data. To help bridge\n these gaps, previous work developed neuro-inspired convolutional neural\n networks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA)\n in the first layer (i.e., LCANets) for computer vision. LCANets learn in a\n combination of supervised and unsupervised learning, reducing dependency on\n labeled samples. Motivated by the fact that auditory cortex is also sparse, we\n extend LCANets to audio recognition tasks and introduce LCANets++, which are\n CNNs that perform sparse coding in multiple layers via LCA. We demonstrate that\n LCANets++ are more robust than standard CNNs and LCANets against perturbations,\n e.g., background noise, as well as black-box and white-box attacks, e.g.,\n evasion and fast gradient sign (FGSM) attacks.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0303153",
        "title": "Riemannian geometry over different normed division algebra",
        "abstract": "We develop a unifed theory to study geometry of manifolds with different\n holonomy groups.\n  They are classified by (1) real, complex, quaternion or octonion number they\n are defined over and (2) being special or not. Specialty is an orientation with\n respect to the corresponding normed algebra A. For example, special Riemannian\n A-manifolds are oriented Riemannian, Calabi-Yau, Hyperkahler and G_2-manifolds\n respectively.\n  For vector bundles over such manifolds, we introduce (special) A-connections.\n They include holomorphic, Hermitian Yang-Mills, Anti-Self-Dual and\n Donaldson-Thomas connections. Similarly we introduce (special) A/2-Lagrangian\n submanifolds as maximally real submanifolds. They include (special) Lagrangian,\n complex Lagrangian, Cayley and (co-)associative submanifolds.\n  We also discuss geometric dualities from this viewpoint: Fourier\n transformations on A-geometry for flat tori and a conjectural SYZ mirror\n transformation from (special) A-geometry to (special) A/2-Lagrangian geometry\n on mirror special A-manifolds.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2108.08738",
        "title": "An experimental setup to generate narrowband bi-photons via four-wave\n  mixing in cold atoms",
        "abstract": "We present our recently-built experimental setup designed to generate\n near-infrared and narrow-band correlated photon pairs by inducing four-wave\n mixing in a cold gas of $^{87}$Rb atoms confined in a magneto-optical trap. The\n experimental setup and its automation and control approach are described in\n detail. A characterization of the optical density of the atomic ensemble as\n well as the basic statistical measurements of the generated light are reported.\n The non-classical nature of the photons pairs is confirmed by observing a\n violation of Cauchy-Schwarz inequality by a factor of 5.6 $\\times 10^5$ in a\n Hanbury Brown - Twiss interferometer. A $1/e$ coherence time for the heralded,\n idler photons of $4.4 \\pm 0.1$ ns is estimated from our observations. We are\n able to achieve a value of $10^{4}$ s$^{-1}$ pair-detection-rate, which results\n in a spectral brightness of 280 (MHz s)$^{-1}$. The combination of high\n brightness and narrow-band spectrum makes this photon-pair source a viable tool\n in fundamental studies of quantum states and opens the door to use them in\n quantum technologies.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.09689",
        "title": "Probing quantum geometry through optical conductivity and magnetic\n  circular dichroism",
        "abstract": "Probing ground-state quantum geometry and topology through optical response\n is not only of fundamental interest, but it can also offer several practical\n advantages. Here, using first-principles calculations on antiferromagnetic\n topological insulator MnBi$_2$Te$_4$ thin films, we demonstrate how the\n generalized optical weight arising from the absorptive part of the optical\n conductivity can be used to probe the ground state quantum geometry and\n topology. We show that three septuple layers MnBi$_2$Te$_4$ exhibit an enhanced\n almost perfect magnetic circular dichroism for a narrow photon energy window in\n the infrared region. We calculate the quantum weight in a few septuple layers\n MnBi$_2$Te$_4$ and show that it far exceeds the lower bound provided by the\n Chern number. Our results suggest that the well-known optical methods are\n powerful tools for probing the ground state quantum geometry and topology.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1806.02030",
        "title": "Improving Performance Models for Irregular Point-to-Point Communication",
        "abstract": "Parallel applications are often unable to take full advantage of emerging\n parallel architectures due to scaling limitations, which arise due to\n inter-process communication. Performance models are used to analyze the sources\n of communication costs. However, traditional models for point-to-point\n communication fail to capture the full cost of many irregular operations, such\n as sparse matrix methods. In this paper, a node-aware based model is presented.\n Furthermore, the model is extended to include communication queue search time\n as well as an additional parameter estimating network contention. The resulting\n model is applied to a variety of irregular communication patterns throughout\n matrix operations, displaying improved accuracy over traditional models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2305.10565",
        "title": "Measurement Based Evaluation and Mitigation of Flood Attacks on a LAN\n  Test-Bed",
        "abstract": "The IoT is vulnerable to network attacks, and Intrusion Detection Systems\n (IDS) can provide high attack detection accuracy and are easily installed in\n IoT Servers. However, IDS are seldom evaluated in operational conditions which\n are seriously impaired by attack overload. Thus a Local Area Network testbed is\n used to evaluate the impact of UDP Flood Attacks on an IoT Server, whose first\n line of defence is an accurate IDS. We show that attacks overload the\n multi-core Server and paralyze its IDS. Thus a mitigation scheme that detects\n attacks rapidly, and drops packets within milli-seconds after the attack\n begins, is proposed and experimentally evaluated.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1602.04339",
        "title": "Mathematical Theory Exploration in Theorema: Reduction Rings",
        "abstract": "In this paper we present the first-ever computer formalization of the theory\n of Gr\\\"obner bases in reduction rings, which is an important theory in\n computational commutative algebra, in Theorema. Not only the formalization, but\n also the formal verification of all results has already been fully completed by\n now; this, in particular, includes the generic implementation and correctness\n proof of Buchberger's algorithm in reduction rings. Thanks to the seamless\n integration of proving and computing in Theorema, this implementation can now\n be used to compute Gr\\\"obner bases in various different domains directly within\n the system. Moreover, a substantial part of our formalization is made up solely\n by \"elementary theories\" such as sets, numbers and tuples that are themselves\n independent of reduction rings and may therefore be used as the foundations of\n future theory explorations in Theorema.\n  In addition, we also report on two general-purpose Theorema tools we\n developed for an efficient and convenient exploration of mathematical theories:\n an interactive proving strategy and a \"theory analyzer\" that already proved\n extremely useful when creating large structured knowledge bases.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2311.16385",
        "title": "A formula for the overlap between Generalized Coherent States of any\n  rank one simple Lie algebra",
        "abstract": "We provide a formula for computing the overlap between two Generalized\n Coherent States of any rank one simple Lie algebra. Then, we apply our formula\n to spin coherent states (i.e. $\\mathfrak{su}(2)$ algebra), pseudo-spin coherent\n states (i.e. $\\mathfrak{su}(1,1)$ algebra), and the\n $\\mathfrak{sl}(2,\\mathbb{R})$ subalgebras of Virasoro. In all these examples,\n we show the emergence of a semi-classical behaviour from the set of coherent\n states and verify that it always happens when some parameter, depending on the\n algebra and its representation, becomes large.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1812.11752",
        "title": "Cusps, Congruence Groups and Monstrous Dessins",
        "abstract": "We study general properties of the dessins d'enfants associated with the\n Hecke congruence subgroups $\\Gamma_0(N)$ of the modular group\n $\\mathrm{PSL}_2(\\mathbb{R})$. The definition of the $\\Gamma_0(N)$ as the\n stabilisers of couples of projective lattices in a two-dimensional vector space\n gives an interpretation of the quotient set\n $\\Gamma_0(N)\\backslash\\mathrm{PSL}_2(\\mathbb{R})$ as the projective lattices\n $N$-hyperdistant from a reference one, and hence as the projective line over\n the ring $\\mathbb{Z}/N\\mathbb{Z}$. The natural action of\n $\\mathrm{PSL}_2(\\mathbb{R})$ on the lattices defines a dessin d'enfant\n structure, allowing for a combinatorial approach to features of the classical\n modular curves, such as the torsion points and the cusps. We tabulate the\n dessins d'enfants associated with the $15$ Hecke congruence subgroups of genus\n zero, which arise in Moonshine for the Monster sporadic group.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2403.19230",
        "title": "Optomechanical cavities based on epitaxial GaP on nominally\n  (001)-oriented Si",
        "abstract": "Gallium phosphide (GaP) has recently received considerable attention as a\n suitable material for building photonic integrated circuits due to its\n remarkable optical and piezoelectric properties. Usually, GaP is grown\n epitaxially on III-V substrates to keep its crystallinity and later transferred\n to silicon wafers for further processing. Here, an alternative promising route\n for the fabrication of optomechanical (OM) cavities on GaP epitaxially grown on\n nominally (001)-oriented Si is introduced by using a two-step process\n consisting of a low-temperature etching of GaP followed by selective etching of\n the underneath silicon. The low-temperature (-30 $^o$C) during the dry-etching\n of GaP hinders the lateral etching rate, preserving the pattern with a\n deviation between the design and the pattern in the GaP layer lower than 5 %,\n avoiding the complex process of transferring and bonding a GaP wafer to a\n silicon-on-insulator wafer. To demonstrate the quality and feasibility of the\n proposed fabrication route, suspended OM cavities are fabricated and\n experimentally characterized. The cavities show optical quality factors between\n 10$^3$ and 10$^4$, and localized mechanical resonances at frequencies around\n 3.1 GHz. Both optical and mechanical resonances are close to those previously\n reported on crystalline GaP structures. These results suggest a simple and\n low-cost way to build GaP-based photonic devices directly integrated on\n industry-standard Si(001) photonic wafers.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-lat/9607064",
        "title": "Polyakov Loops and Magnetic Screening from Monopoles in SU(2) Lattice\n  Gauge Theory",
        "abstract": "We present results from magnetic monopoles in $SU(2)$ lattice gauge theory at\n finite temperature. The lattices are $16^{3}\\times N_{t}$, for\n $N_{t}=4,6,8,12$, at $\\beta=2.5115$. Quantities discussed are: the spacial\n string tension, Polyakov loops, and the screening of timelike and spacelike\n magnetic currents.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0709.2711",
        "title": "Population synthesis at short wavelengths and spectrophotometric\n  diagnostic tools for galaxy evolution",
        "abstract": "Taking advantage of recent important advances in the calculation of\n high-resolution spectral grids of stellar atmospheres at short wavelengths, and\n their implementation for population synthesis models, we briefly review here\n some special properties of ultraviolet emission in SSPs, and discuss their\n potential applications for identifying and tuning up effective diagnostic tools\n to probe distinctive evolutionary properties of early-type galaxies and other\n evolved stellar systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0008277",
        "title": "Quantum Films Adsorbed on Graphite: Third and Fourth Helium Layers",
        "abstract": "Using a path-integral Monte Carlo method for simulating superfluid quantum\n films, we investigate helium layers adsorbed on a substrate consisting of\n graphite plus two solid helium layers. Our results for the promotion densities\n and the dependence of the superfluid density on coverage are in agreement with\n experiment. We can also explain certain features of the measured heat capacity\n as a function of temperature and coverage.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1507.07534",
        "title": "Unified model for cosmic rays above $10^{17}$ eV and the diffuse\n  gamma-ray and neutrino backgrounds",
        "abstract": "We investigate how the extragalactic proton component derived within the\n \"escape model\" can be explained by astrophysical sources. We consider as\n possible cosmic ray (CR) sources normal/starburst galaxies and radio-loud\n active galactic nuclei (AGN). We find that the contribution to the total\n extragalactic proton flux from normal and starburst galaxies is only\n subdominant and does not fit the spectral shape deduced in the escape model. In\n the case of radio-loud AGN, we show that the complete extragalactic proton\n spectrum can be explained by a single source population, BL Lac/FR I, for any\n of the potential acceleration sites in these sources. We calculate the diffuse\n neutrino and $\\gamma$-ray fluxes produced by these CR protons interacting with\n gas inside their sources. For a spectral slope of CRs close to $\\alpha=2.1-2.2$\n as suggested by shock acceleration, we find that these UHECR sources contribute\n the dominant fraction of both the isotropic $\\gamma$-ray background and of the\n extragalactic part of the astrophysical neutrino signal observed by IceCube.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0402354",
        "title": "Quantum dynamics of two capacitively coupled superconducting islands via\n  Josephson junctions",
        "abstract": "In this paper, we consider a system consisting of two capacitively coupled\n superconducting islands via Josephson junctions. We show that it can be reduced\n to two coupling harmonic oscillators under certain conditions, and solved\n exactly in terms of a displacing transformation, a beam-splitter-like\n transformation, and a squeezing transformation. It is found that the system\n evolves by a rotated-squeezed-coherent state when the system is initially in a\n coherent state. Quantum dynamics of the Cooper pairs in the two superconducting\n islands is investigated. It is shown that the number of the Cooper pairs in the\n two islands evolves periodically.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2305.11056",
        "title": "PETAL: Physics Emulation Through Averaged Linearizations for Solving\n  Inverse Problems",
        "abstract": "Inverse problems describe the task of recovering an underlying signal of\n interest given observables. Typically, the observables are related via some\n non-linear forward model applied to the underlying unknown signal. Inverting\n the non-linear forward model can be computationally expensive, as it often\n involves computing and inverting a linearization at a series of estimates.\n Rather than inverting the physics-based model, we instead train a surrogate\n forward model (emulator) and leverage modern auto-grad libraries to solve for\n the input within a classical optimization framework. Current methods to train\n emulators are done in a black box supervised machine learning fashion and fail\n to take advantage of any existing knowledge of the forward model. In this\n article, we propose a simple learned weighted average model that embeds\n linearizations of the forward model around various reference points into the\n model itself, explicitly incorporating known physics. Grounding the learned\n model with physics based linearizations improves the forward modeling accuracy\n and provides richer physics based gradient information during the inversion\n process leading to more accurate signal recovery. We demonstrate the efficacy\n on an ocean acoustic tomography (OAT) example that aims to recover ocean sound\n speed profile (SSP) variations from acoustic observations (e.g. eigenray\n arrival times) within simulation of ocean dynamics in the Gulf of Mexico.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1801.06816",
        "title": "Preferential Attachment Graphs with Planted Communities",
        "abstract": "A variation of the preferential attachment random graph model of Barab\\'asi\n and Albert is defined that incorporates planted communities. The graph is built\n progressively, with new vertices attaching to the existing ones one-by-one. At\n every step, the incoming vertex is randomly assigned a label, which represents\n a community it belongs to. This vertex then chooses certain vertices as its\n neighbors, with the choice of each vertex being proportional to the degree of\n the vertex multiplied by an affinity depending on the labels of the new vertex\n and a potential neighbor. It is shown that the fraction of half-edges attached\n to vertices with a given label converges almost surely for some classes of\n affinity matrices. In addition, the empirical degree distribution for the set\n of vertices with a given label converges to a heavy tailed distribution, such\n that the tail decay parameter can be different for different communities. Our\n proof method may be of independent interest, both for the classical Barab\\'asi\n -Albert model and for other possible extensions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1605.09485",
        "title": "Band Structure and Topological Properties of Graphene in a Superlattice\n  Spin Exchange Field",
        "abstract": "We analyze the energy spectrum of graphene in the presence of spin-orbit\n coupling and a unidirectionally periodic Zeeman field, focusing on the\n stability and location of Dirac points it may support. It is found that the\n Dirac points at the $K$ and $K'$ points are generically moved to other\n locations in the Brillouin zone, but that they remain present when the Zeeman\n field $\\vec{\\Delta}(x)$ integrates to zero within a unit cell. A large variety\n of locations for the Dirac points is shown to be possible: when $\\vec\\Delta\n \\parallel \\hat{z}$ they are shifted from their original locations along the\n direction perpendicular to the superlattice axis, while realizations of\n $\\vec\\Delta(x)$ that rotate periodically move the Dirac points to locations\n that can reflect the orbit of the rotating electron spin as it moves through a\n unit cell. When a uniform Zeeman field is applied in addition to a periodic\n $\\vec\\Delta \\parallel \\hat{z}$ integrating to zero, the system can be brought\n into a metallic, Dirac semimetal, or insulating state, depending on the\n direction of the uniform field. The latter is shown to be an anomalous quantum\n Hall insulator.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2304.13771",
        "title": "Some Problems Concerning Quantum Channels and Entropies",
        "abstract": "Fundamental limits on communication rates over quantum channels are given by\n mathematical expressions involving entropic formulas. Often, it is unclear if\n these expressions are computable. This thesis describes contributions to the\n study of optimizing and approximating entropic formulas over relevant subsets\n of quantum states. It also describes progress on a quantum erasure simulation\n problem in the high noise regime.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1302.4957",
        "title": "Learning Bayesian Networks: A Unification for Discrete and Gaussian\n  Domains",
        "abstract": "We examine Bayesian methods for learning Bayesian networks from a combination\n of prior knowledge and statistical data. In particular, we unify the approaches\n we presented at last year's conference for discrete and Gaussian domains. We\n derive a general Bayesian scoring metric, appropriate for both domains. We then\n use this metric in combination with well-known statistical facts about the\n Dirichlet and normal--Wishart distributions to derive our metrics for discrete\n and Gaussian domains.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1711.05698",
        "title": "Efficient Verification of Multi-Property Designs (The Benefit of Wrong\n  Assumptions) (Extended Version)",
        "abstract": "We consider the problem of efficiently checking a set of safety properties\n P1,....,Pk of one design. We introduce a new approach called JA-verification\n where JA stands for \"Just-Assume\" (as opposed to \"assume-guarantee\"). In this\n approach, when proving property Pi, one assumes that every property Pj for j!=i\n holds. The process of proving properties either results in showing that\n P1,....,Pk hold without any assumptions or finding a \"debugging set\" of\n properties. The latter identifies a subset of failed properties that cause\n failure of other properties. The design behaviors that cause the properties in\n the debugging set to fail must be fixed first. Importantly, in our approach,\n there is no need to prove the assumptions used. We describe the theory behind\n our approach and report experimental results that demonstrate substantial gains\n in performance, especially in the cases where a small debugging set exists.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0810.4411",
        "title": "Compression as a tool to detect Bose glass in cold atoms experiments",
        "abstract": "We suggest that measuring the variation of the radius of an atomic cloud when\n the harmonic tap confinement is varied make it possible to monitor the\n disappearance of the insulating Mott phase of an ultracold atomic gas trapped\n in a disordered optical lattice. This paves the way for an unambiguous\n identification of a Bose glass phase in the system.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1604.00524",
        "title": "Colocalising subcategories of modules over finite group schemes",
        "abstract": "The Hom closed colocalising subcategories of the stable module category of a\n finite group scheme are classified. This complements the classification of the\n tensor closed localising subcategories in our previous work. Both\n classifications involve pi-points in the sense of Friedlander and Pevtsova. We\n identify for each pi-point an endofinite module which both generates the\n corresponding minimal localising subcategory and cogenerates the corresponding\n minimal colocalising subcategory.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.03564",
        "title": "New series of multi-parametric solutions to GYBE: quantum gates and\n  integrability",
        "abstract": "We obtain two series of spectral parameter dependent solutions to the\n generalized Yang-Baxter equations (GYBE), for definite types of $N_1^2\\times\n N_2^2$ matrices with general dimensions $N_1$ and $N_2$. Appropriate extensions\n are presented for the inhomogeneous GYBEs. The first series of the solutions\n includes as particular cases the $X$-shaped trigonometric braiding matrices.\n For construction of the second series the colored and graded permutation\n operators are defined, and multi-spectral parameter Yang-Baxterization is\n performed. For some examples the corresponding integrable models are discussed.\n The unitary solutions existing in these two series can be considered as\n generalizations of the multipartite Bell matrices in the quantum information\n theory.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1712.02828",
        "title": "On the second largest component of random hyperbolic graphs",
        "abstract": "We show that in the random hyperbolic graph model as formalized by Gugelmann\n et al. in the most interesting range of $\\frac12 < \\alpha < 1$ the size of the\n second largest component is $\\Theta((\\log n)^{1/(1-\\alpha)})$, thus answering a\n question of Bode et al. We also show that for $\\alpha=\\frac12$ with constant\n probability the corresponding size is $\\Theta(\\log n)$, whereas for $\\alpha=1$\n it is $\\Omega(n^{b})$ for some $b > 0$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1111.0736",
        "title": "Branching instability in the flux creep regime of type-II\n  superconductors",
        "abstract": "We study theoretically the space-time evolution of the thermal and\n electromagnetic perturbation in a superconductor with a nonlinear\n current-voltage characteristics in the flux creep regime. On the basis of a\n linear analysis of a set of differential equations describing small\n perturbations of temperature and electromagnetic field, it is found that under\n some conditions a branching instability may occur in a superconductor sample.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.11555",
        "title": "Strong magnetic field inside degenerate relativistic plasma and the\n  impacts on the neutrino transport in Core-Collapse Supernovae",
        "abstract": "We study the impacts of magnetic field on the neutrino transport inside\n core-collapse supernovae (CCSNe). Magnetic field quantizes the momentum of\n electrons and positrons, resulting in the modification of weak-interaction\n cross sections and the chemical potentials of electrons and positrons. We\n include these changes in the leakage scheme of neutrino transport and perform\n 1D CCSN simulations with GR1D, assuming the postbounce magnetic field strength\n of $10^{16-17}$ G. The results show that the neutrino opacities are enhanced\n due to the amplified interaction rates, resulting in a larger neutrinosphere.\n This further reduces the peak value of neutrino luminosities and their decay\n rates since neutrinos stay longer inside the neutrinosphere. Meanwhile, the\n neutrino mean energies are smaller shortly after bounce and reach their peak\n values at later times. As these neutrino properties are crucial in subsequent\n nucleosynthesis processes, including the $\\nu$p-process, $\\nu$-process, and\n $r$-process, our findings suggest that the magnetic field may leave discernible\n marks on the abundance pattern of nucleosynthesis in CCSN.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0806.1961",
        "title": "Broadband frequency mode entanglement in waveguided PDC",
        "abstract": "We report the observation of beatings of the coincidence event rate in a\n Hong-Ou-Mandel interference (HOMI) between signal and idler photons from a\n parametric downconversion (PDC) process inside a multi-mode KTP waveguide. As\n explanation we introduce bi-photonic states entangled in their broadband\n frequency modes generated by waveguide mode triples and propose a suitable\n entanglement detection scheme.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2307.07952",
        "title": "Theoretical proposal for the experimental realization of realignment\n  operation",
        "abstract": "Realignment operation has a significant role in detecting bound as well as\n free entanglement. Just like partial transposition, it is also based on\n permutations of the matrix elements. However, the physical implementation of\n realignment operation is not known yet. In this letter, we address the problem\n of experimental realization of realignment operation and to achieve this aim,\n we propose a theoretical proposal for the same. We first show that after\n applying the realignment operation on a bipartite state, the resulting matrix\n can be expressed in terms of the partial transposition operation along with\n column interchange operations. We observed that these column interchange\n operations forms a permutation matrix which can be implemented via SWAP\n operator acting on the density matrix. This mathematical framework is used to\n exactly determine the first moment of the realignment matrix experimentally.\n This has been done by showing that the first moment of the realignment matrix\n can be expressed as the expectation value of a SWAP operator which indicates\n the possibility of its measurement. Further, we have provided an estimation of\n the higher order realigned moments in terms of the first realigned moment and\n thus pave a way to estimate the higher order moments experimentally. Next, we\n develop moments based entanglement detection criteria that detect positive\n partial transpose entangled states (PPTES) as well as negative partial\n transpose entangled states (NPTES). Moreover, we define a new matrix\n realignment operation for three-qubit states and have devised an entanglement\n criteria that is able to detect three-qubit fully entangled states. We have\n developed various methods and techniques in the detection of bipartite and\n tripartite entangled states that may be realized in the current technology.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1311.2799",
        "title": "Aggregation of Affine Estimators",
        "abstract": "We consider the problem of aggregating a general collection of affine\n estimators for fixed design regression. Relevant examples include some commonly\n used statistical estimators such as least squares, ridge and robust least\n squares estimators. Dalalyan and Salmon (2012) have established that, for this\n problem, exponentially weighted (EW) model selection aggregation leads to sharp\n oracle inequalities in expectation, but similar bounds in deviation were not\n previously known. While results indicate that the same aggregation scheme may\n not satisfy sharp oracle inequalities with high probability, we prove that a\n weaker notion of oracle inequality for EW that holds with high probability.\n Moreover, using a generalization of the newly introduced $Q$-aggregation scheme\n we also prove sharp oracle inequalities that hold with high probability.\n Finally, we apply our results to universal aggregation and show that our\n proposed estimator leads simultaneously to all the best known bounds for\n aggregation, including $\\ell_q$-aggregation, $q \\in (0,1)$, with high\n probability.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1711.02881",
        "title": "Topological and statistical properties of nonlinear force-free fields",
        "abstract": "We use our semi-analytic solution of the nonlinear force-free field equation\n to construct three-dimensional magnetic fields that are applicable to the solar\n corona and study their statistical properties for estimating the degree of\n braiding exhibited by these fields. We present a new formula for calculating\n the winding number and compare it with the formula for the crossing number. The\n comparison is shown for a toy model of two helices and for realistic cases of\n nonlinear force-free fields; conceptually the formulae are nearly the same but\n the resulting distributions calculated for a given topology can be different.\n We also calculate linkages, which are useful topological quantities that are\n independent measures of the contribution of magnetic braiding to the total free\n energy and relative helicity of the field. Finally, we derive new analytical\n bounds for the free energy and relative helicity for the field configurations\n in terms of the linking number. These bounds will be of utility in estimating\n the braided energy available for nano-flares or for eruptions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2006.10754",
        "title": "Islands for Reflected Entropy",
        "abstract": "Recent work has demonstrated the need to include contributions from\n entanglement islands when computing the entanglement entropy in QFT states\n coupled to regions of semiclassical gravity. We propose a new formula for the\n reflected entropy that includes additional contributions from such islands. We\n derive this formula from the gravitational path integral by finding additional\n saddles that include generalized replica wormholes. We also demonstrate that\n our covariant formula satisfies all the inequalities required of the reflected\n entropy. We use this formula in various examples that demonstrate its relevance\n in illustrating the structure of multipartite entanglement that are invisible\n to the entropies.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-ph/9907378",
        "title": "QCD-based description of one-particle inclusive B decays",
        "abstract": "We discuss one-particle inclusive B decays in the limit of heavy b and c\n quarks. Using the large-N_C limit we factorize the non-leptonic matrix\n elements, and we employ a short distance expansion. Modeling the remaining\n nonperturbative matrix elements we obtain predictions for various decay\n channels and compare them with existing data.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2009.07940",
        "title": "Scattering Amplitudes and Soft Theorems in Multi-Flavor Galileon\n  Theories",
        "abstract": "In this paper, we initiate the study of multi-flavor Galileon theories using\n the methods of scattering amplitudes. We explore this topic from different\n perspectives and extend the techniques employed so far mainly in the\n single-flavor case. This includes soft theorems, generalized soft theorems with\n non-trivial right-hand side, Galileon dualities, soft bootstrap and bonus\n relations. We demonstrate new properties on two examples, the multi-flavor U(N)\n Galileon and the three-flavor U(2)/U(1) Galileon.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1706.08527",
        "title": "Combinatorics and Topology of Kawai-Lewellen-Tye Relations",
        "abstract": "We revisit the relations between open and closed string scattering amplitudes\n discovered by Kawai, Lewellen, and Tye (KLT). We show that they emerge from the\n underlying algebro-topological identities known as the twisted period\n relations. In order to do so, we formulate tree-level string theory amplitudes\n in the language of twisted de Rham theory. There, open string amplitudes are\n understood as pairings between twisted cycles and cocycles. Similarly, closed\n string amplitudes are given as a pairing between two twisted cocycles. Finally,\n objects relating the two types of string amplitudes are the $\\alpha'$-corrected\n bi-adjoint scalar amplitudes recently defined by the author [arXiv:1610.04230].\n We show that they naturally arise as intersection numbers of twisted cycles. In\n this work we focus on the combinatorial and topological description of twisted\n cycles relevant for string theory amplitudes. In this setting, each twisted\n cycle is a polytope, known in combinatorics as the associahedron, together with\n an additional structure encoding monodromy properties of string integrals. In\n fact, this additional structure is given by higher-dimensional generalizations\n of the Pochhammer contour. An open string amplitude is then computed as an\n integral of a logarithmic form over an associahedron. We show that the inverse\n of the KLT kernel can be calculated from the knowledge of how pairs of\n associahedra intersect one another in the moduli space. In the field theory\n limit, contributions from these intersections localize to vertices of the\n associahedra, giving rise to the bi-adjoint scalar partial amplitudes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1412.1752",
        "title": "Cross-correlation Aided Transport in Stochastically Driven Accretion\n  Flows",
        "abstract": "Origin of linear instability resulting in rotating sheared accretion flows\n has remained a controversial subject for long. While some explanations of such\n non-normal transient growth of disturbances in the Rayleigh stable limit were\n available for magnetized accretion flows, similar instabilities in absence of\n magnetic perturbations remained unexplained. This dichotomy was resolved in two\n recent publications by Chattopadhyay, {\\it et al} where it was shown that such\n instabilities, especially for non-magnetized accretion flows, were introduced\n through interaction of the inherent stochastic noise in the system (even a\n \\enquote{cold} accretion flow at 3000K is too \\enquote{hot} in the statistical\n parlance and is capable of inducing strong thermal modes) with the underlying\n Taylor-Couette flow profiles. Both studies, however, excluded the additional\n energy influx (or efflux) that could result from nonzero cross-correlation of a\n noise perturbing the velocity flow, say, with the noise that is driving the\n vorticity flow (or equivalently the magnetic field and magnetic vorticity flow\n dynamics). In this article we show that nonzero noise cross-correlations\n essentially renormalize the strength of temporal correlations. Apart from an\n overall boost in the energy rate (both for spatial and temporal correlations,\n and hence in the ensemble averaged energy spectra), this results in mutual\n competition in growth rates of affected variables often resulting in\n suppression of oscillating Alfven waves at small times while leading to faster\n saturations at relatively longer time scales. The effects are seen to be more\n pronounced with magnetic field fluxes where the noise cross-correlation\n magnifies the strength of the field concerned.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1710.00947",
        "title": "VIDOSAT: High-dimensional Sparsifying Transform Learning for Online\n  Video Denoising",
        "abstract": "Techniques exploiting the sparsity of images in a transform domain have been\n effective for various applications in image and video processing. Transform\n learning methods involve cheap computations and have been demonstrated to\n perform well in applications such as image denoising and medical image\n reconstruction. Recently, we proposed methods for online learning of\n sparsifying transforms from streaming signals, which enjoy good convergence\n guarantees, and involve lower computational costs than online synthesis\n dictionary learning. In this work, we apply online transform learning to video\n denoising. We present a novel framework for online video denoising based on\n high-dimensional sparsifying transform learning for spatio-temporal patches.\n The patches are constructed either from corresponding 2D patches in successive\n frames or using an online block matching technique. The proposed online video\n denoising requires little memory, and offers efficient processing. Numerical\n experiments compare the performance to the proposed video denoising scheme but\n fixing the transform to be 3D DCT, as well as prior schemes such as dictionary\n learning-based schemes, and the state-of-the-art VBM3D and VBM4D on several\n video data sets, demonstrating the promising performance of the proposed\n methods.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2205.15613",
        "title": "Quasibound states of scalar fields in the consistent 4D\n  Einstein-Gauss-Bonnet-(Anti-)de Sitter gravity",
        "abstract": "We examine the interaction between massless scalar fields and the\n gravitational field generated by a black hole solution that was recently\n obtained in the consistent well-defined 4-dimensional Einstein-Gauss-Bonnet\n gravity with a cosmological constant. In order to do this, we calculate\n quasibound state frequencies of scalar fields for the spherically symmetric\n black hole in the consistent 4-dimensional Einstein-Gauss-Bonnet-de Sitter and\n Anti-de Sitter theories. The expression for the quasibound states is obtained\n by using the polynomial condition associated to the Heun functions, and their\n values are overdamped. We also demonstrate the stability of the systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0403738",
        "title": "Nanothermodynamics:a generic approach to material properties at\n  nanoscale",
        "abstract": "Granular and nanoscale materials containing a relatively small number of\n constituents have been studied to discover how their properties differ from\n their macroscopic counterparts. These studies are designed to test how far the\n known macroscopic approaches such as thermodynamics may be applicable in these\n cases. A brief review of the recent literature on these topics is given as a\n motivation to introduce a generic approach called nanothermodynamics. An\n important feature that must be incorporated into the theory is the non-additive\n property because of the importance of surface contributions to the physics of\n these systems. This is achieved by incorporating fluctuations into the theory\n right from the start. There are currently two approaches to incorporate this\n property. Hill (and further elaborated more recently with Chamberlin) initiated\n an approach by modifying the thermodynamic relations by taking into account the\n surface effects. We generalize Boltzmann-Gibbs statistical mechanics by\n relaxing the additivity properties of thermodynamic quantities to include\n nonextensive features of such systems. An outline of this generalization of the\n macroscopic thermodynamics to nano-systems will be given here.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2207.06417",
        "title": "Regular charged black hole in massive gravity as heat engine",
        "abstract": "We examine the effect of addition of graviton mass on the efficiency of a\n regular charged black hole (RCB). In doing so, we make few comments on the\n critical behaviour of the system and calculate the relevant thermodynamic\n quantities such as entropy, Hawkings temperature and heat capacity. We confirm\n that graviton mass has a positive effect on the efficacy of such a heat engine\n under consideration.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1706.08977",
        "title": "A Millimeter Continuum Size-Luminosity Relationship for Protoplanetary\n  Disks",
        "abstract": "We present a sub-arcsecond resolution survey of the 340 GHz dust continuum\n emission from 50 nearby protoplanetary disks, based on new and archival\n observations with the Submillimeter Array. The observed visibility data were\n modeled with a simple prescription for the radial surface brightness profile.\n The results were used to extract intuitive, empirical estimates of the emission\n \"size\" for each disk, $R_{\\rm eff}$, defined as the radius that encircles a\n fixed fraction of the total continuum luminosity, $L_{\\rm mm}$. We find a\n significant correlation between the sizes and luminosities, such that $R_{\\rm\n eff} \\propto L_{\\rm mm}^{0.5}$, providing a confirmation and quantitative\n characterization of a putative trend that was noted previously. This\n correlation suggests that these disks have roughly the same average surface\n brightness interior to their given effective radius, ~0.2 Jy arcsec$^{-2}$ (or\n 8 K in brightness temperature). The same trend remains, but the 0.2dex of\n dispersion perpendicular to this relation essentially disappears, when we\n account for the irradiation environment of each disk with a crude approximation\n of the dust temperatures based on the stellar host luminosities. We consider\n two (not mutually exclusive) explanations for the origin of this\n size-luminosity relationship. Simple models of the growth and migration of disk\n solids can account for the observed trend for a reasonable range of initial\n conditions, but only on timescales that are much shorter than the nominal ages\n present in the sample. An alternative scenario invokes optically thick emission\n concentrated on unresolved scales, with filling factors of a few tens of\n percent, that are perhaps manifestations of localized particle traps.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.11140",
        "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end\n  Object Detection",
        "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt object\n detectors efficiently with only few annotated samples. Fine-tuning has been\n shown to be an effective and practical approach. However, previous works often\n take the classical base-novel two stage fine-tuning procedure but ignore the\n implicit stability-plasticity contradiction among different modules.\n Specifically, the random re-initialized classifiers need more plasticity to\n adapt to novel samples. The other modules inheriting pre-trained weights demand\n more stability to reserve their class-agnostic knowledge. Regular fine-tuning\n which couples the optimization of these two parts hurts the model\n generalization in FSOD scenarios. In this paper, we find that this problem is\n prominent in the end-to-end object detector Sparse R-CNN for its\n multi-classifier cascaded architecture. We propose to mitigate this\n contradiction by a new three-stage fine-tuning procedure by introducing an\n addtional plasticity classifier fine-tuning(PCF) stage. We further design the\n multi-source ensemble(ME) technique to enhance the generalization of the model\n in the final fine-tuning stage. Extensive experiments verify that our method is\n effective in regularizing Sparse R-CNN, outperforming previous methods in the\n FSOD benchmark.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0705.2373",
        "title": "Bekenstein Bound and Spectral Geometry",
        "abstract": "In this letter it is proposed to study the Bekenstein's $\\xi(4)$ calculation\n of the $S/E$ bound for more general geometries. It is argued that, using some\n relations among eigenvalues obtained in the context of Spectral Geometry, it is\n possible to estimate $\\xi(4)$ without an exact analytical knowledge of the\n spectrum. Finally it is claimed that isospectrality can define a class of\n domains with the same ratio $S/E$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1308.1305",
        "title": "Carbon coating of the SPS dipole chambers",
        "abstract": "The Electron Multipacting (EM) phenomenon is a limiting factor for the\n achievement of high luminosity in accelerators for positively charged particles\n and for the performance of RF devices. At CERN, the Super Proton Synchrotron\n (SPS) must be upgraded in order to feed the Large Hadron Collider (LHC) with 25\n ns bunch spaced beams. At such small bunch spacing, EM may limit the\n performance of the SPS and consequently that of the LHC. To mitigate this\n phenomenon CERN is developing a carbon thin film coating with low Secondary\n Electron Yield (SEY) to coat the internal walls of the SPS dipoles beam pipes.\n This paper presents the progresses in the coating technology, the performance\n of the carbon coatings and the strategy for a large scale production.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1005.2009",
        "title": "HAT-P-16b: A 4 Mj Planet Transiting A Bright Star On An Eccentric Orbit",
        "abstract": "We report the discovery of HAT-P-16b, a transiting extrasolar planet orbiting\n the V = 10.8 mag F8 dwarf GSC 2792-01700, with a period P = 2.775960 +-\n 0.000003 d, transit epoch Tc = 2455027.59293 +- 0.00031 (BJD), and transit\n duration 0.1276 +- 0.0013 d. The host star has a mass of 1.22 +- 0.04 Msun,\n radius of 1.24 +- 0.05 Rsun, effective temperature 6158 +-80 K, and metallicity\n [Fe/H] = +0.17 +- 0.08. The planetary companion has a mass of 4.193 +- 0.094\n MJ, and radius of 1.289 +- 0.066 RJ yielding a mean density of 2.42 +- 0.35\n g/cm3. Comparing these observed characteristics with recent theoretical models,\n we find that HAT-P-16b is consistent with a 1 Gyr H/He-dominated gas giant\n planet. HAT-P-16b resides in a sparsely populated region of the mass{radius\n diagram and has a non-zero eccentricity of e = 0.036 with a significance of 10\n sigma.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2402.00530",
        "title": "Superfiltering: Weak-to-Strong Data Filtering for Fast\n  Instruction-Tuning",
        "abstract": "Instruction tuning is critical to improve LLMs but usually suffers from\n low-quality and redundant data. Data filtering for instruction tuning has\n proved important in improving both the efficiency and performance of the tuning\n process. But it also leads to extra cost and computation due to the involvement\n of LLMs in this process. To reduce the filtering cost, we study Superfiltering:\n Can we use a smaller and weaker model to select data for finetuning a larger\n and stronger model? Despite the performance gap between weak and strong\n language models, we find their highly consistent capability to perceive\n instruction difficulty and data selection results. This enables us to use a\n much smaller and more efficient model to filter the instruction data used to\n train a larger language model. Not only does it largely speed up the data\n filtering, but the filtered-data-finetuned LLM achieves even better performance\n on standard benchmarks. Extensive experiments validate the efficacy and\n efficiency of our approach.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1111.0345",
        "title": "Searching for Unmodeled Sources Using the Earth Occultation Data from\n  the Fermi GBM",
        "abstract": "Employing the 12 NaI detectors in the Fermi GBM, the Earth Occultation\n Technique (EOT) can be used to measure the fluxes of x-ray and gamma-ray\n sources. Each time a source passes behind the Earth (or emerges from behind the\n Earth), a step-like feature is produced in the detector count rate. With a\n predefined catalog of source positions, the times of the occultation steps can\n be calculated, the individual steps fit, and the fluxes derived. However, in\n order to find new sources and generate a complete catalog, a method is needed\n for generating an image of the sky. An imaging algorithm has been developed to\n generate all-sky images using the GBM data. Here we present imaging results\n from ~2.5 years of data in the 12-25 keV and 100-300 keV energy bands.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1501.01983",
        "title": "Neutrino-nucleus interactions and the short-range structure of nuclei",
        "abstract": "Improvements in theoretical modeling of Short Range structures and phenomena,\n and comparisons with data, will require sustained collaboration between nuclear\n theorists and neutrino experimentalists. The extensive history of studying this\n area of nuclear physics in electron- and hadron-scattering experiments, coupled\n with the transformative capabilities of LArTPCs to identify neutrinos, will\n provide a ripe opportunity for new discoveries that will further our\n understanding of the nucleus.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1611.06400",
        "title": "The puzzle of the CNO isotope ratios in AGB carbon stars",
        "abstract": "Previous determinations of the oxygen isotopic ratios in AGB carbon stars\n were at odds with the existing theoretical predictions. We aim to redetermine\n the oxygen ratios in these stars using new spectral analysis tools and further\n develop discussions on the carbon and nitrogen isotopic ratios in order to\n elucidate this problem. Oxygen isotopic ratios were derived from spectra in the\n K-band in a sample of galactic AGB carbon stars of different spectral types and\n near solar metallicity. Synthetic spectra calculated in LTE with spherical\n carbon-rich atmosphere models and updated molecular line lists were used. The\n CNO isotope ratios derived in a homogeneous way, were compared with theoretical\n predictions for low-mass (1.5-3 M_o) AGB stars computed with the FUNS code\n assuming extra mixing both during the RGB and AGB phases. For most of the stars\n the 16O/17O/18O ratios derived are in good agreement with theoretical\n predictions confirming that, for AGB stars, are established using the values\n reached after the FDU according to the initial stellar mass. This fact, as far\n as the oxygen isotopic ratios are concerned, leaves little space for the\n operation of any extra mixing mechanism during the AGB phase. Nevertheless, for\n a few stars with large 16O/17O/18O, the operation of such a mechanism might be\n required, although their observed 12C/13C and 14N/15N ratios would be difficult\n to reconcile within this scenario. Furthermore, J-type stars tend to have lower\n 16O/17O ratios than the normal carbon stars, as already indicated in previous\n studies. Excluding these peculiar stars, AGB carbon stars occupy the same\n region as pre-solar type I oxide grains in a 17O/16O vs. 18O/16O diagram,\n showing little spread. This reinforces the idea that these grains were probably\n formed in low-mass stars during the previous O-rich phases.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2012.04871",
        "title": "A note on truncated degenerate Bell polynomials",
        "abstract": "The aim of this paper is to introduce truncated degenerate Bell polynomials\n and numbers and to investigate some of their properties. In more detail, we\n obtain explicit expressions, identities involving other special polynomials,\n integral representations, Dobinski-like formula and expressions of the\n generating function in terms of differential operators and linear incomplete\n gamma function. In addition, we introduce truncated degenerate modified Bell\n polynomials and numbers and get similar results for those polynomials. As an\n application of our results, we show that the truncated degenerate Bell numbers\n can be expressed as a finite sum involving moments of a beta random variable\n with certain parameters.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1503.04111",
        "title": "Asymptotic behavior of Palais-Smale sequences associated with fractional\n  Yamabe type equations",
        "abstract": "In this paper, we analyze the asymptotic behavior of Palais-Smale sequences\n associated with fractional Yamabe type equations on an asymptotically\n hyperbolic Riemannian manifold. We prove that Palais-Smale sequences can be\n decomposed into the solution of the limit equation plus a finite number of\n bubbles, which are the rescaling of the fundamental solutions to the fractional\n Yamabe equation on Euclidean space. We also verify the non-interfering fact for\n multi-bubbles.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0107625",
        "title": "Pseudogap formation of four-layer BaRuO$_3$ and its electrodynamic\n  response changes",
        "abstract": "We investiaged the optical properties of four-layer BaRuO$_{3}$, which shows\n a fermi-liquid-like behavior at low temperature. Its optical conductivity\n spectra clearly displayed the formation of a pseudogap and the development of a\n coherent peak with decreasing temperature. Temperature-dependences of the\n density $n$ and the scattering rate $1/\\tau$ of the coherent component were\n also derived. As the temperature decreases, both $n$ and $1/\\tau$ decrease for\n four-layer BaRuO$_{3}$. These electrodynamic responses were compared with those\n of nine-layer BaRuO$_{3}$, which also shows a pseudogap formation but has an\n insulator-like state at low temperature. It was found that the relative rates\n of change of both $n$ and $1/\\tau$ determine either metallic or insulator-like\n responses in the ruthenates. The optical properties of the four-layer ruthenate\n were also compared with those of other pseudogap systems, such as high $T_{c}$\n cuprates and heavy electron systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1501.07623",
        "title": "Energy Deposition Studies for the Hi-Lumi LHC Inner Triplet Magnets",
        "abstract": "A detailed model of the High Luminosity LHC inner triplet region with new\n large-aperture Nb3Sn magnets, field maps, corrector packages, and segmented\n tungsten inner absorbers was built and implemented into the FLUKA and MARS15\n codes. In the optimized configuration, the peak power density averaged over the\n magnet inner cable width is safely below the quench limit. For the integrated\n luminosity of 3000 fb -1, the peak dose in the innermost magnet insulator\n ranges from 20 to 35 MGy. Dynamic heat loads to the triplet magnet cold mass\n are calculated to evaluate the cryogenic capability. In general, FLUKA and MARS\n results are in a very good agreement.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1511.03137",
        "title": "k-way Hypergraph Partitioning via n-Level Recursive Bisection",
        "abstract": "We develop a multilevel algorithm for hypergraph partitioning that contracts\n the vertices one at a time. Using several caching and lazy-evaluation\n techniques during coarsening and refinement, we reduce the running time by up\n to two-orders of magnitude compared to a naive $n$-level algorithm that would\n be adequate for ordinary graph partitioning. The overall performance is even\n better than the widely used hMetis hypergraph partitioner that uses a classical\n multilevel algorithm with few levels. Aided by a portfolio-based approach to\n initial partitioning and adaptive budgeting of imbalance within recursive\n bipartitioning, we achieve very high quality. We assembled a large benchmark\n set with 310 hypergraphs stemming from application areas such VLSI, SAT\n solving, social networks, and scientific computing. We achieve significantly\n smaller cuts than hMetis and PaToH, while being faster than hMetis.\n Considerably larger improvements are observed for some instance classes like\n social networks, for bipartitioning, and for partitions with an allowed\n imbalance of 10%. The algorithm presented in this work forms the basis of our\n hypergraph partitioning framework KaHyPar (Karlsruhe Hypergraph Partitioning).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1206.0520",
        "title": "Searching for New Physics with Flavor Violating Observables",
        "abstract": "In this talk, I review the status and prospects of several low energy flavor\n observables that are highly sensitive to New Physics effects. In particular I\n discuss the implications for possible New Physics in b --> s transitions coming\n from the recent experimental results on the B_s mixing phase, the branching\n ratio of the rare decay B_s --> mu+mu-, and angular observables in the B --> K*\n mu+mu- decay. Also the recent evidence for direct CP violation in singly\n Cabibbo suppressed charm decays and its interpretation in the context of New\n Physics models is briefly discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/9311075",
        "title": "Regular Representation of the Quantum Heisenberg Double $U_q(sl(2))$,\n  $Fun_{q}(SL(2))$ ($q$ is a root of unity)",
        "abstract": "Pairing between the universal enveloping algebra $U_q(sl(2))$ and the algebra\n of functions over $SL_q(2)$ is obtained in explicit terms. The regular\n representation of the quantum double is constructed and investigated. The\n structure of the root subspaces of the Casimir operator is revealed and\n described in terms of $SL_q(2)$ elements.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2203.04114",
        "title": "A study on joint modeling and data augmentation of multi-modalities for\n  audio-visual scene classification",
        "abstract": "In this paper, we propose two techniques, namely joint modeling and data\n augmentation, to improve system performances for audio-visual scene\n classification (AVSC). We employ pre-trained networks trained only on image\n data sets to extract video embedding; whereas for audio embedding models, we\n decide to train them from scratch. We explore different neural network\n architectures for joint modeling to effectively combine the video and audio\n modalities. Moreover, data augmentation strategies are investigated to increase\n audio-visual training set size. For the video modality the effectiveness of\n several operations in RandAugment is verified. An audio-video joint mixup\n scheme is proposed to further improve AVSC performances. Evaluated on the\n development set of TAU Urban Audio Visual Scenes 2021, our final system can\n achieve the best accuracy of 94.2% among all single AVSC systems submitted to\n DCASE 2021 Task 1b.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2307.05070",
        "title": "A Logic-Based Analysis of Responsibility",
        "abstract": "This paper presents a logic-based framework to analyze responsibility, which\n I refer to as intentional epistemic act-utilitarian stit theory (IEAUST). To be\n precise, IEAUST is used to model and syntactically characterize various modes\n of responsibility, where by 'modes of responsibility' I mean instances of\n Broersen's three categories of responsibility (causal, informational, and\n motivational responsibility), cast against the background of particular deontic\n contexts. IEAUST is obtained by integrating a modal language to express the\n following components of responsibility on stit models: agency, epistemic\n notions, intentionality, and different senses of obligation. With such a\n language, I characterize the components of responsibility using particular\n formulas. Then, adopting a compositional approach -- where complex modalities\n are built out of more basic ones -- these characterizations of the components\n are used to formalize the aforementioned modes of responsibility.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1604.05495",
        "title": "Deep Saliency with Encoded Low level Distance Map and High Level\n  Features",
        "abstract": "Recent advances in saliency detection have utilized deep learning to obtain\n high level features to detect salient regions in a scene. These advances have\n demonstrated superior results over previous works that utilize hand-crafted low\n level features for saliency detection. In this paper, we demonstrate that\n hand-crafted features can provide complementary information to enhance\n performance of saliency detection that utilizes only high level features. Our\n method utilizes both high level and low level features for saliency detection\n under a unified deep learning framework. The high level features are extracted\n using the VGG-net, and the low level features are compared with other parts of\n an image to form a low level distance map. The low level distance map is then\n encoded using a convolutional neural network(CNN) with multiple 1X1\n convolutional and ReLU layers. We concatenate the encoded low level distance\n map and the high level features, and connect them to a fully connected neural\n network classifier to evaluate the saliency of a query region. Our experiments\n show that our method can further improve the performance of state-of-the-art\n deep learning-based saliency detection methods.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1209.6005",
        "title": "Imaginary quadratic fields with isomorphic abelian Galois groups",
        "abstract": "In 1976, Onabe discovered that, in contrast to the Neukirch-Uchida results\n that were proved around the same time, a number field $K$ is not completely\n characterized by its absolute abelian Galois group $A_K$. The first examples of\n non-isomorphic $K$ having isomorphic $A_K$ were obtained on the basis of a\n classification by Kubota of idele class character groups in terms of their\n infinite families of Ulm invariants, and did not yield a description of $A_K$.\n In this paper, we provide a direct `computation' of the profinite group $A_K$\n for imaginary quadratic $K$, and use it to obtain many different $K$ that all\n have the same minimal absolute abelian Galois group.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0002405",
        "title": "Recovering the Topology of the Initial Density Fluctuations Using the\n  IRAS Point Source Catalogue Redshift Survey",
        "abstract": "We apply the reconstruction technique of Nusser & Dekel (1992) to the\n recently available Point Source Catalogue Redshift Survey (PSCz) in order to\n subtract the phase correlations that are expected to develop in the mild\n non-linear regime of gravitational evolution. We study the evolution of\n isodensity contours defined using an adaptive smoothing algorithm in order to\n minimize the problems derived from the non-comutivity of operators. We study\n the genus curves of the fields thus obtained and concentrate on the evolution\n of the amplitude drops, a meta-statistic able to quantify the level of\n phase-correlation present in the field. In order to test the method and to\n quantify the level of statistical uncertainty, we apply the method to a set of\n mock PSCz catalogues derived from the N-body simulations of two 'standard' CDM\n models, kindly granted to us by the Virgo consortium. We find the method to be\n reliable in recovering the right amplitude drops. When applied to PSCz, the\n level of phase correlations observed is very low on all scales ranging from\n 5h-1Mpc to 60 h-1Mpc, providing support to the theory that structure originated\n from gaussian initial conditions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2304.08602",
        "title": "Crossing Roads of Federated Learning and Smart Grids: Overview,\n  Challenges, and Perspectives",
        "abstract": "Consumer's privacy is a main concern in Smart Grids (SGs) due to the\n sensitivity of energy data, particularly when used to train machine learning\n models for different services. These data-driven models often require huge\n amounts of data to achieve acceptable performance leading in most cases to\n risks of privacy leakage. By pushing the training to the edge, Federated\n Learning (FL) offers a good compromise between privacy preservation and the\n predictive performance of these models. The current paper presents an overview\n of FL applications in SGs while discussing their advantages and drawbacks,\n mainly in load forecasting, electric vehicles, fault diagnoses, load\n disaggregation and renewable energies. In addition, an analysis of main design\n trends and possible taxonomies is provided considering data partitioning, the\n communication topology, and security mechanisms. Towards the end, an overview\n of main challenges facing this technology and potential future directions is\n presented.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1910.10872",
        "title": "Man is to Person as Woman is to Location: Measuring Gender Bias in Named\n  Entity Recognition",
        "abstract": "We study the bias in several state-of-the-art named entity recognition (NER)\n models---specifically, a difference in the ability to recognize male and female\n names as PERSON entity types. We evaluate NER models on a dataset containing\n 139 years of U.S. census baby names and find that relatively more female names,\n as opposed to male names, are not recognized as PERSON entities. We study the\n extent of this bias in several NER systems that are used prominently in\n industry and academia. In addition, we also report a bias in the datasets on\n which these models were trained. The result of this analysis yields a new\n benchmark for gender bias evaluation in named entity recognition systems. The\n data and code for the application of this benchmark will be publicly available\n for researchers to use.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2312.07095",
        "title": "Dual Brunn-Minkowski inequality for C-star bodies",
        "abstract": "In this paper, we consider the concept of $C$-star body in a fixed pointed\n closed convex cone $C$ and study the dual mixed volume for $C$-star bodies. For\n $C$-star bodies, we establish the corresponding dual Brunn-Minkowski\n inequality, the dual Minkowski inequality and the dual Aleksandrov-Fenchel\n inequality. Our dual Brunn-Minkowski inequality for $C$-star bodies strengthens\n Schneider's Brunn-Minkowski inequality for $C$-coconvex sets.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2011.02272",
        "title": "Trustworthy AI",
        "abstract": "Modern AI systems are reaping the advantage of novel learning methods. With\n their increasing usage, we are realizing the limitations and shortfalls of\n these systems. Brittleness to minor adversarial changes in the input data,\n ability to explain the decisions, address the bias in their training data, high\n opacity in terms of revealing the lineage of the system, how they were trained\n and tested, and under which parameters and conditions they can reliably\n guarantee a certain level of performance, are some of the most prominent\n limitations. Ensuring the privacy and security of the data, assigning\n appropriate credits to data sources, and delivering decent outputs are also\n required features of an AI system. We propose the tutorial on Trustworthy AI to\n address six critical issues in enhancing user and public trust in AI systems,\n namely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of\n adversarial attacks, (iv) improved privacy and security in model building, (v)\n being decent, and (vi) model attribution, including the right level of credit\n assignment to the data sources, model architectures, and transparency in\n lineage.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0805.3745",
        "title": "Enslaved Phase-Separation Fronts in One-Dimensional Binary Mixtures",
        "abstract": "Phase-separation fronts leave in their wakes morphologies that are\n substantially different from the morphologies formed in homogeneous\n phase-separation. In this paper we focus on fronts in binary mixtures that are\n enslaved phase-separation fronts, i.e. fronts that follow in the wake of a\n control-parameter front. In the one-dimensional case, which is the focus of\n this paper, the formed morphology is deceptively simple: alternating domains of\n a regular size. However, determining the size of these domains as a function of\n the front speed and other system parameters is a non-trivial problem. We\n present an analytical solution for the case where no material is deposited\n ahead of the front and numerical solutions and scaling arguments for more\n general cases. Through these enslaved phase-separation fronts large domains can\n be formed that are practically unattainable in homogeneous one-dimensional\n phase-separation.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2112.15105",
        "title": "Moire Band Structures of the Double twisted Few Layer Graphene",
        "abstract": "Very recently, unconventional superconductivity has been observed in the\n double twisted trilayer graphene (TLG), where three monolayer graphene (MLG)\n are stacked on top of each other with two twist angles [J. M. Park, et al.,\n Nature 590, 249 (2021); Z. Hao, et al., Science 371, 1133 (2021); X. Zhang, et\n al., Phys. Rev. Lett.127, 166802 (2021)]. When some of MLGs in the double\n twisted TLG are replaced by bilayer graphene (BLG), we get a new family of\n double twisted moire heterostructure, namely double twisted few layer graphene\n (DTFLG). In this work, we theoretically investigate the moire band structures\n of the DTFLGs with diverse arrangements of MLG and BLG. We find that, depending\n on the relative rotation direction of the two twist angles (alternate or chiral\n twist) and the middle van der Waals (vdW) layer (MLG or BLG), a general\n (X+Y+Z)-DTFLG can be classified into four categories, i.e. (X+1+Z)-ATFLG,\n (X+2+Z)-ATFLG, (X+1+Z)-CTFLG and (X+2+Z)-CTFLG, each of which has its own\n unique band structure. Here, X, Y, Z denote the three vdW layers, i.e. MLG or\n BLG. Interestingly, the (X+1+Z)-ATFLGs have a pair of perfect flat bands at the\n magic angle about $1.54^\\circ$ coexisting with a pair of linear or parabolic\n bands, which is quite like the double twisted TLG. Meanwhile, when the twist\n angle is smaller than a \"magic angle\" $1.70^\\circ$, the (X+2+Z)-CTFLGs can have\n two isolated narrow bands at $E_f$ with band width less than 5 meV. The\n influence of electric field and the topological features of the moire bands\n have been studied as well. Our work indicates that the DTFLGs, especially the\n (X+1+Z)-ATFLG and (X+2+Z)-CTFLG, are promising platforms to study the moire\n flat band induced novel correlation and topological effects.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1403.7948",
        "title": "Structure of conflict graphs in constraint alignment problems and\n  algorithms",
        "abstract": "We consider the constrained graph alignment problem which has applications in\n biological network analysis. Given two input graphs $G_1=(V_1,E_1),\n G_2=(V_2,E_2)$, a pair of vertex mappings induces an {\\it edge conservation} if\n the vertex pairs are adjacent in their respective graphs. %In general terms The\n goal is to provide a one-to-one mapping between the vertices of the input\n graphs in order to maximize edge conservation. However the allowed mappings are\n restricted since each vertex from $V_1$ (resp. $V_2$) is allowed to be mapped\n to at most $m_1$ (resp. $m_2$) specified vertices in $V_2$ (resp. $V_1$). Most\n of results in this paper deal with the case $m_2=1$ which attracted most\n attention in the related literature. We formulate the problem as a maximum\n independent set problem in a related {\\em conflict graph} and investigate\n structural properties of this graph in terms of forbidden subgraphs. We are\n interested, in particular, in excluding certain wheals, fans, cliques or claws\n (all terms are defined in the paper), which corresponds in excluding certain\n cycles, paths, cliques or independent sets in the neighborhood of each vertex.\n Then, we investigate algorithmic consequences of some of these properties,\n which illustrates the potential of this approach and raises new horizons for\n further works. In particular this approach allows us to reinterpret a known\n polynomial case in terms of conflict graph and to improve known approximation\n and fixed-parameter tractability results through efficiently solving the\n maximum independent set problem in conflict graphs. Some of our new\n approximation results involve approximation ratios that are function of the\n optimal value, in particular its square root; this kind of results cannot be\n achieved for maximum independent set in general graphs.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1508.03714",
        "title": "Probabilistic Asynchronous Arbitrary Pattern Formation",
        "abstract": "We propose a new probabilistic pattern formation algorithm for oblivious\n mobile robots that operates inthe ASYNC model. Unlike previous work, our\n algorithm makes no assumptions about the local coordinatesystems of robots (the\n robots do not share a common \"North\" nor a common \"Right\"), yet it preserves\n theability from any initial configuration that contains at least 5 robots to\n form any general pattern (and not justpatterns that satisfy symmetricity\n predicates). Our proposal also gets rid of the previous assumption (in thesame\n model) that robots do not pause while moving (so, our robots really are fully\n asynchronous), and theamount of randomness is kept low -- a single random bit\n per robot per Look-Compute-Move cycle is used.Our protocol consists in the\n combination of two phases, a probabilistic leader election phase, and a\n deterministicpattern formation one. As the deterministic phase does not use\n chirality, it may be of independentinterest in the deterministic context. A\n noteworthy feature of our algorithm is the ability to form patternswith\n multiplicity points (except the gathering case due to impossibility results), a\n new feature in the contextof pattern formation that we believe is an important\n asset of our approach.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1312.4434",
        "title": "Electrical conductivity of the quark-gluon plasma and soft photon\n  spectrum in heavy-ion collisions",
        "abstract": "We extract the electrical conductivity $\\sigma_0$ of the quark gluon\n plasma(QGP) and study the effects of magnetic field and chiral anomaly on soft\n photon azimuthal anisotropy, $v_2$, based on the thermal photon spectrum at\n $0.4GeV<p_{\\perp}<0.6GeV$ at RHIC energy. As a basis for our analysis, we\n derive the behavior of retarded photon self energy of a strongly interacting\n neutral plasma in hydrodynamic regime in the presence of magnetic field and\n chiral anomaly. By evolving the resulting soft thermal photon production rate\n over the realistic hydrodynamic background and comparing the results with the\n preliminary data from the PHENIX Collaboration, we found that the electrical\n conductivity at QGP temperature is in the range: $0.4<\\sigma_0/(e^{2}T) <1.1$,\n which is comparable with recent studies on lattice. We also compare the\n contribution from the magnetic field and chiral anomaly to soft thermal photon\n $v_{2}$ with the data. We argue that at LHC, the chiral magnetic wave would\n give negative contribution to photon $v_2$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1804.07890",
        "title": "A Nutritional Label for Rankings",
        "abstract": "Algorithmic decisions often result in scoring and ranking individuals to\n determine credit worthiness, qualifications for college admissions and\n employment, and compatibility as dating partners. While automatic and seemingly\n objective, ranking algorithms can discriminate against individuals and\n protected groups, and exhibit low diversity. Furthermore, ranked results are\n often unstable --- small changes in the input data or in the ranking\n methodology may lead to drastic changes in the output, making the result\n uninformative and easy to manipulate. Similar concerns apply in cases where\n items other than individuals are ranked, including colleges, academic\n departments, or products.\n  In this demonstration we present Ranking Facts, a Web-based application that\n generates a \"nutritional label\" for rankings. Ranking Facts is made up of a\n collection of visual widgets that implement our latest research results on\n fairness, stability, and transparency for rankings, and that communicate\n details of the ranking methodology, or of the output, to the end user. We will\n showcase Ranking Facts on real datasets from different domains, including\n college rankings, criminal risk assessment, and financial services.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/physics/0603233",
        "title": "A Prototype PCI-based Data Acquisition System for Cosmic Ray Detection\n  Below 10^18 eV",
        "abstract": "A prototype flash analog-to-digital readout system for cosmic ray detection\n at energies below 10^18 eV has been designed and tested at Columbia University\n Nevis Laboratories. The electronics consist of an FADC module that digitizes 16\n photomultipliers at 40 MHz with 14-bit dynamic range. The module is read out to\n a PC (running Linux) through a PCI interface. Taking advantage of the large\n bandwidth provided by the PCI bus, we have implemented a software-based data\n acquisition system. This note describes the software and electronics, as well\n as preliminary tests carried out using a prototype FADC module.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0708.1991",
        "title": "Conditions for the Trivers-Willard hypothesis to be valid: A minimal\n  population-genetic model",
        "abstract": "The very insightful Trivers-Willard hypothesis, proposed in the early 1970s,\n states that females in good physiological conditions are more likely to produce\n male offspring, when the variance of reproductive success amongst males is\n high. A number of studies, aimed at its experimental verification, have found\n adequate supportive evidence in its favour. Theoretical investigations,\n however, have been few, perhaps because formulating a population-genetic model\n for describing the Trivers-Willard hypothesis turns out to be surprisingly\n complex. The present study describes a minimal population genetic model to\n explore one specific scenario, viz. how is the preference for a male offspring\n by females in good condition altered when 'g', the proportion of such females\n in the population changes from a low to a high value. As expected, when the\n proportion of such females is low, i.e., for low values of 'g', the\n Trivers-Willard (TW) strategy goes to fixation against the equal investment\n strategy. This holds true up to gmax, a critical value of 'g', above which the\n two strategies coexist, but the proportion of the TW strategy steadily\n decreases as 'g' increases to unity. Similarly, when the effect of well-endowed\n males attaining disproportionately high number of matings is more pronounced,\n the TW strategy is more likely to go to fixation. Interestingly, the success of\n the TW strategy has a complex dependence on the variance in the physiological\n condition of females. If the difference in the two types of conditions is not\n large, TW strategy is favoured, and its success is more likely as the\n difference increases. However, beyond a critical value of the difference, the\n TW strategy is found to be less and less likely to succeed as the difference\n becomes larger. Possible reasons for these effects are discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2008.01033",
        "title": "Experimental evidence of hidden spin polarization in silicon by using\n  strain gradient",
        "abstract": "The centrosymmetric materials with hidden spin polarization are considered to\n be the promising candidates for realization of energy efficient spintronics\n systems and devices. However, the control of hidden spin polarization and\n resulting transport behavior is not well understood. We hypothesized that\n inhomogeneous strain can be the external knob to study and control hidden spin\n polarization. In this work, we demonstrate a strain gradient mediated symmetry\n breaking to discover the hidden spin polarization in centrosymmetric Si\n lattice. The hidden spin polarization gives rise to magnetocrystalline\n anisotropy and local magnetic moment along <111> directions in the Si. The\n local magnetic moment gives rise to spin-acoustic phonon coupling, which is the\n underlying cause of observed spin-Hall effect in both n-Si and p-Si. Discovery\n of hidden magnetic moment in Si not only challenges the fundamental\n understanding of the origin of the magnetism but also presents a giant leap in\n realization of spintronics systems.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1811.07494",
        "title": "Bulk Spectrum and K-theory for Infinite-Area Topological Quasicrystal",
        "abstract": "The bulk spectrum of a possible Chern insulator on a quasicrystalline lattice\n is examined. The effect of being a 2D insulator seems to override any fractal\n properties in the spectrum. We compute that the spectrum is either two\n continuous bands, or that any gaps other than the main gap are small. After\n making estimates on the spectrum, we deduce a finite system size, above which\n the K-theory must coincide with the K-theory of the infinite system. Knowledge\n of the spectrum and $K$-theory of the infinite-area system will control the\n spectrum and K-theory of sufficiently large finite systems.\n  The relation between finite volume $K$-theory and infinite volume Chern\n numbers is only proven to begin, for the model under investigation here, for\n systems on Hilbert space of dimension around 17 million. The real-space method\n based on the Clifford spectrum allows for computing Chern numbers for systems\n on Hilbert space of dimension around 2.7 million. New techniques in numerical\n K-theory are used to equate the K-theory of systems of different sizes.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1712.04781",
        "title": "Recollements from Cotorsion Pairs",
        "abstract": "Given a complete hereditary cotorsion pair $(\\mathcal{A},\\mathcal{B})$ in a\n Grothendieck category $\\mathcal{G}$, the derived category\n $\\mathcal{D}(\\mathcal{B})$ of the exact category $\\mathcal{B}$ is defined as\n the quotient of the category $\\mathrm{Ch}(\\mathcal{B})$, of unbounded complexes\n with terms in $\\mathcal{B}$, modulo the subcategory $\\widetilde{\\mathcal{B}}$\n consisting of the acyclic complexes with terms in $\\mathcal{B}$ and cycles in\n $\\mathcal{B}$.\n  We restrict our attention to the cotorsion pairs such that\n $\\widetilde{\\mathcal{B}}$ coincides with the class $ex\\mathcal{B}$ of the\n acyclic complexes of $\\mathrm{Ch}(\\mathcal{G})$ with terms in $\\mathcal{B}$. In\n this case the derived category $\\mathcal{D}(\\mathcal{B})$ fits into a\n recollement $\\dfrac{ex\\mathcal{B}}{\\sim}\n  \\mathrel{\\substack{\\textstyle\\leftarrow\\textstyle\\rightarrow\\textstyle\\leftarrow}}\n  {K(\\mathcal{B})}\n  \\mathrel{\\substack{\\textstyle\\leftarrow\\textstyle\\rightarrow\\textstyle\\leftarrow}}\n {\\dfrac{\\mathrm{Ch}(\\mathcal{B})}{ex\\mathcal{B} }}$.\n  We will explore the conditions under which\n $\\mathrm{ex}\\,\\mathcal{B}=\\widetilde{\\mathcal{B}}$ and provide many examples.\n  Symmetrically, we prove analogous results for the exact category\n $\\mathcal{A}$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1412.6315",
        "title": "On the environments of type Ia supernovae within host galaxies",
        "abstract": "We present constraints on supernovae type Ia (SNe~Ia) progenitors through an\n analysis of the environments found at the explosion sites of 102 events within\n star-forming host galaxies. H-alpha and GALEX near-UV images are used to trace\n on-going and recent star formation (SF), while broad band B, R, J, K imaging is\n also analysed. Using pixel statistics we find that SNe~Ia show the lowest\n degree of association with H-alpha emission of all supernova types. It is also\n found that they do not trace near-UV emission. As the latter traces SF on\n timescales less than 100 Myr, this rules out any extreme 'prompt' delay-times\n as the dominant progenitor channel of SNe~Ia. SNe~Ia best trace the B-band\n light distribution of their host galaxies. This implies that the population\n within star-forming galaxies is dominated by relatively young progenitors.\n Splitting SNe by their (B-V) colours at maximum light, 'redder' events show a\n higher degree of association to HII regions and are found more centrally within\n hosts. We discuss possible explanations of this result in terms of line of\n sight extinction and progenitor effects. No evidence for correlations between\n SN stretch and environment properties is observed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2208.10527",
        "title": "The Fibonacci decomposition of symmetric Tetranacci polynomials",
        "abstract": "In this manuscript, we introduce (symmetric) Tetranacci polynomials $\\xi_j$\n as a twofold generalization of ordinary Tetranacci numbers, by considering both\n non unity coefficients and generic initial values in their recursive\n definition. The issue of these polynomials arose in condensed matter physics\n and the diagonalization of symmetric Toeplitz matrices having in total four\n non-zero off diagonals. For the latter, the symmetric Tetranacci polynomials\n are the basic entities of the associated eigenvectors; thus, treating the\n recursive structure determines the eigenvalues as well. Subsequently, we\n present a complete closed form expression for any symmetric Tetranacci\n polynomial. The key feature is a decomposition in terms of generalized\n Fibonacci polynomials.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2201.03372",
        "title": "Asymmetry engendered by symmetric kink-antikink scattering in a\n  degenerate two-field model",
        "abstract": "In this paper we analyze the scattering process in a two-field model in\n $(1+1)$-dimensions, with the special property to have several topological\n solutions: i) one with higher rest mass, characterized by a nested defect (lump\n inside a kink), and ii) four others having lower rest mass, degenerated, and\n characterized by a kink inside kink. We investigate kink-antikink symmetric\n scattering, where the kink and antikink have higher rest mass and the same\n initial velocity modulus $v$. The output of scattering presents a wide range of\n behaviors, such as annihilation of the kink-antikink pair, the emission of\n radiation jets, the generation of oscillating pulses and the change of the\n topological sector. We show that the changing of the topological sector is\n favored, and only two of the four sectors are possible as outcomes. Moreover,\n despite the degeneracy in energy, the distribution of the final states is\n asymmetric in the phase space, being an effect of the presence of vibrational\n states.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.03546",
        "title": "NovelGym: A Flexible Ecosystem for Hybrid Planning and Learning Agents\n  Designed for Open Worlds",
        "abstract": "As AI agents leave the lab and venture into the real world as autonomous\n vehicles, delivery robots, and cooking robots, it is increasingly necessary to\n design and comprehensively evaluate algorithms that tackle the ``open-world''.\n To this end, we introduce NovelGym, a flexible and adaptable ecosystem designed\n to simulate gridworld environments, serving as a robust platform for\n benchmarking reinforcement learning (RL) and hybrid planning and learning\n agents in open-world contexts. The modular architecture of NovelGym facilitates\n rapid creation and modification of task environments, including multi-agent\n scenarios, with multiple environment transformations, thus providing a dynamic\n testbed for researchers to develop open-world AI agents.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2006.06130",
        "title": "ROOTS: Object-Centric Representation and Rendering of 3D Scenes",
        "abstract": "A crucial ability of human intelligence is to build up models of individual\n 3D objects from partial scene observations. Recent works achieve object-centric\n generation but without the ability to infer the representation, or achieve 3D\n scene representation learning but without object-centric compositionality.\n Therefore, learning to represent and render 3D scenes with object-centric\n compositionality remains elusive. In this paper, we propose a probabilistic\n generative model for learning to build modular and compositional 3D object\n models from partial observations of a multi-object scene. The proposed model\n can (i) infer the 3D object representations by learning to search and group\n object areas and also (ii) render from an arbitrary viewpoint not only\n individual objects but also the full scene by compositing the objects. The\n entire learning process is unsupervised and end-to-end. In experiments, in\n addition to generation quality, we also demonstrate that the learned\n representation permits object-wise manipulation and novel scene generation, and\n generalizes to various settings. Results can be found on our project website:\n https://sites.google.com/view/roots3d",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1909.04846",
        "title": "Covariance Matrix Adaptation Greedy Search Applied to Water Distribution\n  System Optimization",
        "abstract": "Water distribution system design is a challenging optimisation problem with a\n high number of search dimensions and constraints. In this way, Evolutionary\n Algorithms (EAs) have been widely applied to optimise WDS to minimise cost\n subject whilst meeting pressure constraints. This paper proposes a new hybrid\n evolutionary framework that consists of three distinct phases. The first phase\n applied CMA-ES, a robust adaptive meta-heuristic for continuous optimisation.\n This is followed by an upward-greedy search phase to remove pressure\n violations. Finally, a downward greedy search phase is used to reduce oversized\n pipes. To assess the effectiveness of the hybrid method, it was applied to five\n well-known WDSs case studies. The results reveal that the new framework\n outperforms CMA-ES by itself and other previously applied heuristics on most\n benchmarks in terms of both optimisation speed and network cost.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1803.04092",
        "title": "Estimating Shape of Target Object Moving on Unknown Trajectory by Using\n  Location-Unknown Distance Sensors: Theoretical Framework",
        "abstract": "By using directional distance sensors that have unknown locations, this paper\n proposes a method of estimating the shape of a location-unknown target object\n $T$ moving with unknown speed on an unknown straight line trajectory.\n Regardless of many unknown factors, the proposed method can estimate the shape\n by using each sensor's continuous report of the measured distance to $T$\n without using side information or additional mechanisms such as locations of\n anchor sensors and angle-of-arrival measurements. By using the sensor reports,\n the proposed method estimates (i) the moving speed of $T$, (ii) the length and\n direction of an edge of $T$, and (iii) the order of consecutive edges. As a\n result, we can obtain the shape of $T$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1509.07804",
        "title": "From Statistician to Data Scientist",
        "abstract": "According to a recent report from the European Commission, the world\n generates every minute 1.7 million of billions of data bytes, the equivalent of\n 360,000 DVDs, and companies that build their decision-making processes by\n exploiting these data increase their productivity. The treatment and\n valorization of massive data has consequences on the employment of graduate\n students in statistics. Which additional skills do students trained in\n statistics need to acquire to become data scientists ? How to evolve training\n so that future graduates can adapt to rapid changes in this area, without\n neglecting traditional jobs and the fundamental and lasting foundation for the\n training? After considering the notion of big data and questioning the\n emergence of a \"new\" science: Data Science, we present the current developments\n in the training of engineers in Mathematical and Modeling at INSA Toulouse.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/alg-geom/9509007",
        "title": "Obstruction bundles, semiregularity, and Seiberg-Witten invariants",
        "abstract": "We compare the deformation theory and the analytic structure of the\n Seiberg-Witten moduli spaces of a K\\\"ahler surface to the corresponding\n components of the Hilbert scheme, and show that they are isomorphic. Next we\n show how to compute the invariant in case the moduli space is smooth but not of\n the expected dimension, and apply this study to elliptic surfaces. Finally we\n discuss ruled surfaces, both products and more general ruled surfaces. For\n product ruled surfaces we relate the infinitesimal structure of the moduli\n spaces to Brill-Noether theory and compute the invariant in special cases. For\n more general ruled surfaces, we relate the geometry of the Hilbert scheme to\n properties of stable bundles and give more general computations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.20991",
        "title": "Hard Cases Detection in Motion Prediction by Vision-Language Foundation\n  Models",
        "abstract": "Addressing hard cases in autonomous driving, such as anomalous road users,\n extreme weather conditions, and complex traffic interactions, presents\n significant challenges. To ensure safety, it is crucial to detect and manage\n these scenarios effectively for autonomous driving systems. However, the rarity\n and high-risk nature of these cases demand extensive, diverse datasets for\n training robust models. Vision-Language Foundation Models (VLMs) have shown\n remarkable zero-shot capabilities as being trained on extensive datasets. This\n work explores the potential of VLMs in detecting hard cases in autonomous\n driving. We demonstrate the capability of VLMs such as GPT-4v in detecting hard\n cases in traffic participant motion prediction on both agent and scenario\n levels. We introduce a feasible pipeline where VLMs, fed with sequential image\n frames with designed prompts, effectively identify challenging agents or\n scenarios, which are verified by existing prediction models. Moreover, by\n taking advantage of this detection of hard cases by VLMs, we further improve\n the training efficiency of the existing motion prediction pipeline by\n performing data selection for the training samples suggested by GPT. We show\n the effectiveness and feasibility of our pipeline incorporating VLMs with\n state-of-the-art methods on NuScenes datasets. The code is accessible at\n https://github.com/KTH-RPL/Detect_VLM.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1311.3778",
        "title": "Twisted reduction in large N QCD with adjoint Wilson fermions",
        "abstract": "The twisted space-time reduced model of large $N$ QCD with various flavours\n of adjoint Wilson fermions is constructed applying the symmetric twist boundary\n conditions with flux $k$. The models with one and two flavours show distinctive\n behaviours. For the two flavor case, the string tension, calculated at $N=289$,\n approaches zero as we decrease the quark mass in a way consistent with the\n theory being governed by an infrared fixed point. In contrast, the string\n tension for the case of a single adjoint Wilson fermion remains finite as the\n quark mass decreases to zero, supporting that this is a confining theory.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0604579",
        "title": "Asymptotics of the Gaussian Curvatures of the Canonical Metric on the\n  Surface",
        "abstract": "We study the canonical metric on a compact Riemann surface of genus at least\n two. While it is known that the canonical metric is of nonpositive curvature,\n we show that its Gaussian curvatures are not bounded away from zero nor\n negative infinity when the surface is close to the compactification divisor of\n Riemann's moduli space.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1006.0676",
        "title": "Longitudinal foliation rigidity and Lipschitz-continuous invariant forms\n  for hyperbolic flows",
        "abstract": "In several contexts the defining invariant structures of a hyperbolic\n dynamical system are smooth only in systems of algebraic origin (smooth\n rigidity), and we prove new results of this type for a class of flows. For a\n compact Riemannian manifold and a uniformly quasiconformal transversely\n symplectic Anosov flow we define the longitudinal KAM-cocycle and use it to\n prove a rigidity result: The joint stable/unstable subbundle is\n Zygmund-regular, and higher regularity implies vanishing of the longitudinal\n KAM-cocycle, which in turn implies that the subbundle is Lipschitz-continuous\n and indeed that the flow is smoothly conjugate to an algebraic one. To\n establish the latter, we prove results for algebraic Anosov systems that imply\n smoothness and a special structure for any Lipschitz-continuous invariant\n 1-form. Several features of the reasoning are interesting: The use of exterior\n calculus for Lipschitz-continuous forms, that the arguments for geodesic flows\n and infranilmanifoldautomorphisms are quite different, and the need for mixing\n as opposed to ergodicity in the latter case.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1605.01437",
        "title": "Compound chondrule formation via collision of supercooled droplets",
        "abstract": "We present a novel model showing that compound chondrules are formed by\n collisions of supercooled droplets. This model reproduces two prominent\n observed features of compound chondrules: the nonporphyritic texture and the\n size ratio between two components.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1809.01816",
        "title": "Visual Coreference Resolution in Visual Dialog using Neural Module\n  Networks",
        "abstract": "Visual dialog entails answering a series of questions grounded in an image,\n using dialog history as context. In addition to the challenges found in visual\n question answering (VQA), which can be seen as one-round dialog, visual dialog\n encompasses several more. We focus on one such problem called visual\n coreference resolution that involves determining which words, typically noun\n phrases and pronouns, co-refer to the same entity/object instance in an image.\n This is crucial, especially for pronouns (e.g., `it'), as the dialog agent must\n first link it to a previous coreference (e.g., `boat'), and only then can rely\n on the visual grounding of the coreference `boat' to reason about the pronoun\n `it'. Prior work (in visual dialog) models visual coreference resolution either\n (a) implicitly via a memory network over history, or (b) at a coarse level for\n the entire question; and not explicitly at a phrase level of granularity. In\n this work, we propose a neural module network architecture for visual dialog by\n introducing two novel modules - Refer and Exclude - that perform explicit,\n grounded, coreference resolution at a finer word level. We demonstrate the\n effectiveness of our model on MNIST Dialog, a visually simple yet\n coreference-wise complex dataset, by achieving near perfect accuracy, and on\n VisDial, a large and challenging visual dialog dataset on real images, where\n our model outperforms other approaches, and is more interpretable, grounded,\n and consistent qualitatively.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1810.10267",
        "title": "Thermoelectric generator at optimal power with external and internal\n  irreversibilities",
        "abstract": "There are few exact results on optimal power conditions for a thermoelectric\n generator in the presence of both external and internal\n irreversibilities---modelled as non-ideal thermal contacts and Joule heating,\n respectively. Simplified cases, where only one kind of irreversibility is\n assumed, yield some well-known expressions for efficiency at maximum power\n (EMP), such as Curzon-Ahlborn efficiency for endoreversible model. In this\n work, we analyze situations under the simultaneous presence of internal and\n external irreversibilities. To simplify, we neglect heat leaks, and each kind\n of irreversibility is assumed only on the side of one of the thermal contacts.\n We also present the symmetric case---where each kind of irreversibility\n contributes with equal strengths towards the side of each thermal contact. We\n show the bounds satisfied by EMP in each of these regimes and compare its\n properties for thermal impedence matching and close to equilibrium, where we\n find step-wise changes in EMP.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1611.06514",
        "title": "A scenario-based framework for supply planning under uncertainty:\n  stochastic programming versus robust optimization approaches",
        "abstract": "In this paper we analyze the effect of two modelling approaches for supply\n planning problems under uncertainty: two-stage stochastic programming (SP) and\n robust optimization (RO). The comparison between the two approaches is\n performed through a scenario-based framework methodology, which can be applied\n to any optimization problem affected by uncertainty. For SP we compute the\n minimum expected cost based on the specific probability distribution of the\n uncertain parameters related to a set of scenarios. For RO we consider static\n approaches where random parameters belong to box or ellipsoidal uncertainty\n sets in compliance with the data used to generate SP scenarios. Dynamic\n approaches for RO, via the concept of adjustable robust counterpart, are also\n considered. The efficiency of the methodology has been illustrated for a supply\n planning problem to optimize vehicle-renting and procurement transportation\n activities involving uncertainty on demands and on buying costs for\n extra-vehicles. Numerical experiments through the scenario-based framework\n allow a fair comparison in real case instances. Advantages and disadvantages of\n RO and SP are discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1501.03808",
        "title": "A Probabilistic Approach to Problems on Distance Graphs and Graphs of\n  Diameters (Candidate-Degree Dissertation Author's Review, in Russian)",
        "abstract": "The dissertation is related to combinatorial geometry with a strong\n probabilistic flavor. The main results can be split into three parts. The\n results of the first part guarantee that each \"unit distance graph\" in the\n plane has an induced subgraph with chromatic number at most 4 that covers at\n least 91.7 percent of the vertices of the whole graph.\n  The results of the second and third parts are related to the standard model\n of a random graph with n labeled vertices in which the edges occur\n independently with probability p, where p is a function of n. This is known as\n the Erdos--Renyi model G(n,p). Given a monotone property of a graph, Erdos and\n Renyi's theorem (1960) states that there exists a critical threshold value of\n p(n) below which the probability that a random graph has that property tends to\n one (as n tends to infinity) and above which the probability tends to zero.\n  The main results of the second part are concerned with the (monotone)\n property of a graph to be isomorphic to some unit-distance graph in Euclidean\n d-space with fixed dimension d. The results of this part guarantee that for d\n in {2, 3, 4, 5, 6, 7, 8}, the threshold value of p(n) is big-Theta of 1/n.\n Furthermore, the case d = 1 stands apart from the case of higher dimensions;\n here the threshold probability is big-Theta of 1/(n^(4/3)).\n  The results of the third part are devoted to studying \"graphs of diameters\"\n from the probabilistic standpoint. In particular, it is shown that under some\n conditions, almost all graphs of diameters in the plane have chromatic number\n less than 3. More generally, it is shown for G(n,p) that graphs of diameters\n have a tendency to chromatic degeneration (for large n) when p is close to 0,\n but have a tendency to completeness when p is close to 1.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2003.04546",
        "title": "First-Order Methods for Nonconvex Quadratic Minimization",
        "abstract": "We consider minimization of indefinite quadratics with either trust-region\n (norm) constraints or cubic regularization. Despite the nonconvexity of these\n problems we prove that, under mild assumptions, gradient descent converges to\n their global solutions, and give a non-asymptotic rate of convergence for the\n cubic variant. We also consider Krylov subspace solutions and establish sharp\n convergence guarantees to the solutions of both trust-region and\n cubic-regularized problems. Our rates mirror the behavior of these methods on\n convex quadratics and eigenvector problems, highlighting their scalability.\n When we use Krylov subspace solutions to approximate the cubic-regularized\n Newton step, our results recover the strongest known convergence guarantees to\n approximate second-order stationary points of general smooth nonconvex\n functions.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/cond-mat/0701718",
        "title": "A Numerical Treatment of the Rf SQUID: I. General Properties and Noise\n  Energy",
        "abstract": "We investigate the characteristics and noise performance of rf\n Superconducting Quantum Interference Devices (SQUIDs) by solving the\n corresponding Langevin equations numerically and optimizing the model\n parameters with respect to noise energy. After introducing the basic concepts\n of the numerical simulations, we give a detailed discussion of the performance\n of the SQUID as a function of all relevant parameters. The best performance is\n obtained in the crossover region between the dispersive and dissipative\n regimes, characterized by an inductance parameter \\beta_L'\\equiv 2\\pi L\n I_0/\\Phi_0\\approx 1; L is the loop inductance, I_0 the critical current of the\n Josephson junction, and \\Phi_0 the flux quantum. In this regime, which is not\n well explored by previous analytical approaches, the lowest (intrinsic) values\n of noise energy are a factor of about 2 above previous estimates based on\n analytical approaches. However, several other analytical predictions, such as\n the inverse proportionality of the noise energy on the tank circuit quality\n factor and the square of the coupling coefficient between the tank circuit and\n the SQUID loop, could not be well reproduced. The optimized intrinsic noise\n energy of the rf SQUID is superior to that of the dc SQUID at all temperatures.\n Although for technologically achievable parameters this advantage shrinks,\n particularly at low thermal fluctuation levels, we give an example for\n realistic parameters that leads to a noise energy comparable to that of the dc\n SQUID even in this regime.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1907.10685",
        "title": "Angles between Haagerup--Schultz projections and spectrality of\n  operators",
        "abstract": "We investigate angles between Haagerup--Schultz projections of operators\n belonging to finite von Neumann algebras, in connection with a property\n analogous to Dunford's notion of spectrality of operators. In particular, we\n show that an operator can be written as the sum of a normal and an\n s.o.t.-quasinilpotent operator that commute if and only if the angles between\n its Haagerup--Schultz projections are uniformly bounded away from zero (and we\n call this the uniformly nonzero anlges property). Moreover, we show that\n spectrality is equivalent to this uniformly nonzero angles property plus\n decomposability. Finally, using this characterization, we construct an easy\n example of an operator which is decomposable but not spectral, and we show that\n Voiculescu's circular operator is not spectral (nor are any of the circular\n free Poisson operators).",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1405.4655",
        "title": "Squeezing effect induced by minimal length uncertainty",
        "abstract": "In this work, the dynamics of the deformed one-dimensional harmonic\n oscillator with minimal length uncertainty is examined and the analytical\n solutions for time evolution of position and momentum operators are presented\n in which the rough approximation that neglects the higher order terms in\n BakerHausdor lemma is avoided. Based on these analytical solutions the\n uncertainties for position and momentum operators are calculated in a coherent\n state, and an unexpected squeezing effect in both coordinate and momentum\n directions is found in comparison with ordinary harmonic oscillator. Obviously\n such a squeezing effect is induced by the minimal length uncertainty\n (gravitational effects). Our results are applied to the electrons trapped in\n strong magnetic fields to examine the degree of the existing squeezing effect\n in a real system, which shows the squeezing degree induced by minimal length\n uncertainty is very small.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/quant-ph/0302124",
        "title": "Entanglement induced by spontaneous emission in spatially extended\n  two-atom systems",
        "abstract": "We investigate the role of the collective antisymmetric state in entanglement\n creation by spontaneous emission in a system of two non-overlapping two-level\n atoms. We calculate and illustrate graphically populations of the collective\n atomic states and the Wootters entanglement measure (concurrence) for two sets\n of initial atomic conditions. Our calculations include the dipole-dipole\n interaction and a spatial separation between the atoms that the antisymmetric\n state of the system is included throughout even for small interatomic\n separations. It is shown that spontaneous emission can lead to a transient\n entanglement between the atoms even if the atoms were prepared initially in an\n unentangled state. We find that the ability of spontaneous emission to create\n the transient entanglement relies on the absence of population in the\n collective symmetric state of the system. For the initial state of only one\n atom excited, the entanglement builds up rapidly in time and reaches a maximum\n for the parameter values corresponding roughly to zero population in the\n symmetric state. On the other hand, for the initial condition of both atoms\n excited, the atoms remain unentangled until the symmetric state is depopulated.\n A simple physical interpretation of these results is given in terms of the\n diagonal states of the density matrix of the system. We also study entanglement\n creation in a system of two non-identical atoms of different transition\n frequencies. It is found that the entanglement between the atoms can be\n enhanced compared to that for identical atoms, and can decay with two different\n time scales resulting from the coherent transfer of the population from the\n symmetric to the antisymmetric state. In addition, we find that a decaying\n initial entanglement between the atoms can display a revival behaviour.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2303.16745",
        "title": "Pressure tuning of optical reflectivity in LuH2",
        "abstract": "Recently, the claim of room-temperature superconductivity in nitrogen-doped\n lutetium hydride at near-ambient conditions has attracted tremendous attention.\n Criticism of the work rises shortly, while further explorations are needed to\n settle the dispute. One of the intriguing observations is the pressured-induced\n color change, which has been reproduced in the lutetium dihydride LuH2 while\n its mechanism remains unclear. Through optical reflectivity measurements of\n LuH2 in the visible to near-infrared region, we observe strong light absorption\n next to the sharp plasmon resonance, which continuously shifts to higher\n energies with increasing pressure. It gives rise to the increased reflection of\n red light and suppressed reflection of blue light. Our work sheds light on\n resolving the puzzles regarding the pressure induced color change in LuH2.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1802.01829",
        "title": "Average Case $(s, t)$-weak tractability of non-homogenous tensor product\n  problems",
        "abstract": "We study $d$-variate problem in the average case setting with respect to a\n zero-mean Gaussian measure. The covariance kernel of this Gaussian measure is a\n product of univariate kernels and satisfies some special properties. We study\n $(s, t)$-weak tractability of this multivariate problem, and obtain a necessary\n and sufficient condition for $s>0$ and $t\\in(0,1)$. Our result can apply to the\n problems with covariance kernels corresponding to Euler and Wiener integrated\n processes, Korobov kernels, and analytic Korobov kernels.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1210.7110",
        "title": "Gauss-Bonnet theorem in sub-Riemannian Heisenberg space $H^1$",
        "abstract": "We prove a version of Gauss-Bonnet theorem in sub-Riemannian Heisenberg space\n $H^1$. The sub-Riemannian distance makes $H^1$ a metric space and consenquently\n with a spherical Hausdorff measure. Using this measure, we define a Gaussian\n curvature at points of a surface S where the sub-Riemannian distribution is\n transverse to the tangent space of S. If all points of S have this property, we\n prove a Gauss-Bonnet formula and for compact surfaces (which are topologically\n a torus) we obtain $\\int_S K = 0$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2406.07157",
        "title": "Machine learning potential for the Cu-W system",
        "abstract": "Combining the excellent thermal and electrical properties of Cu with the high\n abrasion resistance and thermal stability of W, Cu-W nanoparticle-reinforced\n metal matrix composites and nano-multilayers (NMLs) are finding applications as\n brazing fillers and shielding material for plasma and radiation. Due to the\n large lattice mismatch between fcc Cu and bcc W, these systems have complex\n interfaces that are beyond the scales suitable for ab initio methods, thus\n motivating the development of chemically accurate interatomic potentials. Here,\n a neural network potential (NNP) for Cu-W is developed within the\n Behler-Parrinello framework using a curated training dataset that captures\n metallurgically-relevant local atomic environments. The Cu-W NNP accurately\n predicts (i) the metallurgical properties (elasticity, stacking faults,\n dislocations, thermodynamic behavior) in elemental Cu and W, (ii) energies and\n structures of Cu-W intermetallics and solid solutions, and (iii) a range of fcc\n Cu/bcc W interfaces, and exhibits physically-reasonable behavior for solid\n W/liquid Cu systems. As will be demonstrated in forthcoming work, this near-ab\n initio-accurate NNP can be applied to understand complex phenomena involving\n interface-driven processes and properties in Cu-W composites.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1807.03891",
        "title": "Decay of correlations and uniqueness of the infinite-volume Gibbs\n  measure of the canonical ensemble of 1d-lattice systems",
        "abstract": "We consider a one-dimensional lattice system of unbounded, real-valued spins\n with arbitrary strong, quadratic, finite-range interaction. We show the\n equivalence of correlations of the grand canonical (gce) and the canonical\n ensemble (ce). As a corollary we obtain that the correlations of the ce decay\n exponentially plus a volume correction term. Then, we use the decay of\n correlation to verify a conjecture that the infinite-volume Gibbs measure of\n the ce is unique on a one-dimensional lattice. For the equivalence of\n correlations, we modify a method that was recently used by the authors to show\n the equivalence of the ce and the gce on the level of thermodynamic functions.\n In this article we also show that the equivalence of the ce and the gce holds\n on the level of observables. One should be able to extend the methods and\n results to graphs with bounded degree as long as the gce has a sufficient\n strong decay of correlations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1212.6543",
        "title": "Rethinking set theory",
        "abstract": "Mathematicians manipulate sets with confidence almost every day, rarely\n making mistakes. Few of us, however, could accurately quote what are often\n referred to as \"the\" axioms of set theory. This suggests that we all carry\n around with us, perhaps subconsciously, a reliable body of operating principles\n for manipulating sets. What if we were to take some of those principles and\n adopt them as our axioms instead? The message of this article is that this can\n be done, in a simple, practical way (due to Lawvere). The resulting axioms are\n ten thoroughly mundane statements about sets.\n  This is an expository article for a general mathematical readership.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1701.02356",
        "title": "Closing the Gap between Teaching and Assessment",
        "abstract": "Evidence-based teaching is based upon a model of learning in which assessment\n plays a central role.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0803.3615",
        "title": "Inversion of marine heat flow measurements by expansion of the\n  temperature decay function",
        "abstract": "Marine heat flow data, obtained with a Lister-type probe, consists of two\n temperature decay curves, frictional and heat pulse decay. Both follow the same\n physical model of a cooling cylinder. The mathematical model describing the\n decays is non-linear as to the thermal sediment parameters thus a direct\n inversion is not possible. To overcome this difficulty, the model equations are\n expanded using a first-orderTaylor series. The linearised model equations are\n used in an iterative scheme to invert the temperature decay for undisturbed\n temperature and thermal conductivity of the sediment. The inversion scheme is\n tested first for its theoretical limitations using synthetic data. Inversion of\n heat flow measurements obtained during a cruise of R/V SONNE in 1996 and needle\n probe measurements in material of known thermal conductivity show that the\n algorithm is robust and gives reliable results. The programme can be obtained\n from the authors.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1506.07403",
        "title": "Three-body quantum Coulomb problem: analytic continuation",
        "abstract": "The second (unphysical) critical charge in the 3-body quantum Coulomb system\n of a nucleus of positive charge $Z$ and mass $m_p$, and two electrons,\n predicted by F~Stillinger has been calculated to be equal to $Z_{B}^{\\infty}\\\n =\\ 0.904854$ and $Z_{B}^{m_p}\\ =\\ 0.905138$ for infinite and finite (proton)\n mass $m_p$, respectively. It is shown that in both cases, the ground state\n energy $E(Z)$ (analytically continued beyond the first critical charge $Z_c$,\n for which the ionization energy vanishes, to $Re Z < Z_c$) has a square-root\n branch point with exponent 3/2 at $Z=Z_B$ in the complex $Z$-plane. Based on\n analytic continuation, the second, excited, spin-singlet bound state of\n negative hydrogen ion H${}^-$ is predicted to be at -0.51554 a.u. (-0.51531\n a.u. for the finite proton mass $m_p$). The first critical charge $Z_c$ is\n found accurately for a finite proton mass $m_p$ in the Lagrange mesh method,\n $Z^{m_p}_{c}\\ =\\ 0.911\\, 069\\, 724\\, 655$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1001.5428",
        "title": "Search for Extra dimensions in a single-jet and missing energy channel\n  at CMS experiment",
        "abstract": "A possible solution to the hierarchy problem is the presence of extra spatial\n dimensions beyond the three ones which are known from our everyday experience.\n The phenomenological ADD model of large extra-dimensions predicts a missing\n transverse energy plus a single-jet signature. This contribution addresses the\n sensitivity of the CMS detector at the LHC pp collider to parameters of this\n model, focusing on the conditions expected for second half of 2010 running\n (sqrt(s) = 10 TeV, O(100) pb-1). It is shown that a significant improvement of\n the existing limits can be obtained in such an early stage.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1911.13256",
        "title": "Betti Numbers of Random Hypersurface Arrangements",
        "abstract": "We study the expected behavior of the Betti numbers of arrangements of the\n zeros of random (distributed according to the Kostlan distribution) polynomials\n in $\\mathbb{R}\\mathrm{P}^n$. Using a random spectral sequence, we prove an\n asymptotically exact estimate on the expected number of connected components in\n the complement of $s$ such hypersurfaces in $\\mathbb{R}\\mathrm{P}^n$. We also\n investigate the same problem in the case where the hypersurfaces are defined by\n random quadratic polynomials. In this case, we establish a connection between\n the Betti numbers of such arrangements with the expected behavior of a certain\n model of a randomly defined geometric graph. While our general result implies\n that the average zeroth Betti number of the union of random hypersurface\n arrangements is bounded from above by a function that grows linearly in the\n number of polynomials in the arrangement, using the connection with random\n graphs, we show an upper bound on the expected zeroth Betti number of random\n quadrics arrangements that is sublinear in the number of polynomials in the\n arrangement. This bound is a consequence of a general result on the expected\n number of connected components in our random graph model which could be of\n independent interest.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1904.01565",
        "title": "Wave-like Properties of Phasor Fields: Experimental Demonstrations",
        "abstract": "Recently, an optical meta concept called the Phasor Field (P-Field) was\n proposed that yields great quality in the reconstruction of hidden objects\n imaged by non-line-of-sight (NLOS) imaging. It is based on virtual sinusoidal\n modulation of the light with frequencies in the MHz range. Phasor Field\n propagation was shown to be described by the Rayleigh-Sommerfeld diffraction\n integral. We extend this concept and stress the analogy between electric field\n and Phasor Field. We introduce Phasor Field optical elements and present\n experiments demonstrating the validity of the approach. Straightforward use of\n the Phasor Field concept in real-world applications is also discussed.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1905.10611",
        "title": "Coherent elastic nuclear scattering of $^{51}$Cr neutrinos",
        "abstract": "Searches for new physics in the coherent elastic neutrino-nucleus scattering\n require a precise knowledge of the neutrino flux and energy spectrum. In this\n paper we investigate the feasibility and the performances of an experiment\n based on a $^{51}$Cr source, whose neutrino spectrum is known and whose\n activity can be heat-monitored at few permil level. With a 5 MCi source placed\n at ~ 25 cm from the detector, under an exposure of two $^{51}$Cr half-lives\n (55.4 days), we evaluate 3900 (900) counts on a 2000 cm$^3$ target of germanium\n (sapphire) featuring an energy threshold of 8 (20) eV. To further increase the\n exposure, multiple activations of the same source could be possible.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1609.00508",
        "title": "The solar chromosphere as induction disk and the inverse Joule-Thomson\n  effect",
        "abstract": "The connection between nuclear fusion in the Sun's core and solar irradiance\n is obscured among other things by uncertainty over the mechanism of coronal\n heating. Data for solar wind density and velocity, sunspot number, and EUV flux\n suggest that electromagnetic energy from the Sun's convection zone is converted\n by induction through the chromosphere into thermal energy. The helium and\n hydrogen mixture exhaled by the Sun is then heated by the inverse Joule-Thomson\n effect when it expands via the corona into space. The almost complete shutdown\n of the solar wind on 10-11 May 1999 demonstrated that its velocity is a more\n faithful indicator of solar activity than are sunspots as it reflects\n short-term variations in coronal heating rather than quasicyclical fluctuations\n in the Sun's magnetism. Its reconstruction from the cosmic ray flux using\n isotopes spanning over 800,000 yr should therefore benefit the analysis and\n long-term forecasting of Earth and space weather.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/hep-th/9705112",
        "title": "Intermediate Volumes and the Role of Instantons",
        "abstract": "We review recent results for the low-lying glueball spectrum on the\n three-sphere in intermediate volumes that incorporate instanton effects. The\n latter are implemented through boundary conditions on the fundamental domain\n obtained by minimising the norm of the gauge field along the gauge orbit.\n Non-perturbative corrections due to the boundary conditions in field space are\n seen to be crucial.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0412667",
        "title": "Halo Luminosity Function From Photometric Calibration of the Revised\n  NLTT",
        "abstract": "We calibrate the photographic photometry of the revised New Luyten Two-Tenths\n catalog (rNLTT) by matching 3448 rNLTT stars to the Sloan Digital Sky Survey\n (SDSS). The correction is linear in magnitude and goes from zero at V ~ 14 to\n 0.32 mag at V=19, in the sense that rNLTT was previously too bright. The\n correction implies that the underlying USNO-A2.0 photometry, on which rNLTT\n photometry is based, is non-linear. The new calibration somewhat improves the\n appearance of the (V,V-J) reduced proper motion diagram in the sense of better\n separation between disk and halo stars. We repeat Gould's analysis of 5000 halo\n stars in rNLTT. The most important change is to move the peak of the halo\n luminosity function about 0.5 mag dimmer, from M_V=10.5 to M_V=11, putting it\n into good agreement with the parallax-based determination of Dahn et al.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2302.09499",
        "title": "Microscopic Energy Storage Mechanism of Dielectric Polymer-Coated\n  Supercapacitors",
        "abstract": "Supercapacitors have been attracting significant attention as promising\n energy storage devices. However, the voltage window limitation associated with\n electrolyte solutions has hindered the improvement of their capacitance. To\n address this issue and enhance the energy storage capabilities of general\n traditional supercapacitors, we put forward the dipole induced effects observed\n in the theoretical framework of the electric double-layer structure. The\n molecular dynamics results demonstrate that, compared to traditional systems,\n an improvement of over 50% in integral capacitance at low voltages is achieved.\n Moreover, a new material-based experimental results obtained from a dielectric\n supercapacitor employing a hydrated electrolyte solution corroborated the\n effectiveness of our proposed model, yielding consistent outcomes. We attribute\n the large capacitance variation to the reorientation of the dipoles, which\n induces the neutral-to-bilayer transition and the overscreening-to-steric\n transition, consistent with the polarization process of the polymer in the\n experiment. We further investigate the capacitance variations under different\n dipole parameters, such as varying the number of layers, different number\n densities and different spacings, thereby enriching the experimental results\n with additional conclusions not previously obtained. This work presents a novel\n approach that exploits dipole-induced capacitance effects, paving the way for\n further advances in the field of energy storage technology.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2010.00318",
        "title": "McStas (i): Introduction, use, and basic principles for ray-tracing\n  simulations",
        "abstract": "We present an overview of, and an introduction to, the general-purpose\n neutron simulation package McStas. We present the basic principles behind Monte\n Carlo ray-tracing simulations of neutrons performed in the package and present\n a few simple examples. We present the implementation of McStas, the status of\n the package and its use in the neutron community. Finally, we briefly discuss\n the planned development of the package.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1410.3933",
        "title": "Weighted Discriminants and Mass Formulas for Number Fields",
        "abstract": "We define the notion of a weighted discriminant and corresponding counting\n function for number fields, and what it means for these counting functions to\n have a mass formula for a set of primes. We extend a result of Kedlaya to show\n that any proper counting function for a finite group $\\Gamma$ has a mass\n formula for the set of primes not dividing $|\\Gamma|$. We also prove that if\n $\\Gamma$ is an $\\ell$-group for some prime $\\ell$, then there are only finitely\n many weighted discriminant counting functions for $\\Gamma$-extensions of $\\Q$\n that have a mass formula for all primes. Finally, we enumerate all such\n counting functions for $\\Gamma=D_4$ and $\\Gamma=Q_8$.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/0704.2862",
        "title": "Feasibility Study of Logic Circuits with Spin Wave Bus",
        "abstract": "We present a feasibility study of logic circuits utilizing spin waves for\n information transmission and processing. As an alternative approach to the\n transistor-based architecture, logic circuits with spin wave bus do not use\n charge as an information carrier. In this work we describe the general concept\n of logic circuits with spin wave bus and illustrate its performance by\n numerical simulations based on available experimental data. Theoretical\n estimates and results of numerical simulations on signal attenuation, signal\n phase velocity, and the minimum spin wave energy required per bit in the spin\n bus are obtained. The transport parameters are compared with ones for\n conventional electronic transmission lines. Spin Wave Bus is not intended to\n substitute traditional metal interconnects since it has higher signal\n attenuation and lower signal propagation speed. The potential value of spin\n wave bus is, however, an interface between electronic circuits and integrated\n spintronics circuits. The logic circuits with spin wave bus allow us to provide\n wireless read-in and read-out.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1709.01568",
        "title": "Model-Based Control Using Koopman Operators",
        "abstract": "This paper explores the application of Koopman operator theory to the control\n of robotic systems. The operator is introduced as a method to generate\n data-driven models that have utility for model-based control methods. We then\n motivate the use of the Koopman operator towards augmenting model-based\n control. Specifically, we illustrate how the operator can be used to obtain a\n linearizable data-driven model for an unknown dynamical process that is useful\n for model-based control synthesis. Simulated results show that with increasing\n complexity in the choice of the basis functions, a closed-loop controller is\n able to invert and stabilize a cart- and VTOL-pendulum systems. Furthermore,\n the specification of the basis function are shown to be of importance when\n generating a Koopman operator for specific robotic systems. Experimental\n results with the Sphero SPRK robot explore the utility of the Koopman operator\n in a reduced state representation setting where increased complexity in the\n basis function improve open- and closed-loop controller performance in various\n terrains, including sand.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1305.5924",
        "title": "The $L^2$-cohomology of a bounded smooth Stein Domain is not necessarily\n  Hausdorff",
        "abstract": "We give an example of a pseudoconvex domain in a complex manifold whose\n $L^2$-Dolbeault cohomology is non-Hausdorff, yet the domain is Stein. The\n domain is a smoothly bounded Levi-flat domain in a two complex-dimensional\n compact complex manifold. The domain is biholomorphic to a product domain in\n $\\mathbb{C}^2$, hence Stein. This implies that for $q>0$, the usual Dolbeault\n cohomology with respect to smooth forms vanishes in degree $(p,q)$. But the\n $L^2$-Cauchy-Riemann operator on the domain does not have closed range on\n $(2,1)$-forms and consequently its $L^2$-Dolbeault cohomology is not Hausdorff.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1605.08648",
        "title": "Addendum to `Algebraic equations for the exceptional eigenspectrum of\n  the generalized Rabi model'",
        "abstract": "In our recent paper (Li and Batchelor J. Phys. A: Math. Theor. 48, 454005\n (2015)) we obtained exceptional points in the eigenspectrum of the generalized\n Rabi model in terms of a set of algebraic equations. We also gave a proof for\n the number of roots of the constraint polynomials defining these exceptional\n solutions as a function of the system parameters and discussed the number of\n crossing points in the eigenspectrum. This approach however, only covered a\n subset of all exceptional points in the eigenspectrum. In this addendum, we\n clarify the distinction between the exceptional parts of the eigenspectrum for\n this model and discuss the subset of exceptional points not determined in our\n paper.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1011.5410",
        "title": "Fe$^{\\bf{15+}}$ dielectronic recombination and the effects of\n  configuration interaction between resonances with different captured electron\n  principal quantum number",
        "abstract": "Dielectronic recombination (DR) of Na-like Fe$^{15+}$ forming Mg-like\n Fe$^{14+}$ via excitation of a $2l$ core electron has been investigated. We\n find that configuration interaction (CI) between DR resonances with different\n captured electron principal quantum numbers $n$ can lead to a significant\n reduction in resonance strengths for $n \\geq 5$. Previous theoretical work for\n this system has not considered this form of CI. Including it accounts for most\n of the discrepancy between previous theoretical and experimental results.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2310.13949",
        "title": "DER Pricing Power in the Presence of Multi-Location Consumers with Load\n  Migration Capabilities",
        "abstract": "Renewable distributed energy resources (DERs) have the potential to provide\n multi-location electricity consumers (MLECs) with electricity at prices lower\n than those offered by the grid using behind-the-meter advantages. This study\n examines the pricing power of such DER owners in a local environment with few\n competitors and how it depends on the MLEC's ability to migrate a portion of\n the load between locations. We simulate a dynamic game between an MLEC and the\n local DER owners, where the MLEC is modeled as a cost-minimizer and the DER\n owners as strategic profit maximizers. We show that, when the MLEC is\n inflexible, the DER owners' optimal behavior is to offer their electricity\n close to maximal prices, that is, at the grid price level. However, when the\n MLEC can migrate a fraction of the load to the other locations, the prices\n offered by the DER owners quickly decrease to the minimum level, that is, the\n DERs' grid feed-in tariffs quickly decrease to a lower level, depending on the\n load migration capability.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2007.10518",
        "title": "The expected number of viable autocatalytic sets in chemical reaction\n  systems",
        "abstract": "The emergence of self-sustaining autocatalytic networks in chemical reaction\n systems has been studied as a possible mechanism for modelling how living\n systems first arose. It has been known for several decades that such networks\n will form within systems of polymers (under cleavage and ligation reactions)\n under a simple process of random catalysis, and this process has since been\n mathematically analysed. In this paper, we provide an exact expression for the\n expected number of self-sustaining autocatalytic networks that will form in a\n general chemical reaction system, and the expected number of these networks\n that will also be uninhibited (by some molecule produced by the system). Using\n these equations, we are able to describe the patterns of catalysis and\n inhibition that maximise or minimise the expected number of such networks. We\n apply our results to derive a general theorem concerning the trade-off between\n catalysis and inhibition, and to provide some insight into the extent to which\n the expected number of self-sustaining autocatalytic networks coincides with\n the probability that at least one such system is present.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/quant-ph/0304143",
        "title": "Duality, Quantum Mechanics and (Almost) Complex Manifolds",
        "abstract": "The classical mechanics of a finite number of degrees of freedom requires a\n symplectic structure on phase space C, but it is independent of any complex\n structure. On the contrary, the quantum theory is intimately linked with the\n choice of a complex structure on C. When the latter is a complex-analytic\n manifold admitting just one complex structure, there is a unique quantisation\n whose classical limit is C. Then the notion of coherence is the same for all\n observers. However, when C admits two or more nonbiholomorphic complex\n structures, there is one different quantisation per different complex structure\n on C. The lack of analyticity in transforming between nonbiholomorphic complex\n structures can be interpreted as the loss of quantum-mechanical coherence under\n the corresponding transformation. Observers using one complex structure\n perceive as coherent the states that other observers, using a different complex\n structure, do not perceive as such. This is the notion of a quantum-mechanical\n duality transformation: the relativity of the notion of a quantum.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1006.5052",
        "title": "Bond-order wave phase, spin solitons and thermodynamics of a frustrated\n  linear spin-1/2 Heisenberg antiferromagnet",
        "abstract": "The linear spin-1/2 Heisenberg antiferromagnet with exchanges $J_1$, $J_2$\n between first and second neighbors has a bond-order wave (BOW) phase that\n starts at the fluid-dimer transition at $J_2/J_1 = 0.2411$ and is particularly\n simple at $J_2/J_1 = 1/2$. The BOW phase has a doubly degenerate singlet ground\n state, broken inversion symmetry and a finite energy gap $E_m$ to the lowest\n triplet state.\n  The interval $0.4<J_2/J_1<1.0$ has large $E_m$ and small finite size\n corrections. Exact solutions are presented up to $N=28$ spins with either\n periodic or open boundary conditions and for thermodynamics up to $N=18$. The\n elementary excitations of the BOW phase with large $E_m$ are topological\n spin-1/2 solitons that separate BOWs with opposite phase in a regular array of\n spins. The molar spin susceptibility $\\chi_M(T)$ is exponentially small for $T\n \\ll E_m$ and increases nearly linearly with $T$ to a broad maximum. $J_1$,\n $J_2$ spin chains approximate the magnetic properties of the BOW phase of\n Hubbard-type models and provide a starting point for modeling alkali-TCNQ\n salts.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2012.11588",
        "title": "A strong non-equilibrium bound for sorting of crosslinkers on growing\n  biopolymers",
        "abstract": "Understanding the role of non-equilibrium driving in self-organization is\n crucial for developing a predictive description of biological systems, yet it\n is impeded by their complexity. The actin cytoskeleton serves as a paradigm for\n how equilibrium and non-equilibrium forces combine to give rise to\n self-organization. Motivated by recent experiments that show that actin\n filament growth rates can tune the morphology of a growing actin bundle\n crosslinked by two competing types of actin binding proteins, we construct a\n minimal model for such a system and show that the dynamics are subject to a set\n of thermodynamic constraints that relate the non-equilibrium driving, bundle\n morphology, and molecular fluxes. The thermodynamic constraints reveal the\n importance of correlations between these molecular fluxes, and offer a route to\n estimating microscopic driving forces from microscopy experiments.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/astro-ph/0509187",
        "title": "Characterizing a cosmic string with the statistics of string lensing",
        "abstract": "The deep imaging of the field of an observed lensing event by a cosmic string\n reveals many additional lensing events. We study the statistics of such string\n lensing. We derive explicit expressions for the distributions of image\n separations of lensing by a cosmic string and point out that they are quite\n sensitive to parameters which characterize the cosmic string, such as the\n redshift and tension of the cosmic string. Thus the statistics of string\n lensing events add new important information on the cosmic string which cannot\n be obtained from the detailed investigation of one lensing event.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/math/0106228",
        "title": "Compactifications defined by arrangements I: the ball quotient case",
        "abstract": "We define a natural compactification of an arrangement complement in a ball\n quotient. We show that when this complement has a moduli space interpretation,\n then this compactification is often one that appears naturally by means of\n geometric invariant theory. We illustrate this with the moduli spaces of smooth\n quartic curves and rational elliptic surfaces.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1710.03176",
        "title": "Frames of exponentials and sub-multitiles in LCA groups",
        "abstract": "In this note we investigate the existence of frames of exponentials for\n $L^2(\\Omega)$ in the setting of LCA groups. Our main result shows that\n sub-multitiling properties of $\\Omega \\subset \\widehat{G}$ with respect to a\n uniform lattice $\\Gamma$ of $\\widehat{G}$ guarantee the existence of a frame of\n exponentials with frequencies in a finite number of translates of the\n annihilator of $\\Gamma$. We also prove the converse of this result and provide\n conditions for the existence of these frames. These conditions extend recent\n results on Riesz bases of exponentials and multitilings to frames.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.18814",
        "title": "Design and Implementation of a New Apparatus for Astrochemistry: Kinetic\n  Measurements of the CH + OCS Reaction and Frequency Comb Spectroscopy in a\n  Cold Uniform Supersonic Flow",
        "abstract": "We present the development of a new astrochemical research tool HILTRAC, the\n Highly Instrumented Low Temperature ReAction Chamber. The instrument is based\n on a pulsed form of the CRESU (Cin\\'etique de R\\'eaction en \\'Ecoulement\n Supersonique Uniforme, meaning reaction kinetics in a uniform supersonic flow)\n apparatus, with the aim of collecting kinetics and spectroscopic information on\n gas phase chemical reactions important in interstellar space or planetary\n atmospheres. We discuss the apparatus design and its flexibility, the\n implementation of pulsed laser photolysis followed by laser induced\n fluorescence (PLP-LIF), and the first implementation of direct infrared\n frequency comb spectroscopy (DFCS) coupled to the uniform supersonic flow.\n Achievable flow temperatures range from 32(3) - 111(9) K, characterising a\n total of five Laval nozzles for use with N2 and Ar buffer gases by pressure\n impact measurements. These results were further validated using LIF and DFCS\n measurements of the CH radical and OCS, respectively. Spectroscopic constants\n and linelists for OCS are reported for the 1001 band near $2890 - 2940 cm^{-1}$\n for both $OC^{32}S$ and $OC^{34}S$, measured using DFCS. Additional peaks in\n the spectrum are tentatively assigned to the OCS-Ar complex. The first reaction\n rate coefficients for the CH + OCS reaction measured between 32(3) K and 58(5)\n K are reported. The reaction rate coefficient at 32(3) K was measured to be\n $3.9(4) \\times 10^{10} cm^3 molecule^{-1} s^{-1}$ and the reaction was found to\n exhibit no observable temperature dependence over this low temperature range.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2208.10333",
        "title": "Are Dipolarization Fronts a Typical Feature of Magnetotail Plasma Jets\n  Fronts?",
        "abstract": "Plasma jets are ubiquitous in the Earth's magnetotail. Plasma jet fronts\n (JFs) are the seat of particle acceleration and energy conversion. JFs are\n commonly associated with dipolarization fronts (DFs) representing solitary\n sharp and strong increases in the northward component of the magnetic field.\n However, MHD and kinetic instabilities can develop at JFs and disturb the front\n structure which questions on the occurrence of DFs at the JFs. We investigate\n the structure of JFs using 5 years (2017-2021) of the Magnetospheric Multiscale\n observations in the CPS in the Earth's magnetotail. We compiled a database of\n 2394 CPS jets. We find that about half (42\\%) of the JFs are associated with\n large amplitude changes in $B_z$. DFs constitute a quarter of these\n large-amplitude events, while the rest are associated with more complicated\n magnetic field structures. We conclude that the ``classical\" picture of DFs at\n the JFs is not the most common situation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2001.00989",
        "title": "Segmentation-Aware and Adaptive Iris Recognition",
        "abstract": "Iris recognition has emerged as one of the most accurate and convenient\n biometric for the human identification and has been increasingly employed in a\n wide range of e-security applications. The quality of iris images acquired\n at-a-distance or under less constrained imaging environments is known to\n degrade the iris matching accuracy. The periocular information is inherently\n embedded in such iris images and can be exploited to assist in the iris\n recognition under such non-ideal scenarios. Our analysis of such iris templates\n also indicates significant degradation and reduction in the region of interest,\n where the iris recognition can benefit from a similarity distance that can\n consider importance of different binary bits, instead of the direct use of\n Hamming distance in the literature. Periocular information can be dynamically\n reinforced, by incorporating the differences in the effective area of available\n iris regions, for more accurate iris recognition. This paper presents such a\n segmentation-assisted adaptive framework for more accurate less-constrained\n iris recognition. The effectiveness of this framework is evaluated on three\n publicly available iris databases using within-dataset and cross-dataset\n performance evaluation and validates the merit of the proposed iris recognition\n framework.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/cs/0610011",
        "title": "Creation and use of Citations in the ADS",
        "abstract": "With over 20 million records, the ADS citation database is regularly used by\n researchers and librarians to measure the scientific impact of individuals,\n groups, and institutions. In addition to the traditional sources of citations,\n the ADS has recently added references extracted from the arXiv e-prints on a\n nightly basis. We review the procedures used to harvest and identify the\n reference data used in the creation of citations, the policies and procedures\n that we follow to avoid double-counting and to eliminate contributions which\n may not be scholarly in nature. Finally, we describe how users and institutions\n can easily obtain quantitative citation data from the ADS, both interactively\n and via web-based programming tools.\n  The ADS is available at http://ads.harvard.edu.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/1502.07467",
        "title": "Reachability is in DynFO",
        "abstract": "Patnaik and Immerman introduced the dynamic complexity class DynFO of\n database queries that can be maintained by first-order dynamic programs with\n the help of auxiliary relations under insertions and deletions of edges\n (Patnaik and Immerman 1997). This article confirms their conjecture that the\n Reachability query is in DynFO.\n  As a byproduct it is shown that the rank of a matrix with small values can be\n maintained in DynFO(+,x). It is further shown that the (size of the) maximum\n matching of a graph can be maintained in non-uniform DynFO, another extension\n of DynFO, with non-uniform initialisation of the auxiliary relations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2005.08745",
        "title": "TAO Conceptual Design Report: A Precision Measurement of the Reactor\n  Antineutrino Spectrum with Sub-percent Energy Resolution",
        "abstract": "The Taishan Antineutrino Observatory (TAO, also known as JUNO-TAO) is a\n satellite experiment of the Jiangmen Underground Neutrino Observatory (JUNO). A\n ton-level liquid scintillator detector will be placed at about 30 m from a core\n of the Taishan Nuclear Power Plant. The reactor antineutrino spectrum will be\n measured with sub-percent energy resolution, to provide a reference spectrum\n for future reactor neutrino experiments, and to provide a benchmark measurement\n to test nuclear databases. A spherical acrylic vessel containing 2.8 ton\n gadolinium-doped liquid scintillator will be viewed by 10 m^2 Silicon\n Photomultipliers (SiPMs) of >50% photon detection efficiency with almost full\n coverage. The photoelectron yield is about 4500 per MeV, an order higher than\n any existing large-scale liquid scintillator detectors. The detector operates\n at -50 degree C to lower the dark noise of SiPMs to an acceptable level. The\n detector will measure about 2000 reactor antineutrinos per day, and is designed\n to be well shielded from cosmogenic backgrounds and ambient radioactivities to\n have about 10% background-to-signal ratio. The experiment is expected to start\n operation in 2022.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.10603",
        "title": "A step towards understanding why classification helps regression",
        "abstract": "A number of computer vision deep regression ap- proaches report improved results when adding a classifica- tion loss to the regression loss. Here, we explore why this is useful in practice and when it is beneficial. To do so, we start from precisely controlled dataset variations and data samplings and find that the effect of adding a classification loss is the most pronounced for regression with imbalanced data. We explain these empirical findings by formalizing the relation between the balanced and imbalanced regression losses. Finally, we show that our findings hold on two real imbalanced image datasets for depth estimation (NYUD2- DIR), and age estimation (IMDB-WIKI-DIR), and on the problem of imbalanced video progress prediction (Break-fast). Our main takeaway is: for a regression task, if the data sampling is imbalanced, then add a classification loss.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10173",
        "title": "DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering",
        "abstract": "Realistic human-centric rendering plays a key role in both computer vision and computer graphics. Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity (e.g., outfit\u2019s fabric/material, body\u2019s interaction with ob- jects, and motion sequences), which are crucial for render- ing effect. Researchers are usually constrained to explore and evaluate a small set of rendering problems on current datasets, while real-world applications require meth- ods to be robust across different scenarios. In this work, we present DNA-Rendering, a large-scale, high-fidelity reposi- tory of human performance data for neural actor rendering. DNA-Rendering presents several alluring attributes. First, our dataset contains over 1500 human subjects, 5000 mo- tion sequences, and 67.5M frames\u2019 data volume. Upon the massive collections, we provide human subjects with grand categories of pose actions, body shapes, clothing, acces- sories, hairdos, and object intersection, which ranges the geometry and appearance variances from everyday life to professional occasions. Second, we provide rich assets for each subject \u2013 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi- view images, and videos. These assets boost the current method\u2019s accuracy on downstream rendering tasks. Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 \u00d7 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation.\nAlong with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of novel view synthesis, novel pose animation synthesis, and novel identity render- ing methods. In this manuscript, we describe our DNA- Rendering effort as a revealing of new observations, chal- lenges, and future directions to human-centric rendering. The dataset, code, and benchmarks will be publicly avail- able at https://dna-rendering.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.17597",
        "title": "Robo3D: Towards Robust and Reliable 3D Perception against Corruptions",
        "abstract": "The robustness of 3D perception systems under natu- ral corruptions from environments and sensors is pivotal for safety-critical applications. Existing large-scale 3D perception datasets often contain data that are meticu- lously cleaned. Such configurations, however, cannot reflect the reliability of perception models during the deployment stage. In this work, we present Robo3D, the first compre- hensive benchmark heading toward probing the robustness of 3D detectors and segmentors under out-of-distribution scenarios against natural corruptions that occur in real- world environments. Specifically, we consider eight corrup- tion types stemming from severe weather conditions, exter- nal disturbances, and internal sensor failure. We uncover that, although promising results have been progressively achieved on standard benchmarks, state-of-the-art 3D per- ception models are at risk of being vulnerable to corrup- tions. We draw key observations on the use of data represen- tations, augmentation schemes, and training strategies, that could severely affect the model\u2019s performance. To pursue better robustness, we propose a density-insensitive training framework along with a simple flexible voxelization strat- egy to enhance the model resiliency. We hope our bench- mark and approach could inspire future research in design- ing more robust and reliable 3D perception models. Our robustness benchmark suite is publicly available1.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.14753",
        "title": "Efficient Discovery and Effective Evaluation of Visual Perceptual Similarity: A Benchmark and Beyond",
        "abstract": "Visual similarity discovery (VSD) is an important task with broad e-commerce applications. Given an image of a certain object, the goal of VSD is to retrieve images of different objects with high perceptual visual similarity. Al- though being a highly addressed problem, the evaluation of proposed methods for VSD is often based on a proxy of an identification-retrieval task, evaluating the ability of a model to retrieve different images of the same object. We posit that evaluating VSD methods based on identification tasks is limited, and faithful evaluation must rely on expert annotations. In this paper, we introduce the first large-scale fashion visual similarity benchmark dataset, consisting of more than 110K expert-annotated image pairs. Besides this major contribution, we share insight from the challenges we faced while curating this dataset. Based on these insights, we propose a novel and efficient labeling procedure that can be applied to any dataset. Our analysis examines its limita- tions and inductive biases, and based on these findings, we propose metrics to mitigate those limitations. Though our primary focus lies on visual similarity, the methodologies we present have broader applications for discovering and evaluating perceptual similarity across various domains.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.03483",
        "title": "DetermiNet: A Large-Scale Diagnostic Dataset for Complex Visually-Grounded Referencing using Determiners",
        "abstract": "State-of-the-art visual grounding models can achieve high detection accuracy, but they are not designed to dis- tinguish between all objects versus only certain objects of interest. In natural language, in order to specify a partic- ular object or set of objects of interest, humans use deter- miners such as \u201cmy\u201d, \u201ceither\u201d and \u201cthose\u201d. Determiners, as an important word class, are a type of schema in nat- ural language about the reference or quantity of the noun. Existing grounded referencing datasets place much less em- phasis on determiners, compared to other word classes such as nouns, verbs and adjectives. This makes it difficult to de- velop models that understand the full variety and complex-ity of object referencing. Thus, we have developed and re- leased the DetermiNet dataset 1, which comprises 250,000 synthetically generated images and captions based on 25 determiners. The task is to predict bounding boxes to iden- tify objects of interest, constrained by the semantics of the given determiner. We find that current state-of-the-art vi- sual grounding models do not perform well on the dataset, highlighting the limitations of existing models on reference and quantification tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2212.02710",
        "title": "Beyond Object Recognition: A New Benchmark towards Object Concept Learning",
        "abstract": "Understanding objects is a central building block of AI,especially for embodied AI. Even though object recogni- tion excels with deep learning, current machines struggle to learn higher-level knowledge, e.g., what attributes an object has, and what we can do with it. Here, we propose a chal- lenging Object Concept Learning (OCL) task to push the envelope of object understanding. It requires machines to reason out affordances and simultaneously give the reason: what attributes make an object possess these affordances. To support OCL, we build a densely annotated knowledge base including extensive annotations for three levels of ob- ject concept (category, attribute, affordance), and the clear causal relations of three levels. By analyzing the causal structure of OCL, we present a baseline, Object Concept Reasoning Network (OCRN). It leverages concept instanti- ation and causal intervention to infer the three levels. In experiments, OCRN effectively infers the object knowledge while following the causalities well. Our data and code are available at https://mvig-rhos.com/ocl.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.05390",
        "title": "HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models",
        "abstract": "In recent years, Text-to-Image (T2I) models have been ex- tensively studied, especially with the emergence of diffusion models that achieve state-of-the-art results on T2I synthesis tasks. However, existing benchmarks heavily rely on subjec- tive human evaluation, limiting their ability to holistically as- sess the model\u2019s capabilities. Furthermore, there is a signifi- cant gap between efforts in developing new T2I architectures and those in evaluation. To address this, we introduce HRS-Bench, a concrete evaluation benchmark for T2I models that is Holistic, Reliable, and Scalable. Unlike existing bench- marks that focus on limited aspects, HRS-Bench measures 13 skills that can be categorized into five major categories: accuracy, robustness, generalization, fairness, and bias. In addition, HRS-Bench covers 50 scenarios, including fash- ion, animals, transportation, food, and clothes. We evaluate nine recent large-scale T2I models using metrics that cover a wide range of skills. A human evaluation aligned with 95% of our evaluations on average was conducted to probe the effectiveness of HRS-Bench. Our experiments demon- strate that existing models often struggle to generate images with the desired count of objects, visual text, or grounded emotions. We hope that our benchmark help ease future text-to-image generation research. The code and data are available at https://eslambakr.github.io/hrsbench.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.11914",
        "title": "Building3D: An Urban-Scale Dataset and Benchmarks for Learning Roof Structures from Point Clouds",
        "abstract": "Urban modeling from LiDAR point clouds is an im- portant topic in computer vision, computer graphics, pho- togrammetry and remote sensing. 3D city models have found a wide range of applications in smart cities, au- tonomous navigation, urban planning and mapping etc. However, existing datasets for 3D modeling mainly focus on common objects such as furniture or cars. Lack of build- ing datasets has become a major obstacle for applying deep learning technology to specific domains such as urban mod- eling. In this paper, we present an urban-scale dataset con- sisting of more than 160 thousands buildings along with corresponding point clouds, mesh and wireframe models, covering 16 cities in Estonia about 998 K m2 . We exten- sively evaluate performance of state-of-the-art algorithms including handcrafted and deep feature based methods. Ex- perimental results indicate that Building3D has challenges\nof high intra-class variance, data imbalance and large- scale noises. The Building3D is the first and largest urban- scale building modeling benchmark, allowing a comparison of supervised and self-supervised learning methods. We be- lieve that our Building3D will facilitate future research on urban modeling, aerial path planning, mesh simplification, and semantic/part segmentation etc.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2208.08080",
        "title": "Multimodal Lecture Presentations Dataset: Understanding Multimodality in Educational Slides",
        "abstract": "Lecture slide presentations, a sequence of pages that contain text and figures ac- companied by speech, are constructed and presented carefully in order to optimally transfer knowledge to students. Previous studies in multimedia and psychology attribute the effectiveness of lecture presentations to their multimodal nature. As a step toward developing AI to aid in student learning as intelligent teacher assis- tants, we introduce the Multimodal Lecture Presentations dataset as a large-scale benchmark testing the capabilities of machine learning models in multimodal un- derstanding of educational content. Our dataset contains aligned slides and spoken language, for 180+ hours of video and 9000+ slides, with 10 lecturers from various subjects (e.g., computer science, dentistry, biology). We introduce two research tasks which are designed as stepping stones towards AI agents that can explain (automatically captioning a lecture presentation) and illustrate (synthesizing vi- sual figures to accompany spoken explanations) educational content. We provide manual annotations to help implement these two research tasks and evaluate state- of-the-art models on them. Comparing baselines and human student performances,\nwe find that current models struggle in (1) weak crossmodal alignment between slides and spoken text, (2) learning novel visual mediums, (3) technical language, and (4) long-range sequences. Towards addressing this issue, we also introduce PolyViLT, a multimodal transformer trained with a multi-instance learning loss that is more effective than current approaches. We conclude by shedding light on the challenges and opportunities in multimodal understanding of educational presentations.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.01590",
        "title": "Probabilistic Precision and Recall Towards Reliable Evaluation of Generative Models",
        "abstract": "Assessing the fidelity and diversity of the generative model is a difficult but important issue for technological advance- ment. So, recent papers have introduced k-Nearest Neighbor (kNN) based precision-recall metrics to break down the sta- tistical distance into fidelity and diversity. While they provide an intuitive method, we thoroughly analyze these metrics and identify oversimplified assumptions and undesirable prop- erties of kNN that result in unreliable evaluation, such as susceptibility to outliers and insensitivity to distributional changes. Thus, we propose novel metrics, P-precision and P- recall (PP&PR), based on a probabilistic approach that ad-\ndress the problems. Through extensive investigations on toy experiments and state-of-the-art generative models, we show that our PP&PR provide more reliable estimates for compar- ing fidelity and diversity than the existing metrics. The codes are available at https://github.com/kdst-team/ Probablistic_precision_recall.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.00146",
        "title": "The Qiyas Benchmark: Measuring ChatGPT Mathematical and Language Understanding in Arabic",
        "abstract": "Despite the growing importance of Arabic as a global language, there is a notable lack of language models pre- trained exclusively on Arabic data. This shortage has led to limited benchmarks available for assessing language model performance in Arabic. To address this gap, we introduce two novel benchmarks designed to evaluate models' mathematical reasoning and language understanding abilities in Arabic. These benchmarks are derived from a General Aptitude Test (GAT) called Qiyas exam, a standardized test widely used for university admissions in Saudi Arabia. For validation purposes, we assess the performance of ChatGPT-3.5-trubo and ChatGPT-4 on our benchmarks. Our findings reveal that these benchmarks pose a significant challenge, with ChatGPT-4 achieving an overall average accuracy of 64%, while ChatGPT-3.5-trubo achieved an overall accuracy of 49% across the various question types in the Qiyas benchmark. We believe the release of these benchmarks will pave the way for enhancing the mathematical reasoning and language understanding capabilities of future models tailored for the low-resource Arabic language.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.00466",
        "title": "BioKGBench: A Knowledge Graph Checking\nBenchmark of AI Agent for Biomedical Science",
        "abstract": "Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws\nincreasing attention, where one common approach is to build a copilot agent driven\nby Large Language Models (LLMs). However, to evaluate such systems, people\neither rely on direct Question-Answering (QA) to the LLM itself, or in a biomedical\nexperimental manner. How to precisely benchmark biomedical agents from an AI\nScientist perspective remains largely unexplored. To this end, we draw inspiration\nfrom one most important abilities of scientists, understanding the literature, and\nintroduce BioKGBench. In contrast to traditional evaluation benchmark that\nonly focuses on factual QA, where the LLMs are known to have hallucination\nissues, we first disentangle \u201cUnderstanding Literature\u201d into two atomic abilities, i)\n\u201cUnderstanding\u201d the unstructured text from research papers by performing scientific\nclaim verification, and ii) Ability to interact with structured Knowledge-Graph\nQuestion-Answering (KGQA) as a form of \u201cLiterature\u201d grounding. We then\nformulate a novel agent task, dubbed KGCheck, using KGQA and domain-based\nRetrieval-Augmented Generation (RAG) to identify the factual errors of existing\nlarge-scale knowledge graph databases. We collect over two thousand data for two\natomic tasks and 225 high-quality annotated data for the agent task. Surprisingly,\nwe discover that state-of-the-art agents, both daily scenarios and biomedical ones,\nhave either failed or inferior performance on our benchmark. We then introduce\na simple yet effective baseline, dubbed BKGAgent. On the widely used popular\nknowledge graph, we discover over 90 factual errors which provide scenarios for\nagents to make discoveries and demonstrate the effectiveness of our approach. The\ncode and data are available at https://github.com/westlake-autolab/BioKGBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.00924",
        "title": "EXCGEC: A Benchmark of Edit-wise Explainable Chinese\nGrammatical Error Correction",
        "abstract": "Existing studies explore the explainability of\nGrammatical Error Correction (GEC) in a limited scenario, where they ignore the interaction between corrections and explanations. To\nbridge the gap, this paper introduces the task of\nEXplainable GEC (EXGEC), which focuses\non the integral role of both correction and explanation tasks. To facilitate the task, we propose EXCGEC, a tailored benchmark for Chinese EXGEC consisting of 8,216 explanationaugmented samples featuring the design of hybrid edit-wise explanations. We benchmark\nseveral series of LLMs in multiple settings, covering post-explaining and pre-explaining. To\npromote the development of the task, we introduce a comprehensive suite of automatic metrics and conduct human evaluation experiments\nto demonstrate the human consistency of the\nautomatic metrics for free-text explanations.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01393",
        "title": "POLygraph: Polish Fake News Dataset",
        "abstract": "This paper presents the POLygraph dataset, a\nunique resource for fake news detection in Polish. The dataset, created by an interdisciplinary\nteam, is composed of two parts: the \u201cfake-ornot\u201d dataset with 11,360 pairs of news articles\n(identified by their URLs) and corresponding labels, and the \u201cfake-they-say\u201d dataset with 5,082\nnews articles (identified by their URLs) and\ntweets commenting on them. Unlike existing\ndatasets, POLygraph encompasses a variety of\napproaches from source literature, providing a\ncomprehensive resource for fake news detection. The data was collected through manual\nannotation by expert and non-expert annotators.\nThe project also developed a software tool that\nuses advanced machine learning techniques to\nanalyze the data and determine content authenticity. The tool and dataset are expected to\nbenefit various entities, from public sector institutions to publishers and fact-checking organizations. Further dataset exploration will foster\nfake news detection and potentially stimulate\nthe implementation of similar models in other\nlanguages. The paper focuses on the creation\nand composition of the dataset, so it does not\ninclude a detailed evaluation of the software\ntool for content authenticity analysis, which is\nplanned at a later stage of the project.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.00379",
        "title": "GraphArena: Benchmarking Large Language Models\non Graph Computational Problems",
        "abstract": "The \u201carms race\u201d of Large Language Models (LLMs) demands novel, challenging, and diverse benchmarks to faithfully examine their progresses. We introduce\nGraphArena, a benchmarking tool designed to evaluate LLMs on graph computational problems using million-scale real-world graphs from diverse scenarios\nsuch as knowledge graphs, social networks, and molecular structures. GraphArena\noffers a suite of 10 computational tasks, encompassing four polynomial-time (e.g.,\nShortest Distance) and six NP-complete challenges (e.g., Travelling Salesman Problem). It features a rigorous evaluation framework that classifies LLM outputs as\ncorrect, suboptimal (feasible but not optimal), or hallucinatory (properly formatted\nbut infeasible). Evaluation of 10 leading LLMs, including GPT-4o and LLaMA3-\n70B-Instruct, reveals that even top-performing models struggle with larger, more\ncomplex graph problems and exhibit hallucination issues. Despite the application\nof strategies such as chain-of-thought prompting, these issues remain unresolved.\nGraphArena contributes a valuable supplement to the existing LLM benchmarks\nand is open-sourced at https://github.com/squareRoot3/GraphArena.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.00981",
        "title": "VisEval: A Benchmark for Data Visualization in the Era of Large\nLanguage Models",
        "abstract": "Translating natural language to visualization (NL2VIS) has shown great promise for visual data analysis, but it remains\na challenging task that requires multiple low-level implementations, such as natural language processing and visualization design.\nRecent advancements in pre-trained large language models (LLMs) are opening new avenues for generating visualizations from\nnatural language. However, the lack of a comprehensive and reliable benchmark hinders our understanding of LLMs\u2019 capabilities\nin visualization generation. In this paper, we address this gap by proposing a new NL2VIS benchmark called VisEval. Firstly, we\nintroduce a high-quality and large-scale dataset. This dataset includes 2,524 representative queries covering 146 databases, paired\nwith accurately labeled ground truths. Secondly, we advocate for a comprehensive automated evaluation methodology covering multiple\ndimensions, including validity, legality, and readability. By systematically scanning for potential issues with a number of heterogeneous\ncheckers, VisEval provides reliable and trustworthy evaluation outcomes. We run VisEval on a series of state-of-the-art LLMs. Our\nevaluation reveals prevalent challenges and delivers essential insights for future advancements.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.00993",
        "title": "Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents",
        "abstract": "With the remarkable advancements of large language models (LLMs), LLM-based agents have\nbecome a research hotspot in human-computer\ninteraction. However, there is a scarcity of\nbenchmarks available for LLM-based mobile\nagents. Benchmarking these agents generally\nfaces three main challenges: (1) The inefficiency of UI-only operations imposes limitations to task evaluation. (2) Specific instructions within a singular application lack adequacy for assessing the multi-dimensional reasoning and decision-making capacities of LLM\nmobile agents. (3) Current evaluation metrics\nare insufficient to accurately assess the process of sequential actions. To this end, we\npropose Mobile-Bench, a novel benchmark for\nevaluating the capabilities of LLM-based mobile agents. First, we expand conventional\nUI operations by incorporating 103 collected\nAPIs to accelerate the efficiency of task completion. Subsequently, we collect evaluation\ndata by combining real user queries with augmentation from LLMs. To better evaluate different levels of planning capabilities for mobile agents, our data is categorized into three\ndistinct groups: SAST, SAMT, and MAMT,\nreflecting varying levels of task complexity.\nMobile-Bench comprises 832 data entries, with\nmore than 200 tasks specifically designed to\nevaluate multi-APP collaboration scenarios.\nFurthermore, we introduce a more accurate\nevaluation metric, named CheckPoint, to assess whether LLM-based mobile agents reach\nessential points during their planning and reasoning steps. Dataset and platform are available\nat https://github.com/XiaoMi/MobileBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01081",
        "title": "CVLUE: A New Benchmark Dataset\nfor Chinese Vision-Language Understanding Evaluation",
        "abstract": "Despite the rapid development of Chinese\nvision-language models (VLMs), most existing Chinese vision-language (VL) datasets are\nconstructed on Western-centric images from existing English VL datasets. The cultural bias in\nthe images makes these datasets unsuitable for\nevaluating VLMs in Chinese culture. To remedy this issue, we present a new Chinese VisionLanguage Understanding Evaluation (CVLUE)\nbenchmark dataset, where the selection of object categories and images is entirely driven\nby Chinese native speakers, ensuring that the\nsource images are representative of Chinese culture. The benchmark contains four distinct VL\ntasks ranging from image-text retrieval to visual question answering, visual grounding and\nvisual dialogue. We present a detailed statistical analysis of CVLUE and provide a baseline\nperformance analysis with several open-source\nmultilingual VLMs on CVLUE and its English\ncounterparts to reveal their performance gap\nbetween English and Chinese. Our in-depth\ncategory-level analysis reveals a lack of Chinese cultural knowledge in existing VLMs. We\nalso find that fine-tuning on Chinese culturerelated VL datasets effectively enhances VLMs\u2019\nunderstanding of Chinese culture. 1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01284",
        "title": "WE-MATH: Does Your Large Multimodal Model\nAchieve Human-like Mathematical Reasoning?",
        "abstract": "Visual mathematical reasoning, as a fundamental visual reasoning ability, has\nreceived widespread attention from the Large Multimodal Models (LMMs) community. Existing benchmarks focus more on the result-oriented performance,\nbut neglecting the underlying principles in knowledge acquisition and generalization. Inspired by human-like mathematical reasoning, we introduce WE-MATH,\nthe first benchmark specifically designed to explore the problem-solving principles beyond the end-to-end performance. We meticulously collect and categorize\n6.5K visual math problems, spanning 67 hierarchical knowledge concepts and\n5 layers of knowledge granularity. We firstly decompose composite problems\ninto sub-problems according to the required knowledge concepts and introduce a\nnovel four-dimensional metric, namely Insufficient Knowledge (IK), Inadequate\nGeneralization (IG), Complete Mastery (CM), and Rote Memorization (RM) to hierarchically assess inherent issues in LMMs\u2019 reasoning process. With WE-MATH,\nwe conduct a thorough evaluation of existing LMMs in visual mathematical reasoning and reveal a negative correlation between solving step and problem-specific\nperformance. We confirm the IK issue of LMMs can be effectively improved\nvia knowledge augmentation strategy. More notably, the primary challenge of\nGPT-4o has significantly transitioned from IK to IG, establishing it as the first\nLMM advancing towards the knowledge generalization stage. In contrast, other\nLMMs exhibit a marked inclination towards Rote Memorization \u2013 they correctly\nsolve composite problems involving multiple knowledge concepts, yet fail in answering sub-problems. We anticipate that WE-MATH will open new pathways for\nadvancements in visual mathematical reasoning for LMMs. The WE-MATH data\nand evaluation code are available at https://github.com/We-Math/We-Math.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01509",
        "title": "MIA-Bench: Towards Better Instruction Following\nEvaluation of Multimodal LLMs",
        "abstract": "We introduce MIA-Bench, a new benchmark designed to evaluate multimodal large\nlanguage models (MLLMs) on their ability to strictly adhere to complex instructions. Our benchmark comprises a diverse set of 400 image-prompt pairs, each\ncrafted to challenge the models\u2019 compliance with layered instructions in generating\naccurate responses that satisfy specific requested patterns. Evaluation results from a\nwide array of state-of-the-art MLLMs reveal significant variations in performance,\nhighlighting areas for improvement in instruction fidelity. Additionally, we create\nextra training data and explore supervised fine-tuning to enhance the models\u2019 ability\nto strictly follow instructions without compromising performance on other tasks.\nWe hope this benchmark not only serves as a tool for measuring MLLM adherence\nto instructions, but also guides future developments in MLLM training methods.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01523",
        "title": "MMLONGBENCH-DOC: Benchmarking Long-context\nDocument Understanding with Visualizations",
        "abstract": "Understanding documents with rich layouts and multi-modal components is a\nlong-standing and practical task. Recent Large Vision-Language Models (LVLMs)\nhave made remarkable strides in various tasks, particularly in single-page document\nunderstanding (DU). However, their abilities on long-context DU remain an open\nproblem. This work presents MMLONGBENCH-DOC, a long-context, multimodal benchmark comprising 1,062 expert-annotated questions. Distinct from\nprevious datasets, it is constructed upon 130 lengthy PDF-formatted documents\nwith an average of 49.4 pages and 20,971 textual tokens. Towards comprehensive\nevaluation, answers to these questions rely on pieces of evidence from (1) different\nsources (text, image, chart, table, and layout structure) and (2) various locations\n(i.e., page number). Moreover, 33.2% of the questions are cross-page questions\nrequiring evidence across multiple pages. 22.8% of the questions are designed to\nbe unanswerable for detecting potential hallucinations. Experiments on 14 LVLMs\ndemonstrate that long-context DU greatly challenges current models. Notably, the\nbest-performing model, GPT-4o, achieves an F1 score of only 42.7%, while the\nsecond-best, GPT-4V, scores 31.4%. Furthermore, 12 LVLMs (all except GPT-4o\nand GPT-4V) even present worse performance than their LLM counterparts which\nare fed with lossy-parsed OCR documents. These results validate the necessity of\nfuture research toward more capable long-context LVLMs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01725",
        "title": "DISCOVERYBENCH: Towards Data-Driven Discovery\nwith Large Language Models",
        "abstract": "Can the rapid advances in code generation, function calling, and data analysis\nusing large language models (LLMs) help automate the search and verification of\nhypotheses purely from a set of provided datasets? To evaluate this question, we\npresent DISCOVERYBENCH, the first comprehensive benchmark that formalizes\nthe multi-step process of data-driven discovery. The benchmark is designed to\nsystematically assess current model capabilities in discovery tasks and provide a\nuseful resource for improving them. Our benchmark contains 264 tasks collected\nacross 6 diverse domains, such as sociology and engineering, by manually deriving\ndiscovery workflows from published papers to approximate the real-world challenges faced by researchers, where each task is defined by a dataset, its metadata,\nand a discovery goal in natural language. We additionally provide 903 synthetic\ntasks to conduct controlled evaluations across task complexity. Furthermore, our\nstructured formalism of data-driven discovery enables a facet-based evaluation that\nprovides useful insights into different failure modes. We evaluate several popular\nLLM-based reasoning frameworks using both open and closed LLMs as baselines\non DISCOVERYBENCH and find that even the best system scores only 25%. Our\nbenchmark, thus, illustrates the challenges in autonomous data-driven discovery\nand serves as a valuable resource for the community to make progress.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01896",
        "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log\nAnalysis",
        "abstract": "Log analysis is crucial for ensuring the orderly and stable operation of information systems, particularly in the field of Artificial\nIntelligence for IT Operations (AIOps). Large Language Models (LLMs) have demonstrated significant potential in natural language\nprocessing tasks. In the AIOps domain, they excel in tasks such as anomaly detection, root cause analysis of faults, operations and\nmaintenance script generation, and alert information summarization. However, the performance of current LLMs in log analysis tasks\nremains inadequately validated. To address this gap, we introduce LogEval, a comprehensive benchmark suite designed to evaluate\nthe capabilities of LLMs in various log analysis tasks for the first time. This benchmark covers tasks such as log parsing, log anomaly\ndetection, log fault diagnosis, and log summarization. LogEval evaluates each task using 4,000 publicly available log data entries and\nemploys 15 different prompts for each task to ensure a thorough and fair assessment. By rigorously evaluating leading LLMs, we\ndemonstrate the impact of various LLM technologies on log analysis performance, focusing on aspects such as self-consistency and\nfew-shot contextual learning. We also discuss findings related to model quantification, Chinese-English question-answering evaluation,\nand prompt engineering. These findings provide insights into the strengths and weaknesses of LLMs in multilingual environments and the effectiveness of different prompt strategies. Various evaluation methods are employed for different tasks to accurately measure the\nperformance of LLMs in log analysis, ensuring a comprehensive assessment. The insights gained from LogEval\u2019s evaluation reveal the\nstrengths and limitations of LLMs in log analysis tasks, providing valuable guidance for researchers and practitioners. Key findings\nindicate that while LLMs show promise in certain areas, there are notable challenges in handling complex log data and maintaining\nhigh accuracy across diverse tasks. LogEval is poised to significantly advance the application and development of LLMs in log analysis,\noffering effective solutions for practical log analysis challenges. The data and code are publicly available at https URL to facilitate\nfurther research and development in this domain.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.02028",
        "title": "Why does in-context learning fail sometimes?\nEvaluating in-context learning on open and closed\nquestions.",
        "abstract": "We measure the performance of in-context learning as a function of task novelty\nand difficulty for open and closed questions. For that purpose, we created a novel\nbenchmark consisting of hard scientific questions, each paired with a context\nof various relevancy. We show that counter-intuitively, a context that is more\naligned with the topic does not always help more than a less relevant context. This\neffect is especially visible for open questions and questions of high difficulty or\nnovelty. This result reveals a fundamental difference between the treatment of closeform and open-form questions by large-language models and shows a need for a\nmore robust evaluation of in-context learning on the variety of different types of\nquestions. It also poses a new question of how to optimally select a context for large\nlanguage models, especially in the context of Retrieval Augmented Generation\n(RAG) systems. Our results suggest that the answer to this question can be highly\napplication-dependent and might be contingent on factors including the format\nof the question, the perceived difficulty level of the questions, and the novelty or\npopularity of the information we seek.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.08816",
        "title": "EgoObjects: A Large-Scale Egocentric Dataset for Fine-Grained Object Understanding",
        "abstract": "Object understanding in egocentric visual data is ar- guably a fundamental research topic in egocentric vision. However, existing object datasets are either non-egocentric or have limitations in object categories, visual content, and annotation granularities. In this work, we intro- duce EgoObjects, a large-scale egocentric dataset for fine- grained object understanding. Its Pilot version contains over 9K videos collected by 250 participants from 50+ countries using 4 wearable devices, and over 650K ob- ject annotations from 368 object categories. Unlike prior datasets containing only object category labels, EgoObjects also annotates each object with an instance-level identifier, and includes over 14K unique object instances. EgoOb- jects was designed to capture the same object under diverse background complexities, surrounding objects, distance, lighting and camera motion. In parallel to the data collec- tion, we conducted data annotation by developing a multi- stage federated annotation process to accommodate the growing nature of the dataset. To bootstrap the research on EgoObjects, we present a suite of 4 benchmark tasks around the egocentric object understanding, including a novel in- stance level- and the classical category level object detec- tion. Moreover, we also introduce 2 novel continual learn- ing object detection tasks. The dataset and API are avail- able at https://github.com/facebookresearch/EgoObjects.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.11111",
        "title": "CAME: Contrastive Automated Model Evaluation",
        "abstract": "The Automated Model Evaluation (AutoEval) framework entertains the possibility of evaluating a trained machine learning model without resorting to a labeled testing set. Despite the promise and some decent results, the existing AutoEval methods heavily rely on computing distribution shifts between the unlabelled testing set and the training set. We believe this reliance on the training set becomes another obstacle in shipping this technology to real-world ML de- velopment. In this work, we propose Contrastive Automatic Model Evaluation (CAME), a novel AutoEval framework that is rid of involving training set in the loop. The core idea of CAME bases on a theoretical analysis which bonds the\nmodel performance with a contrastive loss. Further, with extensive empirical validation, we manage to set up a pre- dictable relationship between the two, simply by deducing on the unlabeled/unseen testing set. The resulting frame- work CAME establishes a new SOTA results for AutoEval by surpassing prior work significantly. 1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.06362",
        "title": "Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception",
        "abstract": "We introduce the Aria Digital Twin (ADT) - an egocen- tric dataset captured using Aria glasses with extensive ob- ject, environment, and human level ground truth. This ADT release contains 200 sequences of real-world activities con- ducted by Aria wearers in two real indoor scenes with 398 object instances (324 stationary and 74 dynamic). Each sequence consists of: a) raw data of two monochrome cam- era streams, one RGB camera stream, two IMU streams; b)\ncomplete sensor calibration; c) ground truth data including continuous 6-degree-of-freedom (6DoF) poses of the Aria devices, object 6DoF poses, 3D eye gaze vectors, 3D hu- man poses, 2D image segmentations, image depth maps; and d) photo-realistic synthetic renderings. To the best of our knowledge, there is no existing egocentric dataset with a level of accuracy, photo-realism and comprehensiveness comparable to ADT. By contributing ADT to the research community, our mission is to set a new standard for evalu- ation in the egocentric machine perception domain, which includes very challenging research problems such as 3D ob- ject detection and tracking, scene reconstruction and un- derstanding, sim-to-real learning, human pose prediction - while also inspiring new machine perception tasks for aug- mented reality (AR) applications. To kick start exploration of the ADT research use cases, we evaluated several existing state-of-the-art methods for object detection, segmentation and image translation tasks that demonstrate the usefulness of ADT as a benchmarking dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2211.04894",
        "title": "Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives",
        "abstract": "The rapid increase in user-generated content (UGC) videos calls for the development of effective video qual- ity assessment (VQA) algorithms. However, the objective of the UGC-VQA problem is still ambiguous and can be viewed from two perspectives: the technical perspective, measuring the perception of distortions; and the aesthetic perspective, which relates to preference and recommenda- tion on contents. To understand how these two perspectives affect overall subjective opinions in UGC-VQA, we con- duct a large-scale subjective study to collect human quality opinions on the overall quality of videos as well as percep- tions from aesthetic and technical perspectives. The col- lected Disentangled Video Quality Database (DIVIDE-3k)\nconfirms that human quality opinions on UGC videos are universally and inevitably affected by both aesthetic and technical perspectives. In light of this, we propose the Disentangled Objective Video Quality Evaluator (DOVER) to learn the quality of UGC videos based on the two per- spectives. The DOVER proves state-of-the-art performance in UGC-VQA under very high efficiency. With perspective opinions in DIVIDE-3k, we further propose DOVER++, the first approach to provide reliable clear-cut quality evalua- tions from a single aesthetic or technical perspective. Code at https://github.com/VQAssessment/DOVER.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.17590",
        "title": "Going Beyond Nouns With Vision & Language Models Using Synthetic Data\n",
        "abstract": "Large-scale pre-trained Vision & Language (VL) mod-\nels have shown remarkable performance in many applica-\ntions, enabling replacing a fixed set of supported classes\nwith zero-shot open vocabulary reasoning over (almost ar-\nbitrary) natural language prompts. However, recent works\nhave uncovered a fundamental weakness of these models.\nFor example, their difficulty to understand Visual Language Concepts (VLC) that go \u2018beyond nouns\u2019 such as the meaning of non-object words (e.g., attributes, actions, relations,\nstates, etc.), or difficulty in performing compositional rea-\nsoning such as understanding the significance of the or-der of the words in a sentence. In this work, we investi-gate to which extent purely synthetic data could be lever-\naged to teach these models to overcome such shortcomings\nwithout compromising their zero-shot capabilities. We con-\ntribute Synthetic Visual Concepts (SyViC) - a million-scale synthetic dataset and data generation codebase allowing to generate additional suitable data to improve VLC understanding and compositional reasoning of VL models. Additionally, we propose a general VL finetuning strategy for effectively leveraging SyViC towards achieving these im-\nprovements. Our extensive experiments and ablations on VL-Checklist, Winoground, and ARO benchmarks demon-strate that it is possible to adapt strong pre-trained VL mod-els with synthetic data significantly enhancing their VLC understanding (e.g. by 9.9% on ARO and 4.3% on VL-Checklist) with under 1% drop in their zero-shot accuracy.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2211.15692",
        "title": "H3WB: Human3.6M 3D WholeBody Dataset and Benchmark",
        "abstract": "We present a benchmark for 3D human whole-body pose estimation, which involves identifying accurate 3D key- points on the entire human body, including face, hands, body, and feet. Currently, the lack of a fully annotated and accurate 3D whole-body dataset results in deep networks being trained separately on specific body parts, which are combined during inference. Or they rely on pseudo- groundtruth provided by parametric body models which are not as accurate as detection based methods. To overcome these issues, we introduce the Human3.6M 3D WholeBody (H3WB) dataset, which provides whole-body annotations for the Human3.6M dataset using the COCO Wholebody layout. H3WB comprises 133 whole-body keypoint anno-\ntations on 100K images, made possible by our new multi- view pipeline. We also propose three tasks: i) 3D whole- body pose lifting from 2D complete whole-body pose, ii) 3D whole-body pose lifting from 2D incomplete whole-body pose, and iii) 3D whole-body pose estimation from a single RGB image. Additionally, we report several baselines from popular methods for these tasks. Furthermore, we also pro- vide automated 3D whole-body annotations of TotalCap- ture and experimentally show that when used with H3WB it helps to improve the performance.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.02008",
        "title": "Zenseact Open Dataset: A large-scale and diverse multimodal dataset for autonomous driving",
        "abstract": "Existing datasets for autonomous driving (AD) often lack diversity and long-range capabilities, focusing instead on 360\u00b0 perception and temporal reasoning. To address this gap, we introduce Zenseact Open Dataset (ZOD), a large- scale and diverse multimodal dataset collected over two years in various European countries, covering an area 9\u00d7 that of existing datasets. ZOD boasts the highest range and resolution sensors among comparable datasets, cou- pled with detailed keyframe annotations for 2D and 3D ob-\njects (up to 245m), road instance/semantic segmentation, traffic sign recognition, and road classification. We believe that this unique combination will facilitate breakthroughs in long-range perception and multi-task learning. The dataset is composed of Frames, Sequences, and Drives, designed to encompass both data diversity and support for spatio- temporal learning, sensor fusion, localization, and map- ping. Frames consist of 100k curated camera images with two seconds of other supporting sensor data, while the 1473 Sequences and 29 Drives include the entire sensor suite for 20 seconds and a few minutes, respectively. ZOD is the only large-scale AD dataset released under a permissive license, allowing for both research and commercial use. More information, and an extensive devkit, can be found at zod.zenseact.com.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09011",
        "title": "CAD-Estate: Large-scale CAD Model Annotation in RGB Videos",
        "abstract": "We propose a method for annotating videos of com- plex multi-object scenes with a globally-consistent 3D rep- resentation of the objects. We annotate each object with a CAD model from a database, and place it in the 3D coordinate frame of the scene with a 9-DoF pose trans- formation. Our method is semi-automatic and works on commonly-available RGB videos, without requiring a depth sensor. Many steps are performed automatically, and the tasks performed by humans are simple, well-specified, and require only limited reasoning in 3D. This makes them fea- sible for crowd-sourcing and has allowed us to construct a large-scale dataset by annotating real-estate videos from YouTube. Our dataset CAD-Estate offers 101k instances of 12k unique CAD models placed in the 3D representations of 20k videos. In comparison to Scan2CAD, the largest ex- isting dataset with CAD model annotations on real scenes, CAD-Estate has 7\u00d7 more instances and 4\u00d7 more unique CAD models. We showcase the benefits of pre-training a Mask2CAD model on CAD-Estate for the task of automatic 3D object reconstruction and pose estimation, demonstrat- ing that it leads to performance improvements on the pop-\nular Scan2CAD benchmark. The dataset is available at https://github.com/google-research/cad-estate .",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.17595",
        "title": "Neglected Free Lunch \u2013\nLearning Image Classifiers Using Annotation Byproducts",
        "abstract": "Supervised learning of image classifiers distills human knowledge into a parametric model f\u03b8 through pairs of im- ages and corresponding labels {(Xi, Yi)}Ni=1. We argue that this simple and widely used representation of human knowl- edge neglects rich auxiliary information from the annotation procedure, such as the time-series of mouse traces and clicks left after image selection. Our insight is that such anno- tation byproducts Z provide approximate human attention that weakly guides the model to focus on the foreground cues, reducing spurious correlations and discouraging short- cut learning. To verify this, we create ImageNet-AB and COCO-AB. They are ImageNet and COCO training sets en-\nriched with sample-wise annotation byproducts, collected by replicating the respective original annotation tasks. We refer to the new paradigm of training models with annota- tion byproducts as learning using annotation byproducts (LUAB). We show that a simple multitask loss for regressing Z together with Y already improves the generalisability and robustness of the learned models. Compared to the original supervised learning, LUAB does not require extra annotation costs. ImageNet-AB and COCO-AB are at github.com/naver- ai/NeglectedFreeLunch.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2302.01872",
        "title": "MOSE: A New Dataset for Video Object Segmentation in Complex Scenes",
        "abstract": "Video object segmentation (VOS) aims at segmenting a particular object throughout the entire video clip sequence. The state-of-the-art VOS methods have achieved excellent performance (e.g., 90+% \ue236 &\ue232 ) on existing datasets. How- ever, since the target objects in these existing datasets are usually relatively salient, dominant, and isolated, VOS under complex scenes has rarely been studied. To revisit VOS and make it more applicable in the real world, we collect a new VOS dataset called coMplex video Object SEgmentation (MOSE) to study the tracking and segmenting objects in complex environments. MOSE contains 2,149 video clips and 5,200 objects from 36 categories, with 431,725 high-quality object segmentation masks. The most notable feature of MOSE dataset is complex scenes with crowded and occluded objects. The target objects in the videos are commonly occluded by others and disappear in some frames. To analyze the proposed MOSE dataset, we benchmark 18 existing VOS methods under 4 differ- ent settings on the proposed MOSE dataset and conduct comprehensive comparisons. The experiments show that current VOS algorithms cannot well perceive objects in complex scenes. For example, under the semi-supervised VOS setting, the highest \ue236 &\ue232 by existing state-of-the-art VOS methods is only 59.4% on MOSE, much lower than their \u223c90% \ue236 &\ue232 performance on DAVIS. The results reveal that although excellent performance has been achieved on existing benchmarks, there are unresolved challenges under complex scenes and more efforts are desired to explore these challenges in the future. The proposed MOSE dataset has been released at https://henghuiding.github.io/MOSE.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.14339",
        "title": "Chop & Learn: Recognizing and Generating Object-State Compositions",
        "abstract": "Recognizing and generating object-state compositions has been a challenging task, especially when generalizing to unseen compositions. In this paper, we study the task of cutting objects in different styles and the resulting object state changes. We propose a new benchmark suite Chop & Learn, to accommodate the needs of learning objects and different cut styles using multiple viewpoints. We also propose a new task of Compositional Image Generation, which can transfer learned cut styles to different objects, by generating novel object-state images. Moreover, we also use the videos for Compositional Action Recognition, and show valuable uses of this dataset for multiple video tasks. Project website: https://chopnlearn.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.17024",
        "title": "HoloAssist: an Egocentric Human Interaction Dataset for Interactive AI Assistants in the Real World",
        "abstract": "Building an interactive AI assistant that can perceive, reason, and collaborate with humans in the real world has been a long-standing pursuit in the AI community. This work is part of a broader research effort to develop intel- ligent agents that can interactively guide humans through performing tasks in the physical world. As a first step in this direction, we introduce HoloAssist, a large-scale egocentric human interaction dataset, where two people collaboratively complete physical manipulation tasks. The task performer executes the task while wearing a mixed-reality headset that captures seven synchronized data streams. The task instruc- tor watches the performer\u2019s egocentric video in real time and guides them verbally. By augmenting the data with action\nand conversational annotations and observing the rich be- haviors of various participants, we present key insights into how human assistants correct mistakes, intervene in the task completion procedure, and ground their instructions to the environment. HoloAssist spans 166 hours of data captured by 350 unique instructor-performer pairs. Furthermore, we construct and present benchmarks on mistake detection, in- tervention type prediction, and hand forecasting, along with detailed analysis. We expect HoloAssist will provide an im- portant resource for building AI assistants that can fluidly collaborate with humans in the real world. Data can be downloaded at https://holoassist.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.17368",
        "title": "SynBody: Synthetic Dataset with Layered Human Models for 3D Human Perception and Modeling",
        "abstract": "Synthetic data has emerged as a promising source for 3D human research as it offers low-cost access to large- scale human datasets. To advance the diversity and anno- tation quality of human models, we introduce a new syn- thetic dataset, SynBody, with three appealing features: 1) a clothed parametric human model that can generate a di- verse range of subjects; 2) the layered human represen- tation that naturally offers high-quality 3D annotations to support multiple tasks; 3) a scalable system for produc-\ning realistic data to facilitate real-world tasks. The dataset comprises 1.2M images with corresponding accurate 3D annotations, covering 10,000 human body models, 1,187 actions, and various viewpoints. The dataset includes two subsets for human pose and shape estimation as well as human neural rendering. Extensive experiments on Syn- Body indicate that it substantially enhances both SMPL and SMPL-X estimation. Furthermore, the incorporation of lay- ered annotations offers a valuable training resource for in- vestigating the Human Neural Radiance Fields(NeRF).",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.11636",
        "title": "OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?",
        "abstract": "This paper presents OxfordTVG-HIC (Humorous Im- age Captions), a large-scale dataset for humour genera- tion and understanding. Humour is an abstract, subjec- tive, and context-dependent cognitive construct involving several cognitive factors, making it a challenging task to generate and interpret. Hence, humour generation and un- derstanding can serve as a new task for evaluating the abil- ity of deep-learning methods to process abstract and sub- jective information. Due to the scarcity of data, humour- related generation tasks such as captioning remain under- explored. To address this gap, OxfordTVG-HIC offers ap- proximately 2.9M image-text pairs with humour scores to train a generalizable humour captioning model. Contrary to existing captioning datasets, OxfordTVG-HIC features a\nwide range of emotional and semantic diversity resulting in out-of-context examples that are particularly conducive to generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive content. We also show how OxfordTVG- HIC can be leveraged for evaluating the humour of a gen- erated text. Through explainability analysis of the trained models, we identify the visual and linguistic cues influen- tial for evoking humour prediction (and generation). We observe qualitatively that these cues are aligned with the benign violation theory of humour in cognitive psychology.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.09618",
        "title": "LaRS: A Diverse Panoptic Maritime Obstacle Detection Dataset and Benchmark",
        "abstract": "The progress in maritime obstacle detection is hindered by the lack of a diverse dataset that adequately captures the complexity of general maritime environments. We present\nthe first maritime panoptic obstacle detection benchmark LaRS, featuring scenes from Lakes, Rivers and Seas. Our major contribution is the new dataset, which boasts the largest diversity in recording locations, scene types, obsta- cle classes, and acquisition conditions among the related datasets. LaRS is composed of over 4000 per-pixel labeled key frames with nine preceding frames to allow utilization of the temporal texture, amounting to over 40k frames. Each key frame is annotated with 8 thing, 3 stuff classes and 19 global scene attributes. We report the results of 27 se- mantic and panoptic segmentation methods, along with sev- eral performance insights and future research directions. To enable objective evaluation, we have implemented an online evaluation server. The LaRS dataset, evaluation toolkit and benchmark are publicly available at: https: //lojzezust.github.io/lars-dataset",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.06292",
        "title": "Joint Metrics Matter: A Better Standard for Trajectory Forecasting",
        "abstract": "Multi-modal trajectory forecasting methods commonly evaluate using single-agent metrics (marginal metrics), such as minimum Average Displacement Error (ADE) and Final Displacement Error (FDE), which fail to capture joint performance of multiple interacting agents. Only focusing on marginal metrics can lead to unnatural predictions, such as colliding trajectories or diverging trajectories for people who are clearly walking together as a group. Consequently, methods optimized for marginal metrics lead to overly-optimistic estimations of performance, which is detrimental to progress in trajectory forecasting research. In response to the limitations of marginal metrics, we present the first comprehensive evaluation of state-of-the- art (SOTA) trajectory forecasting methods with respect\nto multi-agent metrics (joint metrics): JADE, JFDE, and collision rate. We demonstrate the importance of joint metrics as opposed to marginal metrics with quantitative evidence and qualitative examples drawn from the ETH / UCY and Stanford Drone datasets. We introduce a new loss function incorporating joint metrics that, when applied\nto a SOTA trajectory forecasting method, achieves a 7% improvement in JADE / JFDE on the ETH / UCY datasets with respect to the previous SOTA. Our results also indicate that optimizing for joint metrics naturally leads to an im- provement in interaction modeling, as evidenced by a 16% decrease in mean collision rate on the ETH / UCY datasets with respect to the previous SOTA. Code is available at github.com/ericaweng/joint-metrics-matter.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.14407",
        "title": "LPFF: A Portrait Dataset for Face Generators Across Large Poses",
        "abstract": "The creation of 2D realistic facial images and 3D face shapes using generative networks has been a hot topic in re- cent years. Existing face generators exhibit exceptional per- formance on faces in small to medium poses (with respect to frontal faces) but struggle to produce realistic results for large poses. The distorted rendering results on large poses in 3D-aware generators further show that the generated 3D face shapes are far from the distribution of 3D faces in real- ity. We find that the above issues are caused by the training dataset\u2019s pose imbalance.\nIn this paper, we present LPFF, a large-pose Flickr face dataset comprised of 19,590 high-quality real large-pose\nportrait images. We utilize our dataset to train a 2D face generator that can process large-pose face images, as well as a 3D-aware generator that can generate realistic human face geometry. To better validate our pose-conditional 3D- aware generators, we develop a new FID measure to evalu- ate the 3D-level performance. Through this novel FID mea- sure and other experiments, we show that LPFF can help 2D face generators extend their latent space and better ma- nipulate the large-pose data, and help 3D-aware face gen- erators achieve better view consistency and more realistic 3D reconstruction results.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.12067",
        "title": "Replay:\nMulti-modal Multi-view Acted Videos for Casual Holography",
        "abstract": "We introduce Replay, a collection of multi-view, multi- modal videos of humans interacting socially. Each scene is filmed in high production quality, from different view- points with several static cameras, as well as wearable action cameras, and recorded with a large array of mi- crophones at different positions in the room. Overall, the dataset contains over 4000 minutes of footage and over 7 million timestamped high-resolution frames annotated with camera poses and partially with foreground masks. The Re- play dataset has many potential applications, such as novel- view synthesis, 3D reconstruction, novel-view acoustic syn- thesis, human body and face analysis, and training genera- tive models. We provide a benchmark for training and eval-\nuating novel-view synthesis, with two scenarios of different difficulty. Finally, we evaluate several baseline state-of-the- art methods on the new benchmark.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.14392",
        "title": "Human-centric Scene Understanding for 3D Large-scale Scenarios",
        "abstract": "Human-centric scene understanding is significant for real-world applications, but it is extremely challenging due to the existence of diverse human poses and ac- tions, complex human-environment interactions, severe oc- clusions in crowds, etc. In this paper, we present a large- scale multi-modal dataset for human-centric scene under- standing, dubbed HuCenLife, which is collected in diverse daily-life scenarios with rich and fine-grained annotations. Our HuCenLife can benefit many 3D perception tasks, such as segmentation, detection, action recognition, etc., and we also provide benchmarks for these tasks to facili- tate related research. In addition, we design novel mod- ules for LiDAR-based segmentation and action recognition, which are more applicable for large-scale human-centric scenarios and achieve state-of-the-art performance. The dataset and code can be found at https://github. com/4DVLab/HuCenLife.git.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.14710",
        "title": "Pre-training Vision Transformers with Very Limited Synthesized Images",
        "abstract": "Formula-driven supervised learning (FDSL) is a pre- training method that relies on synthetic images generated from mathematical formulae such as fractals. Prior work on FDSL has shown that pre-training vision transformers on such synthetic datasets can yield competitive accuracy on a wide range of downstream tasks. These synthetic im- ages are categorized according to the parameters in the mathematical formula that generate them. In the present work, we hypothesize that the process for generating dif- ferent instances for the same category in FDSL, can be viewed as a form of data augmentation. We validate this hypothesis by replacing the instances with data augmenta- tion, which means we only need a single image per category. Our experiments shows that this one-instance fractal database (OFDB) performs better than the original dataset where instances were explicitly generated. We further scale up OFDB to 21,000 categories and show that it matches, or even surpasses, the model pre-trained on ImageNet-21k in ImageNet-1k fine-tuning. The number of images in OFDB is 21k, whereas ImageNet-21k has 14M. This opens new possibilities for pre-training vision transformers with much smaller datasets.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.00035",
        "title": "FACET: Fairness in Computer Vision Evaluation Benchmark",
        "abstract": "Computer vision models have known performance dis- parities across attributes such as gender and skin tone. This means during tasks such as classification and detection, model performance differs for certain classes based on the demographics of the people in the image. These dispari- ties have been shown to exist, but until now there has not been a unified approach to measure these differences for common use-cases of computer vision models. We present a new benchmark named FACET (FAirness in Computer Vi- sion EvaluaTion), a large, publicly available evaluation set of 32k images for some of the most common vision tasks - image classification, object detection and segmentation. For every image in FACET, we hired expert reviewers to arXiv:2309.00035v1 [cs.CV] 31 Aug 2023 manually annotate person-related attributes such as per- ceived skin tone and hair type, manually draw bounding boxes and label fine-grained person-related classes such as disk jockey or guitarist. In addition, we use FACET to benchmark state-of-the-art vision models and present a deeper understanding of potential performance dispari- ties and challenges across sensitive demographic attributes. With the exhaustive annotations collected, we probe models using single demographics attributes as well as multiple at- tributes using an intersectional approach (e.g. hair color and perceived skin tone). Our results show that classifica- tion, detection, segmentation, and visual grounding mod- els exhibit performance disparities across demographic at- tributes and intersections of attributes. These harms sug- gest that not all people represented in datasets receive fair\nand equitable treatment in these vision tasks. We hope cur- rent and future results using our benchmark will contribute to fairer, more robust vision models. FACET is available publicly at https://facet.metademolab.com.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.07961",
        "title": "EmoSet: A Large-scale Visual Emotion Dataset with Rich Attributes",
        "abstract": "Visual Emotion Analysis (VEA) aims at predicting peo-\nple\u2019s emotional responses to visual stimuli. This is a promising, yet challenging, task in affective computing, which has drawn increasing attention in recent years. Most of the existing work in this area focuses on feature design, while little attention has been paid to dataset construction. In this work, we introduce EmoSet, the first large-scale vi- sual emotion dataset annotated with rich attributes, which is superior to existing datasets in four aspects: scale, anno- tation richness, diversity, and data balance. EmoSet com- prises 3.3 million images in total, with 118,102 of these im- ages carefully labeled by human annotators, making it five times larger than the largest existing dataset. EmoSet in- cludes images from social networks, as well as artistic im- ages, and it is well balanced between different emotion cat- egories. Motivated by psychological studies, in addition to emotion category, each image is also annotated with a set of describable emotion attributes: brightness, colorfulness, scene type, object class, facial expression, and human ac- tion, which can help understand visual emotions in a precise and interpretable way. The relevance of these emotion at- tributes is validated by analyzing the correlations between them and visual emotion, as well as by designing an at- tribute module to help visual emotion recognition. We believe EmoSet will bring some key insights and encourage further research in visual emotion analysis and understand-\ning. Project page: https://vcc.tech/EmoSet.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.09301",
        "title": "RenderIH: A Large-scale Synthetic Dataset for 3D Interacting Hand Pose Estimation",
        "abstract": "The current interacting hand (IH) datasets are relatively simplistic in terms of background and texture, with hand joints being annotated by a machine annotator, which may result in inaccuracies, and the diversity of pose distribution is limited. However, the variability of background, pose distribution, and texture can greatly influence the gener- alization ability. Therefore, we present a large-scale syn- thetic dataset \u2013RenderIH\u2013 for interacting hands with accu- rate and diverse pose annotations. The dataset contains\n1M photo-realistic images with varied backgrounds, per- spectives, and hand textures. To generate natural and di- verse interacting poses, we propose a new pose optimiza- tion algorithm. Additionally, for better pose estimation accuracy, we introduce a transformer-based pose estima- tion network, TransHand, to leverage the correlation be- tween interacting hands and verify the effectiveness of Ren- derIH in improving results. Our dataset is model-agnostic and can improve more accuracy of any hand pose esti- mation method in comparison to other real or synthetic datasets. Experiments have shown that pretraining on our synthetic data can significantly decrease the error from 6.76mm to 5.79mm, and our Transhand surpasses contem- porary methods. Our dataset and code are available at https://github.com/adwardlee/RenderIH.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.11897",
        "title": "TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering",
        "abstract": "Despite thousands of researchers, engineers, and artists\nactively working on improving text-to-image generation mod-\nels, systems often fail to produce images that accurately\nalign with the text inputs. We introduce TIFA (Text-to-Image\nFaithfulness evaluation with question Answering), an auto-\nmatic evaluation metric that measures the faithfulness of a\ngenerated image to its text input via visual question answer-\ning (VQA). Specifically, given a text input, we automatically\ngenerate several question-answer pairs using a language\nmodel. We calculate image faithfulness by checking whether\nexisting VQA models can answer these questions using the generated image. TIFA is a reference-free metric that allows\nfor fine-grained and interpretable evaluations of generated\nimages. TIFA also has better correlations with human judg-\nments than existing metrics. Based on this approach, we\nintroduce TIFA v1.0, a benchmark consisting of 4K diverse\ntext inputs and 25K questions across 12 categories (object,\ncounting, etc.). We present a comprehensive evaluation of ex-\nisting text-to-image models using TIFA v1.0 and highlight the\nlimitations and challenges of current models. For instance,\nwe find that current text-to-image models, despite doing well\non color and material, still struggle in counting, spatial\nrelations, and composing multiple objects. We hope our\nbenchmark will help carefully measure the research progress\nin text-to-image synthesis and provide valuable insights for further research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.09987",
        "title": "ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment",
        "abstract": "We present ClothesNet: a large-scale dataset of 3D clothes objects with information-rich annotations. Our dataset consists of around 4400 models covering 11 cat- egories annotated with clothes features, boundary lines, and keypoints. ClothesNet can be used to facili- tate a variety of computer vision and robot interaction tasks. Using our dataset, we establish benchmark tasks for clothes perception, including classification, bound- ary line segmentation, and keypoint detection, and de- velop simulated clothes environments for robotic interac- tion tasks, including rearranging, folding, hanging, and dressing. We also demonstrate the efficacy of our Clothes-\nNet in real-world experiments. Supplemental materi- als and dataset are available on our project webpage at https://sites.google.com/view/clothesnet.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.13933",
        "title": "AIDE: A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for Assistive Driving Perception",
        "abstract": "Driver distraction has become a significant cause of se- vere traffic accidents over the past decade. Despite the growing development of vision-driven driver monitoring systems, the lack of comprehensive perception datasets re- stricts road safety and traffic security. In this paper, we present an AssIstive Driving pErception dataset (AIDE) that considers context information both inside and outside the vehicle in naturalistic scenarios. AIDE facilitates holis- tic driver monitoring through three distinctive character- istics, including multi-view settings of driver and scene, multi-modal annotations of face, body, posture, and ges- ture, and four pragmatic task designs for driving under- standing. To thoroughly explore AIDE, we provide exper- imental benchmarks on three kinds of baseline frameworks via extensive methods. Moreover, two fusion strategies are introduced to give new insights into learning effective multi- stream/modal representations. We also systematically in- vestigate the importance and rationality of the key com- ponents in AIDE and benchmarks. The project link is https://github.com/ydk122024/AIDE.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.07625",
        "title": "PlanarTrack: A Large-scale Challenging Benchmark for Planar Object Tracking",
        "abstract": "Planar object tracking is a critical computer vision prob- lem and has drawn increasing interest owing to its key roles in robotics, augmented reality, etc. Despite rapid progress, its further development, especially in the deep learning era, is largely hindered due to the lack of large-scale challenging benchmarks. Addressing this, we introduce PlanarTrack, a large-scale challenging planar tracking benchmark. Specif- ically, PlanarTrack consists of 1,000 videos with more than 490K images. All these videos are collected in complex un- constrained scenarios from the wild, which makes Planar- Track, compared with existing benchmarks, more challeng- ing but realistic for real-world applications. To ensure the high-quality annotation, each frame in PlanarTrack is man- ually labeled using four corners with multiple-round careful inspection and refinement. To our best knowledge, Planar- Track, to date, is the largest and most challenging dataset dedicated to planar object tracking. In order to analyze the proposed PlanarTrack, we evaluate 10 planar trackers and conduct comprehensive comparisons and in-depth analysis. Our results, not surprisingly, demonstrate that current top- performing planar trackers degenerate significantly on the challenging PlanarTrack and more efforts are needed to im- prove planar tracking in the future. In addition, we further derive a variant named PlanarTrackBB for generic object tracking from PlanarTrack. Our evaluation of 10 excellent generic trackers on PlanarTrackBB manifests that, surpris- ingly, PlanarTrackBB is even more challenging than several popular generic tracking benchmarks and more attention should be paid to handle such planar objects, though they\nare rigid. All benchmarks and evaluations will be released at the project webpage.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.13411",
        "title": "Harvard Glaucoma Detection and Progression: A Multimodal Multitask Dataset and Generalization-Reinforced Semi-Supervised Learning",
        "abstract": "Glaucoma is the number one cause of irreversible blind- ness globally. A major challenge for accurate glaucoma detection and progression forecasting is the bottleneck of limited labeled patients with the state-of-the-art (SOTA) 3D retinal imaging data of optical coherence tomogra- phy (OCT). To address the data scarcity issue, this pa- per proposes two solutions. First, we develop a novel generalization-reinforced semi-supervised learning (SSL) model called pseudo supervisor to optimally utilize unla- beled data. Compared with SOTA models, the proposed pseudo supervisor optimizes the policy of predicting pseudo labels with unlabeled samples to improve empirical gener- alization. Our pseudo supervisor model is evaluated with\ntwo clinical tasks consisting of glaucoma detection and pro- gression forecasting. The progression forecasting task is evaluated both unimodally and multimodally. Our pseudo supervisor model demonstrates superior performance than SOTA SSL comparison models. Moreover, our model also achieves the best results on the publicly available LAG fun- dus dataset. Second, we introduce the Harvard Glaucoma Detection and Progression (Harvard-GDP) Dataset, a mul- timodal multitask dataset that includes data from 1,000 pa- tients with OCT imaging data, as well as labels for glau- coma detection and progression. This is the largest glau- coma detection dataset with 3D OCT imaging data and the first glaucoma progression forecasting dataset that is pub- licly available. Detailed sex and racial analysis are pro- vided, which can be used by interested researchers for fair- ness learning studies. Our released dataset is benchmarked with several SOTA supervised CNN and transformer deep learning models. The dataset and code are made publicly available via https://ophai.hms.harvard.edu/ datasets/harvard-gdp1000.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.04321",
        "title": "ARNOLD: A Benchmark for Language-Grounded Task Learning With Continuous States in Realistic 3D Scenes",
        "abstract": "Understanding the continuous states of objects is essen- tial for task learning and planning in the real world. How- ever, most existing task learning benchmarks assume discrete (e.g., binary) object goal states, which poses challenges for the learning of complex tasks and transferring learned policy from simulated environments to the real world. Furthermore, state discretization limits a robot\u2019s ability to follow human instructions based on the grounding of actions and states. To tackle these challenges, we present ARNOLD, a benchmark that evaluates language-grounded task learning with con- tinuous states in realistic 3D scenes. ARNOLD is comprised of 8 language-conditioned tasks that involve understanding object states and learning policies for continuous goals. To promote language-instructed learning, we provide expert demonstrations with template-generated language descrip- tions. We assess task performance by utilizing the latest language-conditioned policy learning models. Our results indicate that current models for language-conditioned ma- nipulations continue to experience significant challenges in novel goal-state generalizations, scene generalizations, and object generalizations. These findings highlight the need to develop new algorithms that address this gap and under- score the potential for further research in this area. Project website: https://arnold-benchmark.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.05438",
        "title": "Towards Content-based Pixel Retrieval in Revisited Oxford and Paris",
        "abstract": "This paper introduces the first two pixel retrieval bench- marks. Pixel retrieval is segmented instance retrieval. Like semantic segmentation extends classification to the pixel level, pixel retrieval is an extension of image retrieval and offers information about which pixels are related to the query object. In addition to retrieving images for the given query, it helps users quickly identify the query object in true positive images and exclude false positive images by de- noting the correlated pixels. Our user study results show pixel-level annotation can significantly improve the user ex-\nperience. Compared with semantic and instance segmenta- tion, pixel retrieval requires a fine-grained recognition ca- pability for variable-granularity targets. To this end, we propose pixel retrieval benchmarks named PROxford and PRParis, which are based on the widely used image re- trieval datasets, ROxford and RParis. Three professional annotators label 5,942 images with two rounds of double- checking and refinement. Furthermore, we conduct exten- sive experiments and analysis on the SOTA methods in im- age search, image matching, detection, segmentation, and dense matching using our pixel retrieval benchmarks. Re- sults show that the pixel retrieval task is challenging to these approaches and distinctive from existing problems, suggesting that further research can advance the content- based pixel-retrieval and thus user search experience. The datasets can be downloaded from this link.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.13505",
        "title": "A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition",
        "abstract": "The goal of building a benchmark (suite of datasets) is to provide a unified protocol for fair evaluation and thus facilitate the evolution of a specific area. Nonethe- less, we point out that existing protocols of action recog- nition could yield partial evaluations due to several limita- tions. To comprehensively probe the effectiveness of spa- tiotemporal representation learning, we introduce   BEAR, a new BEnchmark on video Action Recognition. BEAR is a collection of 18 video datasets grouped into 5 cate- gories (anomaly, gesture, daily, sports, and instructional), which covers a diverse set of real-world applications. With\nBEAR, we thoroughly evaluate 6 common spatiotemporal models pre-trained by both supervised and self-supervised learning. We also report transfer performance via stan- dard finetuning, few-shot finetuning, and unsupervised do- main adaptation. Our observation suggests that the cur- rent state-of-the-art cannot solidly guarantee high perfor- mance on datasets close to real-world applications, and we hope BEAR can serve as a fair and challenging evalua- tion benchmark to gain insights on building next-generation spatiotemporal learners. Our dataset, code, and models are released at: https://github.com/AndongDeng/BEAR",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.08723",
        "title": "Revisiting Scene Text Recognition: A Data Perspective",
        "abstract": "This paper aims to re-assess scene text recognition (STR) from a data-oriented perspective. We begin by revisiting the six commonly used benchmarks in STR and observe a trend of performance saturation, whereby only 2.91% of the benchmark images cannot be accurately recognized by an ensemble of 13 representative models. While these re- sults are impressive and suggest that STR could be consid- ered solved, however, we argue that this is primarily due to the less challenging nature of the common benchmarks, thus concealing the underlying issues that STR faces. To this end, we consolidate a large-scale real STR dataset, namely Union14M, which comprises 4 million labeled im-\nages and 10 million unlabeled images, to assess the per- formance of STR models in more complex real-world sce- narios. Our experiments demonstrate that the 13 models can only achieve an average accuracy of 66.53% on the 4 million labeled images, indicating that STR still faces numerous challenges in the real world. By analyzing the error patterns of the 13 models, we identify seven open challenges in STR and develop a challenge-driven bench- mark consisting of eight distinct subsets to facilitate fur- ther progress in the field. Our exploration demonstrates that STR is far from being solved and leveraging data may be a promising solution. In this regard, we find that utiliz- ing the 10 million unlabeled images through self-supervised pre-training can significantly improve the robustness of STR model in real-world scenarios and leads to state-of-the-art performance. Code and dataset is available at https: //github.com/Mountchicken/Union14M .",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.08723",
        "title": "Revisiting Scene Text Recognition: A Data Perspective",
        "abstract": "This paper aims to re-assess scene text recognition (STR) from a data-oriented perspective. We begin by revisiting the six commonly used benchmarks in STR and observe a trend of performance saturation, whereby only 2.91% of the benchmark images cannot be accurately recognized by an ensemble of 13 representative models. While these re- sults are impressive and suggest that STR could be consid- ered solved, however, we argue that this is primarily due to the less challenging nature of the common benchmarks, thus concealing the underlying issues that STR faces. To this end, we consolidate a large-scale real STR dataset, namely Union14M, which comprises 4 million labeled im-\nages and 10 million unlabeled images, to assess the per- formance of STR models in more complex real-world sce- narios. Our experiments demonstrate that the 13 models can only achieve an average accuracy of 66.53% on the 4 million labeled images, indicating that STR still faces numerous challenges in the real world. By analyzing the error patterns of the 13 models, we identify seven open challenges in STR and develop a challenge-driven bench- mark consisting of eight distinct subsets to facilitate fur- ther progress in the field. Our exploration demonstrates that STR is far from being solved and leveraging data may be a promising solution. In this regard, we find that utiliz- ing the 10 million unlabeled images through self-supervised pre-training can significantly improve the robustness of STR model in real-world scenarios and leads to state-of-the-art performance. Code and dataset is available at https: //github.com/Mountchicken/Union14M .",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2211.08095",
        "title": "Will Large-scale Generative Models Corrupt Future Datasets?",
        "abstract": "Recently proposed large-scale text-to-image generative models such as DALL\u00b7E 2 [47], Midjourney [42], and Sta- bleDiffusion [51] can generate high-quality and realistic images from users\u2019 prompts. Not limited to the research community, ordinary Internet users enjoy these generative models, and consequently, a tremendous amount of gen- erated images have been shared on the Internet. Mean- while, today\u2019s success of deep learning in the computer vi- sion field owes a lot to images collected from the Internet. These trends lead us to a research question: \u201cwill such gen- erated images impact the quality of future datasets and the performance of computer vision models positively or negatively?\u201d This paper empirically answers this ques- tion by simulating contamination. Namely, we generate\nImageNet-scale and COCO-scale datasets using a state-of- the-art generative model and evaluate models trained with \u201ccontaminated\u201d datasets on various tasks, including im- age classification and image generation. Throughout ex- periments, we conclude that generated images negatively affect downstream performance, while the significance de- pends on tasks and the amount of generated images. The generated datasets and the codes for experiments will be publicly released for future research. Generated datasets and source codes are available from https://github. com/moskomule/dataset-contamination.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.14630",
        "title": "360VOT: A New Benchmark Dataset for Omnidirectional Visual Object Tracking",
        "abstract": "360\u25e6 images can provide an omnidirectional field of view which is important for stable and long-term scene percep- tion. In this paper, we explore 360\u25e6 images for visual ob- ject tracking and perceive new challenges caused by large distortion, stitching artifacts, and other unique attributes of 360\u25e6 images. To alleviate these problems, we take ad- vantage of novel representations of target localization, i.e., bounding field-of-view, and then introduce a general 360 tracking framework that can adopt typical trackers for om- nidirectional tracking. More importantly, we propose a new large-scale omnidirectional tracking benchmark dataset, 360VOT, in order to facilitate future research. 360VOT con- tains 120 sequences with up to 113K high-resolution frames in equirectangular projection. The tracking targets cover 32 categories in diverse scenarios. Moreover, we provide 4 types of unbiased ground truth, including (rotated) bound- ing boxes and (rotated) bounding field-of-views, as well as new metrics tailored for 360\u25e6 images which allow for the accurate evaluation of omnidirectional tracking perfor- mance. Finally, we extensively evaluated 20 state-of-the-art visual trackers and provided a new baseline for future com- parisons. Homepage: https://360vot.hkustvgd.com",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2402.19479",
        "title": "Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers",
        "abstract": "The quality of the data and annotation upper-bounds the\nquality of a downstream model. While there exist large text\ncorpora and image-text pairs, high-quality video-text data\nis much harder to collect. First of all, manual labeling is\nmore time-consuming, as it requires an annotator to watch\nan entire video. Second, videos have a temporal dimension,\nconsisting of several scenes stacked together, and showing\nmultiple actions. Accordingly, to establish a video dataset\nwith high-quality captions, we propose an automatic approach leveraging multimodal inputs, such as textual video\ndescription, subtitles, and individual video frames. Specifically, we curate 3.8M high-resolution videos from the publicly available HD-VILA-100M dataset. We then split them\ninto semantically consistent video clips, and apply multiple\ncross-modality teacher models to obtain captions for each\nvideo. Next, we finetune a retrieval model on a small subset\nwhere the best caption of each video is manually selected\nand then employ the model in the whole dataset to select\nthe best caption as the annotation. In this way, we get 70M\nvideos paired with high-quality text captions. We dub the\ndataset as Panda-70M. We show the value of the proposed\ndataset on three downstream tasks: video captioning, video\nand text retrieval, and text-driven video generation. The\nmodels trained on the proposed data score substantially better on the majority of metrics across all the tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2404.00989",
        "title": "360+x: A Panoptic Multi-modal Scene Understanding Dataset",
        "abstract": "Human perception of the world is shaped by a multitude\nof viewpoints and modalities. While many existing datasets\nfocus on scene understanding from a certain perspective\n(e.g. egocentric or third-person views), our dataset offers a\npanoptic perspective (i.e. multiple viewpoints with multiple\ndata modalities). Specifically, we encapsulate third-person\npanoramic and front views, as well as egocentric monocular/binocular views with rich modalities including video,\nmulti-channel audio, directional binaural delay, location\ndata and textual scene descriptions within each scene captured, presenting comprehensive observation of the world.\nFigure 1 offers a glimpse of all 28 scene categories of our\n360+x dataset. To the best of our knowledge, this is the\nfirst database that covers multiple viewpoints with multiple data modalities to mimic how daily information is accessed in the real world. Through our benchmark analysis,\nwe presented 5 different scene understanding tasks on the\nproposed 360+x dataset to evaluate the impact and benefit\nof each data modality and perspective in panoptic scene understanding. We hope this unique dataset could broaden the\nscope of comprehensive scene understanding and encourage the community to approach these problems from more\ndiverse perspectives.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.02835",
        "title": "Traffic Scene Parsing through the TSP6K Dataset",
        "abstract": "Traffic scene perception in computer vision is a critically important task to achieve intelligent cities. To date, most existing datasets focus on autonomous driving scenes. We observe that the models trained on those driving datasets often yield unsatisfactory results on traffic monitoring scenes. However, little effort has been put into improving the traffic monitoring scene understanding, mainly due to the lack of specific datasets. To fill this gap, we introduce a specialized traffic monitoring dataset, termed TSP6K, containing images from the traffic monitoring scenario, with high-quality pixellevel and instance-level annotations. The TSP6K dataset captures more crowded traffic scenes with several times more traffic participants than the existing driving scenes. We perform a detailed analysis of the dataset and comprehensively evaluate previous popular scene parsing methods, instance segmentation methods and unsupervised domain adaption methods. Furthermore, considering the vast difference in instance sizes, we propose a detail refining decoder for scene parsing, which recovers the details of different semantic regions in traffic scenes owing to the proposed TSP6K dataset. Experiments show its effectiveness in parsing the traffic monitoring scenes. Code and dataset are available at https://github.com/PengtaoJiang/TSP6K.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2403.18775",
        "title": "ImageNet-D: Benchmarking Neural Network Robustness on\nDiffusion Synthetic Object",
        "abstract": "We establish rigorous benchmarks for visual perception robustness. Synthetic images such as ImageNet-C,\nImageNet-9, and Stylized ImageNet provide specific type\nof evaluation over synthetic corruptions, backgrounds, and\ntextures, yet those robustness benchmarks are restricted\nin specified variations and have low synthetic quality. In\nthis work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models\u2019 robustness. Leveraging diffusion models, we are able\nto generate images with more diversified backgrounds, textures, and materials than any prior work, where we term\nthis benchmark as ImageNet-D. Experimental results show\nthat ImageNet-D results in a significant accuracy drop to\na range of vision models, from the standard ResNet visual classifier to the latest foundation models like CLIP and\nMiniGPT-4, significantly reducing their accuracy by up to\n60%. Our work suggests that diffusion models can be an\neffective source to test vision models. The code and dataset\nare available at https://github.com/chenshuangzhang/imagenet_d.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.17982",
        "title": "VBench: Comprehensive Benchmark Suite for Video Generative Models",
        "abstract": "Video generation has witnessed significant advancements, yet evaluating these models remains a challenge. A\ncomprehensive evaluation benchmark for video generation\nis indispensable for two reasons: 1) Existing metrics do\nnot fully align with human perceptions; 2) An ideal evaluation system should provide insights to inform future developments of video generation. To this end, we present\nVBench, a comprehensive benchmark suite that dissects\n\u201cvideo generation quality\u201d into specific, hierarchical, and\ndisentangled dimensions, each with tailored prompts and\nevaluation methods. VBench has three appealing properties: 1) Comprehensive Dimensions: VBench comprises 16 dimensions in video generation (e.g., subject identity inconsistency, motion smoothness, temporal flickering, and\nspatial relationship, etc.). The evaluation metrics with\nfine-grained levels reveal individual models\u2019 strengths and\nweaknesses. 2) Human Alignment: We also provide a\ndataset of human preference annotations to validate our\nbenchmarks\u2019 alignment with human perception, for each\nevaluation dimension respectively. 3) Valuable Insights:\nWe look into current models\u2019 ability across various evaluation dimensions, and various content types. We also investigate the gaps between video and image generation models.\nWe will open-source VBench, including all prompts, evaluation methods, generated videos, and human preference\nannotations, and also include more video generation models in VBench to drive forward the field of video generation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03321",
        "title": "Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages",
        "abstract": "Many recent works have explored using language models for planning problems.\nOne line of research focuses on translating natural language descriptions of planning tasks into structured planning languages, such as the planning domain definition language (PDDL). While this approach is promising, accurately measuring\nthe quality of generated PDDL code continues to pose significant challenges. First,\ngenerated PDDL code is typically evaluated using planning validators that check\nwhether the problem can be solved with a planner. This method is insufficient\nbecause a language model might generate valid PDDL code that does not align\nwith the natural language description of the task. Second, existing evaluation sets\noften have natural language descriptions of the planning task that closely resemble\nthe ground truth PDDL, reducing the challenge of the task. To bridge this gap, we\nintroduce Planetarium, a benchmark designed to evaluate language models\u2019 ability\nto generate PDDL code from natural language descriptions of planning tasks. We\nbegin by creating a PDDL equivalence algorithm that rigorously evaluates the\ncorrectness of PDDL code generated by language models by flexibly comparing it\nagainst a ground truth PDDL. Then, we present a dataset of 132, 037 text-to-PDDL\npairs across 13 different tasks, with varying levels of difficulty. Finally, we evaluate several API-access and open-weight language models that reveal this task\u2019s\ncomplexity. For example, 87.6% of the PDDL problem descriptions generated\nby GPT-4o are syntactically parseable, 82.2% are valid, solve-able problems, but\nonly 35.1% are semantically correct, highlighting the need for a more rigorous\nbenchmark for this problem.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03314",
        "title": "BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations",
        "abstract": "This paper presents Bag-of-Concept Graph\n(BACON) to gift models with limited linguistic\nabilities to taste the privilege of Vision Language Models (VLMs) and reduce hallucinations in the downstream tasks such as detection,\nvisual question answering (VQA), and image\ngeneration. Since the visual scenes in physical worlds are structured with complex relations between objects, BACON breaks down\nannotations into basic minimum elements and\npresents them in a graph structure. Elementwise style enables easy understanding, and\nstructural composition liberates difficult locating. Careful prompt design births the BACON captions with the help of public-available\nVLMs and segmentation methods. In this way,\nwe gather a dataset with 100K annotated images, which endow VLMs with remarkable capabilities, such as accurately generating BACON, transforming prompts into BACON format, envisioning scenarios in the style of BACON, and dynamically modifying elements\nwithin BACON through interactive dialogue and\nmore. Wide representative experiments, including detection, VQA, and image generation\ntasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel in their current\ncutting-edge solutions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03311",
        "title": "Value-Penalized Auxiliary Control from Examples for Learning without Rewards or Demonstrations",
        "abstract": "Learning from examples of success is an appealing approach to reinforcement learning that eliminates many of the disadvantages of using handcrafted reward functions or full expert-demonstration trajectories, both of which can be difficult to acquire, biased, or suboptimal. However, learning from examples alone dramatically increases the exploration challenge, especially for complex tasks. This work introduces value-penalized auxiliary control from examples (VPACE); we significantly improve exploration in example-based control by adding scheduled auxiliary control and examples of auxiliary tasks. Furthermore, we identify a value-calibration problem, where policy value estimates can exceed their theoretical limits based on successful data. We resolve this problem, which is exacerbated by learning auxiliary tasks, through the addition of an above-successlevel value penalty. Across three simulated and one real robotic manipulation environment, and 21 different main tasks, we show that our approach substantially improves learning efficiency. Videos, code, and datasets are available at https://papers.starslab.ca/vpace.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03308",
        "title": "ACCELERATED PROTON RESONANCE FREQUENCY-BASED\nMAGNETIC RESONANCE THERMOMETRY BY OPTIMIZED DEEP\nLEARNING METHOD",
        "abstract": "Background: Proton resonance frequency (PRF)\u2013based magnetic resonance (MR) thermometry is\nessential in thermal ablation therapies through focused ultrasound (FUS). The clinical treatments\nrequire temperature feedback must be rapid and accurate. Purpose: This work aims to enhance\ntemporal resolution in dynamic MR temperature map reconstruction with an improved deep learning\nmethod, to ensure the safety and effectiveness of FUS treatments.\nMethods: The training-optimized methods and five classical neural networks were applied on the\n2-fold and 4-fold under-sampling k-space data to reconstruct the temperature maps. The used neural\nnetworks were cascade net, complex valued U-Net, shift window transformer for MRI, real valued\nU-Net and U-Net with residual block. The enhanced training modules included offline/online data\naugmentations, knowledge distillation, and the amplitude-phase decoupling loss function. The heating\nexperiments were performed by a FUS transducer on phantom and ex vivo tissues, respectively. In\ndatasets, the ground-truth was the complex MR images with accurate temperature increases. These\ndata were also manually under-sampled to imitate acceleration procedures and trained in our method\nto get the reconstruction model. The additional dozen or so testing datasets were separately obtained\nfor evaluating the real-time performance and temperature accuracy.\nResults: Acceleration factors of 1.9 and 3.7 were found for 2\u00d7 and 4\u00d7 k-space under-sampling\nstrategies and the ResUNet-based deep learning reconstruction performed exceptionally well. In\n2-fold acceleration scenario, the RMSE of temperature map patches provided the values of 0.888 \u00b0C\nand 1.145 \u00b0C on phantom and ex vivo testing datasets. The DICE value of temperature areas enclosed\nby 43 \u00b0C isotherm was 0.809, and the Bland-Altman analysis showed a bias of \u22120.253 \u00b0C with the\napart of \u00b12.16 \u00b0C. In 4\u00d7 under-sampling case, these evaluating values decreased by approximately\n10%.\nConclusion: This study demonstrates that the application of deep learning-based reconstruction\nsignificantly enhances the accuracy and efficiency of MR thermometry, particularly benefiting the\nclinical thermal therapies for uterine fibroid, essential tremor, and prostate cancer by FUS.\nThe source code for our optimizing methods and neural networks is available at: https://github.\ncom/minipuding/FastMRT.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03307",
        "title": "HoloHisto: End-to-end Gigapixel WSI Segmentation with 4K Resolution Sequential Tokenization",
        "abstract": "In digital pathology, the traditional method for deep learning-based\nimage segmentation typically involves a two-stage process: initially segmenting\nhigh-resolution whole slide images (WSI) into smaller patches (e.g., 256\n\u00d7 256\n,\n512\n\u00d7 512\n, 1024\n\u00d7 1024) and subsequently reconstructing them to their original\nscale. This method often struggles to capture the complex details and vast scope\nof WSIs. In this paper, we propose the holistic histopathology (HoloHisto) segmentation method to achieve end-to-end segmentation on gigapixel WSIs, whose\nmaximum resolution is above 80,000\n\u00d770,000 pixels. HoloHisto fundamentally\nshifts the paradigm of WSI segmentation to an end-to-end learning fashion with\n1) a large (4K) resolution base patch for elevated visual information inclusion\nand efficient processing, and 2) a novel sequential tokenization mechanism to\nproperly model the contextual relationships and efficiently model the rich information from the 4K input. To our best knowledge, HoloHisto presents the first\nholistic approach for gigapixel resolution WSI segmentation, supporting direct\nI/O of complete WSI and their corresponding gigapixel masks. Under the HoloHisto platform, we unveil a random 4K sampler that transcends ultra-high resolution, delivering 31 and 10 times more pixels than standard 2D and 3D patches,\nrespectively, for advancing computational capabilities. To facilitate efficient 4K\nresolution dense prediction, we leverage sequential tokenization, utilizing a pretrained image tokenizer to group image features into a discrete token grid. To\nassess the performance, our team curated a new kidney pathology image segmentation (KPIs) dataset with WSI-level glomeruli segmentation from whole mouse\nkidneys. From the results, HoloHisto-4K delivers remarkable performance gains\nover previous state-of-the-art models.\"",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03300",
        "title": "DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents",
        "abstract": "Diffusion models (DMs) have revolutionized generative learning. They utilize a diffusion process\nto encode data into a simple Gaussian distribution. However, encoding a complex, potentially\nmultimodal data distribution into a single continuous Gaussian distribution arguably represents\nan unnecessarily challenging learning problem.\nWe propose Discrete-Continuous Latent Variable\nDiffusion Models (DisCo-Diff) to simplify this\ntask by introducing complementary discrete latent variables. We augment DMs with learnable\ndiscrete latents, inferred with an encoder, and\ntrain DM and encoder end-to-end. DisCo-Diff\ndoes not rely on pre-trained networks, making the\nframework universally applicable. The discrete\nlatents significantly simplify learning the DM\u2019s\ncomplex noise-to-data mapping by reducing the\ncurvature of the DM\u2019s generative ODE. An additional autoregressive transformer models the distribution of the discrete latents, a simple step because DisCo-Diff requires only few discrete variables with small codebooks. We validate DisCoDiff on toy data, several image synthesis tasks as\nwell as molecular docking, and find that introducing discrete latents consistently improves model\nperformance. For example, DisCo-Diff achieves\nstate-of-the-art FID scores on class-conditioned\nImageNet-64/128 datasets with ODE sampler.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03298",
        "title": "Eyes on the Game: Deciphering Implicit Human Signals to Infer Human Proficiency, Trust, and Intent",
        "abstract": "Effective collaboration between humans and AIs\nhinges on transparent communication and alignment of mental\nmodels. However, explicit, verbal communication is not always\nfeasible. Under such circumstances, human-human teams often\ndepend on implicit, nonverbal cues to glean important information about their teammates such as intent and expertise,\nthereby bolstering team alignment and adaptability. Among\nthese implicit cues, two of the most salient and fundamental\nare a human\u2019s actions in the environment and their visual\nattention. In this paper, we present a novel method to combine\neye gaze data and behavioral data, and evaluate their respective\npredictive power for human proficiency, trust, and intent. We\nfirst collect a dataset of paired eye gaze and gameplay data\nin the fast-paced collaborative \u201cOvercooked\u201d environment. We\nthen train models on this dataset to compare how the predictive\npowers differ between gaze data, gameplay data, and their\ncombination. We additionally compare our method to prior\nworks that aggregate eye gaze data and demonstrate how these\naggregation methods can substantially reduce the predictive\nability of eye gaze. Our results indicate that, while eye gaze\ndata and gameplay data excel in different situations, a model\nthat integrates both types consistently outperforms all baselines.\nThis work paves the way for developing intuitive and responsive\nagents that can efficiently adapt to new teammates.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03291",
        "title": "VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation",
        "abstract": "Complex human activity recognition (CHAR) remains a pivotal challenge within ubiquitous computing, especially in the\ncontext of smart environments. Existing studies typically require meticulous labeling of both atomic and complex activities,\na task that is labor-intensive and prone to errors due to the scarcity and inaccuracies of available datasets. Most prior\nresearch has focused on datasets that either precisely label atomic activities or, at minimum, their sequence\u2014approaches\nthat are often impractical in real-world settings. In response, we introduce VCHAR (Variance-Driven Complex Human\nActivity Recognition), a novel framework that treats the outputs of atomic activities as a distribution over specified intervals.\nLeveraging generative methodologies, VCHAR elucidates the reasoning behind complex activity classifications through\nvideo-based explanations, accessible to users without prior machine learning expertise. Our evaluation across three publicly\navailable datasets demonstrates that VCHAR enhances the accuracy of complex activity recognition without necessitating\nprecise temporal or sequential labeling of atomic activities. Furthermore, user studies confirm that VCHAR\u2019s explanations are\nmore intelligible compared to existing methods, facilitating a broader understanding of complex activity recognition among\nnon-experts.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03282",
        "title": "LLM Internal States Reveal Hallucination Risk Faced With a Query",
        "abstract": "The hallucination problem of Large Language\nModels (LLMs) significantly limits their reliability and trustworthiness. Humans have a selfawareness process that allows us to recognize\nwhat we don\u2019t know when faced with queries.\nInspired by this, our paper investigates whether\nLLMs can estimate their own hallucination risk\nbefore response generation. We analyze the\ninternal mechanisms of LLMs broadly both in\nterms of training data sources and across 15\ndiverse Natural Language Generation (NLG)\ntasks, spanning over 700 datasets. Our empirical analysis reveals two key insights: (1) LLM\ninternal states indicate whether they have seen\nthe query in training data or not; and (2) LLM\ninternal states show they are likely to hallucinate or not regarding the query. Our study\nexplores particular neurons, activation layers,\nand tokens that play a crucial role in the LLM\nperception of uncertainty and hallucination risk.\nBy a probing estimator, we leverage LLM selfassessment, achieving an average hallucination\nestimation accuracy of 84.32% at run time.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03277",
        "title": "Evaluating Automatic Metrics with Incremental Machine Translation Systems",
        "abstract": "We introduce a dataset comprising commercial\nmachine translations, gathered weekly over six\nyears across 12 translation directions. Since human A/B testing is commonly used, we assume\ncommercial systems improve over time, which\nenables us to evaluate machine translation (MT)\nmetrics based on their preference for more recent translations. Our study confirms several\nprevious findings in MT metrics research and\ndemonstrates the dataset\u2019s value as a testbed\nfor metric evaluation. We release our code.1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03236",
        "title": "CATT: Character-based Arabic Tashkeel Transformer",
        "abstract": "Tashkeel, or Arabic Text Diacritization (ATD),\ngreatly enhances the comprehension of Arabic text by removing ambiguity and minimizing the risk of misinterpretations caused by\nits absence. It plays a crucial role in improving Arabic text processing, particularly in applications such as text-to-speech and machine\ntranslation. This paper introduces a new approach to training ATD models. First, we\nfinetuned two transformers, encoder-only and\nencoder-decoder, that were initialized from a\npretrained character-based BERT. Then, we\napplied the Noisy-Student approach to boost\nthe performance of the best model. We evaluated our models alongside 11 commercial and\nopen-source models using two manually labeled benchmark datasets: WikiNews and our\nCATT dataset. Our findings show that our top\nmodel surpasses all evaluated models by relative Diacritic Error Rates (DERs) of 30.83%\nand 35.21% on WikiNews and CATT, respectively, achieving state-of-the-art in ATD. In addition, we show that our model outperforms\nGPT-4-turbo on CATT dataset by a relative\nDER of 9.36%. We open-source our CATT\nmodels and benchmark dataset for the research\ncommunity1\n.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03216",
        "title": "Learning Disentangled Representation in\nObject-Centric Models for Visual Dynamics Prediction\nvia Transformers",
        "abstract": "Recent work has shown that object-centric representations can greatly help improve the accuracy of learning dynamics while also bringing interpretability. In\nthis work, we take this idea one step further, ask the following question: \"can learning disentangled representation further improve the accuracy of visual dynamics\nprediction in object-centric models?\" While there has been some attempt to learn\nsuch disentangled representations for the case of static images [26], to the best of\nour knowledge, ours is the first work which tries to do this in a general setting for\nvideo, without making any specific assumptions about the kind of attributes that\nan object might have. The key building block of our architecture is the notion of a\nblock, where several blocks together constitute an object. Each block is represented\nas a linear combination of a given number of learnable concept vectors, which\nis iteratively refined during the learning process. The blocks in our model are\ndiscovered in an unsupervised manner, by attending over object masks, in a style\nsimilar to discovery of slots [21], for learning a dense object-centric representation.\nWe employ self-attention via transformers over the discovered blocks to predict\nthe next state resulting in discovery of visual dynamics. We perform a series of\nexperiments on several benchmark 2-D, and 3-D datasets demonstrating that our\narchitecture (1) can discover semantically meaningful blocks (2) help improve\naccuracy of dynamics prediction compared to SOTA object-centric models (3) perform significantly better in OOD setting where the specific attribute combinations\nare not seen earlier during training. Our experiments highlight the importance\ndiscovery of disentangled representation for visual dynamics prediction.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.03115",
        "title": "Lp-norm Distortion-Efficient Adversarial Attack",
        "abstract": "Adversarial examples have shown a powerful ability to make a well-trained model\nmisclassified. Current mainstream adversarial attack methods only consider one of\nthe distortions among L0-norm, L2-norm, and L\u221e-norm. L0-norm based methods\ncause large modification on a single pixel, resulting in naked-eye visible detection,\nwhile L2-norm and L\u221e-norm based methods suffer from weak robustness against\nadversarial defense since they always diffuse tiny perturbations to all pixels. A\nmore realistic adversarial perturbation should be sparse and imperceptible. In this\npaper, we propose a novel Lp-norm distortion-efficient adversarial attack, which\nnot only owns the least L2-norm (or L\u221e-norm) loss but also significantly reduces\nthe L0-norm distortion. To this aim, we design a new optimization scheme, which\nfirst optimizes an initial adversarial perturbation under L2-norm (or L\u221e-norm)\nconstraint, and then constructs a dimension unimportance matrix for the initial\nperturbation. Such a dimension unimportance matrix can indicate the adversarial unimportance of each dimension of the initial perturbation. Furthermore, we\nintroduce a new concept of adversarial threshold for the dimension unimportance\nmatrix. The dimensions of the initial perturbation whose unimportance is higher\nthan the threshold will be all set to zero, greatly decreasing the L0-norm distortion.\nExperimental results on three benchmark datasets (MNIST, CIFAR10, and ImageNet) show that under the same query budget, the adversarial examples generated\nby our method have lower L0-norm and L2-norm (or L\u221e-norm) distortion than the\nstate-of-the-art. Especially for the MNIST dataset, our attack reduces 8.1% L2-\nnorm distortion meanwhile remaining 47% pixels unattacked. This demonstrates\nthe superiority of the proposed method over its competitors in terms of adversarial\nrobustness and visual imperceptibility.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.03277",
        "title": "INSTRUCTION TUNING WITH GPT-4",
        "abstract": "Prior work has shown that finetuning large language models (LLMs) using machinegenerated instruction-following data enables such models to achieve remarkable\nzero-shot capabilities on new tasks, and no human-written instructions are needed.\nIn this paper, we present the first attempt to use GPT-4 to generate instructionfollowing data for LLM finetuning. Our early experiments on instruction-tuned\nLLaMA models show that the 52K English and Chinese instruction-following\ndata generated by GPT-4 leads to superior zero-shot performance on new tasks to\nthe instruction-following data generated by previous state-of-the-art models. We\nalso collect feedback and comparison data from GPT-4 to enable a comprehensive\nevaluation and reward model training. We make our data generated using GPT-4 as\nwell as our codebase publicly available. 1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13245",
        "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
        "abstract": "Multi-query attention (MQA), which only uses\na single key-value head, drastically speeds up\ndecoder inference. However, MQA can lead to\nquality degradation, and moreover it may not\nbe desirable to train a separate model just for\nfaster inference. We (1) propose a recipe for\nuptraining existing multi-head language model\ncheckpoints into models with MQA using 5%\nof original pre-training compute, and (2) introduce grouped-query attention (GQA), a generalization of multi-query attention which uses\nan intermediate (more than one, less than number of query heads) number of key-value heads.\nWe show that uptrained GQA achieves quality\nclose to multi-head attention with comparable\nspeed to MQA.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.13394",
        "title": "MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models",
        "abstract": "Multimodal Large Language Model (MLLM) relies on\nthe powerful LLM to perform multimodal tasks, showing\namazing emergent abilities in recent studies, such as writing poems based on an image. However, it is difficult for\nthese case studies to fully reflect the performance of MLLM,\nlacking a comprehensive evaluation. In this paper, we fill\nin this blank, presenting the first comprehensive MLLM\nEvaluation benchmark MME1\n. It measures both perception\nand cognition abilities on a total of 14 subtasks. In order\nto avoid data leakage that may arise from direct use of public datasets for evaluation, the annotations of instructionanswer pairs are all manually designed. The concise instruction design allows us to fairly compare MLLMs, instead of struggling in prompt engineering. Besides, with\nsuch an instruction, we can also easily carry out quantitative statistics. A total of 30 advanced MLLMs are comprehensively evaluated on our MME, which not only suggests that existing MLLMs still have a large room for improvement, but also reveals the potential directions for the\nsubsequent model optimization. The data application manner and online leaderboards are released at https://\ngithub.com/BradyFU/Awesome- MultimodalLarge-Language-Models/tree/Evaluation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.16154",
        "title": "MMVP: Motion-Matrix-based Video Prediction",
        "abstract": "A central challenge of video prediction lies where the\nsystem has to reason the objects\u2019 future motions from image\nframes while simultaneously maintaining the consistency\nof their appearances across frames. This work introduces\nan end-to-end trainable two-stream video prediction framework, Motion-Matrix-based Video Prediction (MMVP), to\ntackle this challenge. Unlike previous methods that usually handle motion prediction and appearance maintenance\nwithin the same set of modules, MMVP decouples motion\nand appearance information by constructing appearanceagnostic motion matrices. The motion matrices represent\nthe temporal similarity of each and every pair of feature\npatches in the input frames, and are the sole input of the\nmotion prediction module in MMVP. This design improves\nvideo prediction in both accuracy and efficiency, and reduces the model size. Results of extensive experiments\ndemonstrate that MMVP outperforms state-of-the-art systems on public data sets by non-negligible large margins (\u2248\n1 db in PSNR, UCF Sports) in significantly smaller model\nsizes (84% the size or smaller). Please refer to this link for\nthe official code and the datasets used in this paper",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14596",
        "title": "ICAL: Continual Learning of Multimodal Agents by Transforming Trajectories into Actionable Insights",
        "abstract": "Large-scale generative language and vision-language models (LLMs and VLMs) excel in few-shot in-context learning for decision making and instruction following. However, they require high-quality exemplar demonstrations to be included in their context window. In this work, we ask: Can LLMs and VLMs generate their own prompt examples from generic, sub-optimal demonstrations? We propose In-Context Abstraction Learning (ICAL), a method that builds a memory of multimodal experience insights from sub-optimal demonstrations and human feedback. Given a noisy demonstration in a new domain, VLMs abstract the trajectory into a general program by fixing inefficient actions and annotating cognitive abstractions: task relationships, object state changes, temporal subgoals, and task construals. These abstractions are refined and adapted interactively through human feedback while the agent attempts to execute the trajectory in a similar environment. The resulting abstractions, when used as exemplars in the prompt, significantly improve decision-making in retrieval-augmented LLM and VLM agents. Our ICAL agent surpasses the state-of-the-art in dialogue-based instruction following in TEACh, multimodal web agents in VisualWebArena, and action anticipation in Ego4D. In TEACh, we achieve a 12.6% improvement in goal-condition success. In VisualWebArena, our task success rate improves over the SOTA from 14.3% to 22.7%. In Ego4D action forecasting, we improve over few-shot GPT-4V and remain competitive with supervised models. We show finetuning our retrieval-augmented in-context agent yields additional improvements. Our approach significantly reduces reliance on expert-crafted examples and consistently outperforms in-context learning from action plans that lack such insights.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14599",
        "title": "Stylebreeder : Exploring and Democratizing Artistic Styles through Text-to-Image Models",
        "abstract": "Text-to-image models are becoming increasingly popular, revolutionizing the land- scape of digital art creation by enabling highly detailed and creative visual content generation. These models have been widely employed across various domains, particularly in art generation, where they facilitate a broad spectrum of creative expression and democratize access to artistic creation. In this paper, we introduce STYLEBREEDER, a comprehensive dataset of 6.8M images and 1.8M prompts gen- erated by 95K users on Artbreeder, a platform that has emerged as a significant hub for creative exploration with over 13M users. We introduce a series of tasks with this dataset aimed at identifying diverse artistic styles, generating personalized content, and recommending styles based on user interests. By documenting unique, user-generated styles that transcend conventional categories like \u2018cyberpunk\u2019 or \u2018Picasso,\u2019 we explore the potential for unique, crowd-sourced styles that could provide deep insights into the collective creative psyche of users worldwide. We also evaluate different personalization methods to enhance artistic expression and introduce a style atlas, making these models available in LoRA format for public use. Our research demonstrates the potential of text-to-image diffusion models to uncover and promote unique artistic expressions, further democratizing AI in art and fostering a more diverse and inclusive artistic community. The dataset, code and models are available at https://stylebreeder.github.io under a Public Domain (CC0) license.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14874",
        "title": "TraceNet: Segment one thing efficiently",
        "abstract": "Efficient single instance segmentation is essential for unlocking features in the mobile imaging applications, such as capture or editing. Existing on-the-fly mobile imaging applications scope the segmentation task to portraits or the salient subject due to the computational constraints. Instance segmentation, despite its re- cent developments towards efficient networks, is still heavy due to the cost of computation on the entire image to identify all in- stances. To address this, we propose and formulate a one tap driven single instance segmentation task that segments a single instance selected by a user via a positive tap. This task, in contrast to the broader task of segmenting anything as suggested in the Segment Anything Model [19], focuses on efficient segmentation of a single instance specified by the user. To solve this problem, we present TraceNet, which explicitly locates the selected instance by way of receptive field tracing. TraceNet identifies image regions that are related to the user tap and heavy computations are only performed on selected regions of the image. Therefore overall computation cost and memory consumption are reduced during inference. We evaluate the performance of TraceNet on instance IoU average over taps and the proportion of the region that a user tap can fall into for a high-quality single-instance mask. Experimental results on MS-COCO and LVIS demonstrate the effectiveness and efficiency of the proposed approach. TraceNet can jointly achieve the efficiency and interactivity, filling in the gap between needs for efficient mo- bile inference and recent research trend towards multimodal and interactive segmentation models.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.01424",
        "title": "A Global-Local Attention Mechanism for Relation Classification",
        "abstract": "Relation classification, a crucial component of relation extraction, involves identifying connections between two entities. Previous studies have predominantly focused on integrating the attention mechanism into relation classification at a global scale, overlooking the importance of the local context. To address this gap, this paper introduces a novel global-local attention mechanism for relation classification, which enhances global attention with a localized focus. Additionally, we propose innovative hard and soft localization mechanisms to identify potential keywords for local attention. By incorporating both hard and soft localization strategies, our approach offers a more nuanced and comprehensive understanding of the contextual cues that contribute to effective relation classification. Our experimental results on the SemEval-2010 Task 8 dataset highlight the superior performance of our method compared to previous attention-based approaches in relation classification.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.01411",
        "title": "HyperLoader: Integrating Hypernetwork-Based LoRA and Adapter Layers into Multi-Task Transformers for Sequence Labelling",
        "abstract": "We present HyperLoader, a simple approach that combines different parameter-efficient fine-tuning methods in a multi-task setting. To achieve this goal, our model uses a hypernetwork to generate the weights of these modules based on the task, the transformer layer, and its position within this layer. Our method combines the benefits of multi-task learning by capturing the structure of all tasks while reducing the task interference problem by encapsulating the task-specific knowledge in the generated weights and the benefits of combining different parameter-efficient methods to outperform full-fine tuning. We provide empirical evidence that HyperLoader outperforms previous approaches in most datasets and obtains the best average performance across tasks in high-resource and low-resource scenarios.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.01409",
        "title": "Dynamic Few-Shot Learning for Knowledge Graph Question Answering",
        "abstract": "Large language models present opportunities for innovative Question Answering over Knowledge Graphs (KGQA). However, they are not inherently designed for query generation. To bridge this gap, solutions have been proposed that rely on fine-tuning or ad-hoc architectures, achieving good results but limited out-of-domain distribution generalization. In this study, we introduce a novel approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the efficiency of in-context learning and semantic similarity and provides a generally applicable solution for KGQA with state-of-the-art performance. We run an extensive evaluation across multiple benchmark datasets and architecture configurations.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2407.01393",
        "title": "POLygraph: Polish Fake News Dataset",
        "abstract": "This paper presents the POLygraph dataset, a unique resource for fake news detection in Polish. The dataset, created by an interdisciplinary team, is composed of two parts: the \"fake-or-not\" dataset with 11,360 pairs of news articles (identified by their URLs) and corresponding labels, and the \"fake-they-say\" dataset with 5,082 news articles (identified by their URLs) and tweets commenting on them. Unlike existing datasets, POLygraph encompasses a variety of approaches from source literature, providing a comprehensive resource for fake news detection. The data was collected through manual annotation by expert and non-expert annotators. The project also developed a software tool that uses advanced machine learning techniques to analyze the data and determine content authenticity. The tool and dataset are expected to benefit various entities, from public sector institutions to publishers and fact-checking organizations. Further dataset exploration will foster fake news detection and potentially stimulate the implementation of similar models in other languages. The paper focuses on the creation and composition of the dataset, so it does not include a detailed evaluation of the software tool for content authenticity analysis, which is planned at a later stage of the project.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01374",
        "title": "Bridging the Gap: Transfer Learning from English PLMs to Malaysian English",
        "abstract": "Malaysian English is a low resource creole language, where it carries the elements of Malay, Chinese, and Tamil languages, in addition to Standard English. Named Entity Recognition (NER) models underperform when capturing entities from Malaysian English text due to its distinctive morphosyntactic adaptations, semantic features and code-switching (mixing English and Malay). Considering these gaps, we introduce MENmBERT and MENBERT, a pre-trained language model with contextual understanding, specifically tailored for Malaysian English. We have fine-tuned MENmBERT and MENBERT using manually annotated entities and relations from the Malaysian English News Article (MEN) Dataset. This fine-tuning process allows the PLM to learn representations that capture the nuances of Malaysian English relevant for NER and RE tasks. MENmBERT achieved a 1.52\\% and 26.27\\% improvement on NER and RE tasks respectively compared to the bert-base-multilingual-cased model. Although the overall performance of NER does not have a significant improvement, our further analysis shows that there is a significant improvement when evaluated by the 12 entity labels. These findings suggest that pre-training language models on language-specific and geographically-focused corpora can be a promising approach for improving NER performance in low-resource settings. The dataset and code published in this paper provide valuable resources for NLP research work focusing on Malaysian English.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01315",
        "title": "Language Portability Strategies for Open-domain Dialogue with Pre-trained Language Models from High to Low Resource Languages",
        "abstract": "In this paper we propose a study of linguistic portability strategies of large pre-trained language models (PLMs) used for open-domain dialogue systems in a high-resource language for this task. In particular the target low-resource language (L_T) will be simulated with French, as it lacks of task-specific resources and allows our human evaluation, when the source language (L_S) is English. For obvious reasons, recent works using such models for open-domain dialogue are mostly developed in English. Yet building specific PLMs for each possible target language supposes collecting new datasets and is costly. For this reason, trying to leverage all existing resources (PLMs and data) in both L_S and L_T , we wish to assess the performance achievable in L_T with different approaches. The first two approaches evaluate the usage of Neural Machine Translation (NMT) at different levels: TrainOnTarget where a L_S dataset is translated before fine-tuning in L_T and TestOnSource where a L_S model is coupled with NMT modules during inference. Then, the advent of BLOOM [2], the world first open-access multilingual large PLM, allow researchers to develop new approaches aiming to leverage not only the model's full accessibility but also its multilingualism and translation abilities. In this context the task is learned in L_S first and adapted to L_T using the MAD-X Adapter architecture [16]. In the two sets of experiments models are evaluated in spoken dialogue conditions with human and the strategies can be compared in terms of perceived interaction quality.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01264",
        "title": "SignCLIP: Connecting Text and Sign Language by Contrastive Learning",
        "abstract": "We present SignCLIP, which re-purposes CLIP (Contrastive Language-Image Pretraining) to project spoken language text and sign language videos, two classes of natural languages of distinct modalities, into the same space. SignCLIP is an efficient method of learning useful visual representations for sign language processing from large-scale, multilingual video-text pairs, without directly optimizing for a specific task or sign language which is often of limited size. We pretrain SignCLIP on Spreadthesign, a prominent sign language dictionary consisting of ~500 thousand video clips in up to 44 sign languages, and evaluate it with various downstream datasets. SignCLIP discerns in-domain signing with notable text-to-video/video-to-text retrieval accuracy. It also performs competitively for out-of-domain downstream tasks such as isolated sign language recognition upon essential few-shot prompting or fine-tuning. We analyze the latent space formed by the spoken language text and sign language poses, which provides additional linguistic insights. Our code and models are openly available.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01530",
        "title": "xLSTM-UNet can be an Effective 2D \\& 3D Medical Image Segmentation Backbone with Vision-LSTM (ViL) better than its Mamba Counterpart",
        "abstract": "Convolutional Neural Networks (CNNs) and Vision Transformers (ViT) have been pivotal in biomedical image segmentation, yet their ability to manage long-range dependencies remains constrained by inherent locality and computational overhead. To overcome these challenges, in this technical report, we first propose xLSTM-UNet, a UNet structured deep learning neural network that leverages Vision-LSTM (xLSTM) as its backbone for medical image segmentation. xLSTM is a recently proposed as the successor of Long Short-Term Memory (LSTM) networks and have demonstrated superior performance compared to Transformers and State Space Models (SSMs) like Mamba in Neural Language Processing (NLP) and image classification (as demonstrated in Vision-LSTM, or ViL implementation). Here, xLSTM-UNet we designed extend the success in biomedical image segmentation domain. By integrating the local feature extraction strengths of convolutional layers with the long-range dependency capturing abilities of xLSTM, xLSTM-UNet offers a robust solution for comprehensive image analysis. We validate the efficacy of xLSTM-UNet through experiments. Our findings demonstrate that xLSTM-UNet consistently surpasses the performance of leading CNN-based, Transformer-based, and Mamba-based segmentation networks in multiple datasets in biomedical segmentation including organs in abdomen MRI, instruments in endoscopic images, and cells in microscopic images. With comprehensive experiments performed, this technical report highlights the potential of xLSTM-based architectures in advancing biomedical image analysis in both 2D and 3D. The code, models, and datasets are publicly available at \\href{this http URL}{this http URL}",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2403.12895",
        "title": "mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding",
        "abstract": "Structure information is critical for understanding the semantics of text-rich images, such as documents, tables, and charts. Existing Multimodal Large Language Models (MLLMs) for Visual Document Understanding are equipped with text recognition ability but lack general structure understanding abilities for text-rich document images. In this work, we emphasize the importance of structure information in Visual Document Understanding and propose the Unified Structure Learning to boost the performance of MLLMs. Our Unified Structure Learning comprises structureaware parsing tasks and multi-grained text localization tasks across 5 domains: document, webpage, table, chart, and natural image. To better encode structure information, we design a simple and effective vision-to-text module H-Reducer, which can not only maintain the layout information but also reduce the length of visual features by merging horizontal adjacent patches through convolution, enabling the LLM to understand high-resolution images more efficiently. Furthermore, by constructing structure-aware text sequences and multi-grained pairs of texts and bounding boxes for publicly available text-rich images, we build a comprehensive training set DocStruct4M to support structure learning. Finally, we construct a small but high-quality reasoning tuning dataset DocReason25K to trigger the detailed explanation ability in the document domain. Our model DocOwl 1.5 achieves state-of-the-art performance on 10 visual document understanding benchmarks, improving the SOTA performance of MLLMs with a 7B LLM by more than 10 points in 5/10 benchmarks. Our codes, models, and datasets are publicly available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl1.5.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01080",
        "title": "Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese",
        "abstract": "The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark \\emph{Face4RAG} for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called \\emph{L-Face4RAG} with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available.\\footnote{\\url{this https URL}\\label{link_face4rag}}",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01026",
        "title": "Augmenting Document-level Relation Extraction with Efficient Multi-Supervision",
        "abstract": "Despite its popularity in sentence-level relation extraction, distantly supervised data is rarely utilized by existing work in document-level relation extraction due to its noisy nature and low information density. Among its current applications, distantly supervised data is mostly used as a whole for pertaining, which is of low time efficiency. To fill in the gap of efficient and robust utilization of distantly supervised training data, we propose Efficient Multi-Supervision for document-level relation extraction, in which we first select a subset of informative documents from the massive dataset by combining distant supervision with expert supervision, then train the model with Multi-Supervision Ranking Loss that integrates the knowledge from multiple sources of supervision to alleviate the effects of noise. The experiments demonstrate the effectiveness of our method in improving the model performance with higher time efficiency than existing baselines.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.00938",
        "title": "MalAlgoQA: A Pedagogical Approach for Evaluating Counterfactual Reasoning Abilities",
        "abstract": "This paper introduces MalAlgoQA, a novel dataset designed to evaluate the counterfactual reasoning capabilities of Large Language Models (LLMs) through a pedagogical approach. The dataset comprises mathematics and reading comprehension questions, each accompanied by four answer choices and their corresponding rationales. We focus on the incorrect answer rationales, termed \"malgorithms\", which highlights flawed reasoning steps leading to incorrect answers and offers valuable insights into erroneous thought processes. We also propose the Malgorithm Identification task, where LLMs are assessed based on their ability to identify corresponding malgorithm given an incorrect answer choice. To evaluate the model performance, we introduce two metrics: Algorithm Identification Accuracy (AIA) for correct answer rationale identification, and Malgorithm Identification Accuracy (MIA) for incorrect answer rationale identification. The task is challenging since state-of-the-art LLMs exhibit significant drops in MIA as compared to AIA. Moreover, we find that the chain-of-thought prompting technique not only fails to consistently enhance MIA, but can also lead to underperformance compared to simple prompting. These findings hold significant implications for the development of more cognitively-inspired LLMs to improve their counterfactual reasoning abilities, particularly through a pedagogical perspective where understanding and rectifying student misconceptions are crucial.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.00668",
        "title": "HRDE: Retrieval-Augmented Large Language Models for Chinese Health Rumor Detection and Explainability",
        "abstract": "As people increasingly prioritize their health, the speed and breadth of health information dissemination on the internet have also grown. At the same time, the presence of false health information (health rumors) intermingled with genuine content poses a significant potential threat to public health. However, current research on Chinese health rumors still lacks a large-scale, public, and open-source dataset of health rumor information, as well as effective and reliable rumor detection methods. This paper addresses this gap by constructing a dataset containing 1.12 million health-related rumors (HealthRCN) through web scraping of common health-related questions and a series of data processing steps. HealthRCN is the largest known dataset of Chinese health information rumors to date. Based on this dataset, we propose retrieval-augmented large language models for Chinese health rumor detection and explainability (HRDE). This model leverages retrieved relevant information to accurately determine whether the input health information is a rumor and provides explanatory responses, effectively aiding users in verifying the authenticity of health information. In evaluation experiments, we compared multiple models and found that HRDE outperformed them all, including GPT-4-1106-Preview, in rumor detection accuracy and answer quality. HRDE achieved an average accuracy of 91.04% and an F1 score of 91.58%.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.00653",
        "title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs",
        "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various natural language processing (NLP) tasks, which involve increasingly complex reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving new knowledge from existing one.While it has been widely studied in the context of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored. In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for knowledge reasoning, including methodologies for both dataset construction and model learning. For dataset construction, we create KnowReason via rule mining on KGs. For model learning, we observe rule overfitting induced by naive training. Hence, we enhance CoK with a trial-and-error mechanism that simulates the human process of internal knowledge exploration. We conduct extensive experiments with KnowReason. Our results show the effectiveness of CoK in refining LLMs in not only knowledge reasoning, but also general reasoning benchmarkms.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01393",
        "title": "POLygraph: Polish Fake News Dataset",
        "abstract": "This paper presents the POLygraph dataset, a unique resource for fake news detection in Polish. The dataset, created by an interdisciplinary team, is composed of two parts: the \"fake-or-not\" dataset with 11,360 pairs of news articles (identified by their URLs) and corresponding labels, and the \"fake-they-say\" dataset with 5,082 news articles (identified by their URLs) and tweets commenting on them. Unlike existing datasets, POLygraph encompasses a variety of approaches from source literature, providing a comprehensive resource for fake news detection. The data was collected through manual annotation by expert and non-expert annotators. The project also developed a software tool that uses advanced machine learning techniques to analyze the data and determine content authenticity. The tool and dataset are expected to benefit various entities, from public sector institutions to publishers and fact-checking organizations. Further dataset exploration will foster fake news detection and potentially stimulate the implementation of similar models in other languages. The paper focuses on the creation and composition of the dataset, so it does not include a detailed evaluation of the software tool for content authenticity analysis, which is planned at a later stage of the project.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01212",
        "title": "EconNLI: Evaluating Large Language Models on Economics Reasoning",
        "abstract": "Large Language Models (LLMs) are widely used for writing economic analysis reports or providing financial advice, but their ability to understand economic knowledge and reason about potential results of specific economic events lacks systematic evaluation. To address this gap, we propose a new dataset, natural language inference on economic events (EconNLI), to evaluate LLMs' knowledge and reasoning abilities in the economic domain. We evaluate LLMs on (1) their ability to correctly classify whether a premise event will cause a hypothesis event and (2) their ability to generate reasonable events resulting from a given premise. Our experiments reveal that LLMs are not sophisticated in economic reasoning and may generate wrong or hallucinated answers. Our study raises awareness of the limitations of using LLMs for critical decision-making involving economic reasoning and analysis. The dataset and codes are available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01091",
        "title": "M2QA: Multi-domain Multilingual Question Answering",
        "abstract": "Generalization and robustness to input variation are core desiderata of machine learning research. Language varies along several axes, most importantly, language instance (e.g. French) and domain (e.g. news). While adapting NLP models to new languages within a single domain, or to new domains within a single language, is widely studied, research in joint adaptation is hampered by the lack of evaluation datasets. This prevents the transfer of NLP systems from well-resourced languages and domains to non-dominant language-domain combinations. To address this gap, we introduce M2QA, a multi-domain multilingual question answering benchmark. M2QA includes 13,500 SQuAD 2.0-style question-answer instances in German, Turkish, and Chinese for the domains of product reviews, news, and creative writing. We use M2QA to explore cross-lingual cross-domain performance of fine-tuned models and state-of-the-art LLMs and investigate modular approaches to domain and language adaptation. We witness 1) considerable performance variations across domain-language combinations within model classes and 2) considerable performance drops between source and target language-domain combinations across all model sizes. We demonstrate that M2QA is far from solved, and new methods to effectively transfer both linguistic and domain-specific information are necessary. We make M2QA publicly available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.01080",
        "title": "Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese",
        "abstract": "The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark \\emph{Face4RAG} for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called \\emph{L-Face4RAG} with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available.\\footnote{\\url{this https URL}\\label{link_face4rag}}",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.00938",
        "title": "MalAlgoQA: A Pedagogical Approach for Evaluating Counterfactual Reasoning Abilities",
        "abstract": "This paper introduces MalAlgoQA, a novel dataset designed to evaluate the counterfactual reasoning capabilities of Large Language Models (LLMs) through a pedagogical approach. The dataset comprises mathematics and reading comprehension questions, each accompanied by four answer choices and their corresponding rationales. We focus on the incorrect answer rationales, termed \"malgorithms\", which highlights flawed reasoning steps leading to incorrect answers and offers valuable insights into erroneous thought processes. We also propose the Malgorithm Identification task, where LLMs are assessed based on their ability to identify corresponding malgorithm given an incorrect answer choice. To evaluate the model performance, we introduce two metrics: Algorithm Identification Accuracy (AIA) for correct answer rationale identification, and Malgorithm Identification Accuracy (MIA) for incorrect answer rationale identification. The task is challenging since state-of-the-art LLMs exhibit significant drops in MIA as compared to AIA. Moreover, we find that the chain-of-thought prompting technique not only fails to consistently enhance MIA, but can also lead to underperformance compared to simple prompting. These findings hold significant implications for the development of more cognitively-inspired LLMs to improve their counterfactual reasoning abilities, particularly through a pedagogical perspective where understanding and rectifying student misconceptions are crucial.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.05653",
        "title": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning",
        "abstract": "We introduce MAmmoTH, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving. The MAmmoTH models are trained on MathInstruct, our meticulously curated instruction tuning dataset. MathInstruct is compiled from 13 math datasets with intermediate rationales, six of which have rationales newly curated by us. It presents a unique hybrid of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also ensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT not only unleashes the potential of tool use but also allows different thought processes for different math problems. As a result, the MAmmoTH series substantially outperform existing open-source models on nine mathematical reasoning datasets across all scales with an average accuracy gain between 16% and 32%. Remarkably, our MAmmoTH-7B model reaches 33% on MATH (a competition-level dataset), which exceeds the best open-source 7B model (WizardMath) by 23%, and the MAmmoTH-34B model achieves 44% accuracy on MATH, even surpassing GPT4\u2019s CoT result. Our work underscores the importance of diverse problem coverage and the use of hybrid rationales in developing superior math generalist models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2405.11891",
        "title": "Unveiling and Manipulating Prompt Influence in Large Language Models",
        "abstract": "Prompts play a crucial role in guiding the responses of Large Language Models (LLMs). However, the intricate role of individual tokens in prompts, known as input saliency, in shaping the responses remains largely underexplored. Existing saliency methods either misalign with LLM generation objectives or rely heavily on linearity assumptions, leading to potential inaccuracies. To address this, we propose Token Distribution Dynamics (TDD), a simple yet effective approach to unveil and manipulate the role of prompts in generating LLM outputs. TDD leverages the robust interpreting capabilities of the language model head (LM head) to assess input saliency. It projects input tokens into the embedding space and then estimates their significance based on distribution dynamics over the vocabulary. We introduce three TDD variants: forward, backward, and bidirectional, each offering unique insights into token relevance. Extensive experiments reveal that the TDD surpasses state-of-the-art baselines with a big margin in elucidating the causal relationships between prompts and LLM outputs. Beyond mere interpretation, we apply TDD to two prompt manipulation tasks for controlled text generation: zero-shot toxic language suppression and sentiment steering. Empirical results underscore TDD\u2019s proficiency in identifying both toxic and sentimental cues in prompts, subsequently mitigating toxicity or modulating sentiment in the generated content.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2405.15012",
        "title": "Extracting Prompts by Inverting LLM Outputs",
        "abstract": "We consider the problem of language model inversion: given outputs of a language model, we seek to extract the prompt that generated these outputs. We develop a new black-box method, output2prompt, that extracts prompts without access to the model\u2019s logits and without adversarial or jailbreaking queries. Unlike previous methods, output2prompt only needs outputs of normal user queries. To improve memory efficiency, output2prompt employs a new sparse encoding techique. We measure the efficacy of output2prompt on a variety of user and system prompts and demonstrate zero-shot transferability across different LLMs. 1",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2401.14295",
        "title": "Demystifying Chains, Trees, and Graphs of Thoughts",
        "abstract": "The field of natural language processing (NLP) has witnessed significant progress in recent years, with a notable focus on improving large language models\u2019 (LLM) performance through innovative prompting techniques. Among these, prompt engineering coupled with structures has emerged as a promising paradigm, with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts, in which the overall LLM reasoning is guided by a structure such as a graph. As illustrated with numerous examples, this paradigm significantly enhances the LLM\u2019s capability to solve numerous tasks, ranging from logical or mathematical reasoning to planning or creative writing. To facilitate the understanding of this growing field and pave the way for future developments, we devise a general blueprint for effective and efficient LLM reasoning schemes. For this, we conduct an in-depth analysis of the prompt execution pipeline, clarifying and clearly defining different concepts. We then build the first taxonomy of structure-enhanced LLM reasoning schemes. We focus on identifying fundamental classes of harnessed structures, and we analyze the representations of these structures, algorithms executed with these structures, and many others. We refer to these structures as reasoning topologies, because their representation becomes to a degree spatial, as they are contained within the LLM context. Our study compares existing prompting schemes using the proposed taxonomy, discussing how certain design choices lead to different patterns in performance and cost. We also outline theoretical underpinnings, relationships between prompting and other parts of the LLM ecosystem such as knowledge bases, and the associated research challenges. Our work will help to advance future prompt engineering techniques.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/abs/2406.16860",
        "title": "Cambrian-1: A Fully Open, Vision-CentricExploration of Multimodal LLMs",
        "abstract": "We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a visioncentric approach. While stronger language models can enhance multimodal capabilities, the design choices for vision components are often insufficiently explored and disconnected from visual representation learning research. This gap hinders accurate sensory grounding in realworld scenarios. Our study uses LLMs and visual instruction tuning as an interface to evaluate various visual representations, offering new insights into different models and architectures\u2014 self-supervised, strongly supervised, or combinations thereof\u2014based on experiments with over 20 vision encoders. We critically examine existing MLLM benchmarks, addressing the difficulties involved in consolidating and interpreting results from various tasks, and introduce a new vision-centric benchmark, CV-Bench. To further improve visual grounding, we propose the Spatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that integrates high-resolution vision features with LLMs while reducing the number of tokens. Additionally, we discuss the curation of high-quality visual instruction-tuning data from publicly available sources, emphasizing the importance of data source balancing and distribution ratio. Collectively, Cambrian-1 not only achieves state-of-the-art performance but also serves as a comprehensive, open cookbook for instruction-tuned MLLMs. We provide model weights, code, supporting tools, datasets, and detailed instruction-tuning and evaluation recipes. We hope our release will inspire and accelerate advancements in multimodal systems and visual representation learning.Website https://cambrian-mllm.github.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01725",
        "title": "DiscoveryBench: Towards Data-Driven Discovery with Large Language Models",
        "abstract": "Can the rapid advances in code generation, function calling, and data analysis using large language models (LLMs) help automate the search and verification of hypotheses purely from a set of provided datasets? To evaluate this question, we present DiscoveryBench, the first comprehensive benchmark that formalizes the multi-step process of data-driven discovery. The benchmark is designed to systematically assess current model capabilities in discovery tasks and provide a useful resource for improving them. Our benchmark contains 264 tasks collected across 6 diverse domains, such as sociology and engineering, by manually deriving discovery workflows from published papers to approximate the real-world challenges faced by researchers, where each task is defined by a dataset, its metadata, and a discovery goal in natural language. We additionally provide 903 synthetic tasks to conduct controlled evaluations across task complexity. Furthermore, our structured formalism of data-driven discovery enables a facet-based evaluation that provides useful insights into different failure modes. We evaluate several popular LLM-based reasoning frameworks using both open and closed LLMs as baselines on DiscoveryBench and find that even the best system scores only 25%. Our benchmark, thus, illustrates the challenges in autonomous data-driven discovery and serves as a valuable resource for the community to make progress.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01863",
        "title": "VSP: Assessing the dual challenges of perception and reasoning in spatial planning tasks for VLMs",
        "abstract": "Vision language models (VLMs) are an exciting emerging class of language models (LMs) that have merged classic LM capabilities with those of image processing systems. However, the ways that these capabilities combine are not always intuitive and warrant direct investigation. One understudied capability in VLMs is visual spatial planning -- the ability to comprehend the spatial arrangements of objects and devise action plans to achieve desired outcomes in visual scenes. In our study, we introduce VSP, a benchmark that 1) evaluates the spatial planning capability in these models in general, and 2) breaks down the visual planning task into finer-grained sub-tasks, including perception and reasoning, and measure the LMs capabilities in these sub-tasks. Our evaluation shows that both open-source and private VLMs fail to generate effective plans for even simple spatial planning tasks. Evaluations on the fine-grained analytical tasks further reveal fundamental deficiencies in the models' visual perception and bottlenecks in reasoning abilities, explaining their worse performance in the general spatial planning tasks. Our work illuminates future directions for improving VLMs' abilities in spatial planning. Our benchmark is publicly available at https://github.com/UCSB-NLP-Chang/Visual-Spatial-Planning.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01896",
        "title": "LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis",
        "abstract": "Log analysis is crucial for ensuring the orderly and stable operation of information systems, particularly in the field of Artificial Intelligence for IT Operations (AIOps). Large Language Models (LLMs) have demonstrated significant potential in natural language processing tasks. In the AIOps domain, they excel in tasks such as anomaly detection, root cause analysis of faults, operations and maintenance script generation, and alert information summarization. However, the performance of current LLMs in log analysis tasks remains inadequately validated. To address this gap, we introduce LogEval, a comprehensive benchmark suite designed to evaluate the capabilities of LLMs in various log analysis tasks for the first time. This benchmark covers tasks such as log parsing, log anomaly detection, log fault diagnosis, and log summarization. LogEval evaluates each task using 4,000 publicly available log data entries and employs 15 different prompts for each task to ensure a thorough and fair assessment. By rigorously evaluating leading LLMs, we demonstrate the impact of various LLM technologies on log analysis performance, focusing on aspects such as self-consistency and few-shot contextual learning. We also discuss findings related to model quantification, Chinese-English question-answering evaluation, and prompt engineering. These findings provide insights into the strengths and weaknesses of LLMs in multilingual environments and the effectiveness of different prompt strategies. Various evaluation methods are employed for different tasks to accurately measure the performance of LLMs in log analysis, ensuring a comprehensive assessment. The insights gained from LogEvals evaluation reveal the strengths and limitations of LLMs in log analysis tasks, providing valuable guidance for researchers and practitioners.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01909",
        "title": "Pinyin Regularization in Error Correction for Chinese Speech Recognition with Large Language Models",
        "abstract": "Recent studies have demonstrated the efficacy of large language models (LLMs) in error correction for automatic speech recognition (ASR). However, much of the research focuses on the English language. This paper redirects the attention to Chinese. Firstly, we construct a specialized benchmark dataset aimed at error correction for Chinese ASR with 724K hypotheses transcription pairs, named the Chinese Hypotheses Paradise dataset (ChineseHP), which contains a wide range of scenarios and presents significant challenges. Subsequently, we conduct a preliminary evaluation using the dataset for both direct-prompting and fine-tuning pre-trained LLMs. Furthermore, we propose a straightforward method of Pinyin regularization for prompts, which involves the transcription of Pinyin directly from text hypotheses. The experimental results reveal that Pinyin regularization consistently enhances the error-correcting ability of LLMs when compared with those without regularization. The dataset is available on the website.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2407.01920",
        "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models",
        "abstract": "Large Language Models (LLMs) trained on extensive corpora inevitably retain sensitive data, such as personal privacy information and copyrighted material. Recent advancements in knowledge unlearning involve updating LLM parameters to erase specific knowledge. However, current unlearning paradigms are mired in vague forgetting boundaries, often erasing knowledge indiscriminately. In this work, we introduce KnowUnDo, a benchmark containing copyrighted content and user privacy domains to evaluate if the unlearning process inadvertently erases essential knowledge. Our findings indicate that existing unlearning methods often suffer from excessive unlearning. To address this, we propose a simple yet effective method, MemFlex, which utilizes gradient information to precisely target and unlearn sensitive parameters. Experimental results show that MemFlex is superior to existing methods in both precise knowledge unlearning and general knowledge retaining of LLMs. Code and dataset will be released at https://github.com/zjunlp/KnowUnDo.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.16962",
        "title": "MetaGreen: Meta-Learning Inspired Transformer Selection for Green Semantic Communication",
        "abstract": "Semantic Communication can transform the way we transmit information, prioritizing meaningful and effective content over individual symbols or bits. This evolution promises significant benefits, including reduced latency, lower bandwidth usage, and higher throughput compared to traditional communication. However, the development of Semantic Communication faces a crucial challenge: the need for universal metrics to benchmark the joint effects of semantic information loss and energy consumption. This research introduces an innovative solution: the ``Energy-Optimized Semantic Loss'' (EOSL) function, a novel multi-objective loss function that effectively balances semantic information loss and energy consumption. Through comprehensive experiments on transformer models, including energy benchmarking, we demonstrate the remarkable effectiveness of EOSL-based model selection. We have established that EOSL-based transformer model selection achieves up to 83\\% better similarity-to-power ratio (SPR) compared to BLEU score-based selection and 67\\% better SPR compared to solely lowest power usage-based selection. Furthermore, we extend the applicability of EOSL to diverse and varying contexts, inspired by the principles of Meta-Learning. By cumulatively applying EOSL, we enable the model selection system to adapt to this change, leveraging historical EOSL values to guide the learning process. This work lays the foundation for energy-efficient model selection and the development of green semantic communication.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/abs/2406.16953",
        "title": "Validation of a new, minimally-invasive, software smartphone device to predict sleep apnea and its severity: transversal study",
        "abstract": "Obstructive sleep apnea (OSA) is frequent and responsible for cardiovascular complications and excessive daytime sleepiness. It is underdiagnosed due to the difficulty to access the gold standard for diagnosis, polysomnography (PSG). Alternative methods using smartphone sensors could be useful to increase diagnosis. The objective is to assess the performances of Apneal, an application that records the sound using a smartphone's microphone and movements thanks to a smartphone's accelerometer and gyroscope, to estimate patients' AHI. In this article, we perform a monocentric proof-of-concept study with a first manual scoring step, and then an automatic detection of respiratory events from the recorded signals using a sequential deep-learning model which was released internally at Apneal at the end of 2022 (version 0.1 of Apneal automatic scoring of respiratory events), in adult patients during in-hospital polysomnography.46 patients (women 34 per cent, mean BMI 28.7 kg per m2) were included. For AHI superior to 15, sensitivity of manual scoring was 0.91, and positive predictive value (PPV) 0.89. For AHI superior to 30, sensitivity was 0.85, PPV 0.94. We obtained an AUC-ROC of 0.85 and an AUC-PR of 0.94 for the identification of AHI superior to 15, and AUC-ROC of 0.95 and AUC-PR of 0.93 for AHI superior to 30. Promising results are obtained for the automatic annotations of events.This article shows that manual scoring of smartphone-based signals is possible and accurate compared to PSG-based scorings. Automatic scoring method based on a deep learning model provides promising results. A larger multicentric validation study, involving subjects with different SAHS severity is required to confirm these results.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/abs/2406.16903",
        "title": "Towards a copilot in BIM authoring tool using a large language model-based agent for intelligent human-machine interaction",
        "abstract": "Facing increasingly complex BIM authoring software and the accompanying expensive learning costs, designers often seek to interact with the software in a more intelligent and lightweight manner. They aim to automate modeling workflows, avoiding obstacles and difficulties caused by software usage, thereby focusing on the design process itself. To address this issue, we proposed an LLM-based autonomous agent framework that can function as a copilot in the BIM authoring tool, answering software usage questions, understanding the user's design intentions from natural language, and autonomously executing modeling tasks by invoking the appropriate tools. In a case study based on the BIM authoring software Vectorworks, we implemented a software prototype to integrate the proposed framework seamlessly into the BIM authoring scenario. We evaluated the planning and reasoning capabilities of different LLMs within this framework when faced with complex instructions. Our work demonstrates the significant potential of LLM-based agents in design automation and intelligent interaction.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/abs/2406.17095",
        "title": "Attention Instruction: Amplifying Attention in the Middle via Prompting",
        "abstract": "The context window of large language models has been extended to 128k tokens or more. However, language models still suffer from position bias and have difficulty in accessing and using the middle part of the context due to the lack of attention. We examine the relative position awareness of LLMs and the feasibility of mitigating disproportional attention through prompting. We augment the original task instruction with attention instructions",
        "label": 0
    },
    {
        "url": "https://arxiv.org/abs/2406.17294",
        "title": "Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models",
        "abstract": "Large language models (LLMs) have demonstrated impressive reasoning capabilities, particularly in textual mathematical problem-solving. However, existing open-source image instruction fine-tuning datasets, containing limited question-answer pairs per image, do not fully exploit visual information to enhance the multimodal mathematical reasoning capabilities of Multimodal LLMs (MLLMs). To bridge this gap, we address the lack of high-quality, diverse multimodal mathematical datasets by collecting 40K high-quality images with question-answer pairs from 24 existing datasets and synthesizing 320K new pairs, creating the MathV360K dataset, which enhances both the breadth and depth of multimodal mathematical questions. We introduce Math-LLaVA, a LLaVA-1.5-based model fine-tuned with MathV360K. This novel approach significantly improves the multimodal mathematical reasoning capabilities of LLaVA-1.5, achieving a 19-point increase and comparable performance to GPT-4V on MathVista's minitest split. Furthermore, Math-LLaVA demonstrates enhanced generalizability, showing substantial improvements on the MMMU benchmark. Our research highlights the importance of dataset diversity and synthesis in advancing MLLMs' mathematical reasoning abilities. The code and data are available at: \\url{this https URL}.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17287",
        "title": "Predicting the Big Five Personality Traits in Chinese Counselling Dialogues Using Large Language Models",
        "abstract": "Accurate assessment of personality traits is crucial for effective psycho-counseling, yet traditional methods like self-report questionnaires are time-consuming and biased. This study exams whether Large Language Models (LLMs) can predict the Big Five personality traits directly from counseling dialogues and introduces an innovative framework to perform the task. Our framework applies role-play and questionnaire-based prompting to condition LLMs on counseling sessions, simulating client responses to the Big Five Inventory. We evaluated our framework on 853 real-world counseling sessions, finding a significant correlation between LLM-predicted and actual Big Five traits, proving the validity of framework. Moreover, ablation studies highlight the importance of role-play simulations and task simplification via questionnaires in enhancing prediction accuracy. Meanwhile, our fine-tuned Llama3-8B model, utilizing Direct Preference Optimization with Supervised Fine-Tuning, achieves a 130.95\\% improvement, surpassing the state-of-the-art Qwen1.5-110B by 36.94\\% in personality prediction validity. In conclusion, LLMs can predict personality based on counseling dialogues. Our code and model are publicly available at \\url{this https URL}, providing a valuable tool for future research in computational psychometrics.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17274",
        "title": "Can We Trust the Performance Evaluation of Uncertainty Estimation Methods in Text Summarization?",
        "abstract": "Text summarization, a key natural language generation (NLG) task, is vital in various domains. However, the high cost of inaccurate summaries in risk-critical applications, particularly those involving human-in-the-loop decision-making, raises concerns about the reliability of uncertainty estimation on text summarization (UE-TS) evaluation methods. This concern stems from the dependency of uncertainty model metrics on diverse and potentially conflicting NLG metrics. To address this issue, we introduce a comprehensive UE-TS benchmark incorporating 31 NLG metrics across four dimensions. The benchmark evaluates the uncertainty estimation capabilities of two large language models and one pre-trained language model on three datasets, with human-annotation analysis incorporated where applicable. We also assess the performance of 14 common uncertainty estimation methods within this benchmark. Our findings emphasize the importance of considering multiple uncorrelated NLG metrics and diverse uncertainty estimation methods to ensure reliable and efficient evaluation of UE-TS techniques.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17260",
        "title": "Mitigating Hallucination in Fictional Character Role-Play",
        "abstract": "Role-playing has wide-ranging applications in customer support, embodied agents, computational social science, etc. The influence of parametric world knowledge of large language models (LLMs) often causes role-playing characters to act out of character and hallucinate about things outside the scope of their knowledge. In this work, we focus on the evaluation and mitigation of hallucination in fictional character role-play. We introduce a dataset with more than 2,000 characters and 72,000 interviews, including 18,000 adversarial questions. We propose RoleFact, a role-playing method that mitigates hallucination by modulating the influence of parametric knowledge using a pre-calibrated confidence threshold. Experiments show that the proposed method improves the factual precision of generated responses by 18% for adversarial questions with a 44% reduction in temporal hallucination for time-sensitive interviews. The code and the dataset will be available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17253",
        "title": "How Well Can Knowledge Edit Methods Edit Perplexing Knowledge?",
        "abstract": "As large language models (LLMs) are widely deployed, targeted editing of their knowledge has become a critical challenge. Recently, advancements in model editing techniques, such as Rank-One Model Editing (ROME), have paved the way for updating LLMs with new knowledge. However, the efficacy of these methods varies across different types of knowledge. This study investigates the capability of knowledge editing methods to incorporate new knowledge with varying degrees of \"perplexingness\", a term we use to describe the initial difficulty LLMs have in understanding new concepts. We begin by quantifying the \"perplexingness\" of target knowledge using pre-edit conditional probabilities, and assess the efficacy of edits through post-edit conditional probabilities. Utilizing the widely-used CounterFact dataset, we find significant negative correlations between the \"perplexingness\" of the new knowledge and the edit efficacy across all 12 scenarios. To dive deeper into this phenomenon, we introduce a novel dataset, HierarchyData, consisting of 99 hyponym-hypernym pairs across diverse categories. Our analysis reveal that more abstract concepts (hypernyms) tend to be more perplexing than their specific counterparts (hyponyms). Further exploration into the influence of knowledge hierarchy on editing outcomes indicates that knowledge positioned at higher hierarchical levels is more challenging to modify in some scenarios. Our research highlights a previously overlooked aspect of LLM editing: the variable efficacy of editing methods in handling perplexing knowledge. By revealing how hierarchical relationships can influence editing outcomes, our findings offer new insights into the challenges of updating LLMs and pave the way for more nuanced approaches to model editing in the future.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17169",
        "title": "Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability of Large Language Models",
        "abstract": "As Large Language Models (LLMs) continue to exhibit remarkable performance in natural language understanding tasks, there is a crucial need to measure their ability for human-like multi-step logical reasoning. Existing logical reasoning evaluation benchmarks often focus primarily on simplistic single-step or multi-step reasoning with a limited set of inference rules. Furthermore, the lack of datasets for evaluating non-monotonic reasoning represents a crucial gap since it aligns more closely with human-like reasoning. To address these limitations, we propose Multi-LogiEval, a comprehensive evaluation dataset encompassing multi-step logical reasoning with various inference rules and depths. Multi-LogiEval covers three logic types--propositional, first-order, and non-monotonic--consisting of more than 30 inference rules and more than 60 of their combinations with various depths. Leveraging this dataset, we conduct evaluations on a range of LLMs including GPT-4, ChatGPT, Gemini-Pro, Yi, Orca, and Mistral, employing a zero-shot chain-of-thought. Experimental results show that there is a significant drop in the performance of LLMs as the reasoning steps/depth increases (average accuracy of ~68% at depth-1 to ~43% at depth-5). We further conduct a thorough investigation of reasoning chains generated by LLMs which reveals several important findings. We believe that Multi-LogiEval facilitates future research for evaluating and enhancing the logical reasoning ability of LLMs. Data is available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17158",
        "title": "DEXTER: A Benchmark for open-domain Complex Question Answering using LLMs",
        "abstract": "Open-domain complex Question Answering (QA) is a difficult task with challenges in evidence retrieval and reasoning. The complexity of such questions could stem from questions being compositional, hybrid evidence, or ambiguity in questions. While retrieval performance for classical QA tasks is well explored, their capabilities for heterogeneous complex retrieval tasks, especially in an open-domain setting, and the impact on downstream QA performance, are relatively unexplored. To address this, in this work, we propose a benchmark composing diverse complex QA tasks and provide a toolkit to evaluate state-of-the-art pre-trained dense and sparse retrieval models in an open-domain setting. We observe that late interaction models and surprisingly lexical models like BM25 perform well compared to other pre-trained dense retrieval models. In addition, since context-based reasoning is critical for solving complex QA tasks, we also evaluate the reasoning capabilities of LLMs and the impact of retrieval performance on their reasoning capabilities. Through experiments, we observe that much progress is to be made in retrieval for complex QA to improve downstream QA performance. Our software and related data can be accessed at this https URL",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17557",
        "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale",
        "abstract": "The performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. However, the pretraining datasets for state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly available and very little is known about how they were created. In this work, we introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl snapshots that produces better-performing LLMs than other open pretraining datasets. To advance the understanding of how best to curate high-quality pretraining datasets, we carefully document and ablate all of the design choices used in FineWeb, including in-depth investigations of deduplication and filtering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion token collection of educational text filtered from FineWeb. LLMs pretrained on FineWeb-Edu exhibit dramatically better performance on knowledge- and reasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we publicly release our data curation codebase and all of the models trained during our ablation experiments.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17535",
        "title": "Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian Benchmark",
        "abstract": "Recent advancements in Large Language Models (LLMs) have significantly enhanced their ability to generate and manipulate human language, highlighting their potential across various applications. Evaluating LLMs in languages other than English is crucial for ensuring their linguistic versatility, cultural relevance, and applicability in diverse global contexts, thus broadening their usability and effectiveness. We tackle this challenge by introducing a structured benchmark using the INVALSI tests, a set of well-established assessments designed to measure educational competencies across Italy. Our study makes three primary contributions: Firstly, we adapt the INVALSI benchmark for automated LLM evaluation, which involves rigorous adaptation of the test format to suit automated processing while retaining the essence of the original tests. Secondly, we provide a detailed assessment of current LLMs, offering a crucial reference point for the academic community. Finally, we visually compare the performance of these models against human results. Additionally, researchers are invited to submit their models for ongoing evaluation, ensuring the benchmark remains a current and valuable resource.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17526",
        "title": "LumberChunker: Long-Form Narrative Document Segmentation",
        "abstract": "Modern NLP tasks increasingly rely on dense retrieval methods to access up-to-date and relevant contextual information. We are motivated by the premise that retrieval benefits from segments that can vary in size such that a content's semantic independence is better captured. We propose LumberChunker, a method leveraging an LLM to dynamically segment documents, which iteratively prompts the LLM to identify the point within a group of sequential passages where the content begins to shift. To evaluate our method, we introduce GutenQA, a benchmark with 3000 \"needle in a haystack\" type of question-answer pairs derived from 100 public domain narrative books available on Project Gutenberg. Our experiments show that LumberChunker not only outperforms the most competitive baseline by 7.37% in retrieval performance (DCG@20) but also that, when integrated into a RAG pipeline, LumberChunker proves to be more effective than other chunking methods and competitive baselines, such as the Gemini 1.5M Pro. Our Code and Data are available at this https URL",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17385",
        "title": "Native Design Bias: Studying the Impact of English Nativeness on Language Model Performance",
        "abstract": "Large Language Models (LLMs) excel at providing information acquired during pretraining on large-scale corpora and following instructions through user prompts. This study investigates whether the quality of LLM responses varies depending on the demographic profile of users. Considering English as the global lingua franca, along with the diversity of its dialects among speakers of different native languages, we explore whether non-native English speakers receive lower-quality or even factually incorrect responses from LLMs more frequently. Our results show that performance discrepancies occur when LLMs are prompted by native versus non-native English speakers and persist when comparing native speakers from Western countries with others. Additionally, we find a strong anchoring effect when the model recognizes or is made aware of the user's nativeness, which further degrades the response quality when interacting with non-native speakers. Our analysis is based on a newly collected dataset with over 12,000 unique annotations from 124 annotators, including information on their native language and English proficiency.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17764",
        "title": "BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning",
        "abstract": "Large language models (LLMs) possess extensive parametric knowledge, but this knowledge is difficult to update with new information because retraining is very expensive and infeasible for closed-source models. Knowledge editing (KE) has emerged as a viable solution for updating the knowledge of LLMs without compromising their overall performance. On-the-fly KE methods, inspired by in-context learning (ICL), have shown great promise and allow LLMs to be treated as black boxes. In the past, KE was primarily employed in English contexts, whereas the potential for cross-lingual KE in current English-centric LLMs has not been fully explored. To foster more research in this direction, we introduce the BMIKE-53 benchmark for evaluating cross-lingual KE on 53 diverse languages across three KE task types. We also propose a gradient-free KE method called Multilingual In-context Knowledge Editing (MIKE) and evaluate it on BMIKE-53. Our evaluation focuses on cross-lingual knowledge transfer in terms of reliability, generality, locality, and portability, offering valuable insights and a framework for future research in cross-lingual KE. Our code and data are publicly accessible via the anonymous repository at https://anonymous.4open.science/r/MIKE.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17761",
        "title": "CaLMQA: Exploring culturally specific long-form question answering across 23 languages",
        "abstract": "Large language models (LLMs) are commonly used for long-form question answering, which requires them to generate paragraph-length answers to complex questions. While long-form QA has been well-studied in English via many different datasets and evaluation metrics, this research has not been extended to cover most other languages. To bridge this gap, we introduce CaLMQA, a collection of 2.6K complex questions spanning 23 languages, including under-resourced, rarely-studied languages such as Fijian and Kirundi. Our dataset includes both naturally-occurring questions collected from community web forums as well as questions written by native speakers, whom we hire for this purpose. Our process yields diverse, complex questions that reflect cultural topics (e.g. traditions, laws, news) and the language usage of native speakers. We conduct automatic evaluation across a suite of open- and closed-source models using our novel metric CaLMScore, which detects incorrect language and token repetitions in answers, and observe that the quality of LLM-generated answers degrades significantly for some low-resource languages. We perform human evaluation on a subset of models and see that model performance is significantly worse for culturally specific questions than for culturally agnostic questions. Our findings highlight the need for further research in LLM multilingual capabilities and non-English LFQA evaluation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17755",
        "title": "Accelerating Clinical Evidence Synthesis with Large Language Models",
        "abstract": "Automatic medical discovery by AI is a dream of many. One step toward that goal is to create an AI model to understand clinical studies and synthesize clinical evidence from the literature. Clinical evidence synthesis currently relies on systematic reviews of clinical trials and retrospective analyses from medical literature. However, the rapid expansion of publications presents challenges in efficiently identifying, summarizing, and updating evidence. We introduce TrialMind, a generative AI-based pipeline for conducting medical systematic reviews, encompassing study search, screening, and data extraction phases. We utilize large language models (LLMs) to drive each pipeline component while incorporating human expert oversight to minimize errors. To facilitate evaluation, we also create a benchmark dataset TrialReviewBench, a custom dataset with 870 annotated clinical studies from 25 meta-analysis papers across various medical treatments. Our results demonstrate that TrialMind significantly improves the literature review process, achieving high recall rates (0.897-1.000) in study searching from over 20 million PubMed studies and outperforming traditional language model embeddings-based methods in screening (Recall@20 of 0.227-0.246 vs. 0.000-0.102). Furthermore, our approach surpasses direct GPT-4 performance in result extraction, with accuracy ranging from 0.65 to 0.84. We also support clinical evidence synthesis in forest plots, as validated by eight human annotators who preferred TrialMind over the GPT-4 baseline with a winning rate of 62.5%-100% across the involved reviews. Our findings suggest that an LLM-based clinical evidence synthesis approach, such as TrialMind, can enable reliable and high-quality clinical evidence synthesis to improve clinical research efficiency.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17716",
        "title": "ViANLI: Adversarial Natural Language Inference for Vietnamese",
        "abstract": "The development of Natural Language Processing (NLI) datasets and models has been inspired by innovations in annotation design. With the rapid development of machine learning models today, the performance of existing machine learning models has quickly reached state-of-the-art results on a variety of tasks related to natural language processing, including natural language inference tasks. By using a pre-trained model during the annotation process, it is possible to challenge current NLI models by having humans produce premise-hypothesis combinations that the machine model cannot correctly predict. To remain attractive and challenging in the research of natural language inference for Vietnamese, in this paper, we introduce the adversarial NLI dataset to the NLP research community with the name ViANLI. This data set contains more than 10K premise-hypothesis pairs and is built by a continuously adjusting process to obtain the most out of the patterns generated by the annotators. ViANLI dataset has brought many difficulties to many current SOTA models when the accuracy of the most powerful model on the test set only reached 48.4%. Additionally, the experimental results show that the models trained on our dataset have significantly improved the results on other Vietnamese NLI datasets.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17692",
        "title": "From Distributional to Overton Pluralism: Investigating Large Language Model Alignment",
        "abstract": "The alignment process changes several properties of a large language model's (LLM's) output distribution. We analyze two aspects of post-alignment distributional shift of LLM responses. First, we re-examine previously reported reductions in response diversity post-alignment. Our analysis suggests that an apparent drop in the diversity of responses is largely explained by quality control and information aggregation. Alignment suppresses irrelevant and unhelpful content while shifting the output distribution toward longer responses that cover information spanning several responses from the base LLM, essentially presenting diverse information in a single response. Finding little evidence that alignment suppresses useful information, it is natural to ask the opposite question: do aligned models surface information that cannot be recovered from base models? Our second investigation shows this is not the case and the behavior of aligned models is recoverable from base models without fine-tuning. A combination of in-context examples and lower-resolution semantic hints about response content can elicit responses from base LLMs that are as similar to alignment-tuned LLM responses as alignment-tuned LLM responses are to each other. Taken together, these results indicate that current alignment techniques capture but do not extend the useful subset of assistant-like base LLM behavior, providing further evidence for the Superficial Alignment Hypothesis. They also show that in-context alignment can go surprisingly far as a strategy for imitating aligned LLMs without fine-tuning. Our code and data is available at this https URL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17681",
        "title": "VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation",
        "abstract": "As large language models achieve impressive scores on traditional benchmarks, an increasing number of researchers are becoming concerned about benchmark data leakage during pre-training, commonly known as the data contamination problem. To ensure fair evaluation, recent benchmarks release only the training and validation sets, keeping the test set labels closed-source. They require anyone wishing to evaluate his language model to submit the model's predictions for centralized processing and then publish the model's result on their leaderboard. However, this submission process is inefficient and prevents effective error analysis. To address this issue, we propose to variabilize benchmarks and evaluate language models dynamically. Specifically, we extract variables from each test case and define a value range for each variable. For each evaluation, we sample new values from these value ranges to create unique test cases, thus ensuring a fresh evaluation each time. We applied this variable perturbation method to four datasets: GSM8K, ARC, CommonsenseQA, and TruthfulQA, which cover mathematical generation and multiple-choice tasks. Our experimental results demonstrate that this approach provides a more accurate assessment of the true capabilities of language models, effectively mitigating the contamination problem.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17675",
        "title": "Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models",
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional task-solving capabilities, increasingly adopting roles akin to human-like assistants. The broader integration of LLMs into society has sparked interest in whether they manifest psychological attributes, and whether these attributes are stable-inquiries that could deepen the understanding of their behaviors. Inspired by psychometrics, this paper presents a framework for investigating psychology in LLMs, including psychological dimension identification, assessment dataset curation, and assessment with results validation. Following this framework, we introduce a comprehensive psychometrics benchmark for LLMs that covers six psychological dimensions: personality, values, emotion, theory of mind, motivation, and intelligence. This benchmark includes thirteen datasets featuring diverse scenarios and item types. Our findings indicate that LLMs manifest a broad spectrum of psychological attributes. We also uncover discrepancies between LLMs' self-reported traits and their behaviors in real-world scenarios. This paper demonstrates a thorough psychometric assessment of LLMs, providing insights into reliable evaluation and potential applications in AI and social sciences.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17626",
        "title": "CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue Coreference",
        "abstract": "As large language models (LLMs) constantly evolve, ensuring their safety remains a critical research problem. Previous red-teaming approaches for LLM safety have primarily focused on single prompt attacks or goal hijacking. To the best of our knowledge, we are the first to study LLM safety in multi-turn dialogue coreference. We created a dataset of 1,400 questions across 14 categories, each featuring multi-turn coreference safety attacks. We then conducted detailed evaluations on five widely used open-source LLMs. The results indicated that under multi-turn coreference safety attacks, the highest attack success rate was 56% with the LLaMA2-Chat-7b model, while the lowest was 13.9% with the Mistral-7B-Instruct model. These findings highlight the safety vulnerabilities in LLMs during dialogue coreference interactions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/abs/2406.17588",
        "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
        "abstract": "The long-context capabilities of large language models (LLMs) have been a hot topic in recent years. To evaluate the performance of LLMs in different scenarios, various assessment benchmarks have emerged. However, as most of these benchmarks focus on identifying key information to answer questions, which mainly requires the retrieval ability of LLMs, these benchmarks can partially represent the reasoning performance of LLMs from large amounts of information. Meanwhile, although LLMs often claim to have context windows of 32k, 128k, 200k, or even longer, these benchmarks fail to reveal the actual supported length of these LLMs. To address these issues, we propose the LongIns benchmark dataset, a challenging long-context instruction-based exam for LLMs, which is built based on the existing instruction datasets. Specifically, in our LongIns, we introduce three evaluation settings: Global Instruction & Single Task (GIST), Local Instruction & Single Task (LIST), and Local Instruction & Multiple Tasks (LIMT). Based on LongIns, we perform comprehensive evaluations on existing LLMs and have the following important findings: (1). The top-performing GPT-4 with 128k context length performs poorly on the evaluation context window of 16k in our LongIns. (2). For the multi-hop reasoning ability of many existing LLMs, significant efforts are still needed under short context windows (less than 4k).",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.11045",
        "title": "Orca 2: Teaching Small Language Models How to Reason",
        "abstract": "Orca 1 learns from rich signals, such as explanation traces, allowing it to outperform conventional instruction-tuned models on benchmarks like BigBench Hard and AGIEval. In Orca 2, we continue exploring how improved training signals can enhance smaller LMs\u2019 reasoning abilities. Research on training small LMs has often relied on imitation learning to replicate the output of more capable models. We contend that excessive emphasis on imitation may restrict the potential of smaller models. We seek to teach small LMs to employ different solution strategies for different tasks, potentially different from the one used by the larger model. For example, while larger models might provide a direct answer to a complex task, smaller models may not have the same capacity. In Orca 2, we teach the model various reasoning techniques (step-by-step, recall then generate, recall-reason-generate, direct answer, etc.). Moreover, we aim to help the model learn to determine the most effective solution strategy for each task. We evaluate Orca 2 using a comprehensive set of 15 diverse benchmarks (corresponding to approximately 100 tasks and over 36K unique prompts). Orca 2 significantly surpasses models of similar size and attains performance levels similar or better to those of models 5-10x larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings. We make Orca 2 weights publicly available at aka.ms/orca-lm to support research on the development, evaluation, and alignment of smaller LMs.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2402.14830",
        "title": "Orca-Math: Unlocking the potential of SLMs in Grade School Math",
        "abstract": "We show that an SLM can reach \u223c 87% pass@1 on GSM8K while trained on only 200K synthetic math problems. Mathematical word problem-solving has long been recognized as a complex task for small language models (SLMs). A recent study hypothesized that the smallest model size, needed to achieve over 80% accuracy on the GSM8K benchmark, is 34 billion parameters. To reach this level of performance with smaller models, researcher often train SLMs to generate Python code or use tools to help avoid calculation errors. Additionally, they employ ensembling, where outputs of up to 100 model runs are combined to arrive at a more accurate result. Result selection is done using consensus, majority vote or a separate a verifier model used in conjunction with the SLM. Ensembling provides a substantial boost in accuracy but at a significant cost increase with multiple calls to the model (e.g., Phi-GSM uses top-48 to boost the performance from 68.2 to 81.5, [38] uses top-100 to boost LLAMA-2\u2019s performance from 38.6% to 71.9%). In this work, we present Orca-Math, a 7-billion-parameter SLM based on the Mistral-7B, which achieves 86.81% on GSM8k without the need for multiple model calls or the use of verifiers, code execution or any other external tools. Our approach has the following key elements: (1) A high quality synthetic dataset of 200K math problems created using a multiagent setup where agents collaborate to create the data, (2) An iterative learning techniques that enables the SLM to practice solving problems, receive feedback on its solutions and learn from preference pairs incorporating the SLM solutions and the feedback. When trained with Supervised Fine-Tuning alone, Orca-Math achieves 81.50% on GSM8k pass@1 metric. With iterative preference learning, Orca-Math achieves 86.81% pass@1. Orca-Math surpasses the performance of significantly larger models such as LLAMA-2-70B, WizardMath-70B, Gemini-Pro, ChatGPT-3.5. It also significantly outperforms other smaller models while using much smaller data (hundreds of thousands vs. millions of problems).",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.00720",
        "title": "COMPLEXITY-BASED PROMPTING FOR MULTI-STEP REASONING",
        "abstract": "We study the task of prompting large-scale language models to perform multistep reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new reasoning chains and predict answers for new inputs. A central question is which reasoning examples make the most effective prompts. In this work, we propose complexitybased prompting, a simple and effective example selection scheme for multi-step reasoning. We show that prompts with higher reasoning complexity, i.e., chains with more reasoning steps, achieve substantially better performance on multistep reasoning tasks over strong baselines. We further extend our complexitybased criteria from prompting (selecting inputs) to decoding (selecting outputs), where we sample multiple reasoning chains from the model, then choose the majority of generated answers from complex reasoning chains (over simple chains). When used to prompt GPT-3 and Codex, our approach substantially improves multi-step reasoning accuracy and achieves new state-of-the-art (SOTA) performance on three math benchmarks (GSM8K, MultiArith, and MathQA) and two BigBenchHard tasks (Date Understanding and Penguins), with an average +5.3 and up to +18 accuracy improvements. Compared with existing example selection schemes like manual tuning or retrieval-based selection, selection based on reasoning complexity is intuitive, easy to implement, and annotation-efficient. Further results demonstrate the robustness of performance gains from complex prompts under format perturbation and distribution shift.",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2306.06427",
        "title": "Boosting Language Models Reasoning with Chain-of-Knowledge Prompting",
        "abstract": "Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like \u201cLet\u2019s think step by step\u201d or multiple incontext exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate reasoning steps. However, the generated rationales often come with hallucinations, making unfactual and unfaithful reasoning chains. To mitigate this brittleness, we propose a novel Chain-of-Knowledge (CoK) prompting, where we aim at eliciting LLMs to generate explicit pieces of knowledge evidence in the form of structure triple. This is inspired by our human behaviors, i.e., we can draw a mind map or knowledge map as the reasoning evidence in the brain before answering a complex question. Benefiting from CoK, we additionally introduce a F2 -Verification method to estimate the reliability of the reasoning chains in terms of factuality and faithfulness. For the unreliable response, the wrong evidence can be indicated to prompt the LLM to rethink. Extensive experiments demonstrate that our method can further improve the performance of commonsense, factual, symbolic, and arithmetic reasoning tasks 1 .",
        "label": 0
    },
    {
        "url": "https://arxiv.org/pdf/2308.11462",
        "title": "LEGALBENCH: A COLLABORATIVELY BUILT BENCHMARK FOR MEASURING LEGAL REASONING IN LARGE LANGUAGE MODELS",
        "abstract": "The advent of large language models (LLMs) and their adoption by the legal community has given rise to the question: what types of legal reasoning can LLMs perform? To enable greater study of this question, we present LEGALBENCH: a collaboratively constructed legal reasoning bench- mark consisting of 162 tasks covering six different types of legal reasoning. LEGALBENCH was built through an interdisciplinary process, in which we collected tasks designed and hand-crafted by legal professionals. Because these subject matter experts took a leading role in construction, tasks either measure legal reasoning capabilities that are practically useful, or measure reasoning skills that lawyers find interesting. To enable cross-disciplinary conversations about LLMs in the law, we additionally show how popular legal frameworks for describing legal reasoning\u2014which distinguish between its many forms\u2014correspond to LEGALBENCH tasks, thus giving lawyers and LLM developers a common vocabulary. This paper describes LEGALBENCH, presents an empirical evaluation of 20 open-source and commercial LLMs, and illustrates the types of research explorations LEGALBENCH enables.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.07327",
        "title": "OpenAssistant Conversations - Democratizing Large Language Model Alignment",
        "abstract": "Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 complete and fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers. Models trained on OpenAssistant Conversations show consistent improvements on standard benchmarks over respective base models. We release our code2 and data3 under a fully permissive licence.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.11248",
        "title": "CROSSCODEEVAL: A Diverse and Multilingual Benchmark for Cross-File Code Completion\n",
        "abstract": "Code completion models have made significant progress in recent years, yet current popular evaluation datasets, such as HumanEval and MBPP, predominantly focus on code completion tasks within a single file. This over-simplified setting falls short of representing the real-world software development scenario where repositories span multiple files with numerous cross-file dependencies, and accessing and understanding cross-file context is often required to complete the code correctly. To fill in this gap, we propose CROSSCODEEVAL, a diverse and multilingual code completion benchmark that necessitates an in-depth cross-file contextual understanding to complete the code accurately. CROSSCODEEVAL is built on a diverse set of real-world, open-sourced, permissively-licensed repositories in four popular programming languages: Python, Java, TypeScript, and C#. To create examples that strictly require cross-file context for accurate completion, we propose a straightforward yet efficient static-analysis-based approach to pinpoint the use of cross-file context within the current file.\nExtensive experiments on state-of-the-art code language models like CodeGen and StarCoder demonstrate that CROSSCODEEVAL is extremely challenging when the relevant cross-file context is absent, and we see clear improvements when adding these context into the prompt. However, despite such improvements, the pinnacle of performance remains notably unattained even with the highest-performing model, indicating that CROSSCODEEVAL is also capable of assessing model\u2019s capability in leveraging extensive context to make better code completion. Finally, we benchmarked various methods in retrieving cross-file context, and show that CROSSCODEEVAL can also be used to measure the capability of code retrievers.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11698",
        "title": "DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models",
        "abstract": "\nGenerative Pre-trained Transformer (GPT) models have exhibited exciting progress in their capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applica- tions such as healthcare and finance \u2013 where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives\n\u2013 including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT mod- els can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard bench- marks, GPT-4 is more vulnerable given jailbreaking system or user prompts, po- tentially because GPT-4 follows (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/; our dataset can be previewed at https: //huggingface.co/datasets/AI-Secure/DecodingTrust; a concise ver- sion of this work is at https://openreview.net/pdf?id=kaHpo8OZw2.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.01026",
        "title": "Temporal Graph Benchmark\nfor Machine Learning on Temporal Graphs",
        "abstract": "We present the Temporal Graph Benchmark (TGB), a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evalua- tion of machine learning models on temporal graphs. TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks. For both tasks, we design evaluation protocols based on realistic use-cases. We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets. In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models. We believe that these findings open up opportunities for future research on tempo- ral graphs. Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, including data loading, ex- periment setup and performance evaluation. TGB will be maintained and updated on a regular basis and welcomes community feedback. TGB datasets, data load- ers, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13040",
        "title": "SpokenWOZ: A Large-Scale Speech-Text Benchmark for Spoken Task-Oriented Dialogue Agents",
        "abstract": "Task-oriented dialogue (TOD) models have made significant progress in recent years. However, previous studies primarily focus on datasets written by annotators, which has resulted in a gap between academic research and real-world spoken con- versation scenarios. While several small-scale spoken TOD datasets are proposed to address robustness issues such as ASR errors, they ignore the unique challenges in spoken conversation. To tackle the limitations, we introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD, containing 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from human-to-human spoken conversations. SpokenWOZ further incorporates common spoken characteristics such as word-by-word processing and reasoning in spoken language. Based on these characteristics, we present cross-turn slot and reasoning slot detection as new challenges. We conduct experiments on various baselines, including text-modal models, newly proposed dual-modal models, and LLMs, e.g., ChatGPT. The results show that the current models still have substantial room for improvement in spoken conversation, where the most advanced dialogue state tracker only achieves 25.65% in joint goal accuracy and the SOTA end-to-end model only correctly completes the user request in 52.1% of dialogues. Our dataset, code, and leaderboard are available at https://spokenwoz.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.05562",
        "title": "AircraftVerse: A Large-Scale Multimodal Dataset of Aerial Vehicle Designs",
        "abstract": "We present AircraftVerse, a publicly available aerial vehicle design dataset. Air- craft design encompasses different physics domains and, hence, multiple modalities of representation. The evaluation of these cyber-physical system (CPS) designs re- quires the use of scientific analytical and simulation models ranging from computer- aided design tools for structural and manufacturing analysis, computational fluid dynamics tools for drag and lift computation, battery models for energy estimation, and simulation models for flight control and dynamics. AircraftVerse contains 27,714 diverse air vehicle designs - the largest corpus of engineering designs with this level of complexity. Each design comprises the following artifacts: a symbolic design tree describing topology, propulsion subsystem, battery subsystem, and other design details; a STandard for the Exchange of Product (STEP) model data; a 3D CAD design using a stereolithography (STL) file format; a 3D point cloud for the shape of the design; and evaluation results from high fidelity state-of-the-art physics models that characterize performance metrics such as maximum flight distance and hover-time. We also present baseline surrogate models that use dif- ferent modalities of design representation to predict design performance metrics, which we provide as part of our dataset release. Finally, we discuss the potential impact of this dataset on the use of learning in aircraft design and, more generally, in CPS. AircraftVerse is accompanied by a data card, and it is released under Creative Commons Attribution-ShareAlike (CC BY-SA) license. The dataset is hosted at https://zenodo.org/record/6525446, baseline models and code at https://github.com/SRI-CSL/AircraftVerse, and the dataset description at https://aircraftverse.onrender.com/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.14623",
        "title": "BUBBLEML: A MULTI-PHYSICS DATASET AND BENCHMARKS FOR MACHINE LEARNING",
        "abstract": "In the field of phase change phenomena, the lack of accessible and diverse datasets suitable for machine learning (ML) training poses a significant challenge. Existing experimental datasets are often restricted, with limited availability and sparse ground truth data, impeding our understanding of this complex multiphysics phenomena. To bridge this gap, we present the BubbleML Dataset 1 which leverages physics-driven simulations to provide accurate ground truth information for various boiling scenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled boiling. This extensive dataset covers a wide range of parameters, including varying gravity conditions, flow rates, sub-cooling levels, and wall superheat, comprising 79 simulations. BubbleML is validated against experimental observations and trends, establishing it as an invaluable resource for ML research. Furthermore, we showcase its potential to facilitate exploration of diverse downstream tasks by introducing two benchmarks: (a) optical flow analysis to capture bubble dynamics, and (b) operator networks for learning temperature dynamics. The BubbleML dataset and its benchmarks serve as a catalyst for advancements in ML-driven research on multiphysics phase change phenomena, enabling the development and comparison of state-of-the-art techniques and models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2207.10062",
        "title": "DataPerf:\nBenchmarks for Data-Centric AI Development",
        "abstract": "Machine learning research has long focused on models rather than datasets, and prominent datasets are used for common ML tasks without regard to the breadth, difficulty, and faithfulness of the underlying problems. Neglecting the fundamen- tal importance of data has given rise to inaccuracy, bias, and fragility in real-world applications, and research is hindered by saturation across existing dataset bench- marks. In response, we present DataPerf, a community-led benchmark suite for evaluating ML datasets and data-centric algorithms. We aim to foster innovation in data-centric AI through competition, comparability, and reproducibility. We enable the ML community to iterate on datasets, instead of just architectures, and we provide an open, online platform with multiple rounds of challenges to support this iterative development. The first iteration of DataPerf contains five benchmarks covering a wide spectrum of data-centric techniques, tasks, and modalities in vi- sion, speech, acquisition, debugging, and diffusion prompting, and we support hosting new contributed benchmarks from the community. The benchmarks, on- line evaluation platform, and baseline implementations are open source, and the MLCommons Association will maintain DataPerf to ensure long-term benefits to academia and industry.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2109.10399",
        "title": "SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking",
        "abstract": "Subseasonal forecasting of the weather two to six weeks in advance is critical for resource allocation and advance disaster notice but poses many challenges for the forecasting community. At this forecast horizon, physics-based dynami- cal models have limited skill, and the targets for prediction depend in a complex manner on both local weather and global climate variables. Recently, machine learning methods have shown promise in advancing the state of the art but only at the cost of complex data curation, integrating expert knowledge with aggrega- tion across multiple relevant data sources, file formats, and temporal and spatial resolutions. To streamline this process and accelerate future development, we introduce SubseasonalClimateUSA, a curated dataset for training and benchmark- ing subseasonal forecasting models in the United States. We use this dataset to benchmark a diverse suite of subseasonal models, including operational dynamical models, classical meteorological baselines, and ten state-of-the-art machine learn- ing and deep learning-based methods from the literature. Overall, our benchmarks suggest simple and effective ways to extend the accuracy of current operational models. SubseasonalClimateUSA is regularly updated and accessible via the https://github.com/microsoft/subseasonal_data/ Python package.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.00750",
        "title": "Are These the Same Apple? Comparing Images Based on Object Intrinsics",
        "abstract": "The human visual system can effortlessly recognize an object under different extrinsic factors such as lighting, object poses, and background, yet current com- puter vision systems often struggle with these variations. An important step to understanding and improving artificial vision systems is to measure image simi- larity purely based on intrinsic object properties that define object identity. This problem has been studied in the computer vision literature as re-identification, though mostly restricted to specific object categories such as people and cars. We propose to extend it to general object categories, exploring an image simi- larity metric based on object intrinsics. To benchmark such measurements, we collect the Common paired objects Under differenT Extrinsics (CUTE) dataset of 18, 000 images of 180 objects under different extrinsic factors such as light- ing, poses, and imaging conditions. While existing methods such as LPIPS and CLIP scores do not measure object intrinsics well, we find that combining deep features learned from contrastive self-supervised learning with foreground filtering is a simple yet effective approach to approximating the similarity. We conduct an extensive survey of pre-trained features and foreground extraction methods to arrive at a strong baseline that best measures intrinsic object-centric image similarity among current methods. Finally, we demonstrate that our approach can aid in downstream applications such as acting as an analog for human subjects and improving generalizable re-identification. Please see our project website at https://s-tian.github.io/projects/cute/ for visualizations of the data and demos of our metric.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.03721",
        "title": "ClimateSet: A Large-Scale\nClimate Model Dataset for Machine Learning",
        "abstract": "Climate models have been key for assessing the impact of climate change and simulating future climate scenarios. The machine learning (ML) community has taken an increased interest in supporting climate scientists\u2019 efforts on various tasks such as climate model emulation, downscaling, and prediction tasks. Many of those tasks have been addressed on datasets created with single climate models. However, both the climate science and ML communities have suggested that to address those tasks at scale, we need large, consistent, and ML-ready climate model datasets. Here, we introduce ClimateSet, a dataset containing the inputs and outputs of 36 climate models from the Input4MIPs and CMIP6 archives. In addition, we provide a modular dataset pipeline for retrieving and preprocessing additional climate models and scenarios. We showcase the potential of our dataset by using it as a benchmark for ML-based climate model emulation. We gain new insights about the performance and generalization capabilities of the different ML models by analyzing their performance across different climate models. Furthermore, the dataset can be used to train an ML emulator on several climate models instead of just one. Such a \u201csuper emulator\u201d can quickly project new climate change scenarios, complementing existing scenarios already provided to policymakers. We believe ClimateSet will create the basis needed for the ML community to tackle climate-related tasks at scale.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.06350",
        "title": "T2I-CompBench: A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation",
        "abstract": "Despite the stunning ability to generate high-quality images by recent text-to- image models, current approaches often struggle to effectively compose objects with different attributes and relationships into a complex and coherent scene. We propose T2I-CompBench, a comprehensive benchmark for open-world composi- tional text-to-image generation, consisting of 6,000 compositional text prompts from 3 categories (attribute binding, object relationships, and complex composi- tions) and 6 sub-categories (color binding, shape binding, texture binding, spatial relationships, non-spatial relationships, and complex compositions). We further propose several evaluation metrics specifically designed to evaluate compositional text-to-image generation and explore the potential and limitations of multimodal LLMs for evaluation. We introduce a new approach, Generative mOdel finetun- ing with Reward-driven Sample selection (GORS), to boost the compositional text-to-image generation abilities of pretrained text-to-image models. Extensive experiments and evaluations are conducted to benchmark previous methods on T2I- CompBench, and to validate the effectiveness of our proposed evaluation metrics and GORS approach. Project page is available at https://karine-h.github.io/T2I- CompBench/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.18652",
        "title": "EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images",
        "abstract": "Electronic Health Records (EHRs), which contain patients\u2019 medical histories in various multi-modal formats, often overlook the potential for joint reasoning across imaging and table modalities underexplored in current EHR Question Answering (QA) systems. In this paper, we introduce EHRXQA, a novel multi-modal ques- tion answering dataset combining structured EHRs and chest X-ray images. To develop our dataset, we first construct two uni-modal resources: 1) The MIMIC- CXR-VQA dataset, our newly created medical visual question answering (VQA) benchmark, specifically designed to augment the imaging modality in EHR QA, and 2) EHRSQL (MIMIC-IV), a refashioned version of a previously established table-based EHR QA dataset. By integrating these two uni-modal resources, we successfully construct a multi-modal EHR QA dataset that necessitates both uni-modal and cross-modal reasoning. To address the unique challenges of multi- modal questions within EHRs, we propose a NeuralSQL-based strategy equipped with an external VQA API. This pioneering endeavor enhances engagement with multi-modal EHR sources and we believe that our dataset can catalyze advances in real-world medical scenarios such as clinical decision-making and research. EHRXQA is available at https://github.com/baeseongsu/ehrxqa.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.11408",
        "title": "Stable Bias:\nEvaluating Societal Representations in Diffusion Models",
        "abstract": "As machine learning-enabled Text-to-Image (TTI) systems are becoming increasingly prevalent and seeing growing adoption as commercial services, characterizing the social biases they exhibit is a necessary first step to lowering their risk of discriminatory outcomes. This evaluation, however, is made more difficult by the synthetic nature of these systems\u2019 outputs: common definitions of diversity are grounded in social categories of people living in the world, whereas the artificial depictions of fictive humans created by these systems have no inherent gender or ethnicity. To address this need, we propose a new method for exploring the social biases in TTI systems. Our approach relies on characterizing the variation in generated images triggered by enumerating gender and ethnicity markers in the prompts, and comparing it to the variation engendered by spanning different professions. This allows us to (1) identify specific bias trends, (2) provide targeted scores to directly compare models in terms of diversity and representation, and (3) jointly model interdependent social variables to support a multidimensional analysis. We leverage this method to analyze images generated by 3 popular TTI systems (Dall\u00b7E 2, Stable Diffusion v 1.4 and 2) and find that while all of their outputs show correlations with US labor demographics, they also consistently under-represent marginalized identities to different extents. We also release the datasets and low-code interactive bias exploration platforms developed for this work, as well as the necessary tools to similarly evaluate additional TTI systems.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.06595",
        "title": "VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use",
        "abstract": "We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real- world use. Our starting point is curating 70 \u201cinstruction families\u201d that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following cura- tion, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction- specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption de- scribes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evalu- ation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps between models and refer- ences using both human and automatic evaluations; e.g., the top-performing instruction-following model wins against the GPT-4 reference in just 27% of the comparison. VisIT-Bench is dynamic to participate, practitioners simply submit their model\u2019s response on the project website; Data, code and leaderboard is available at https://visit-bench.github.io/.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.05391",
        "title": "pinpointing Why Object Recognition Performance Degrades Across Income Levels and Geographies\n",
        "abstract": "Despite impressive advances in object-recognition, deep learning systems\u2019 performance degrades significantly across geographies and lower income levels\u2014raising press- ing concerns of inequity. Addressing such performance gaps remains a challenge, as little is understood about why performance degrades across incomes or geographies. We take a step in this direction by annotating images from Dollar Street, a popular benchmark of geographically and economically diverse images, labeling each image with factors such as color, shape, and background. These anno- tations unlock a new granular view into how objects differ across incomes/regions. We then use these object differ- ences to pinpoint model vulnerabilities across incomes and regions. We study a range of modern vision models, find- ing that performance disparities are most associated with differences in texture, occlusion, and images with darker lighting. We illustrate how insights from our factor labels can surface mitigations to improve models\u2019 performance disparities. As an example, we show that mitigating a model\u2019s vulnerability to texture can improve performance on the lower income level. We release all the factor an- notations along with an interactive dashboard to facilitate research into more equitable vision systems.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09424",
        "title": "SSL4EO-L:\nDatasets and Foundation Models for Landsat Imagery",
        "abstract": "The Landsat program is the longest-running Earth observation program in history, with 50+ years of data acquisition by 8 satellites. The multispectral imagery cap- tured by sensors onboard these satellites is critical for a wide range of scientific fields. Despite the increasing popularity of deep learning and remote sensing, the majority of researchers still use decision trees and random forests for Land- sat image analysis due to the prevalence of small labeled datasets and lack of foundation models. In this paper, we introduce SSL4EO-L, the first ever dataset designed for Self-Supervised Learning for Earth Observation for the Landsat fam- ily of satellites (including 3 sensors and 2 product levels) and the largest Landsat dataset in history (5M image patches). Additionally, we modernize and re-release the L7 Irish and L8 Biome cloud detection datasets, and introduce the first ML benchmark datasets for Landsats 4\u20135 TM and Landsat 7 ETM+ SR. Finally, we pre-train the first foundation models for Landsat imagery using SSL4EO-L and evaluate their performance on multiple semantic segmentation tasks. All datasets and model weights are available via the TorchGeo1 library, making reproducibility and experimentation easy, and enabling scientific advancements in the burgeoning field of remote sensing for a multitude of downstream applications.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.15521",
        "title": "What a MESS: Multi-Domain Evaluation of Zero-Shot Semantic Segmentation",
        "abstract": "While semantic segmentation has seen tremendous improvements in the past, there are still significant labeling efforts necessary and the problem of limited gener- alization to classes that have not been present during training. To address this problem, zero-shot semantic segmentation makes use of large self-supervised vision-language models, allowing zero-shot transfer to unseen classes. In this work, we build a benchmark for Multi-domain Evaluation of Semantic Segmentation (MESS), which allows a holistic analysis of performance across a wide range of domain-specific datasets such as medicine, engineering, earth monitoring, biology, and agriculture. To do this, we reviewed 120 datasets, developed a taxonomy, and classified the datasets according to the developed taxonomy. We select a repre- sentative subset consisting of 22 datasets and propose it as the MESS benchmark. We evaluate eight recently published models on the proposed MESS benchmark and analyze characteristics for the performance of zero-shot transfer models. The toolkit is available at https://github.com/blumenstiel/MESS.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1805.04687",
        "title": "BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning",
        "abstract": "\nDatasets drive vision progress, yet existing driving datasets are impoverished in terms of visual content and supported tasks to study multitask learning for autonomous driving. Researchers are usually constrained to study a small set of problems on one dataset, while real-world com- puter vision applications require performing tasks of var- ious complexities. We construct BDD100K 1, the largest driving video dataset with 100K videos and 10 tasks to eval- uate the exciting progress of image recognition algorithms on autonomous driving. The dataset possesses geographic, environmental, and weather diversity, which is useful for training models that are less likely to be surprised by new conditions. Based on this diverse dataset, we build a bench- mark for heterogeneous multitask learning and study how to solve the tasks together. Our experiments show that special training strategies are needed for existing models to per- form such heterogeneous tasks. BDD100K opens the door for future studies in this important venue.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1901.05946",
        "title": "uided Curriculum Model Adaptation and Uncertainty-Aware Evaluation for Semantic Nighttime Image Segmentation",
        "abstract": "Most progress in semantic segmentation reports on day- time images taken under favorable illumination conditions. We instead address the problem of semantic segmentation of nighttime images and improve the state-of-the-art, by adapting daytime models to nighttime without using night- time annotations. Moreover, we design a new evaluation framework to address the substantial uncertainty of seman- tics in nighttime images. Our central contributions are: 1) a curriculum framework to gradually adapt semantic segmen- tation models from day to night via labeled synthetic images and unlabeled real images, both for progressively darker times of day, which exploits cross-time-of-day correspon- dences for the real images to guide the inference of their labels; 2) a novel uncertainty-aware annotation and evalu- ation framework and metric for semantic segmentation, de- signed for adverse conditions and including image regions beyond human recognition capability in the evaluation in a principled fashion; 3) the Dark Zurich dataset, which com- prises 2416 unlabeled nighttime and 2920 unlabeled twi- light images with correspondences to their daytime coun- terparts plus a set of 151 nighttime images with fine pixel- level annotations created with our protocol, which serves as a first benchmark to perform our novel evaluation. Exper- iments show that our guided curriculum adaptation signifi- cantly outperforms state-of-the-art methods on real night- time sets both for standard metrics and our uncertainty- aware metric. Furthermore, our uncertainty-aware eval- uation reveals that selective invalidation of predictions can lead to better results on data with ambiguous content such as our nighttime benchmark and profit safety-oriented ap- plications which involve invalid inputs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1705.07206",
        "title": "Multi-Human Parsing in the Wild",
        "abstract": "Human parsing is attracting increasing research attention. In this work, we aim to push the frontier of human parsing by introducing the problem of multi-human parsing in the wild. Existing works on human parsing mainly tackle single-person scenarios, which deviates from real-world applications where multiple persons are present simultaneously with interaction and occlusion. To address the multi-human parsing problem, we introduce a new multi-human parsing (MHP) dataset and a novel multi-human parsing model named MH-Parser. The MHP dataset contains multiple persons captured in real-world scenes with pixel-level fine-grained se- mantic annotations in an instance-aware setting. The MH-Parser generates global parsing maps and person instance masks simultaneously in a bottom-up fashion with the help of a new Graph-GAN model. We envision that the MHP dataset will serve as a valuable data resource to develop new multi-human parsing models, and the MH-Parser offers a strong baseline to drive future research for multi-human parsing in the wild.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2105.05409",
        "title": "a  Large-Scale Benchmark for Food Image Segmentation",
        "abstract": "Food image segmentation is a critical and indispensible task for developing health-related applications such as estimating food calo- ries and nutrients. Existing food image segmentation models are underperforming due to two reasons: (1) there is a lack of high quality food image datasets with fine-grained ingredient labels and pixel-wise location masks\u2014the existing datasets either carry coarse ingredient labels or are small in size; and (2) the complex appear- ance of food makes it difficult to localize and recognize ingredients in food images, e.g., the ingredients may overlap one another in the same image, and the identical ingredient may appear distinctly in different food images.\nIn this work, we build a new food image dataset FoodSeg103 (and its extension FoodSeg154) containing 9,490 images. We annotate these images with 154 ingredient classes and each image has an average of 6 ingredient labels and pixel-wise masks. In addition, we propose a multi-modality pre-training approach called ReLeM that explicitly equips a segmentation model with rich and semantic food knowledge. In experiments, we use three popular semantic segmentation methods (i.e., Dilated Convolution based [17], Fea- ture Pyramid based [22], and Vision Transformer based [54]) as baselines, and evaluate them as well as ReLeM on our new datasets. We believe that the FoodSeg103 (and its extension FoodSeg154) and the pre-trained models using ReLeM can serve as a bench- mark to facilitate future works on fine-grained food image un- derstanding. We make all these datasets and methods public at https://xiongweiwu.github.io/foodseg103.html.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2111.11567",
        "title": "ATLANTIS: A BENCHMARK FOR SEMANTIC SEGMENTATION OF WATERBODY IMAGES",
        "abstract": "Vision-based semantic segmentation of waterbodies and nearby related objects provides important information for managing water resources and handling flooding emergency. However, the lack of large-scale labeled training and testing datasets for water-related categories prevents researchers from studying water-related issues in the computer vision field. To tackle this problem, we present AT- LANTIS, a new benchmark for semantic segmentation of waterbodies and related objects. ATLANTIS consists of 5,195 images of waterbodies, as well as high quality pixel-level manual annotations of 56 classes of objects, including 17 classes of man-made objects, 18 classes of natural objects and 21 general classes. We analyze ATLANTIS in detail and evaluate several state-of-the-art semantic segmentation networks on our benchmark. In addition, a novel deep neural network, AQUANet, is developed for waterbody semantic segmentation by processing the aquatic and non-aquatic regions in two different paths. AQUANet also incorporates low-level feature modulation and cross-path modula- tion for enhancing feature representation. Experimental results show that the proposed AQUANet outperforms other state-of-the-art semantic segmentation networks on ATLANTIS. We claim that ATLANTIS is the largest waterbody image dataset for semantic segmentation providing a wide range of water and water-related classes and it will benefit researchers of both computer vision and water resources engineering.Monocular depth estimation has experienced significant progress on terrestrial images in recent years, largely due to deep learning advancements. However, it remains in- adequate for underwater scenes, primarily because of data scarcity. Given the inherent challenges of light attenuation and backscattering in water, acquiring clear underwater images or precise depth information is notably difficult and costly. Consequently, learning-based approaches often rely on synthetic data or turn to unsupervised or self-supervised methods to mitigate this lack of data. Nonetheless, the per- formance of these methods is often constrained by the do- main gap and looser constraints. In this paper, we propose a novel pipeline for generating photorealistic underwater images using accurate terrestrial depth data. This approach facilitates the training of supervised models for underwa- ter depth estimation, effectively reducing the performance disparity between terrestrial and underwater environments. Contrary to prior synthetic datasets that merely apply style transfer to terrestrial images without altering the scene con- tent, our approach uniquely creates vibrant, non-existent underwater scenes by leveraging terrestrial depth data\nthrough the innovative Stable Diffusion model. Specifi- cally, we introduce a unique Depth2Underwater Control- Net, trained on specially prepared {Underwater, Depth, Text} data triplets, for this generation task. Our newly de- veloped dataset enables terrestrial depth estimation mod- els to achieve considerable improvements, both quantita- tively and qualitatively, on unseen underwater images, sur- passing their terrestrial pre-trained counterparts. More- over, the enhanced depth accuracy for underwater scenes also aids underwater image restoration techniques that rely on depth maps, further demonstrating our dataset\u2019s util- ity. The dataset will be publicly available at https: //github.com/zkawfanx/Atlantis.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.12471",
        "title": "Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion",
        "abstract": "Monocular depth estimation has experienced significant progress on terrestrial images in recent years, largely due to deep learning advancements. However, it remains in- adequate for underwater scenes, primarily because of data scarcity. Given the inherent challenges of light attenuation and backscattering in water, acquiring clear underwater images or precise depth information is notably difficult and costly. Consequently, learning-based approaches often rely on synthetic data or turn to unsupervised or self-supervised methods to mitigate this lack of data. Nonetheless, the per- formance of these methods is often constrained by the do- main gap and looser constraints. In this paper, we propose a novel pipeline for generating photorealistic underwater images using accurate terrestrial depth data. This approach facilitates the training of supervised models for underwa- ter depth estimation, effectively reducing the performance disparity between terrestrial and underwater environments. Contrary to prior synthetic datasets that merely apply style transfer to terrestrial images without altering the scene con- tent, our approach uniquely creates vibrant, non-existent underwater scenes by leveraging terrestrial depth data\nthrough the innovative Stable Diffusion model. Specifi- cally, we introduce a unique Depth2Underwater Control- Net, trained on specially prepared {Underwater, Depth, Text} data triplets, for this generation task. Our newly de- veloped dataset enables terrestrial depth estimation mod- els to achieve considerable improvements, both quantita- tively and qualitatively, on unseen underwater images, sur- passing their terrestrial pre-trained counterparts. More- over, the enhanced depth accuracy for underwater scenes also aids underwater image restoration techniques that rely on depth maps, further demonstrating our dataset\u2019s util- ity. The dataset will be publicly available at https: //github.com/zkawfanx/Atlantis.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1905.12886",
        "title": "iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images",
        "abstract": "Existing Earth Vision datasets are either suitable for se- mantic segmentation or object detection. In this work, we introduce the first benchmark dataset for instance segmen- tation in aerial imagery that combines instance-level object detection and pixel-level segmentation tasks. In comparison to instance segmentation in natural scenes, aerial images present unique challenges e.g., a huge number of instances per image, large object-scale variations and abundant tiny objects. Our large-scale and densely annotated Instance Segmentation in Aerial Images Dataset (iSAID) comes with 655,451 object instances for 15 categories across 2,806 high-resolution images. Such precise per-pixel annotations for each instance ensure accurate localization that is essen- tial for detailed scene analysis. Compared to existing small- scale aerial image based instance segmentation datasets, iSAID contains 15\u00d7 the number of object categories and 5\u00d7 the number of instances. We benchmark our dataset us- ing two popular instance segmentation approaches for nat- ural images, namely Mask R-CNN and PANet. In our ex- periments we show that direct application of off-the-shelf Mask R-CNN and PANet on aerial images provide subop- timal instance segmentation results, thus requiring special- ized solutions from the research community. The dataset is publicly available at: https://captain-whu.github. io/iSAID/index.html\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2012.02951",
        "title": "FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding",
        "abstract": "isual scene understanding is the core task in making any crucial decision in any computer vision system. Al- though popular computer vision datasets like Cityscapes, MS-COCO, PASCAL provide good benchmarks for several tasks (e.g. image classification, segmentation, object de- tection), these datasets are hardly suitable for post disas- ter damage assessments. On the other hand, existing natu- ral disaster datasets include mainly satellite imagery which have low spatial resolution and a high revisit period. There- fore, they do not have a scope to provide quick and effi- cient damage assessment tasks. Unmanned Aerial Vehicle (UAV) can effortlessly access difficult places during any dis- aster and collect high resolution imagery that is required for aforementioned tasks of computer vision. To address these issues we present a high resolution UAV imagery, FloodNet, captured after the hurricane Harvey. This dataset demon- strates the post flooded damages of the affected areas. The images are labeled pixel-wise for semantic segmentation task and questions are produced for the task of visual ques- tion answering. FloodNet poses several challenges includ- ing detection of flooded roads and buildings and distin- guishing between natural water and flooded water. With the advancement of deep learning algorithms, we can analyze the impact of any disaster which can make a precise under- standing of the affected areas. In this paper, we compare and contrast the performances of baseline methods for im- age classification, semantic segmentation, and visual ques- tion answering on our dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2111.02995",
        "title": "Unsupervised Change Detection of Extreme Events Using ML On-Board",
        "abstract": "In this paper, we introduce RaV\u00c6n, a lightweight, unsupervised approach for change detection in satellite data based on Variational Auto-Encoders (VAEs) with the specific purpose of on-board deployment. Applications such as disaster man- agement enormously benefit from the rapid availability of satellite observations. Traditionally, data analysis is performed on the ground after all data is transferred \u2013 downlinked \u2013 to a ground station. Constraint on the downlink capabilities there- fore affects any downstream application. In contrast, RaV\u00c6n pre-processes the sampled data directly on the satellite and flags changed areas to prioritise for downlink, shortening the response time. We verified the efficacy of our system on a dataset composed of time series of catastrophic events \u2013 which we plan to release alongside this publication \u2013 demonstrating that RaV\u00c6n outperforms pixel- wise baselines. Finally we tested our approach on resource-limited hardware for assessing computational and memory limitations.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1810.10438",
        "title": "UAVid: A Semantic Segmentation Dataset for UAV Imagery",
        "abstract": "Semantic segmentation has been one of the leading re- search interests in computer vision recently. It serves as a perception foundation for many fields, such as robotics and autonomous driving. The fast development of seman- tic segmentation attributes enormously to the large scale datasets, especially for the deep learning related methods. There already exist several semantic segmentation datasets for comparison among semantic segmentation methods in complex urban scenes, such as the Cityscapes and CamVid datasets, where the side views of the objects are captured with a camera mounted on the driving car. There also exist semantic labeling datasets for the airborne images and the satellite images, where the top views of the ob- jects are captured. However, only a few datasets capture urban scenes from an oblique Unmanned Aerial Vehicle (UAV) perspective, where both of the top view and the side view of the objects can be observed, providing more in- formation for object recognition. In this paper, we intro- duce our UAVid dataset, a new high-resolution UAV seman- tic segmentation dataset as a complement, which brings new challenges, including large scale variation, moving object recognition and temporal consistency preservation. Our UAV dataset consists of 30 video sequences captur- ing 4K high-resolution images in slanted views. In to- tal, 300 images have been densely labeled with 8 classes for the semantic labeling task. We have provided several deep learning baseline methods with pre-training, among which the proposed Multi-Scale-Dilation net performs the best via multi-scale feature extraction, reaching a mean intersection-over-union (IoU) score around 50% and out- performing the others by more than 1.6%. We have also ex- plored the influence of spatial-temporal regularization for sequence data by leveraging on feature space optimization (FSO) and 3D conditional random field (CRF), which im- proves the mean IoU scores by around another 0.5%. Our UAVid website and the labeling tool have been published ",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2101.00442",
        "title": "CRYONUSEG: A DATASET FOR NUCLEI INSTANCE SEGMENTATION OF CRYOSECTIONED H&E-STAINED HISTOLOGICAL IMAGES",
        "abstract": "Nuclei instance segmentation plays an important role in the analysis of Hematoxylin and Eosin (H&E)-stained images. While supervised deep learning (DL)-based approaches rep- resent the state-of-the-art in automatic nuclei instance seg- mentation, annotated datasets are required to train these mod- els. There are two main types of tissue processing protocols, namely formalin-fixed paraffin-embedded samples (FFPE) and frozen tissue samples (FS). Although FFPE-derived H&E stained tissue sections are the most widely used samples, H&E staining on frozen sections derived from FS samples is a relevant method in intra-operative surgical sessions as it can be performed fast. Due to differences in the protocols of these two types of samples, the derived images and in particular the nuclei appearance may be different in the acquired whole slide images. Analysis of FS-derived H&E stained images can be more challenging as rapid preparation, staining, and scanning of FS sections may lead to deterioration in image quality.\nIn this paper, we introduce CryoNuSeg, the first fully annotated FS-derived cryosectioned and H&E-stained nu- clei instance segmentation dataset. The dataset contains images from 10 human organs that were not exploited in other publicly available datasets, and is provided with three manual mark-ups to allow measuring intra-observer and inter- observer variability. Moreover, we investigate the effects of tissue fixation/embedding protocol (i.e., FS or FFPE) on the automatic nuclei instance segmentation performance of one of the state-of-the-art DL approaches. We also create a base- line segmentation benchmark for the dataset that can be used in future research.\nA step-by-step guide to generate the dataset as well as the full dataset and other detailed information are made avail- able to fellow researchers at https://github.com/ masih4/CryoNuSeg.\nIndex Terms\u2014 Medical Image Analysis, Computational Pathology, Nuclei Segmentation, H&E Staining, Frozen Tis-\nsue Samples, Deep Learning, Intra-Observer Variability, Inter-Observer Variability",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.03416",
        "title": "Detailed Annotations of Chest X-Rays via CT Projection for Report Understanding",
        "abstract": "In clinical radiology reports, doctors capture important information about the patient\u2019s health status. They convey their observations from raw medical imaging data about the inner structures of a patient. As such, formulating reports requires medical experts to possess wide-ranging knowledge about anatomical regions with their normal, healthy ap- pearance as well as the ability to recognize abnormalities. This explicit grasp on both the patient\u2019s anatomy and their appearance is missing in current medical image-processing systems as annotations are especially difficult to gather. This renders the models to be narrow experts e.g. for identifying specific diseases. In this work, we recover this miss- ing link by adding human anatomy into the mix and enable the association of content in medical reports to their occurrence in associated imagery (medical phrase grounding). To exploit anatomical structures in this scenario, we present a sophisticated automatic pipeline to gather and integrate human bodily structures from computed tomography datasets, which we incorporate in our PAXRAY: A Projected dataset for the segmenta- tion of Anatomical structures in X-RAY data. Our evaluation shows that methods that take advantage of anatomical information benefit heavily in visually grounding radiol- ogists\u2019 findings, as our anatomical segmentations allow for up to absolute 50% better grounding results on the OpenI dataset as compared to commonly used region proposals.\n\n  \n2 SEIBOLD ET AL.: DETAILED X-RAY ANNOTATIONS VIA CT PROJECTION\n  Figure 1: Overlap between the segmentation of anatomies and expert annotations on a sample of OpenI [16] indicating the necessity of anatomical understanding. Boxes are radiologists\u2019 annotation of findings. Masks show predictions for \u20186th right rib\u2019, \u2018spine\u2019 and \u2018heart\u2019\ntake advantage of anatomical information benefit heavily in visually grounding radiol- ogists\u2019 findings, as our anatomical segmentations allow for up to absolute 50% better grounding results on the OpenI dataset as compared to commonly used region proposals.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2208.13054",
        "title": "CrackSeg9k: A Collection and Benchmark for Crack Segmentation Datasets and Frameworks",
        "abstract": "The detection of cracks is a crucial task in monitoring struc- tural health and ensuring structural safety. The manual process of crack detection is time-consuming and subjective to the inspectors. Several researchers have tried tackling this problem using traditional Image Pro- cessing or learning-based techniques. However, their scope of work is limited to detecting cracks on a single type of surface (walls, pavements, glass, etc.). The metrics used to evaluate these methods are also var- ied across the literature, making it challenging to compare techniques. This paper addresses these problems by combining previously available datasets and unifying the annotations by tackling the inherent problems within each dataset, such as noise and distortions. We also present a pipeline that combines Image Processing and Deep Learning models. Fi- nally, we benchmark the results of proposed models on these metrics on our new dataset and compare them with state-of-the-art models in the literature.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1909.10980",
        "title": "PST900: RGB-Thermal Calibration, Dataset and Segmentation Network",
        "abstract": "Abstract\u2014In this work we propose long wave infrared (LWIR) imagery as a viable supporting modality for semantic segmentation using learning-based techniques. We first address the problem of RGB-thermal camera calibration by proposing a passive calibration target and procedure that is both portable and easy to use. Second, we present PST900, a dataset of 894 synchronized and calibrated RGB and Thermal image pairs with per pixel human annotations across four distinct classes from the DARPA Subterranean Challenge. Lastly, we propose a CNN architecture for fast semantic segmentation that combines both RGB and Thermal imagery in a way that leverages RGB imagery independently. We compare our method against the state-of-the-art and show that our method outperforms them in our dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2106.02740",
        "title": "ZeroWaste Dataset:\nTowards Deformable Object Segmentation in Cluttered Scenes",
        "abstract": "Less than 35% of recyclable waste is being actually re- cycled in the US [2], which leads to increased soil and sea pollution and is one of the major concerns of envi- ronmental researchers as well as the common public. At the heart of the problem are the inefficiencies of the waste sorting process (separating paper, plastic, metal, glass, etc.) due to the extremely complex and cluttered nature of the waste stream. Recyclable waste detection poses a unique computer vision challenge as it requires detection of highly deformable and often translucent objects in clut- tered scenes without the kind of context information usually present in human-centric datasets. This challenging com- puter vision task currently lacks suitable datasets or meth- ods in the available literature. In this paper, we take a step towards computer-aided waste detection and present the first in-the-wild industrial-grade waste detection and segmentation dataset, ZeroWaste. We believe that Ze- roWaste will catalyze research in object detection and semantic segmentation in extreme clutter as well as appli- cations in the recycling domain. Our project page can be found at http://ai.bu.edu/zerowaste/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2004.01241",
        "title": "Semantic Segmentation of Underwater Imagery: Dataset and Benchmark",
        "abstract": "In this paper, we present the first large-scale dataset for semantic Segmentation of Underwater IMagery (SUIM). It contains over 1500 images with pixel anno- tations for eight object categories: fish (vertebrates), reefs (invertebrates), aquatic plants, wrecks/ruins, human divers, robots, and sea-floor. The images have been rigorously collected during oceanic explorations and human-robot col- laborative experiments, and annotated by human participants. We also present a benchmark evaluation of state-of-the- art semantic segmentation approaches based on standard performance metrics. In addition, we present SUIM-Net, a fully-convolutional encoder-decoder model that balances the trade-off between performance and computational efficiency. It offers competitive performance while ensuring fast end-to- end inference, which is essential for its use in the autonomy pipeline of visually-guided underwater robots. In particular, we demonstrate its usability benefits for visual servoing, saliency prediction, and detailed scene understanding. With a variety of use cases, the proposed model and benchmark dataset open up promising opportunities for future research in underwater robot vision.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10350",
        "title": "Improving Multimodal Datasets with Image Captioning",
        "abstract": "Massive web datasets play a key role in the success of large vision-language models like CLIP and Flamingo. However, the raw web data is noisy, and existing filtering methods to reduce noise often come at the expense of data diversity. Our work focuses on caption quality as one major source of noise, and studies how generated captions can increase the utility of web-scraped datapoints with nondescript text. Through exploring different mixing strategies for raw and generated captions, we outperform the best filtering method proposed by the DataComp benchmark by 2% on ImageNet and 4% on average across 38 tasks, given a candidate pool of 128M image-text pairs. Our best approach is also 2\u00d7 better at Flickr and MS-COCO retrieval. We then analyze what makes synthetic captions an effective source of text supervision. In experimenting with different image captioning models, we also demonstrate that the performance of a model on standard image captioning benchmarks (e.g., NoCaps CIDEr) is not a reliable indicator of the utility of the captions it generates for multimodal training. Finally, our experiments with using generated captions at DataComp\u2019s large scale (1.28B image-text pairs) offer insights into the limitations of synthetic text, as well as the importance of image curation with increasing training data quantity. The generated captions used in our experiments are now available on HuggingFace6 .",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08259",
        "title": "LargeST: A Benchmark Dataset for Large-Scale Traffic Forecasting",
        "abstract": "Road traffic forecasting plays a critical role in smart city initiatives and has experi- enced significant advancements thanks to the power of deep learning in capturing non-linear patterns of traffic data. However, the promising results achieved on current public datasets may not be applicable to practical scenarios due to lim- itations within these datasets. First, the limited sizes of them may not reflect the real-world scale of traffic networks. Second, the temporal coverage of these datasets is typically short, posing hurdles in studying long-term patterns and ac- quiring sufficient samples for training deep models. Third, these datasets often lack adequate metadata for sensors, which compromises the reliability and inter- pretability of the data. To mitigate these limitations, we introduce the LargeST benchmark dataset. It encompasses a total number of 8,600 sensors in California with a 5-year time coverage and includes comprehensive metadata. Using LargeST, we perform in-depth data analysis to extract data insights, benchmark well-known baselines in terms of their performance and efficiency, and identify challenges as well as opportunities for future research. We release the datasets and baseline implementations at: https://github.com/liuxu77/LargeST.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.18773",
        "title": "CityRefer: Geography-aware 3D Visual Grounding Dataset on City-scale Point Cloud Data",
        "abstract": "City-scale 3D point cloud is a promising way to express detailed and complicated outdoor structures. It encompasses both the appearance and geometry features of segmented city components, including cars, streets, and buildings, that can be uti- lized for attractive applications such as user-interactive navigation of autonomous vehicles and drones. However, compared to the extensive text annotations avail- able for images and indoor scenes, the scarcity of text annotations for outdoor scenes poses a significant challenge for achieving these applications. To tackle this problem, we introduce the CityRefer dataset1 for city-level visual grounding. The dataset consists of 35k natural language descriptions of 3D objects appearing in SensatUrban [19] city scenes and 5k landmarks labels synchronizing with Open- StreetMap. To ensure the quality and accuracy of the dataset, all descriptions and labels in the CityRefer dataset are manually verified. We also have developed a baseline system that can learn encoded language descriptions, 3D object instances, and geographical information about the city\u2019s landmarks to perform visual ground- ing on the CityRefer dataset. To the best of our knowledge, the CityRefer dataset is the largest city-level visual grounding dataset for localizing specific 3D objects.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.09688",
        "title": "Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation",
        "abstract": "Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi- locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, which can benefit various existing tasks as well as enable new tasks. To test the potential of the dataset, we introduce three tasks in this work: (1) next-product recommendation, (2) next-product recommendation with domain shifts, and (3) next-product title generation. With the above tasks, we benchmark a range of algorithms on our proposed dataset, drawing new insights for further research and practice. In addition, based on the proposed dataset and tasks, we hosted a competition in the KDD CUP 20232 and have attracted thousands of users and submissions. The winning solutions and the associated workshop can be accessed at our website https://kddcup23.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.01813",
        "title": "FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain Text-to-Video Generation",
        "abstract": "Recently, open-domain text-to-video (T2V) generation models have made remark- able progress. However, the promising results are mainly shown by the qualitative cases of generated videos, while the quantitative evaluation of T2V models still faces two critical problems. Firstly, existing studies lack fine-grained evaluation of T2V models on different categories of text prompts. Although some bench- marks have categorized the prompts, their categorization either only focuses on a single aspect or fails to consider the temporal information in video generation. Secondly, it is unclear whether the automatic evaluation metrics are consistent with human standards. To address these problems, we propose FETV, a benchmark for Fine-grained Evaluation of Text-to-Video generation. FETV is multi-aspect, categorizing the prompts based on three orthogonal aspects: the major content, the attributes to control and the prompt complexity. FETV is also temporal-aware, which introduces several temporal categories tailored for video generation. Based on FETV, we conduct comprehensive manual evaluations of four representative T2V models, revealing their pros and cons on different categories of prompts from different aspects. We also extend FETV as a testbed to evaluate the re- liability of automatic T2V metrics. The multi-aspect categorization of FETV enables fine-grained analysis of the metrics\u2019 reliability in different scenarios. We find that existing automatic metrics (e.g., CLIPScore and FVD) correlate poorly with human evaluation. To address this problem, we explore several solutions to improve CLIPScore and FVD, and develop two automatic metrics that exhibit significant higher correlation with humans than existing metrics. Benchmark page: https://github.com/llyx97/FETV.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13457",
        "title": "Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric Super-Resolution with BLASTNet 2.0 Data",
        "abstract": "Analysis of compressible turbulent flows is essential for applications related to propulsion, energy generation, and the environment. Here, we present BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples from 34 high-fidelity direct numerical simulations, which addresses the current limited availability of 3D high-fidelity reacting and non-reacting compressible turbulent flow simulation data. With this data, we benchmark a total of 49 variations of five deep learning approaches for 3D super-resolution \u2013 which can be applied for improving scientific imaging, simulations, turbulence models, as well as in com- puter vision applications. We perform neural scaling analysis on these models to examine the performance of different machine learning (ML) approaches, including two scientific ML techniques. We demonstrate that (i) predictive performance can scale with model size and cost, (ii) architecture matters significantly, especially for smaller models, and (iii) the benefits of physics-based losses can persist with increasing model size. The outcomes of this benchmark study are anticipated to offer insights that can aid the design of 3D super-resolution models, especially for turbulence models, while this data is expected to foster ML methods for a broad range of flow physics applications. This data is publicly available with download links and browsing tools consolidated at https://blastnet.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09200",
        "title": "ChessGPT: Bridging Policy Learning and Language Modeling",
        "abstract": "When solving decision-making tasks, humans typically depend on information from two key sources: (1) Historical policy data, which provides interaction replay from the environment, and (2) Analytical insights in natural language form, exposing the invaluable thought process or strategic considerations. Despite this, the majority of preceding research focuses on only one source: they either use historical replay exclusively to directly learn policy or value functions, or engaged in language model training utilizing mere language corpus. In this paper, we argue that a powerful autonomous agent should cover both sources. Thus, we propose ChessGPT, a GPT model bridging policy learning and language modeling by integrating data from these two sources in Chess games. Specifically, we build a large-scale game and language dataset related to chess. Leveraging the dataset, we showcase two model examples ChessCLIP and ChessGPT, integrating policy learning and language modeling. Finally, we propose a full evaluation framework for evaluating language model\u2019s chess ability. Experimental results validate our model and dataset\u2019s effectiveness. We open source our code, model, and dataset at https://github.com/waterhorse1/ChessGPT.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.04287",
        "title": "Holistic Evaluation of Text-to-Image Models",
        "abstract": "The stunning qualitative improvement of recent text-to-image models has led to their widespread attention and adoption. However, we lack a comprehensive quantitative understanding of their capabilities and risks. To fill this gap, we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models (HEIM). Whereas previous evaluations focus mostly on text-image alignment and image quality, we identify 12 aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios encompassing these aspects and evaluate 26 state-of-the-art text-to-image models on this benchmark. Our results reveal that no single model excels in all aspects, with different models demonstrating different strengths. We release the generated images and human evaluation results for full transparency at https://crfm.stanford.edu/heim/v1.1.0 and the code at https://github.com/stanford-crfm/helm, which is integrated with the HELM codebase [1].",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.13490",
        "title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor Computational Graphs",
        "abstract": "Precise hardware performance models play a crucial role in code optimizations. They can assist compilers in making heuristic decisions or aid autotuners in identi- fying the optimal configuration for a given program. For example, the autotuner for XLA, a machine learning compiler, discovered 10\u201320% speedup on state-of-the-art models serving substantial production traffic at Google. Although there exist a few datasets for program performance prediction, they target small sub-programs such as basic blocks or kernels. This paper introduces TPUGRAPHS, a performance prediction dataset on full tensor programs, represented as computational graphs, running on Tensor Processing Units (TPUs). Each graph in the dataset represents the main computation of a machine learning workload, e.g., a training epoch or an inference step. Each data sample contains a computational graph, a compila- tion configuration, and the execution time of the graph when compiled with the configuration. The graphs in the dataset are collected from open-source machine learning programs, featuring popular model architectures, e.g., ResNet, Efficient- Net, Mask R-CNN, and Transformer. TPUGRAPHS provides 25x more graphs than the largest graph property prediction dataset (with comparable graph sizes), and 770x larger graphs on average compared to existing performance prediction datasets on machine learning programs. This graph-level prediction task on large graphs introduces new challenges in learning, ranging from scalability, training efficiency, to model quality.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.05877",
        "title": "A Performance-Driven Benchmark for Feature Selection in Tabular Deep Learning",
        "abstract": "Academic tabular benchmarks often contain small sets of curated features. In contrast, data scientists typically collect as many features as possible into their datasets, and even engineer new features from existing ones. To prevent overfit- ting in subsequent downstream modeling, practitioners commonly use automated feature selection methods that identify a reduced subset of informative features. Existing benchmarks for tabular feature selection consider classical downstream models, toy synthetic datasets, or do not evaluate feature selectors on the basis of downstream performance. Motivated by the increasing popularity of tabular deep learning, we construct a challenging feature selection benchmark evaluated on downstream neural networks including transformers, using real datasets and multiple methods for generating extraneous features. We also propose an input- gradient-based analogue of Lasso for neural networks that outperforms classical feature selection methods on challenging problems such as selecting from corrupted or second-order features",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.12645",
        "title": "KuaiSim: A Comprehensive Simulator for Recommender Systems",
        "abstract": "Reinforcement Learning (RL)-based recommender systems (RSs) have garnered considerable attention due to their ability to learn optimal recommendation policies and maximize long-term user rewards. However, deploying RL models directly in online environments and generating authentic data through A/B tests can pose challenges and require substantial resources. Simulators offer an alternative ap- proach by providing training and evaluation environments for RS models, reducing reliance on real-world data. Existing simulators have shown promising results but also have limitations such as simplified user feedback, lack of consistency with real-world data, the challenge of simulator evaluation, and difficulties in migration and expansion across RSs. To address these challenges, we propose KuaiSim, a comprehensive user environment that provides user feedback with multi-behavior and cross-session responses. The resulting simulator can support three levels of recommendation problems: the request level list-wise recommendation task, the whole-session level sequential recommendation task, and the cross-session level retention optimization task. For each task, KuaiSim also provides evaluation pro- tocols and baseline recommendation algorithms that further serve as benchmarks for future research. We also restructure existing competitive simulators on the KuaiRand Dataset and compare them against KuaiSim to further assess their perfor- mance and behavioral differences. Furthermore, to showcase KuaiSim\u2019s flexibility in accommodating different datasets, we demonstrate its versatility and robustness when deploying it on the ML-1m dataset. The implementation code is available online to ease reproducibility 3.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.00556",
        "title": "ProBio: A Protocol-guided Multimodal Dataset for Molecular Biology Lab",
        "abstract": "The challenge of replicating research results has posed a significant impediment to the field of molecular biology. The advent of modern intelligent systems has led to notable progress in various domains. Consequently, we embarked on an investigation of intelligent monitoring systems as a means of tackling the issue of the reproducibility crisis. Specifically, we first curate a comprehensive multimodal dataset, named ProBio, as an initial step towards this objective. This dataset comprises fine-grained hierarchical annotations intended for studying activity un- derstanding in Molecular Biology Lab (BioLab). Next, we devise two challenging benchmarks, transparent solution tracking, and multimodal action recognition, to emphasize the unique characteristics and difficulties associated with activity understanding in BioLab settings. Finally, we provide a thorough experimental evaluation of contemporary video understanding models and highlight their limita- tions in this specialized domain to identify potential avenues for future research. We hope ProBio with associated benchmarks may garner increased focus on modern AI techniques in the realm of molecular biology.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.15171",
        "title": "RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions",
        "abstract": "Depth estimation from monocular images is pivotal for real-world visual perception systems. While current learning-based depth estimation models train and test on meticulously curated data, they often overlook out-of-distribution (OoD) situations. Yet, in practical settings \u2013 especially safety-critical ones like autonomous driv- ing \u2013 common corruptions can arise. Addressing this oversight, we introduce a comprehensive robustness test suite, RoboDepth, encompassing 18 corruptions spanning three categories: i) weather and lighting conditions; ii) sensor failures and movement; and iii) data processing anomalies. We subsequently benchmark 42 depth estimation models across indoor and outdoor scenes to assess their resilience to these corruptions. Our findings underscore that, in the absence of a dedicated robustness evaluation framework, many leading depth estimation models may be susceptible to typical corruptions. We delve into design considerations for crafting more robust depth estimation models, touching upon pre-training, augmentation, modality, model capacity, and learning paradigms. We anticipate our benchmark will establish a foundational platform for advancing robust OoD depth estimation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.12269",
        "title": "The Cambridge Law Corpus: A Dataset for Legal AI Research",
        "abstract": "We introduce the Cambridge Law Corpus (CLC), a dataset for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.14183",
        "title": "Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition",
        "abstract": "The development of foundation vision models has pushed the general visual recog- nition to a high level, but cannot well address the fine-grained recognition in special- ized domain such as invasive species classification. Identifying and managing inva- sive species has strong social and ecological value. Currently, most invasive species datasets are limited in scale and cover a narrow range of species, which restricts the development of deep-learning based invasion biometrics systems. To fill the gap of this area, we introduced Species196, a large-scale semi-supervised dataset of 196-category invasive species. It collects over 19K images with expert-level ac- curate annotations (Species196-L), and 1.2M unlabeled images of invasive species (Species196-U). The dataset provides four experimental settings for benchmarking the existing models and algorithms, namely, supervised learning, semi-supervised learning, self-supervised pretraining and zero-shot inference ability of large multi- modal models. To facilitate future research on these four learning paradigms, we conduct an empirical study of the representative methods on the introduced dataset. The dataset is publicly available at https://species-dataset.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.10577",
        "title": "OpenDataVal: a Unified Benchmark for Data Valuation",
        "abstract": "Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of eleven different state-of-the-art data valu- ation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparing the efficacy of state-of-the-art data valu- ation approaches. We find that no single algorithm performs uniformly best across all tasks, and an appropriate algorithm should be employed for a user\u2019s downstream task. OpenDataVal is publicly available at https://opendataval.github.io with comprehensive documentation. Furthermore, we provide a leaderboard where researchers can evaluate the effectiveness of their own data valuation algorithms.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.13347",
        "title": "NurViD: A Large Expert-Level Video Database for Nursing Procedure Activity Understanding",
        "abstract": "The application of deep learning to nursing procedure activity understanding has the potential to greatly enhance the quality and safety of nurse-patient interactions. By utilizing the technique, we can facilitate training and education, improve quality control, and enable operational compliance monitoring. However, the development of automatic recognition systems in this field is currently hindered by the scarcity of appropriately labeled datasets. The existing video datasets pose several limitations: 1) these datasets are small-scale in size to support comprehensive investigations of nursing activity; 2) they primarily focus on single procedures, lacking expert- level annotations for various nursing procedures and action steps; and 3) they lack temporally localized annotations, which prevents the effective localization of targeted actions within longer video sequences. To mitigate these limitations, we propose NurViD, a large video dataset with expert-level annotation for nursing procedure activity understanding. NurViD consists of over 1.5k videos totaling 144 hours, making it approximately four times longer than the existing largest nursing activity datasets. Notably, it encompasses 51 distinct nursing procedures and 177 action steps, providing a much more comprehensive coverage compared to existing datasets that primarily focus on limited procedures. To evaluate the efficacy of current deep learning methods on nursing activity understanding, we establish three benchmarks on NurViD: procedure recognition on untrimmed videos, procedure and action recognition on trimmed videos, and action detection. Our benchmark and code will be available at https://github.com/minghu0830/NurViD-benchmark.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2206.08005",
        "title": "Evaluating Self-Supervised Learning for Molecular Graph Embeddings",
        "abstract": "Graph Self-Supervised Learning (GSSL) provides a robust pathway for acquiring\nembeddings without expert labelling, a capability that carries profound implica-\ntions for molecular graphs due to the staggering number of potential molecules\nand the high cost of obtaining labels. However, GSSL methods are designed not\nfor optimisation within a specific domain but rather for transferability across a\nvariety of downstream tasks. This broad applicability complicates their evalu-\nation. Addressing this challenge, we present \"Molecular Graph Representation\nEvaluation\" (MOLGRAPHEVAL), generating detailed profiles of molecular graph\nembeddings with interpretable and diversified attributes. MOLGRAPHEVAL of-\nfers a suite of probing tasks grouped into three categories: (i) generic graph,\n(ii) molecular substructure, and (iii) embedding space properties. By leverag-\ning MOLGRAPHEVAL to benchmark existing GSSL methods against both current\ndownstream datasets and our suite of tasks, we uncover significant inconsistencies\nbetween inferences drawn solely from existing datasets and those derived from\nmore nuanced probing. These findings suggest that current evaluation methodolo-\ngies fail to capture the entirety of the landscape.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.01835",
        "title": "EMBERSim: A Large-Scale Databank for Boosting Similarity Search in Malware Analysis",
        "abstract": "In recent years there has been a shift from heuristics-based malware detection towards machine learning, which proves to be more robust in the current heavily adversarial threat landscape. While we acknowledge machine learning to be better equipped to mine for patterns in the increasingly high amounts of similar-looking files, we also note a remarkable scarcity of the data available for similarity-targeted research. Moreover, we observe that the focus in the few related works falls on quantifying similarity in malware, often overlooking the clean data. This one- sided quantification is especially dangerous in the context of detection bypass. We propose to address the deficiencies in the space of similarity research on binary files, starting from EMBER \u2014 one of the largest malware classification data sets. We enhance EMBER with similarity information as well as malware class tags, to enable further research in the similarity space. Our contribution is threefold: (1) we publish EMBERSim, an augmented version of EMBER, that includes similarity-informed tags; (2) we enrich EMBERSim with automatically determined malware class tags using the open-source tool AVClass on VirusTotal data and (3) we describe and share the implementation for our class scoring technique and leaf similarity method.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1804.04637",
        "title": "EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models",
        "abstract": "This paper describes EMBER: a labeled benchmark dataset for training machine learning models to statically detect malicious Windows portable executable files. The dataset includes features extracted from 1.1M binary files: 900K training samples (300K malicious, 300K benign, 300K un- labeled) and 200K test samples (100K malicious, 100K be- nign). To accompany the dataset, we also release open source code for extracting features from additional bina- ries so that additional sample features can be appended to the dataset. This dataset fills a void in the information security machine learning community: a benign/malicious dataset that is large, open and general enough to cover sev- eral interesting use cases. We enumerate several use cases that we considered when structuring the dataset. Addition- ally, we demonstrate one use case wherein we compare a baseline gradient boosted decision tree model trained us- ing LightGBM with default settings to MalConv, a recently published end-to-end (featureless) deep learning model for malware detection. Results show that even without hyper- parameter optimization, the baseline EMBER model outper- forms MalConv. The authors hope that the dataset, code and baseline model provided by EMBER will help invigorate machine learning research for malware detection, in much the same way that benchmark datasets have advanced com- puter vision research",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.08710",
        "title": "Waymax: An Accelerated, Data-Driven Simulator for Large-Scale Autonomous Driving Research",
        "abstract": "Simulation is an essential tool to develop and benchmark autonomous vehicle planning software in a safe and cost-effective manner. However, realistic simula- tion requires accurate modeling of nuanced and complex multi-agent interactive behaviors. To address these challenges, we introduce Waymax, a new data-driven simulator for autonomous driving in multi-agent scenes, designed for large-scale simulation and testing. Waymax uses publicly-released, real-world driving data (e.g., the Waymo Open Motion Dataset [15]) to initialize or play back a diverse set of multi-agent simulated scenarios. It runs entirely on hardware accelerators such as TPUs/GPUs and supports in-graph simulation for training, making it suitable for modern large-scale, distributed machine learning workflows. To support online training and evaluation, Waymax includes several learned and hard-coded behav- ior models that allow for realistic interaction within simulation. To supplement Waymax, we benchmark a suite of popular imitation and reinforcement learning algorithms with ablation studies on different design decisions, where we highlight the effectiveness of routes as guidance for planning agents and the ability of RL to overfit against simulated agents.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.17448",
        "title": "SMPLer-X: Scaling Up Expressive Human Pose and Shape Estimation",
        "abstract": "Expressive human pose and shape estimation (EHPS) unifies body, hands, and face motion capture with numerous applications. Despite encouraging progress, current state-of-the-art methods still depend largely on a confined set of training datasets. In this work, we investigate scaling up EHPS towards the first generalist foundation model (dubbed SMPLer-X), with up to ViT-Huge as the backbone and training with up to 4.5M instances from diverse data sources. With big data and the large model, SMPLer-X exhibits strong performance across diverse test benchmarks and excellent transferability to even unseen environments. 1) For the data scaling, we perform a systematic investigation on 32 EHPS datasets, including a wide range of scenarios that a model trained on any single dataset cannot handle. More importantly, capitalizing on insights obtained from the extensive benchmarking process, we optimize our training scheme and select datasets that lead to a significant leap in EHPS capabilities. 2) For the model scaling, we take advantage of vision transformers to study the scaling law of model sizes in EHPS. Moreover, our finetuning strategy turn SMPLer-X into specialist models, allowing them to achieve further performance boosts. Notably, our foundation model SMPLer-X consistently delivers state-of-the-art results on seven benchmarks such as AGORA (107.2 mm NMVE), UBody (57.4 mm PVE), EgoBody (63.6 mm PVE), and EHF (62.3 mm PVE without finetuning).",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.15482",
        "title": "Salient Object Detection in RGB-D Videos",
        "abstract": "Given the widespread adoption of depth-sensing acquisition devices, RGB-D videos and related data/media have gained considerable traction in various aspects of daily life. Consequently, conducting salient object detection (SOD) in RGB- D videos presents a highly promising and evolving avenue. Despite the potential of this area, SOD in RGB-D videos remains somewhat under-explored, with RGB-D SOD and video SOD (VSOD) traditionally studied in isolation. To explore this emerging field, this paper makes two primary contributions: the dataset and the model. On one front, we construct the RDVS dataset, a new RGB-D VSOD dataset with realistic depth and characterized by its diversity of scenes and rigorous frame- by-frame annotations. We validate the dataset through com- prehensive attribute and object-oriented analyses, and provide training and testing splits. Moreover, we introduce DCTNet+, a three-stream network tailored for RGB-D VSOD, with an emphasis on RGB modality and treats depth and optical flow as auxiliary modalities. In pursuit of effective feature enhancement, refinement, and fusion for precise final prediction, we propose two modules: the multi-modal attention module (MAM) and the refinement fusion module (RFM). To enhance interaction and fusion within RFM, we design a universal interaction module (UIM) and then integrate holistic multi-modal attentive paths (HMAPs) for refining multi-modal low-level features be- fore reaching RFMs. Comprehensive experiments, conducted on pseudo RGB-D video datasets alongside our proposed RDVS, highlight the superiority of DCTNet+ over 17 VSOD models and 14 RGB-D SOD models. Additionally, insightful ablation experiments were performed on both pseudo and realistic RGB- D video datasets to demonstrate the advantages of individual modules as well as the necessity of introducing realistic depth into VSOD. Our code together with RDVS dataset will be available at https://github.com/kerenfu/RDVS/.\nIndex Terms\u2014Salient object detection, RGB-D videos, depth, optical flow, multi-modal fusion",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.05721",
        "title": "HA-VID: A HUMAN ASSEMBLY VIDEO DATASET FOR COMPREHENSIVE ASSEMBLY KNOWLEDGE UNDERSTANDING",
        "abstract": "Understanding comprehensive assembly knowledge from videos is critical for futuristic ultra- intelligent industry. To enable technological breakthrough, we present HA-ViD \u2013 the first human assembly video dataset that features representative industrial assembly scenarios, natural procedural knowledge acquisition process, and consistent human-robot shared annotations. Specifically, HA-ViD captures diverse collaboration patterns of real-world assembly, natural human behaviors and learning progression during assembly, and granulate action annotations to subject, action verb, manipulated object, target object, and tool. We provide 3222 multi-view, multi-modality videos (each video contains one assembly task), 1.5M frames, 96K temporal labels and 2M spatial labels. We benchmark four foundational video understanding tasks: action recognition, action segmentation, object detection and multi-object tracking. Importantly, we analyze their performance for comprehending knowledge in assembly progress, process efficiency, task collaboration, skill parameters and human intention. Details of HA-ViD is available at: https://iai-hrc.github.io/ha-vid",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2211.12421",
        "title": "Cola: A Benchmark for Compositional Text-to-image Retrieval",
        "abstract": "Compositional reasoning is a hallmark of human visual intelligence. Yet despite the size of large vision-language models, they struggle to represent simple com- positions by combining objects with their attributes. To measure this lack of compositional capability, we design Cola, a text-to-image retrieval benchmark to Compose Objects Localized with Attributes. To solve Cola, a model must retrieve images with the correct configuration of attributes and objects, and avoid choosing a distractor image with the same objects and attributes but in the wrong configuration. Cola contains about 1.2k composed queries of 168 objects and 197 attributes on around 30K images. Our human evaluation finds that Cola is 83.33% accurate, similar to contemporary compositionality benchmarks. Using Cola as a testbed, we explore empirical modeling designs to adapt pre-trained vision-language models to reason compositionally. We explore 6 adaptation strate- gies on 2 seminal vision-language models, using compositionality-centric test benchmarks - Cola and CREPE. We find the optimal adaptation strategy is to train a multi-modal attention layer that jointly attends over the frozen pre-trained image and language features. Surprisingly, training multimodal layers on CLIP performs better than tuning a larger FLAVA model with already pre-trained multi- modal layers. Furthermore, our adaptation strategy improves CLIP and FLAVA to comparable levels, suggesting that training multimodal layers using contrastive attribute-object data is key, as opposed to using them pre-trained. Lastly, we show that Cola is harder than a closely-related contemporary benchmark, CREPE, since simpler fine-tuning strategies without multimodal layers suffice on CREPE, but not on Cola. However, we still see a significant gap between our best adaptation and human accuracy, suggesting considerable room for further research. Project page: https://cs-people.bu.edu/array/research/cola/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.12241",
        "title": "ScenarioNet: Open-Source Platform for Large-Scale Traffic Scenario Simulation and Modeling",
        "abstract": "Large-scale driving datasets such as Waymo Open Dataset and nuScenes substan- tially accelerate autonomous driving research, especially for perception tasks such as 3D detection and trajectory forecasting. Since the driving logs in these datasets contain HD maps and detailed object annotations that accurately reflect the real- world complexity of traffic behaviors, we can harvest a massive number of complex traffic scenarios and recreate their digital twins in simulation. Compared to the hand- crafted scenarios often used in existing simulators, data-driven scenarios collected from the real world can facilitate many research opportunities in machine learning and autonomous driving. In this work, we present ScenarioNet, an open-source platform for large-scale traffic scenario modeling and simulation. ScenarioNet defines a unified scenario description format and collects a large-scale repository of real-world traffic scenarios from the heterogeneous data in various driving datasets including Waymo, nuScenes, Lyft L5, Argoverse, and nuPlan datasets. These scenarios can be further replayed and interacted with in multiple views from Bird- Eye-View layout to realistic 3D rendering in MetaDrive simulator. This provides a benchmark for evaluating the safety of autonomous driving stacks in simulation before their real-world deployment. We further demonstrate the strengths of Sce- narioNet on large-scale scenario generation, imitation learning, and reinforcement learning in both single-agent and multi-agent settings. Code, demo videos, and website are available at https://metadriverse.github.io/scenarionet.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1912.04838",
        "title": "Scalability in Perception for Autonomous Driving: Waymo Open Dataset",
        "abstract": "The research community has increasing interest in au- tonomous driving research, despite the resource intensity of obtaining representative real world data. Existing self- driving datasets are limited in the scale and variation of the environments they capture, even though generalization within and between operating regions is crucial to the over- all viability of the technology. In an effort to help align the research community\u2019s contributions with real-world self- driving problems, we introduce a new large-scale, high quality, diverse dataset. Our new dataset consists of 1150 scenes that each span 20 seconds, consisting of well syn- chronized and calibrated high quality LiDAR and camera data captured across a range of urban and suburban ge- ographies. It is 15x more diverse than the largest cam- era+LiDAR dataset available based on our proposed geo- graphical coverage metric. We exhaustively annotated this data with 2D (camera image) and 3D (LiDAR) bounding boxes, with consistent identifiers across frames. Finally, we provide strong baselines for 2D as well as 3D detection and tracking tasks. We further study the effects of dataset size and generalization across geographies on 3D detection methods. Find data, code and more up-to-date information at http://www.waymo.com/open.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1903.11027",
        "title": "nuScenes: A multimodal dataset for autonomous driving",
        "abstract": "Robust detection and tracking of objects is crucial for the deployment of autonomous vehicle technology. Image based benchmark datasets have driven development in com- puter vision tasks such as object detection, tracking and seg- mentation of agents in the environment. Most autonomous vehicles, however, carry a combination of cameras and range sensors such as lidar and radar. As machine learn- ing based methods for detection and tracking become more prevalent, there is a need to train and evaluate such meth- ods on datasets containing range sensor data along with im- ages. In this work we present nuTonomy scenes (nuScenes), the first dataset to carry the full autonomous vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 de- gree field of view. nuScenes comprises 1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as many annotations and 100x as many images as the pioneering KITTI dataset. We define novel 3D detection and tracking metrics. We also provide careful dataset analysis as well as baselines for li- dar and image based detection and tracking. Data, devel- opment kit and more information are available online",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.06352",
        "title": "NuScenes-MQA: Integrated Evaluation of Captions and QA for Autonomous Driving Datasets using Markup Annotations",
        "abstract": "Visual Question Answering (VQA) is one of the most im- portant tasks in autonomous driving, which requires accu- rate recognition and complex situation evaluations. How- ever, datasets annotated in a QA format, which guaran- tees precise language generation and scene recognition from driving scenes, have not been established yet. In this work, we introduce Markup-QA, a novel dataset annota- tion technique in which QAs are enclosed within markups. This approach facilitates the simultaneous evaluation of a model\u2019s capabilities in sentence generation and VQA. Moreover, using this annotation methodology, we designed the NuScenes-MQA dataset. This dataset empowers the de- velopment of vision language models, especially for au- tonomous driving tasks, by focusing on both descriptive capabilities and precise QA. The dataset is available at https://github.com/turingmotors/NuScenes-MQA.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2006.14480",
        "title": "One Thousand and One Hours: Self-driving Motion Prediction Dataset",
        "abstract": "Motivated by the impact of large-scale datasets on ML systems we present the largest self-driving dataset for motion prediction to date, containing over 1,000 hours of data. This was collected by a fleet of 20 autonomous vehicles along a fixed route in Palo Alto, California, over a four-month period. It consists of 170,000 scenes, where each scene is 25 seconds long and captures the percep- tion output of the self-driving system, which encodes the precise positions and motions of nearby vehicles, cyclists, and pedestrians over time. On top of this, the dataset contains a high-definition semantic map with 15,242 labelled elements and a high-definition aerial view over the area. We show that using a dataset of this size dramatically improves performance for key self-driving problems. Combined with the provided software kit, this collection forms the largest and most detailed dataset to date for the development of self-driving machine learning tasks, such as motion forecasting, motion planning and simulation.\nKeywords: Dataset, Self-driving, Motion prediction",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.18921",
        "title": "Large Car-following Data Based on Lyft level-5 Open Dataset: Following Autonomous Vehicles vs. Human-driven Vehicles",
        "abstract": "Car-Following (CF), as a fundamental driving behaviour, has significant influences on the safety and efficiency of traffic flow. Investigating how human drivers react differently when following autonomous vs. human-driven vehicles (HV) is thus critical for mixed traffic flow. Research in this field can be expedited with trajectory datasets collected by Autonomous Vehicles (AVs). However, trajectories collected by AVs are noisy and not readily applicable for studying CF behaviour. This paper extracts and enhances two categories of CF data, HV-following-AV (H-A) and HV-following-HV (H-H), from the open Lyft level-5 dataset. First, CF pairs are selected based on specific rules. Next, the quality of raw data is assessed by anomaly analysis. Then, the raw CF data is corrected and enhanced via motion planning, Kalman filtering, and wavelet denoising. As a result, 29k+ H-A and 42k+ H-H car-following segments are obtained, with a total driving distance of 150k+ km. A diversity assessment shows that the processed data cover complete CF regimes for calibrating CF models. This open and ready-to-use dataset provides the opportunity to investigate the CF behaviours of following AVs vs. HVs from real-world data. It can further facilitate studies on exploring the impact of AVs on mixed urban traffic.\nIndex Terms\u2014 Car-following, trajectory dataset, autonomous vehicle, driving behaviour",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1911.02620",
        "title": "Argoverse: 3D Tracking and Forecasting with Rich Maps",
        "abstract": "We present Argoverse \u2013 two datasets designed to sup- port autonomous vehicle machine learning tasks such as 3D tracking and motion forecasting. Argoverse was col- lected by a fleet of autonomous vehicles in Pittsburgh and Miami. The Argoverse 3D Tracking dataset includes 360\u25e6 images from 7 cameras with overlapping fields of view, 3D point clouds from long range LiDAR, 6-DOF pose, and 3D track annotations. Notably, it is the only modern AV dataset that provides forward-facing stereo imagery. The Argoverse Motion Forecasting dataset includes more than 300,000 5 second tracked scenarios with a particular vehicle identi- fied for trajectory forecasting. Argoverse is the first au- tonomous vehicle dataset to include \u201cHD maps\u201d with 290 km of mapped lanes with geometric and semantic metadata. All data is released under a Creative Commons license at www.argoverse.org . In our baseline experiments, we illustrate how detailed map information such as lane direc- tion, driveable area, and ground height improves the ac- curacy of 3D object tracking and motion forecasting. Our tracking and forecasting experiments represent only an ini- tial exploration of the use of rich maps in robotic percep- tion. We hope that Argoverse will enable the research com- munity to explore these problems in greater depth.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.00493",
        "title": "Argoverse 2: Next Generation Datasets for Self-Driving Perception and Forecasting",
        "abstract": "We introduce Argoverse 2 (AV2) \u2014 a collection of three datasets for perception and forecasting research in the self-driving domain. The annotated Sensor Dataset con- tains 1,000 sequences of multimodal data, encompassing high-resolution imagery from seven ring cameras, and two stereo cameras in addition to lidar point clouds, and 6-DOF map-aligned pose. Sequences contain 3D cuboid annotations for 26 object categories, all of which are sufficiently-sampled to support training and evaluation of 3D perception models. The Lidar Dataset contains 20,000 sequences of unlabeled lidar point clouds and map-aligned pose. This dataset is the largest ever collection of lidar sensor data and supports self-supervised learning and the emerging task of point cloud forecasting. Finally, the Motion Forecasting Dataset contains 250,000 scenarios mined for interesting and challenging interactions be- tween the autonomous vehicle and other actors in each local scene. Models are tasked with the prediction of future motion for \u201cscored actors\" in each scenario and are provided with track histories that capture object location, heading, velocity, and category. In all three datasets, each scenario contains its own HD Map with 3D lane and crosswalk geometry \u2014 sourced from data captured in six distinct cities. We believe these datasets will support new and existing machine learning research problems in ways that existing datasets do not. All datasets are released under the CC BY-NC-SA 4.0 license.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2106.11810",
        "title": "nuPlan: A closed-loop ML-based planning benchmark for autonomous vehicles",
        "abstract": "In this work, we propose the world\u2019s first closed-loop ML-based planning benchmark for autonomous driving. While there is a growing body of ML-based motion plan- ners, the lack of established datasets and metrics has limited the progress in this area. Existing benchmarks for autonomous vehicle motion prediction have focused on short-term motion forecasting, rather than long-term planning. This has led previous works to use open-loop evaluation with L2-based metrics, which are not suitable for fairly evaluating long-term planning. Our bench- mark overcomes these limitations by introducing a large- scale driving dataset, lightweight closed-loop simulator, and motion-planning-specific metrics. We provide a high- quality dataset with 1500h of human driving data from 4 cities across the US and Asia with widely varying traffic pat- terns (Boston, Pittsburgh, Las Vegas and Singapore). We will provide a closed-loop simulation framework with re- active agents and provide a large set of both general and scenario-specific planning metrics. We plan to release the dataset at NeurIPS 2021 and organize benchmark chal- lenges starting in early 2022.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2403.04133",
        "title": "Towards learning-based planning:\nThe nuPlan benchmark for real-world autonomous driving",
        "abstract": "Machine Learning (ML) has replaced handcrafted methods for perception and prediction in autonomous vehicles. Yet for the equally important planning task, the adoption of ML-based techniques is slow. We present nuPlan, the world\u2019s first real-world autonomous driving dataset and benchmark. The benchmark is designed to test the ability of ML-based planners to handle diverse driving situations and to make safe and efficient decisions. We introduce a new large-scale dataset that consists of 1282 hours of diverse driving scenarios from 4 cities (Las Vegas, Boston, Pittsburgh, and Singapore) and includes high-quality auto-labeled object tracks and traffic light data. We mine and taxonomize common & rare driving scenarios which are used during evaluation to get fine-grained insights into the performance and characteristics of a planner. Beyond the dataset, we provide a simulation and evaluation framework that enables a planner\u2019s actions to be simulated in closed-loop to account for interactions with other traffic partici- pants. We present a detailed analysis of numerous baselines and investigate gaps between ML-based and traditional methods. Find the nuPlan dataset and code at nuplan.org.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.08348",
        "title": "LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios",
        "abstract": "Building agents based on tree-search planning capabilities with learned models has achieved remarkable success in classic decision-making problems, such as Go and Atari. However, it has been deemed challenging or even infeasible to extend Monte Carlo Tree Search (MCTS) based algorithms to diverse real-world applications, especially when these environments involve complex action spaces and significant simulation costs, or inherent stochasticity. In this work, we introduce LightZero, the first unified benchmark for deploying MCTS/MuZero in general sequential decision scenarios. Specificially, we summarize the most critical challenges in designing a general MCTS-style decision-making solver, then decompose the tightly-coupled algorithm and system design of tree-search RL methods into distinct sub-modules. By incorporating more appropriate exploration and optimization strategies, we can significantly enhance these sub-modules and construct powerful LightZero agents to tackle tasks across a wide range of domains, such as board games, Atari, MuJoCo, MiniGrid and GoBigger. Detailed benchmark results reveal the significant potential of such methods in building scalable and efficient decision intelligence. The code is available as part of OpenDILab at https://github.com/opendilab/LightZero.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1708.01641",
        "title": "Localizing Moments in Video with Natural Language",
        "abstract": "We consider retrieving a specific temporal segment, or moment, from a video given a natural language text de- scription. Methods designed to retrieve whole video clips with natural language determine what occurs in a video but not when. To address this issue, we propose the Mo- ment Context Network (MCN) which effectively localizes natural language queries in videos by integrating local and global video features over time. A key obstacle to train- ing our MCN model is that current video datasets do not include pairs of localized video segments and referring ex- pressions, or text descriptions which uniquely identify a corresponding moment. Therefore, we collect the Distinct Describable Moments (DiDeMo) dataset which consists of over 10,000 unedited, personal videos in diverse visual set- tings with pairs of localized video segments and referring expressions. We demonstrate that MCN outperforms sev- eral baseline methods and believe that our initial results together with the release of DiDeMo will inspire further re- search on localizing video moments with natural language.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2107.09609",
        "title": "QVHIGHLIGHTS: Detecting Moments and Highlights in Videos via Natural Language Queries",
        "abstract": "Detecting customized moments and highlights from videos given natural language (NL) user queries is an important but under-studied topic. One of the challenges in pursuing this direction is the lack of annotated data. To address this issue, we present the Query-based Video Highlights (QVHIGHLIGHTS) dataset. It consists of over 10,000 YouTube videos, covering a wide range of topics, from everyday activities and travel in lifestyle vlog videos to social and political activities in news videos. Each video in the dataset is annotated with: (1) a human-written free-form NL query, (2) relevant moments in the video w.r.t. the query, and (3) five-point scale saliency scores for all query-relevant clips. This comprehensive annotation enables us to develop and evaluate systems that detect relevant moments as well as salient highlights for diverse, flexible user queries. We also present a strong baseline for this task, Moment-DETR, a transformer encoder-decoder model that views moment retrieval as a direct set prediction problem, taking extracted video and query representations as inputs and predicting moment coordinates and saliency scores end-to-end. While our model does not utilize any human prior, we show that it performs competitively when compared to well-engineered architectures. With weakly supervised pretraining using ASR captions, Moment- DETR substantially outperforms previous methods. Lastly, we present several ablations and visualizations of Moment-DETR. Data and code is publicly available at https://github.com/jayleicn/moment_detr.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.00168",
        "title": "REASONER: An Explainable Recommendation Dataset with Multi-aspect Real User Labeled Ground Truths",
        "abstract": "Explainable recommendation has attracted much attention from the industry and academic communities. It has shown great potential for improving the recommendation persuasiveness, informative- ness and user satisfaction. Despite a lot of promising explainable recommender models have been proposed in the past few years, the evaluation strategies of these models suffer from several limitations. For example, the explanation ground truths are not labeled by real users, the explanations are mostly evaluated based on only one as- pect and the evaluation strategies can be hard to unify. To alleviate the above problems, we propose to build an explainable recommen- dation dataset with multi-aspect real user labeled ground truths. In specific, we firstly develop a video recommendation platform, where a series of questions around the recommendation explainabil- ity are carefully designed. Then, we recruit about 3000 users with different backgrounds to use the system, and collect their behaviors and feedback to our questions. In this paper, we detail the con- struction process of our dataset and also provide extensive analysis on its characteristics. In addition, we develop a library, where ten well-known explainable recommender models are implemented in a unified framework. Based on this library, we build several bench- marks for different explainable recommendation tasks. At last, we present many new opportunities brought by our dataset, which are expected to shed some new lights to the explainable recommenda- tion field. Our dataset, library and the related documents have been released at https://reasoner2023.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2202.05012",
        "title": "SUPA: A Lightweight Diagnostic Simulator for Machine Learning in Particle Physics",
        "abstract": "Deep learning methods have gained popularity in high energy physics for fast mod- eling of particle showers in detectors. Detailed simulation frameworks such as the gold standard GEANT4 are computationally intensive, and current deep generative architectures work on discretized, lower resolution versions of the detailed simula- tion. The development of models that work at higher spatial resolutions is currently hindered by the complexity of the full simulation data, and by the lack of simpler, more interpretable benchmarks. Our contribution is SUPA, the SUrrogate PArticle propagation simulator, an algorithm and software package for generating data by simulating simplified particle propagation, scattering and shower development in matter. The generation is extremely fast and easy to use compared to GEANT4, but still exhibits the key characteristics and challenges of the detailed simulation. The proposed simulator generates thousands of particle showers per second on a desktop machine, a speed up of up to 6 orders of magnitudes over GEANT4, and stores detailed geometric information about the shower propagation. SUPA provides much greater flexibility for setting initial conditions and defining multi- ple benchmarks for the development of models. Moreover, interpreting particle showers as point clouds creates a connection to geometric machine learning and provides challenging and fundamentally new datasets for the field.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.04455",
        "title": "RD-Suite: A Benchmark for Ranking Distillation",
        "abstract": "The distillation of ranking models has become an important topic in both academia and industry. In recent years, several advanced methods have been proposed to tackle this problem, often leveraging ranking information from teacher rankers that is absent in traditional classification settings. To date, there is no well- established consensus on how to evaluate this class of models. Moreover, in- consistent benchmarking on a wide range of tasks and datasets make it difficult to assess or invigorate advances in this field. This paper first examines represen- tative prior arts on ranking distillation, and raises three questions to be answered around methodology and reproducibility. To that end, we propose a systematic and unified benchmark, Ranking Distillation Suite (RD-Suite), which is a collection of tasks with 4 large real-world datasets, encompassing two major modalities (textual and numeric) and two applications (standard distillation and distillation transfer). RD-Suite consists of benchmark results that challenge some of the common wis- dom in the field, and the release of datasets with teacher scores and evaluation scripts for future research. RD-Suite paves the way towards better understanding of ranking distillation, facilities more research in this direction, and presents new challenges.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11443",
        "title": "UUKG: Unified Urban Knowledge Graph Dataset for Urban Spatiotemporal Prediction",
        "abstract": "Accurate Urban SpatioTemporal Prediction (USTP) is of great importance to the development and operation of the smart city. As an emerging building block, multi-sourced urban data are usually integrated as urban knowledge graphs (Ur- banKGs) to provide critical knowledge for urban spatiotemporal prediction models. However, existing UrbanKGs are often tailored for specific downstream prediction tasks and are not publicly available, which limits the potential advancement. This paper presents UUKG, the unified urban knowledge graph dataset for knowledge- enhanced urban spatiotemporal predictions. Specifically, we first construct Ur- banKGs consisting of millions of triplets for two metropolises by connecting heterogeneous urban entities such as administrative boroughs, POIs, and road seg- ments. Moreover, we conduct qualitative and quantitative analysis on constructed UrbanKGs and uncover diverse high-order structural patterns, such as hierarchies and cycles, that can be leveraged to benefit downstream USTP tasks. To validate and facilitate the use of UrbanKGs, we implement and evaluate 15 KG embedding methods on the KG completion task and integrate the learned KG embeddings into 9 spatiotemporal models for five different USTP tasks. The extensive experimental results not only provide benchmarks of knowledge-enhanced USTP models under different task settings but also highlight the potential of state-of-the-art high-order structure-aware UrbanKG embedding methods. We hope the proposed UUKG fosters research on urban knowledge graphs and broad smart city applications. The dataset and source code are available at https://github.com/usail-hkust/UUKG/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09803",
        "title": "Framework and Benchmarks for Combinatorial and Mixed-variable Bayesian Optimization",
        "abstract": "This paper introduces a modular framework for Mixed-variable and Combinatorial Bayesian Optimization (MCBO) to address the lack of systematic benchmarking and standardized evaluation in the field. Current MCBO papers often introduce non-diverse or non-standard benchmarks to evaluate their methods, impeding the proper assessment of different MCBO primitives and their combinations. Addi- tionally, papers introducing a solution for a single MCBO primitive often omit benchmarking against baselines that utilize the same methods for the remaining primitives [1\u20134]. This omission is primarily due to the significant implementation overhead involved, resulting in a lack of controlled assessments and an inability to showcase the merits of a contribution effectively. To overcome these chal- lenges, our proposed framework enables an effortless combination of Bayesian Optimization components, and provides a diverse set of synthetic and real-world benchmarking tasks. Leveraging this flexibility, we implement 47 novel MCBO algorithms and benchmark them against seven existing MCBO solvers and five standard black-box optimization algorithms on ten tasks, conducting over 4000 experiments. Our findings reveal a superior combination of MCBO primitives outperforming existing approaches and illustrate the significance of model fit and the use of a trust region. We make our MCBO library available under the MIT license at https://github.com/huawei-noah/HEBO/tree/master/MCBO.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.00716",
        "title": "rPPG-Toolbox: Deep Remote PPG Toolbox",
        "abstract": "Camera-based physiological measurement is a fast growing field of computer vision. Remote photoplethysmography (rPPG) utilizes imaging devices (e.g., cameras) to measure the peripheral blood volume pulse (BVP), and enables cardiac measurement via webcams and smartphones. However, the task is non-trivial with important pre-processing, modeling, and post-processing steps required to obtain state-of-the-art results. Replication of results and benchmarking of new models is critical for scientific progress; however, as with many other applications of deep learning, reliable codebases are not easy to find or use. We present a comprehensive toolbox, rPPG-Toolbox, that contains unsupervised and supervised rPPG models with support for public benchmark datasets, data augmentation, and systematic evaluation: https://github.com/ubicomplab/rPPG-Toolbox",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.05174",
        "title": "GSLB: The Graph Structure Learning Benchmark",
        "abstract": "Graph Structure Learning (GSL) has recently garnered considerable attention due to its ability to optimize both the parameters of Graph Neural Networks (GNNs) and the computation graph structure simultaneously. Despite the proliferation of GSL methods developed in recent years, there is no standard experimental setting or fair comparison for performance evaluation, which creates a great obstacle to understanding the progress in this field. To fill this gap, we systematically analyze the performance of GSL in different scenarios and develop a comprehensive Graph Structure Learning Benchmark (GSLB) curated from 20 diverse graph datasets and 16 distinct GSL algorithms. Specifically, GSLB systematically investigates the characteristics of GSL in terms of three dimensions: effectiveness, robustness, and complexity. We comprehensively evaluate state-of-the-art GSL algorithms in node- and graph-level tasks, and analyze their performance in robust learning and model complexity. Further, to facilitate reproducible research, we have developed an easy-to-use library for training, evaluating, and visualizing different GSL methods. Empirical results of our extensive experiments demonstrate the ability of GSL and reveal its potential benefits on various downstream tasks, offering insights and opportunities for future research. The code of GSLB is available at: https: //github.com/GSL-Benchmark/GSLB.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09030",
        "title": "DiPlomat:\nA Dialogue Dataset for Situated Pragmatic Reasoning",
        "abstract": "Pragmatic reasoning plays a pivotal role in deciphering implicit meanings that frequently arise in real-life conversations and is essential for the development of communicative social agents. In this paper, we introduce a novel challenge, DiPlomat, aiming at benchmarking machines\u2019 capabilities on pragmatic reason- ing and situated conversational understanding. Compared with previous works that treat different figurative expressions (e.g. metaphor, sarcasm) as individual tasks, DiPlomat provides a cohesive framework towards general pragmatic un- derstanding. Our dataset is created through the utilization of Amazon Mechanical Turk (AMT), resulting in a total of 4, 177 multi-turn dialogues. In conjunction with the dataset, we propose two tasks, Pragmatic Identification and Reasoning (PIR) and Conversational Question Answering (CQA). Experimental results with state-of-the-art (SOTA) neural architectures reveal several significant findings: 1) large language models (LLMs) exhibit poor performance in tackling this subjective domain; 2) comprehensive comprehension of context emerges as a critical factor for establishing benign human-machine interactions; 3) current models defect in the application of pragmatic reasoning. As a result, we call on more attention to improve the ability of context understanding, reasoning, and implied meaning modeling.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.12552",
        "title": "SITUATEDGEN: Incorporating Geographical and Temporal Contexts into Generative Commonsense Reasoning",
        "abstract": "Recently, commonsense reasoning in text generation has attracted much attention. Generative commonsense reasoning is the task that requires machines, given a group of keywords, to compose a single coherent sentence with commonsense plausibility. While existing datasets targeting generative commonsense reason- ing focus on everyday scenarios, it is unclear how well machines reason under specific geographical and temporal contexts. We formalize this challenging task as SITUATEDGEN, where machines with commonsense should generate a pair of contrastive sentences given a group of keywords including geographical or temporal entities. We introduce a corresponding English dataset consisting of 8,268 contrastive sentence pairs, which are built upon several existing common- sense reasoning benchmarks with minimal manual labor. Experiments show that state-of-the-art generative language models struggle to generate sentences with commonsense plausibility and still lag far behind human performance. Our dataset is publicly available at https://github.com/yunx-z/situated_gen",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.05443",
        "title": "PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance",
        "abstract": "Although large language models (LLMs) has shown great performance on natural language processing (NLP) in the financial domain, there are no publicly available financial tailtored LLMs, instruction tuning datasets, and evaluation benchmarks, which is critical for continually pushing forward the open-source development of financial artificial intelligence (AI). This paper introduces PIXIU, a comprehensive framework including the first financial LLM based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples to support the fine- tuning, and an evaluation benchmark with 5 tasks and 9 datasets. We first construct the large-scale multi-task instruction data considering a variety of financial tasks, financial document types, and financial data modalities. We then propose a financial LLM called FinMA by fine-tuning LLaMA with the constructed dataset to be able to follow instructions for various financial tasks. To support the evaluation of financial LLMs, we propose a standardized benchmark that covers a set of critical financial tasks, including five financial NLP tasks and one financial prediction task. With this benchmark, we conduct a detailed analysis of FinMA and several existing LLMs, uncovering their strengths and weaknesses in handling critical financial tasks. The model, datasets, benchmark, and experimental results are open-sourced 1 to facilitate future research in financial AI.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.13304",
        "title": "ToolQA: A Dataset for LLM Question Answering with External Tools",
        "abstract": "\nLarge Language Models (LLMs) have demonstrated impressive performance in various NLP tasks, but they still suffer from challenges such as hallucination and weak numerical reasoning. To overcome these challenges, external tools can be used to enhance LLMs\u2019 question-answering abilities. However, current evaluation methods do not distinguish between questions that can be answered using LLMs\u2019 internal knowledge and those that require external information through tool use. To address this issue, we introduce a new dataset called ToolQA, which is designed to faithfully evaluate LLMs\u2019 ability to use external tools for question answering. Our development of ToolQA involved a scalable, automated process for dataset curation, along with 13 specialized tools designed for interaction with external knowledge in order to answer questions. Importantly, we strive to minimize the overlap between our benchmark data and LLMs\u2019 pre-training data, enabling a more precise evaluation of LLMs\u2019 tool-use reasoning abilities. We conducted an in-depth diagnosis of existing tool-use LLMs to highlight their strengths, weaknesses, and potential improvements. Our findings set a new benchmark for evaluating LLMs and suggest new directions for future advancements. Our data and code are freely available for the broader scientific community on GitHub 2.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.07934",
        "title": "BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information",
        "abstract": "Automated reasoning with unstructured natural text is a key requirement for many potential applications of NLP and for developing robust AI systems. Recently, Language Models (LMs) have demonstrated complex reasoning capacities even without any finetuning. However, existing evaluation for automated reasoning assumes access to a consistent and coherent set of information over which models reason. When reasoning in the real-world, the available information is frequently inconsistent or contradictory, and therefore models need to be equipped with a strategy to resolve such conflicts when they arise. One widely-applicable way of resolving conflicts is to impose preferences over information sources (e.g., based on source credibility or information recency) and adopt the source with higher preference. In this paper, we formulate the problem of reasoning with contradictory information guided by preferences over sources as the classical problem of defeasible reasoning, and develop a dataset called BoardgameQA for measuring the reasoning capacity of LMs in this setting. BoardgameQA also incorporates reasoning with implicit background knowledge, to better reflect reasoning problems in downstream applications. We benchmark various LMs on BoardgameQA and the results reveal a significant gap in the reasoning capacity of state-of-the-art LMs on this problem, showing that reasoning with conflicting information does not surface out-of-the-box in LMs. While performance can be improved with finetuning, it nevertheless remains poor.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.02394",
        "title": "NeuroEvoBench: Benchmarking Evolutionary Optimizers for Deep Learning Applications",
        "abstract": "Recently, the Deep Learning community has become interested in evolutionary opti- mization (EO) as a means to address hard optimization problems, e.g. meta-learning through long inner loop unrolls or optimizing non-differentiable operators. One core reason for this trend has been the recent innovation in hardware acceleration and compatible software \u2013 making distributed population evaluations much easier than before. Unlike for gradient descent-based methods though, there is a lack of hyperparameter understanding and best practices for EO \u2013 arguably due to severely less \u201cgraduate student descent\u201d and benchmarking being performed for EO meth- ods. Additionally, classical benchmarks from the evolutionary community provide few practical insights for Deep Learning applications. This poses challenges for newcomers to hardware-accelerated EO and hinders significant adoption. Hence, we establish a new benchmark of EO methods (NeuroEvoBench) tailored toward Deep Learning applications and exhaustively evaluate traditional and meta-learned EO. We investigate core scientific questions including resource allocation, fitness shaping, normalization, regularization & scalability of EO. The benchmark is open-sourced at https://github.com/neuroevobench/neuroevobench un- der Apache-2.0 license.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.19257",
        "title": "A High-Resolution Dataset for Instance Detection with Multi-View Instance Capture\n",
        "abstract": "Instance detection (InsDet) is a long-lasting problem in robotics and computer vision, aiming to detect object instances (predefined by some visual examples) in a cluttered scene. Despite its practical significance, its advancement is overshadowed by Object Detection, which aims to detect objects belonging to some predefined classes. One major reason is that current InsDet datasets are too small in scale by today\u2019s standards. For example, the popular InsDet dataset GMU (published in 2016) has only 23 instances, far less than COCO (80 classes), a well-known object detection dataset published in 2014. We are motivated to introduce a new InsDet dataset and protocol. First, we define a realistic setup for InsDet: training data consists of multi-view instance captures, along with diverse scene images allowing synthesizing training images by pasting instance images on them with free box annotations. Second, we release a real-world database, which contains multi-view capture of 100 object instances, and high-resolution (6k\u00d78k) testing images. Third, we extensively study baseline methods for InsDet on our dataset, analyze their performance and suggest future work. Somewhat surprisingly, using the off-the-shelf class-agnostic segmentation model (Segment Anything Model, SAM) and the self-supervised feature representation DINOv2 performs the best, achieving >10 AP better than end-to-end trained InsDet models that repurpose object detectors (e.g., FasterRCNN and RetinaNet).",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.15599",
        "title": "OCEANBENCH:\nThe Sea Surface Height Edition",
        "abstract": "The ocean is a crucial component of the Earth\u2019s system. It profoundly influences human activities and plays a critical role in climate regulation. Our understand- ing has significantly improved over the last decades with the advent of satellite remote sensing data, allowing us to capture essential sea surface quantities over the globe, e.g., sea surface height (SSH). Despite their ever-increasing abundance, ocean satellite data presents challenges for information extraction due to their sparsity and irregular sampling, signal complexity, and noise. Machine learning (ML) techniques have demonstrated their capabilities in dealing with large-scale, complex signals. Therefore we see an opportunity for these ML models to har- ness the full extent of the information contained in ocean satellite data. However, data representation and relevant evaluation metrics can be the defining factors when determining the success of applied ML. The processing steps from the raw observation data to a ML-ready state and from model outputs to interpretable quantities require domain expertise, which can be a significant barrier to entry for ML researchers. In addition, imposing fixed processing steps, like committing to specific variables, regions, and geometries, will narrow the scope of ML models and their potential impact on real-world applications. OceanBench is a unifying framework that provides standardized processing steps that comply with domain- expert standards. It is designed with a flexible and pedagogical abstraction: it a) provides plug-and-play data and pre-configured pipelines for ML researchers to benchmark their models w.r.t. ML and domain-related baselines and b) provides a transparent and configurable framework for researchers to customize and extend the pipeline for their tasks. In this work, we demonstrate the OceanBench framework through a first edition dedicated to SSH interpolation challenges. We provide datasets and ML-ready benchmarking pipelines for the long-standing problem of interpolating observations from simulated ocean satellite data, multi-modal and multi-sensor fusion issues, and transfer-learning to real ocean satellite observations. The OceanBench framework is available at github.com/jejjohnson/oceanbench and the dataset registry is available at github.com/quentinf00/oceanbench-data-registry.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13353",
        "title": "RenderMe-360: A Large Digital Asset Library and Benchmarks Towards High-fidelity Head Avatars",
        "abstract": "Synthesizing high-fidelity head avatars is a central prob- lem for many applications on AR, VR, and Metaverse. While head avatar synthesis algorithms have advanced rapidly, the best ones still face great obstacles in real-world sce- narios. One of the vital causes is the inadequate datasets \u2013 1) current public datasets can only support researchers to explore high-fidelity head avatars in one or two task direc- tions, such as viewpoint, head pose, hairstyle, or facial ex-\npression; 2) these datasets usually contain digital head as- sets with limited data volume, and narrow distribution over different attributes, such as expressions, ages, and acces- sories. In this paper, we present RenderMe-360, a compre- hensive 4D human head dataset to drive advance in head avatar algorithms across different scenarios. RenderMe- 360 contains massive data assets, with 243+ million com- plete head frames of over 800k video sequences from 500 different identities captured by synchronized HD multi-view cameras at 30 FPS. It is a large-scale digital library for  (a) High Fidelity\n(b) High Diversity\n  (c) Rich Annotations\narXiv:2305.13353v1 [cs.CV] 22 May 2023\nhead avatars with three key attributes: 1) High Fidelity: all subjects are captured by 60 synchronized, high-resolution 2K cameras to collect their portrait data in 360 degrees. 2) High Diversity: The collected subjects vary from differ- ent ages, eras, ethnicities, and cultures, providing abundant materials with distinctive styles in appearance and geom- etry. Moreover, each subject is asked to perform various dynamic motions, such as expressions and head rotations, which further extend the richness of assets. 3) Rich Annota- tions: the dataset provides annotations with different gran- ularities: cameras\u2019 parameters, background matting, scan, 2D as well as 3D facial landmarks, FLAME fitting, and text description.\nBased on the dataset, we build a comprehensive bench- mark for head avatar research, with 16 state-of-the-art methods performed on five main tasks: novel view synthe- sis, novel expression synthesis, hair rendering, hair edit- ing, and talking head generation. Our experiments un- cover the strengths and weaknesses of state-of-the-art meth- ods, showing that extra efforts are needed for them to per- form in such diverse scenarios. RenderMe-360 opens the door for future exploration in modern head avatars. All of the data, code, and models will be publicly available at https://RenderMe-360.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.05685",
        "title": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https: //github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08571",
        "title": "GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image",
        "abstract": "The extraordinary ability of generative models to generate photographic images has intensified concerns about the spread of disinformation, thereby leading to the demand for detectors capable of distinguishing between AI-generated fake images and real images. However, the lack of large datasets containing images from the most advanced image generators poses an obstacle to the development of such detectors. In this paper, we introduce the GenImage dataset, which has the following advantages: 1) Plenty of Images, including over one million pairs of AI-generated fake images and collected real images. 2) Rich Image Content, encompassing a broad range of image classes. 3) State-of-the-art Generators, synthesizing images with advanced diffusion models and GANs. The aforemen- tioned advantages allow the detectors trained on GenImage to undergo a thorough evaluation and demonstrate strong applicability to diverse images. We conduct a comprehensive analysis of the dataset and propose two tasks for evaluating the detection method in resembling real-world scenarios. The cross-generator image classification task measures the performance of a detector trained on one generator when tested on the others. The degraded image classification task assesses the capa- bility of the detectors in handling degraded images such as low-resolution, blurred, and compressed images. With the GenImage dataset, researchers can effectively expedite the development and evaluation of superior AI-generated image detectors in comparison to prevailing methodologies.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11551",
        "title": "IMP-MARL: a Suite of Environments for Large-scale Infrastructure Management Planning via MARL",
        "abstract": "We introduce IMP-MARL, an open-source suite of multi-agent reinforcement learning (MARL) environments for large-scale Infrastructure Management Plan- ning (IMP), offering a platform for benchmarking the scalability of cooperative MARL methods in real-world engineering applications. In IMP, a multi-component engineering system is subject to a risk of failure due to its components\u2019 damage con- dition. Specifically, each agent plans inspections and repairs for a specific system component, aiming to minimise maintenance costs while cooperating to minimise system failure risk. With IMP-MARL, we release several environments including one related to offshore wind structural systems, in an effort to meet today\u2019s needs to improve management strategies to support sustainable and reliable energy systems. Supported by IMP practical engineering environments featuring up to 100 agents, we conduct a benchmark campaign, where the scalability and performance of state-of-the-art cooperative MARL methods are compared against expert-based heuristic policies. The results reveal that centralised training with decentralised execution methods scale better with the number of agents than fully centralised or decentralised RL approaches, while also outperforming expert-based heuristic policies in most IMP environments. Based on our findings, we additionally out- line remaining cooperation and scalability challenges that future MARL methods should still address. Through IMP-MARL, we encourage the implementation of new environments and the further development of MARL methods.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.06939",
        "title": "Multimodal C4:\nAn Open, Billion-scale Corpus of Images Interleaved with Text",
        "abstract": "\nIn-context vision and language models like Flamingo [2] support arbitrarily in- terleaved sequences of images and text as input. This format not only enables few-shot learning via interleaving independent supervised (image, text) examples, but also, more complex prompts involving interaction between images, e.g., \u201cWhat do image A and image B have in common?\u201d To support this interface, pretraining occurs over web corpora that similarly contain interleaved images+text. To date, however, large-scale data of this form have not been publicly available.\nWe release Multimodal C4 (mmc4), an augmentation of the popular text-only c4 corpus2 with images interleaved. We use a linear assignment algorithm to place images into longer bodies of text using CLIP features [24], a process that we show outperforms alternatives. mmc4 spans everyday topics like cooking, travel, technology, etc. A manual inspection of a random sample of documents shows that a vast majority (88%) of images are topically relevant, and that linear assignment frequently selects individual sentences specifically well-aligned with each image (80%). After filtering NSFW images, ads, etc., the resulting mmc4 corpus consists of 101.2M documents with 571M images interleaved in 43B English tokens.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.07921",
        "title": "OpenIllumination: A Multi-Illumination Dataset for Inverse Rendering Evaluation on Real Objects",
        "abstract": "We introduce OpenIllumination, a real-world dataset containing over 108K im- ages of 64 objects with diverse materials, captured under 72 camera views and a large number of different illuminations. For each image in the dataset, we provide accurate camera parameters, illumination ground truth, and foreground segmentation masks. Our dataset enables the quantitative evaluation of most in- verse rendering and material decomposition methods for real objects. We examine several state-of-the-art inverse rendering methods on our dataset and compare their performances. The dataset and code can be found on the project page: https://oppo-us-research.github.io/OpenIllumination.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.10188",
        "title": "WordScape: a Pipeline to extract multilingual, visually rich Documents with Layout Annotations from Web Crawl Data",
        "abstract": "We introduce WordScape, a novel pipeline for the creation of cross-disciplinary, multilingual corpora comprising millions of pages with annotations for document layout detection. Relating visual and textual items on document pages has gained further significance with the advent of multimodal models. Various approaches proved effective for visual question answering or layout segmentation. However, the interplay of text, tables, and visuals remains challenging for a variety of document understanding tasks. In particular, many models fail to generalize well to diverse domains and new languages due to insufficient availability of training data. WordScape addresses these limitations. Our automatic annotation pipeline parses the Open XML structure of Word documents obtained from the web, jointly providing layout-annotated document images and their textual representations. In turn, WordScape offers unique properties as it (1) leverages the ubiquity of the Word file format on the internet, (2) is readily accessible through the Common Crawl web corpus, (3) is adaptive to domain-specific documents, and (4) offers culturally and linguistically diverse document pages with natural semantic structure and high-quality text. Together with the pipeline, we will additionally release 9.5M urls to word documents which can be processed using WordScape to create a dataset of over 40M pages. Finally, we investigate the quality of text and layout annotations extracted by WordScape, assess the impact on document understanding benchmarks, and demonstrate that manual labeling costs can be substantially reduced.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.13384",
        "title": "DiffInfinite: Large Mask-Image Synthesis via Parallel Random Patch Diffusion in Histopathology",
        "abstract": "\nWe present DiffInfinite, a hierarchical diffusion model that generates arbitrarily large histological images while preserving long-range correlation structural infor- mation. Our approach first generates synthetic segmentation masks, subsequently used as conditions for the high-fidelity generative diffusion process. The proposed sampling method can be scaled up to any desired image size while only requiring\nsmall patches for fast training. Moreover, it can be parallelized more efficiently than previous large-content generation methods while avoiding tiling artifacts. The training leverages classifier-free guidance to augment a small, sparsely an- notated dataset with unlabelled data. Our method alleviates unique challenges in histopathological imaging practice: large-scale information, costly manual anno- tation, and protective data handling. The biological plausibility of DiffInfinite data is evaluated in a survey by ten experienced pathologists as well as a downstream classification and segmentation task. Samples from the model score strongly on anti-copying metrics which is relevant for the protection of patient data",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.03310",
        "title": "LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning",
        "abstract": "Lifelong learning offers a promising paradigm of building a generalist agent that learns and adapts over its lifespan. Unlike traditional lifelong learning problems in image and text domains, which primarily involve the transfer of declarative knowl- edge of entities and concepts, lifelong learning in decision-making (LLDM) also necessitates the transfer of procedural knowledge, such as actions and behaviors. To advance research in LLDM, we introduce LIBERO, a novel benchmark of lifelong learning for robot manipulation. Specifically, LIBERO highlights five key research topics in LLDM: 1) how to efficiently transfer declarative knowledge, procedural knowledge, or the mixture of both; 2) how to design effective policy architectures and 3) effective algorithms for LLDM; 4) the robustness of a lifelong learner with respect to task ordering; and 5) the effect of model pretraining for LLDM. We develop an extendible procedural generation pipeline that can in principle generate infinitely many tasks. For benchmarking purpose, we create four task suites (130 tasks in total) that we use to investigate the above-mentioned research topics. To support sample-efficient learning, we provide high-quality human-teleoperated demonstration data for all tasks. Our extensive experiments present several insightful or even unexpected discoveries: sequential finetuning outperforms existing lifelong learning methods in forward transfer, no single visual encoder architecture excels at all types of knowledge transfer, and naive supervised pretraining can hinder agents\u2019 performance in the subsequent LLDM",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.13867",
        "title": "Mathematical Capabilities of ChatGPT",
        "abstract": "We investigate the mathematical capabilities of two iterations of ChatGPT (released 9-January- 2023 and 30-January-2023) and of GPT-4 by testing them on publicly available datasets, as well as hand-crafted ones, using a novel methodology. In contrast to formal mathematics, where large databases of formal proofs are available (e.g., the Lean Mathematical Library), current datasets of natural-language mathematics, used to benchmark language models, either cover only elementary mathematics or are very small. We address this by publicly releasing two new datasets: GHOSTS and miniGHOSTS. These are the first natural-language datasets curated by working researchers in mathematics that (1) aim to cover graduate-level mathematics, (2) provide a holistic overview of the mathematical capabilities of language models, and (3) distinguish multiple dimensions of mathematical reasoning. These datasets also test whether ChatGPT and GPT-4 can be helpful assistants to professional mathematicians by emulating use cases that arise in the daily professional activities of mathematicians. We benchmark the models on a range of fine-grained performance metrics. For advanced mathematics, this is the most detailed evaluation effort to date. We find that ChatGPT can be used most successfully as a mathematical assistant for querying facts, acting as a mathematical search engine and knowledge base interface. GPT-4 can additionally be used for undergraduate-level mathematics but fails on graduate-level difficulty. Contrary to many positive reports in the media about GPT-4 and ChatGPT\u2019s exam-solving abilities (a potential case of selection bias), their overall mathematical performance is well below the level of a graduate student. Hence, if your goal is to use ChatGPT to pass a graduate-level math exam, you would be better off copying from your average peer!",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.04751",
        "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources",
        "abstract": "In this work we explore recent advances in instruction-tuning language models on a range of open instruction-following datasets. Despite recent claims that open models can be on par with state-of-the-art proprietary models, these claims are often accompanied by limited evaluation, making it difficult to compare models across the board and determine the utility of various resources. We provide a large set of instruction-tuned models from 6.7B to 65B parameters in size, trained on 12 instruc- tion datasets ranging from manually curated (e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and systematically evaluate them on their factual knowledge, reasoning, multilinguality, coding, safety, and open-ended instruction following abilities through a collection of automatic, model-based, and human-based metrics. We further introduce T\u00dcLU , our best performing instruction-tuned model suite finetuned on a combination of high-quality open resources.\nOur experiments show that different instruction-tuning datasets can uncover or enhance specific skills, while no single dataset (or combination) provides the best performance across all evaluations. Interestingly, we find that model and human preference-based evaluations fail to reflect differences in model capabilities exposed by benchmark-based evaluations, suggesting the need for the type of systemic evaluation performed in this work. Our evaluations show that the best model in any given evaluation reaches on average 87% of ChatGPT performance, and 73% of GPT-4 performance, suggesting that further investment in building better base models and instruction-tuning data is required to close the gap. We release our instruction-tuned models, including a fully finetuned 65B T\u00dcLU , along with our code, data, and evaluation framework to facilitate future research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.03517",
        "title": "SOUNDCAM: A Dataset for Finding Humans Using Room Acoustics",
        "abstract": "A room\u2019s acoustic properties are a product of the room\u2019s geometry, the objects within the room, and their specific positions. A room\u2019s acoustic properties can be characterized by its impulse response (RIR) between a source and listener location, or roughly inferred from recordings of natural signals present in the room. Variations in the positions of objects in a room can effect measurable changes in the room\u2019s acoustic properties, as characterized by the RIR. Existing datasets of RIRs either do not systematically vary positions of objects in an environment, or they consist of only simulated RIRs. We present SOUNDCAM, the largest dataset of unique RIRs from in-the-wild rooms publicly released to date.1 It includes 5,000 10-channel real-world measurements of room impulse responses and 2,000 10-channel recordings of music in three different rooms, including a controlled acoustic lab, an in-the-wild living room, and a conference room, with different humans in positions throughout each room. We show that these measurements can be used for interesting tasks, such as detecting and identifying humans, and tracking their positions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.07494",
        "title": "A Comprehensive Study on Large-Scale Graph Training: Benchmarking and Rethinking",
        "abstract": "Large-scale graph training is a notoriously challenging problem for graph neu- ral networks (GNNs). Due to the nature of evolving graph structures into the training process, vanilla GNNs usually fail to scale up, limited by the GPU memory space. Up to now, though numerous scalable GNN architectures have been proposed, we still lack a comprehensive survey and fair benchmark of this reservoir to find the rationale for designing scalable GNNs. To this end, we first systematically formulate the representative methods of large-scale graph training into several branches and further establish a fair and consistent bench- mark for them by a greedy hyperparameter searching. In addition, regarding efficiency, we theoretically evaluate the time and space complexity of various branches and empirically compare them w.r.t GPU memory usage, through- put, and convergence. Furthermore, We analyze the pros and cons for various branches of scalable GNNs and then present a new ensembling training man- ner, named EnGCN, to address the existing issues. Our code is available at https://github.com/VITA-Group/Large_Scale_GCN_Benchmarking.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.11606",
        "title": "StoryBench: A Multifaceted Benchmark for Continuous Story Visualization",
        "abstract": "Generating video stories from text prompts is a complex task. In addition to having high visual quality, videos need to realistically adhere to a sequence of text prompts whilst being consistent throughout the frames. Creating a benchmark for video gen- eration requires data annotated over time, which contrasts with the single caption used often in video datasets. To fill this gap, we collect comprehensive human an- notations on three existing datasets, and introduce StoryBench: a new, challenging multi-task benchmark to reliably evaluate forthcoming text-to-video models. Our benchmark includes three video generation tasks of increasing difficulty: action execution, where the next action must be generated starting from a conditioning video; story continuation, where a sequence of actions must be executed starting from a conditioning video; and story generation, where a video must be generated from only text prompts. We evaluate small yet strong text-to-video baselines, and show the benefits of training on story-like data algorithmically generated from existing video captions. Finally, we establish guidelines for human evaluation of video stories, and reaffirm the need of better automatic metrics for video generation. StoryBench aims at encouraging future research efforts in this exciting new area.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.09666",
        "title": "AbdomenAtlas-8K: Annotating 8,000 CT Volumes for Multi-Organ Segmentation in Three Weeks",
        "abstract": "Annotating medical images, particularly for organ segmentation, is laborious and time-consuming. For example, annotating an abdominal organ requires an estimated rate of 30\u201360 minutes per CT volume based on the expertise of an annotator and the size, visibility, and complexity of the organ. Therefore, publicly available datasets for multi-organ segmentation are often limited in data size and organ diversity. This paper proposes an active learning procedure to expedite the annotation process for organ segmentation and creates the largest multi-organ dataset (by far) with the spleen, liver, kidneys, stomach, gallbladder, pancreas, aorta, and IVC annotated in 8,448 CT volumes, equating to 3.2 million slices. The conventional annotation methods would take an experienced annotator up to 1,600 weeks (or roughly 30.8 years) to complete this task. In contrast, our annotation procedure has accomplished this task in three weeks (based on an 8-hour workday, five days a week) while maintaining a similar or even better annotation quality. This achievement is attributed to three unique properties of our method: (1) label bias reduction using multiple pre-trained segmentation models, (2) effective error detection in the model predictions, and (3) attention guidance for annotators to make corrections on the most salient errors. Furthermore, we summarize the taxonomy of common errors made by AI algorithms and annotators. This allows for continuous improvement of AI and annotations, significantly reducing the annotation costs required to create large-scale datasets for a wider variety of medical imaging tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.05934",
        "title": "ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition",
        "abstract": "Sign languages are used as a primary language by approximately 70 million D/deaf people world-wide. However, most communication technologies operate in spoken and written languages, creating inequities in access. To help tackle this problem, we release ASL Citizen, the first crowdsourced Isolated Sign Language Recognition (ISLR) dataset, collected with consent and containing 83,399 videos for 2,731 distinct signs filmed by 52 signers in a variety of environments. We propose that this dataset be used for sign language dictionary retrieval for American Sign Language (ASL), where a user demonstrates a sign to their webcam to retrieve matching signs from a dictionary. We show that training supervised machine learning classifiers with our dataset advances the state-of-the-art on metrics relevant for dictionary retrieval, achieving 63% accuracy and a recall-at-10 of 91%, evaluated entirely on videos of users who are not present in the training or validation sets.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.04618",
        "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations",
        "abstract": "This paper reexamines the research on out-of-distribution (OOD) robustness in the field of NLP. We find that the distribution shift settings in previous studies com- monly lack adequate challenges, hindering the accurate evaluation of OOD robust- ness. To address these issues, we propose a benchmark construction protocol that ensures clear differentiation and challenging distribution shifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution robustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we conduct a series of experiments on pre- trained language models for analysis and evaluation of OOD robustness. First, for vanilla fine-tuning, we examine the relationship between in-distribution (ID) and OOD performance. We identify three typical types that unveil the inner learning mechanism, which could potentially facilitate the forecasting of OOD robustness, correlating with the advancements on ID datasets. Then, we evaluate 5 classic meth- ods on BOSS and find that, despite exhibiting some effectiveness in specific cases, they do not offer significant improvement compared to vanilla fine-tuning. Further, we evaluate 5 LLMs with various adaptation paradigms and find that when sufficient ID data is available, fine-tuning domain-specific models outperform LLMs on ID examples significantly. However, in the case of OOD instances, prioritizing LLMs with in-context learning yields better results. We identify that both fine-tuned small models and LLMs face challenges in effectively addressing downstream tasks. The code is public at https://github.com/lifan-yuan/OOD_NLP.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1704.05426",
        "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
        "abstract": "\nThis paper introduces the Multi-Genre Natu- ral Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora avail- able for natural language inference (a.k.a. rec- ognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by of- fering data from ten distinct genres of written and spoken English, making it possible to eval- uate systems on nearly the full complexity of the language, while supplying an explicit set- ting for evaluating cross-genre domain adap- tation. In addition, an evaluation using exist- ing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2105.07464",
        "title": "FEW-NERD: A Few-shot Named Entity Recognition Dataset",
        "abstract": "Recently, considerable literature has grown up around the theme of few-shot named entity recognition (NER), but little published bench- mark data specifically focused on the practical and challenging task. Current approaches col- lect existing supervised NER datasets and re- organize them into the few-shot setting for em- pirical study. These strategies conventionally aim to recognize coarse-grained entity types with few examples, while in practice, most unseen entity types are fine-grained. In this paper, we present FEW-NERD, a large-scale human-annotated few-shot NER dataset with a hierarchy of 8 coarse-grained and 66 fine- grained entity types. FEW-NERD consists of 188,238 sentences from Wikipedia, 4,601,160 words are included and each is annotated as context or a part of a two-level entity type. To the best of our knowledge, this is the first few-shot NER dataset and the largest human- crafted NER dataset. We construct bench- mark tasks with different emphases to com- prehensively assess the generalization capabil- ity of models. Extensive empirical results and analysis show that FEW-NERD is challeng- ing and the problem requires further research. We make FEW-NERD public at https:// ningding97.github.io/fewnerd/. ",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1606.05250",
        "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
        "abstract": "We present the Stanford Question Answer- ing Dataset (SQuAD), a new reading compre- hension dataset consisting of 100,000+ ques- tions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the cor- responding reading passage. We analyze the dataset to understand the types of reason- ing required to answer the questions, lean- ing heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple base- line (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2012.15349",
        "title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis",
        "abstract": "We introduce DynaSent (\u2018Dynamic Senti- ment\u2019), a new English-language benchmark task for ternary (positive/negative/neutral) sen- timent analysis. DynaSent combines natu- rally occurring sentences with sentences cre- ated using the open-source Dynabench Plat- form, which facilities human-and-model-in- the-loop dataset creation. DynaSent has a total of 121,634 sentences, each validated by five crowdworkers, and its development and test splits are designed to produce chance perfor- mance for even the best models we have been able to develop; when future models solve this task, we will use them to create DynaSent ver- sion 2, continuing the dynamic evolution of this benchmark. Here, we report on the dataset creation effort, focusing on the steps we took to increase quality and reduce artifacts. We also present evidence that DynaSent\u2019s Neutral category is more coherent than the compara- ble category in other benchmarks, and we mo- tivate training models from scratch for each round over successive fine-tuning.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2203.09509",
        "title": "TOXIGEN: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
        "abstract": "Toxic language detection systems often falsely flag text that contains minority group men- tions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic lan- guage. To help mitigate these issues, we cre- ate TOXIGEN, a new large-scale and machine- generated dataset of 274k toxic and benign statements about 13 minority groups. We de- velop a demonstration-based prompting frame- work and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model (Brown et al., 2020). Controlling ma- chine generation in this way allows TOXIGEN to cover implicitly toxic text at a larger scale, and about more demographic groups, than pre- vious resources of human-written text. We conduct a human evaluation on a challeng- ing subset of TOXIGEN and find that annota- tors struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data im- proves its performance on human-written data substantially. We also demonstrate that TOXI- GEN can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset. Our code and data can be found at https:// github.com/microsoft/ToxiGen.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2109.05322",
        "title": "Latent Hatred: A Benchmark for Understanding Implicit Hate Speech",
        "abstract": "Hate speech has grown significantly on social media, causing serious consequences for vic- tims of all demographics. Despite much at- tention being paid to characterize and detect discriminatory speech, most work has focused on explicit or overt hate speech, failing to ad- dress a more pervasive form based on coded or indirect language. To fill this gap, this work introduces a theoretically-justified taxon- omy of implicit hate speech and a benchmark corpus with fine-grained labels for each mes- sage and its implication. We present system- atic analyses of our dataset using contempo- rary baselines to detect and explain implicit hate speech, and we discuss key features that challenge existing models. This dataset will continue to serve as a useful benchmark for un- derstanding this multifaceted issue. To down- load the data, see https://github.com/ GT-SALT/implicit-hate",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1910.14599",
        "title": "Adversarial NLI: A New Benchmark for Natural Language Understanding",
        "abstract": "We introduce a new large-scale NLI bench- mark dataset, collected via an iterative, ad- versarial human-and-model-in-the-loop proce- dure. We show that training models on this new dataset leads to state-of-the-art perfor- mance on a variety of popular NLI bench- marks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-the- art models, and shows that non-expert annota- tors are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2110.01799",
        "title": "ContractNLI: A Dataset for Document-level Natural Language Inference for Contracts",
        "abstract": "Reviewing contracts is a time-consuming pro- cedure that incurs large expenses to companies and social inequality to those who cannot af- ford it. In this work, we propose document- level natural language inference (NLI) for con- tracts, a novel, real-world application of NLI that addresses such problems. In this task, a system is given a set of hypotheses (such as \u201cSome obligations of Agreement may survive termination.\u201d) and a contract, and it is asked to classify whether each hypothesis is entailed by, contradicting to or not mentioned by (neu- tral to) the contract as well as identifying ev- idence for the decision as spans in the con- tract. We annotated and release the largest cor- pus to date consisting of 607 annotated con- tracts. We then show that existing models fail badly on our task and introduce a strong baseline, which (1) models evidence identifi- cation as multi-label classification over spans instead of trying to predict start and end to- kens, and (2) employs more sophisticated con- text segmentation for dealing with long docu- ments. We also show that linguistic character- istics of contracts, such as negations by excep- tions, are contributing to the difficulty of this task and that there is much room for improve- ment.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2201.05955",
        "title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation",
        "abstract": "A recurring challenge of crowdsourcing NLP datasets at scale is that human writers often rely on repetitive patterns when crafting ex- amples, leading to a lack of linguistic diver- sity. We introduce a novel approach for dataset creation based on worker and AI collabo- ration, which brings together the generative strength of language models and the evaluative strength of humans. Starting with an existing dataset, MultiNLI for natural language infer- ence (NLI), our approach uses dataset cartog- raphy to automatically identify examples that demonstrate challenging reasoning patterns, and instructs GPT-3 to compose new exam- ples with similar patterns. Machine generated examples are then automatically filtered, and finally revised and labeled by human crowd- workers. The resulting dataset, WANLI, con- sists of 107,885 NLI examples and presents unique empirical strengths over existing NLI datasets. Remarkably, training a model on WANLI improves performance on eight out- of-domain test sets we consider, including by 11% on HANS and 9% on Adversarial NLI, compared to training on the 4\u00d7 larger MultiNLI. Moreover, it continues to be more effective than MultiNLI augmented with other NLI datasets. Our results demonstrate the promise of leveraging natural language gener- ation techniques and re-imagining the role of humans in the dataset creation process.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.16225",
        "title": "CLEANCONLL: A Nearly Noise-Free Named Entity Recognition Dataset",
        "abstract": "The CoNLL-03 corpus is arguably the most well-known and utilized benchmark dataset for named entity recognition (NER). However, prior works found significant numbers of an- notation errors, incompleteness, and inconsis- tencies in the data. This poses challenges to objectively comparing NER approaches and an- alyzing their errors, as current state-of-the-art models achieve F1-scores that are comparable to or even exceed the estimated noise level in CoNLL-03. To address this issue, we present a comprehensive relabeling effort assisted by automatic consistency checking that corrects 7.0% of all labels in the English CoNLL-03. Our effort adds a layer of entity linking annota- tion both for better explainability of NER labels and as additional safeguard of annotation qual- ity. Our experimental evaluation finds not only that state-of-the-art approaches reach signifi- cantly higher F1-scores (97.1%) on our data, but crucially that the share of correct predic- tions falsely counted as errors due to annotation noise drops from 47% to 6%. This indicates that our resource is well suited to analyze the remaining errors made by state-of-the-art mod- els, and that the theoretical upper bound even on high resource, coarse-grained NER is not yet reached. To facilitate such analysis, we make CLEANCONLL publicly available to the research community1.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2405.11865",
        "title": "CoNLL#: Fine-grained Error Analysis and a Corrected Test Set for CoNLL-03 English",
        "abstract": "\nModern named entity recognition systems have steadily improved performance in the age of larger and more powerful neural models. However, over the past several years, the state-of-the-art has seemingly hit another plateau on the benchmark CoNLL-03 English dataset. In this paper, we perform a deep dive into the test outputs of the highest-performing NER models, conducting a fine-grained evaluation of their performance by introducing new document-level annotations on the test set. We go beyond F1 scores by categorizing errors in order to interpret the true state of the art for NER and guide future work. We review previous attempts at correcting the various flaws of the test set and introduce CoNLL#, a new corrected version of the test set that addresses its systematic and most prevalent errors, allowing for low-noise, interpretable error analysis.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2212.09306",
        "title": "E-NER \u2014 An Annotated Named Entity Recognition Corpus of Legal Text",
        "abstract": "Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models re- quires an annotated data set, which can be a time-consuming labour-intensive task. Never- theless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a signifi- cant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a pub- licly available legal NER data set, called E- NER, based on legal company filings available from the US Securities and Exchange Commis- sion\u2019s EDGAR data set. Training a number of different NER algorithms on the general En- glish CoNLL-2003 corpus but testing on our test collection confirmed significant degrada- tions in accuracy, as measured by the F1-score, of between 29.4% and 60.4%, compared to training and testing on the E-NER collection.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.16156",
        "title": "From Text to Multimodal: A Comprehensive Survey of Adversarial Example Generation in Question Answering Systems",
        "abstract": "Integrating adversarial machine learning with Question Answering (QA) systems has emerged as a critical area for understanding the vulnerabilities and robust- ness of these systems. This article aims to comprehensively review adversarial example-generation techniques in the QA field, including textual and multimodal contexts. We examine the techniques employed through systematic categoriza- tion, providing a comprehensive, structured review. Beginning with an overview of traditional QA models, we traverse the adversarial example generation by exploring rule-based perturbations and advanced generative models. We then extend our research to include multimodal QA systems, analyze them across var- ious methods, and examine generative models, seq2seq architectures, and hybrid methodologies. Our research grows to different defense strategies, adversarial datasets, and evaluation metrics and illustrates the comprehensive literature on adversarial QA. Finally, the paper considers the future landscape of adversarial question generation, highlighting potential research directions that can advance textual and multimodal QA systems in the context of adversarial challenges.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1611.09830",
        "title": "NEWSQA: A MACHINE COMPREHENSION DATASET",
        "abstract": "We present NewsQA, a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and an- swers based on a set of over 10,000 news articles from CNN, with answers consist- ing of spans of text from the corresponding articles. We collect this dataset through a four-stage process designed to solicit exploratory questions that require reasoning. A thorough analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing textual entailment. We measure human performance on the dataset and compare it to several strong neural models. The performance gap between humans and machines (0.198 in F1) indicates that significant progress can be made on NewsQA through future research. The dataset is freely available athttps://datasets.maluuba.com/NewsQA.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1704.05179",
        "title": "SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine",
        "abstract": "We publicly release a new large-scale dataset, called SearchQA, for machine comprehension, or question-answering. Unlike recently released datasets, such as DeepMind CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to reflect a full pipeline of general question-answering. That is, we start not from an existing article and generate a question-answer pair, but start from an ex- isting question-answer pair, crawled from J! Archive, and augment it with text snip- pets retrieved by Google. Following this approach, we built SearchQA, which con- sists of more than 140k question-answer pairs with each pair having 49.6 snippets on average. Each question-answer-context tuple of the SearchQA comes with ad- ditional meta-data such as the snippet\u2019s URL, which we believe will be valuable resources for future research. We conduct human evaluation as well as test two base- line methods, one simple word selection and the other deep learning based, on the SearchQA. We show that there is a mean- ingful gap between the human and ma- chine performances. This suggests that the proposed dataset could well serve as a benchmark for question-answering.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09375",
        "title": "Symmetry-Informed Geometric Representation for Molecules, Proteins, and Crystalline Materials",
        "abstract": "Artificial intelligence for scientific discovery has recently generated significant interest within the machine learning and scientific communities, particularly in the domains of chemistry, biology, and material discovery. For these scientific prob- lems, molecules serve as the fundamental building blocks, and machine learning has emerged as a highly effective and powerful tool for modeling their geometric structures. Nevertheless, due to the rapidly evolving process of the field and the knowledge gap between science (e.g., physics, chemistry, & biology) and machine learning communities, a benchmarking study on geometrical representation for such data has not been conducted. To address such an issue, in this paper, we first provide a unified view of the current symmetry-informed geometric methods, classifying them into three main categories: invariance, equivariance with spherical frame basis, and equivariance with vector frame basis. Then we propose a platform, coined Geom3D, which enables benchmarking the effectiveness of geometric strategies. Geom3D contains 16 advanced symmetry-informed geometric repre- sentation models and 14 geometric pretraining methods over 46 diverse datasets, including small molecules, proteins, and crystalline materials. We hope that Geom3D can, on the one hand, eliminate barriers for machine learning researchers interested in exploring scientific problems; and, on the other hand, provide valuable guidance for researchers in computational chemistry, structural biology, and materials science, aiding in the informed selection of representation techniques for specific applications. The source code is available on the GitHub repository.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13226",
        "title": "Real3D-AD: A Dataset of Point Cloud Anomaly Detection",
        "abstract": "High-precision point cloud anomaly detection is the gold standard for identify- ing the defects of advancing machining and precision manufacturing. Despite some methodological advances in this area, the scarcity of datasets and the lack of a systematic benchmark hinder its development. We introduce Real3D-AD, a challenging high-precision point cloud anomaly detection dataset, addressing the limitations in the field. With 1,254 high-resolution 3D items (from forty thou- sand to millions of points for each item), Real3D-AD is the largest dataset for high-precision 3D industrial anomaly detection to date. Real3D-AD surpasses existing 3D anomaly detection datasets available regarding point cloud resolution (0.0010mm-0.0015mm), 360 degree coverage and perfect prototype. Additionally, we present a comprehensive benchmark for Real3D-AD, revealing the absence of baseline methods for high-precision point cloud anomaly detection. To ad- dress this, we propose Reg3D-AD, a registration-based 3D anomaly detection method incorporating a novel feature memory bank that preserves local and global representations. Extensive experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD. For reproducibility and accessibility, we provide the Real3D-AD dataset, benchmark source code, and Reg3D-AD on our web- site:https://github.com/M-3LAB/Real3D-AD.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.16044",
        "title": "Stanford-ORB: A Real-World 3D Object Inverse Rendering Benchmark",
        "abstract": "We introduce Stanford-ORB, a new real-world 3D Object inverse Rendering Bench- mark. Recent advances in inverse rendering have enabled a wide range of real-world applications in 3D content generation, moving rapidly from research and commer- cial use cases to consumer devices. While the results continue to improve, there is no real-world benchmark that can quantitatively assess and compare the perfor- mance of various inverse rendering methods. Existing real-world datasets typically consist only of the shape and multi-view images of objects, which are not sufficient for evaluating the quality of material recovery and object relighting. Methods capa- ble of recovering material and lighting often resort to synthetic data for quantitative evaluation, which on the other hand does not guarantee generalization to complex real-world environments. We introduce a new dataset of real-world objects captured under a variety of natural scenes with ground-truth 3D scans, multi-view images, and environment lighting. Using this dataset, we establish the first comprehensive real-world evaluation benchmark for object inverse rendering tasks from in-the- wild scenes and compare the performance of various existing methods. All data, code, and models can be accessed at https://stanfordorb.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.11709",
        "title": "Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT",
        "abstract": "Numerous studies have been conducted to investigate the properties of large-scale temporal graphs. Despite the ubiquity of these graphs in real-world scenarios, it\u2019s usually impractical for us to obtain the whole real-time graphs due to privacy concerns and technical limitations. In this paper, we introduce the concept of Live Graph Lab for temporal graphs, which enables open, dynamic and real transaction graphs from blockchains. Among them, Non-fungible tokens (NFTs) have become one of the most prominent parts of blockchain over the past several years. With more than $40 billion market capitalization, this decentralized ecosystem produces massive, anonymous and real transaction activities, which naturally forms a com- plicated transaction network. However, there is limited understanding about the characteristics of this emerging NFT ecosystem from a temporal graph analysis perspective. To mitigate this gap, we instantiate a live graph with NFT transaction network and investigate its dynamics to provide new observations and insights. Specifically, through downloading and parsing the NFT transaction activities, we obtain a temporal graph with more than 4.5 million nodes and 124 million edges. Then, a series of measurements are presented to understand the properties of the NFT ecosystem. Through comparisons with social, citation, and web networks, our analyses give intriguing findings and point out potential directions for future exploration. Finally, we also study machine learning models in this live graph to enrich the current datasets and provide new opportunities for the graph community. The source codes and dataset are available at https://livegraphlab.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.04662",
        "title": "MADLAD-400: A Multilingual And Document-Level Large Audited Dataset",
        "abstract": "We introduce MADLAD-400, a manually audited, general domain 3T token mono- lingual dataset based on CommonCrawl, spanning 419 languages. We discuss the limitations revealed by self-auditing MADLAD-400, and the role data auditing had in the dataset creation process. We then train and release a 10.7B-parameter multilingual machine translation model on 250 billion tokens covering over 450 languages using publicly available data, and find that it is competitive with models that are significantly larger, and report the results on different domains. In addi- tion, we train a 8B-parameter language model, and assess the results on few-shot translation. We make the baseline models 1 available to the research community.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.07105",
        "title": "CORL: Research-oriented Deep Offline Reinforcement Learning Library",
        "abstract": "CORL1 is an open-source library that provides thoroughly benchmarked single-file implementations of both deep offline and offline-to-online reinforcement learning algorithms. It emphasizes a simple developing experience with a straightforward codebase and a modern analysis tracking tool. In CORL, we isolate methods implementation into separate single files, making performance-relevant details easier to recognize. Additionally, an experiment tracking feature is available to help log metrics, hyperparameters, dependencies, and more to the cloud. Finally, we have ensured the reliability of the implementations by benchmarking commonly employed D4RL datasets providing a transparent source of results that can be reused for robust evaluation tools such as performance profiles, probability of improvement, or expected online performance.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13890",
        "title": "Bitstream-corrupted Video Recovery: A Novel Benchmark Dataset and Method",
        "abstract": "The past decade has witnessed great strides in video recovery by specialist tech- nologies, like video inpainting, completion, and error concealment. However, they typically simulate the missing content by manual-designed error masks, thus failing to fill in the realistic video loss in video communication (e.g., telepresence, live streaming, and internet video) and multimedia forensics. To address this, we intro- duce the bitstream-corrupted video (BSCV) benchmark, the first benchmark dataset with more than 28,000 video clips, which can be used for bitstream-corrupted video recovery in the real world. The BSCV is a collection of 1) a proposed three- parameter corruption model for video bitstream, 2) a large-scale dataset containing rich error patterns, multiple corruption levels, and flexible dataset branches, and 3) a plug-and-play module in video recovery framework that serves as a bench- mark. We evaluate state-of-the-art video inpainting methods on the BSCV dataset, demonstrating existing approaches\u2019 limitations and our framework\u2019s advantages in solving the bitstream-corrupted video recovery problem. The benchmark and dataset are released at https://github.com/LIUTIGHE/BSCV-Dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.10280",
        "title": "OpenGSL: A Comprehensive Benchmark for Graph Structure Learning",
        "abstract": "\nGraph Neural Networks (GNNs) have emerged as the de facto standard for repre- sentation learning on graphs, owing to their ability to effectively integrate graph topology and node attributes. However, the inherent suboptimal nature of node con- nections, resulting from the complex and contingent formation process of graphs, presents significant challenges in modeling them effectively. To tackle this issue, Graph Structure Learning (GSL), a family of data-centric learning approaches, has garnered substantial attention in recent years. The core concept behind GSL is to jointly optimize the graph structure and the corresponding GNN models. Despite the proposal of numerous GSL methods, the progress in this field remains unclear due to inconsistent experimental protocols, including variations in datasets, data processing techniques, and splitting strategies. In this paper, we introduce OpenGSL, the first comprehensive benchmark for GSL, aimed at addressing this gap. OpenGSL enables a fair comparison among state-of-the-art GSL methods by evaluating them across various popular datasets using uniform data processing and splitting strategies. Through extensive experiments, we observe that existing GSL methods do not consistently outperform vanilla GNN counterparts. We also find that there is no significant correlation between the homophily of the learned struc- ture and task performance, challenging the common belief. Moreover, we observe that the learned graph structure demonstrates a strong generalization ability across different GNN models, despite the high computational and space consumption. We hope that our open-sourced library will facilitate rapid and equitable evaluation and inspire further innovative research in this field. The code of the benchmark can be found in https://github.com/OpenGSL/OpenGSL.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.15701",
        "title": "HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models",
        "abstract": "Advancements in deep neural networks have allowed automatic speech recognition (ASR) systems to attain human parity on several publicly available clean speech datasets. However, even state-of-the-art ASR systems experience performance degradation when confronted with adverse conditions, as a well-trained acous- tic model is sensitive to variations in the speech domain, e.g., background noise. Intuitively, humans address this issue by relying on their linguistic knowledge: the meaning of ambiguous spoken terms is usually inferred from contextual cues thereby reducing the dependency on the auditory system. Inspired by this observa- tion, we introduce the first open-source benchmark to utilize external large language models (LLMs) for ASR error correction, where N-best decoding hypotheses pro- vide informative elements for true transcription prediction. This approach is a paradigm shift from the traditional language model rescoring strategy that can only select one candidate hypothesis as the output transcription. The proposed benchmark contains a novel dataset, \u201cHyPoradise\u201d (HP), encompassing more than 334,000 pairs of N-best hypotheses and corresponding accurate transcriptions across prevalent speech domains. Given this dataset, we examine three types of error correction techniques based on LLMs with varying amounts of labeled hypotheses-transcription pairs, which gains a significant word error rate (WER) reduction. Experimental evidence demonstrates the proposed technique achieves a breakthrough by surpassing the upper bound of traditional re-ranking based meth- ods. More surprisingly, LLM with reasonable prompt and its generative capability can even correct those tokens that are missing in N-best list. We make our results publicly accessible for reproducible pipelines with released pre-trained models, thus providing a new evaluation paradigm for ASR error correction with LLMs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.03533",
        "title": "Low-shot Object Learning with Mutual Exclusivity Bias",
        "abstract": "This paper introduces Low-shot Object Learning with Mutual Exclusivity Bias (LSME), the first computational framing of mutual exclusivity bias, a phenomenon commonly observed in infants during word learning. We provide a novel dataset, comprehensive baselines, and a state-of-the-art method to enable the ML com- munity to tackle this challenging learning task. The goal of LSME is to analyze an RGB image of a scene containing multiple objects and correctly associate a previously-unknown object instance with a provided category label. This associa- tion is then used to perform low-shot learning to test category generalization. We provide a data generation pipeline for the LSME problem and conduct a thorough analysis of the factors that contribute to its difficulty. Additionally, we evaluate the performance of multiple baselines, including state-of-the-art foundation models. Finally, we present a baseline approach that outperforms state-of-the-art models in terms of low-shot accuracy. Code and data are available at https://github.com/rehg- lab/LSME.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2206.10498",
        "title": "PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change",
        "abstract": "Generating plans of action, and reasoning about change have long been considered a core competence of intelligent agents. It is thus no surprise that evaluating the planning and reasoning capabilities of large language models (LLMs) has become a hot topic of research. Most claims about LLM planning capabilities are however based on common sense tasks\u2013where it becomes hard to tell whether LLMs are planning or merely retrieving from their vast world knowledge. There is a strong need for systematic and extensible planning benchmarks with sufficient diversity to evaluate whether LLMs have innate planning capabilities. Motivated by this, we propose PlanBench, an extensible benchmark suite based on the kinds of domains used in the automated planning community, especially in the International Planning Competition, to test the capabilities of LLMs in planning or reasoning about actions and change. PlanBench provides sufficient diversity in both the task domains and the specific planning capabilities. Our studies also show that on many critical capabilities\u2013including plan generation\u2013LLM performance falls quite short, even with the SOTA models. PlanBench can thus function as a useful marker of progress of LLMs in planning and reasoning.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.05144",
        "title": "Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in the Mediterranean",
        "abstract": "We introduce Mesogeos1, a large-scale multi-purpose dataset for wildfire modeling in the Mediterranean. Mesogeos integrates variables representing wildfire drivers (meteorology, vegetation, human activity) and historical records of wildfire igni- tions and burned areas for 17 years (2006-2022). It is designed as a cloud-friendly spatio-temporal dataset, namely a datacube, harmonizing all variables in a grid of 1km x 1km x 1-day resolution. The datacube structure offers opportunities to assess machine learning (ML) usage in various wildfire modeling tasks. We extract two ML-ready datasets that establish distinct tracks to demonstrate this potential: (1) short-term wildfire danger forecasting and (2) final burned area estimation given the point of ignition. We define appropriate metrics and baselines to evaluate the performance of models in each track. By publishing the datacube, along with the code to create the ML datasets and models, we encourage the community to foster the implementation of additional tracks for mitigating the increasing threat of wildfires in the Mediterranean.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08754",
        "title": "ClimSim: A large multi-scale dataset for hybrid physics-ML climate emulation",
        "abstract": "Modern climate projections lack adequate spatial and temporal resolution due to computational constraints. A consequence is inaccurate and imprecise predictions of critical processes such as storms. Hybrid methods that combine physics with machine learning (ML) have introduced a new generation of higher fidelity climate simulators that can sidestep Moore\u2019s Law by outsourcing compute-hungry, short, high-resolution simulations to ML emulators. However, this hybrid ML-physics simulation approach requires domain-specific treatment and has been inaccessible to ML experts because of lack of training data and relevant, easy-to-use workflows. We present ClimSim, the largest-ever dataset designed for hybrid ML-physics re- search. It comprises multi-scale climate simulations, developed by a consortium of climate scientists and ML researchers. It consists of 5.7 billion pairs of multivariate input and output vectors that isolate the influence of locally-nested, high-resolution, high-fidelity physics on a host climate simulator\u2019s macro-scale physical state.\nThe dataset is global in coverage, spans multiple years at high sampling frequency, and is designed such that resulting emulators are compatible with downstream cou- pling into operational climate simulators. We implement a range of deterministic and stochastic regression baselines to highlight the ML challenges and their scoring. The data (https://huggingface.co/datasets/LEAP/ClimSim_high-res 2) and code (https://leap-stc.github.io/ClimSim) are released openly to support the development of hybrid ML-physics and high-fidelity climate simula- tions for the benefit of science and society.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11207",
        "title": "Quilt-1M: One Million Image-Text Pairs for Histopathology",
        "abstract": "Recent accelerations in multi-modal applications have been made possible with the plethora of image and text data available online. However, the scarcity of analogous data in the medical field, specifically in histopathology, has slowed comparable progress. To enable similar representation learning for histopathology, we turn to YouTube, an untapped resource of videos, offering 1, 087 hours of valuable educational histopathology videos from expert clinicians. From YouTube, we curate QUILT: a large-scale vision-language dataset consisting of 802,144 image and text pairs. QUILT was automatically curated using a mixture of models, including large language models, handcrafted algorithms, human knowledge databases, and automatic speech recognition. In comparison, the most comprehensive datasets curated for histopathology amass only around 200K samples. We combine QUILT with datasets from other sources, including Twitter, research papers, and the internet in general, to create an even larger dataset: QUILT-1M, with 1M paired image- text samples, marking it as the largest vision-language histopathology dataset to date. We demonstrate the value of QUILT-1M by fine-tuning a pre-trained CLIP model. Our model outperforms state-of-the-art models on both zero-shot and linear probing tasks for classifying new histopathology images across 13 diverse patch-level datasets of 8 different sub-pathologies and cross-modal retrieval tasks",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.18724",
        "title": "WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts",
        "abstract": "Machine learning based decision-support tools in criminal justice systems are subjects of intense discussions and academic research. There are important open questions about the utility and fairness of such tools. Academic researchers often rely on a few small datasets that are not sufficient to empirically study various real-world aspects of these questions. In this paper, we contribute WCLD, a curated large dataset of 1.5 million criminal cases from circuit courts in the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020 to curate attributes like prior criminal counts and recidivism outcomes. The dataset contains large number of samples from five racial groups, in addition to information like sex and age (at judgment and first offense). Other attributes in this dataset include neighborhood characteristics obtained from census data, detailed types of offense, charge severity, case decisions, sentence lengths, year of filing etc. We also provide pseudo-identifiers for judge, county and zipcode. The dataset will not only enable researchers to more rigorously study algorithmic fairness in the context of criminal justice, but also relate algorithmic challenges with various systemic issues. We also discuss in detail the process of constructing the dataset and provide a datasheet. The WCLD dataset is available at https://clezdata.github.io/wcld/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.02405",
        "title": "BEDD: The MineRL BASALT Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks",
        "abstract": "The MineRL BASALT competition has served to catalyze advances in learning from human feedback through four hard-to-specify tasks in Minecraft, such as create and photograph a waterfall. Given the completion of two years of BASALT competitions, we offer to the community a formalized benchmark through the BASALT Evaluation and Demonstrations Dataset (BEDD), which serves as a re- source for algorithm development and performance assessment. BEDD consists of a collection of 26 million image-action pairs from nearly 14,000 videos of human players completing the BASALT tasks in Minecraft. It also includes over 3,000 dense pairwise human evaluations of human and algorithmic agents. These com- parisons serve as a fixed, preliminary leaderboard for evaluating newly-developed algorithms. To enable this comparison, we present a streamlined codebase for benchmarking new algorithms against the leaderboard. In addition to presenting these datasets, we conduct a detailed analysis of the data from both datasets to guide algorithm development and evaluation. The released code and data are available at https://github.com/minerllabs/basalt-benchmark.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08893",
        "title": "LOVM: Language-Only Vision Model Selection",
        "abstract": "Pre-trained multi-modal vision-language models (VLMs) are becoming increas- ingly popular due to their exceptional performance on downstream vision appli- cations, particularly in the few- and zero-shot settings. However, selecting the best-performing VLM for some downstream applications is non-trivial, as it is dataset and task-dependent. Meanwhile, the exhaustive evaluation of all available VLMs on a novel application is not only time and computationally demanding but also necessitates the collection of a labeled dataset for evaluation. As the number of open-source VLM variants increases, there is a need for an efficient model selection strategy that does not require access to a curated evaluation dataset. This paper proposes a novel task and benchmark for efficiently evaluating VLMs\u2019 zero-shot performance on downstream applications without access to the downstream task dataset. Specifically, we introduce a new task LOVM: Language- Only Vision Model Selection, where methods are expected to perform both model selection and performance prediction based solely on a text description of the desired downstream application. We then introduced an extensive LOVM benchmark consisting of ground-truth evaluations of 35 pre-trained VLMs and 23 datasets, where methods are expected to rank the pre-trained VLMs and predict their zero-shot performance.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.03329",
        "title": "AVIDa-hIL6: A Large-Scale VHH Dataset Produced from an Immunized Alpaca for Predicting Antigen-Antibody Interactions",
        "abstract": "Antibodies have become an important class of therapeutic agents to treat human diseases. To accelerate therapeutic antibody discovery, computational methods, especially machine learning, have attracted considerable interest for predicting specific interactions between antibody candidates and target antigens such as viruses and bacteria. However, the publicly available datasets in existing works have notable limitations, such as small sizes and the lack of non-binding samples and exact amino acid sequences. To overcome these limitations, we have developed AVIDa-hIL6, a large-scale dataset for predicting antigen-antibody interactions in the variable domain of heavy chain of heavy chain antibodies (VHHs), produced from an alpaca immunized with the human interleukin-6 (IL-6) protein, as antigens. By leveraging the simple structure of VHHs, which facilitates identification of full- length amino acid sequences by DNA sequencing technology, AVIDa-hIL6 contains 573,891 antigen-VHH pairs with amino acid sequences. All the antigen-VHH pairs have reliable labels for binding or non-binding, as generated by a novel labeling method. Furthermore, via introduction of artificial mutations, AVIDa-hIL6 contains 30 different mutants in addition to wild-type IL-6 protein. This characteristic provides opportunities to develop machine learning models for predicting changes in antibody binding by antigen mutations. We report experimental benchmark results on AVIDa-hIL6 by using machine learning models. The results indicate that the existing models have potential, but further research is needed to generalize them to predict effective antibodies against unknown mutants. The dataset is available at https://avida-hil6.cognanous.com.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.14108",
        "title": "DATACOMP:\nIn search of the next generation of multimodal datasets",
        "abstract": "\nMultimodal datasets are a critical component in recent breakthroughs such as CLIP, Stable Diffusion and GPT-4, yet their design does not receive the same research attention as model architectures or training algorithms. To address this shortcoming in the machine learning ecosystem, we introduce DATACOMP, a testbed for dataset experiments centered around a new candidate pool of 12.8 billion image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing the resulting model on 38 downstream test sets. Our benchmark consists of multiple compute scales spanning four orders of magnitude, which enables the study of scaling trends and makes the benchmark accessible to researchers with varying resources. Our baseline experiments show that the DATACOMP workflow leads to better training sets. Our best baseline, DATACOMP-1B, enables training a CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming OpenAI\u2019s CLIP ViT-L/14 by 3.7 percentage points while using the same training procedure and compute. We release DATACOMP and all accompanying code at www.datacomp.ai.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09549",
        "title": "QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules",
        "abstract": "Supervised machine learning approaches have been increasingly used in acceler- ating electronic structure prediction as surrogates of first-principle computational methods, such as density functional theory (DFT). While numerous quantum chem- istry datasets focus on chemical properties and atomic forces, the ability to achieve accurate and efficient prediction of the Hamiltonian matrix is highly desired, as it is the most important and fundamental physical quantity that determines the quantum states of physical systems and chemical properties. In this work, we generate a new Quantum Hamiltonian dataset, named as QH9, to provide pre- cise Hamiltonian matrices for 999 or 2998 molecular dynamics trajectories and 130,831 stable molecular geometries, based on the QM9 dataset. By designing benchmark tasks with various molecules, we show that current machine learning models have the capacity to predict Hamiltonian matrices for arbitrary molecules. Both the QH9 dataset and the baseline models are provided to the community through an open-source benchmark, which can be highly valuable for developing machine learning methods and accelerating molecular and materials design for scientific and technological applications. Our benchmark is publicly available at https://github.com/divelab/AIRS/tree/main/OpenDFT/QHBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.03886",
        "title": "FIND: A Function Description Benchmark for Evaluating Interpretability Methods",
        "abstract": "Labeling neural network submodules with human-legible descriptions is useful for many downstream tasks: such descriptions can surface failures, guide interventions, and perhaps even explain important model behaviors. To date, most mechanistic descriptions of trained networks have involved small models, narrowly delimited phenomena, and large amounts of human labor. Labeling all human-interpretable sub-computations in models of increasing size and complexity will almost certainly require tools that can generate and validate descriptions automatically. Recently, techniques that use learned models in-the-loop for labeling have begun to gain traction, but methods for evaluating their efficacy are limited and ad-hoc. How should we validate and compare open-ended labeling tools? This paper introduces FIND (Function INterpretation and Description), a benchmark suite for evaluating the building blocks of automated interpretability methods. FIND contains functions that resemble components of trained neural networks, and accompanying descrip- tions of the kind we seek to generate. The functions are procedurally constructed across textual and numeric domains, and involve a range of real-world complexities, including noise, composition, approximation, and bias. We evaluate methods that use pretrained language models (LMs) to produce code-based and natural language descriptions of function behavior. Additionally, we introduce a new interactive method in which an Automated Interpretability Agent (AIA) generates function descriptions. We find that an AIA, built with an off-the-shelf LM augmented with black-box access to functions, can sometimes infer function structure\u2014acting as a scientist by forming hypotheses, proposing experiments, and updating descriptions in light of new data. However, FIND also reveals that LM-based descriptions capture global function behavior while missing local details. These results suggest that FIND will be useful for characterizing the performance of more sophisticated interpretability methods before they are applied to real-world models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.08322",
        "title": "C-EVAL: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models",
        "abstract": "New NLP benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present C-EVAL , the first comprehensive Chi- nese evaluation suite designed to assess advanced knowledge and reasoning abilities of foundation models in a Chinese context. C-EVAL comprises multiple-choice questions across four difficulty levels: middle school, high school, college, and professional. The questions span 52 diverse disciplines, ranging from humanities to science and engineering. C-EVAL is accompanied by C-EVAL HARD, a subset of very challenging subjects in C-EVAL that requires advanced reasoning abilities to solve. We conduct a comprehensive evaluation of the most advanced LLMs on C-EVAL, including both English- and Chinese-oriented models. Results indicate that only GPT-4 could achieve an average accuracy of over 60%, suggesting that there is still significant room for improvement for current LLMs. We anticipate C-EVAL will help analyze important strengths and shortcomings of foundation models, and foster their development and growth for Chinese users.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.16447",
        "title": "ChimpACT: A Longitudinal Dataset for Understanding Chimpanzee Behaviors",
        "abstract": "\nUnderstanding the behavior of non-human primates is crucial for improving animal welfare, modeling social behavior, and gaining insights into distinctively human and phylogenetically shared behaviors. However, the lack of datasets on non-human primate behavior hinders in-depth exploration of primate social interactions, posing challenges to research on our closest living relatives. To address these limitations, we present ChimpACT, a comprehensive dataset for quantifying the longitudinal behavior and social relations of chimpanzees within a social group. Spanning from 2015 to 2018, ChimpACT features videos of a group of over 20 chimpanzees residing at the Leipzig Zoo, Germany, with a particular focus on documenting the developmental trajectory of one young male, Azibo. ChimpACT is both com- prehensive and challenging, consisting of 163 videos with a cumulative 160,500 frames, each richly annotated with detection, identification, pose estimation, and fine-grained spatiotemporal behavior labels. We benchmark representative methods of three tracks on ChimpACT: (i) tracking and identification, (ii) pose estimation, and (iii) spatiotemporal action detection of the chimpanzees. Our experiments reveal that ChimpACT offers ample opportunities for both devising new methods and adapting existing ones to solve fundamental computer vision tasks applied to chimpanzee groups, such as detection, pose estimation, and behavior analy- sis, ultimately deepening our comprehension of communication and sociality in non-human primates",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2207.04043",
        "title": "The Harvard USPTO Patent Dataset:\nA Large-Scale, Well-Structured, and Multi-Purpose Corpus of Patent Applications",
        "abstract": "Innovation is a major driver of economic and social development, and informa- tion about many kinds of innovation is embedded in semi-structured data from patents and patent applications. Although the impact and novelty of innovations expressed in patent data are difficult to measure through traditional means, ML offers a promising set of techniques for evaluating novelty, summarizing contribu- tions, and embedding semantics. In this paper, we introduce the Harvard USPTO Patent Dataset (HUPD), a large-scale, well-structured, and multi-purpose corpus of English-language patent applications filed to the United States Patent and Trade- mark Office (USPTO) between 2004 and 2018. With more than 4.5 million patent documents, HUPD is two to three times larger than comparable corpora. Unlike previously proposed patent datasets in NLP, HUPD contains the inventor-submitted versions of patent applications\u2014not the final versions of granted patents\u2014thereby allowing us to study patentability at the time of filing using NLP methods for the first time. It is also novel in its inclusion of rich structured metadata alongside the text of patent filings: By providing each application\u2019s metadata along with all of its text fields, the dataset enables researchers to perform new sets of NLP tasks that leverage variation in structured covariates. As a case study on the types of research HUPD makes possible, we introduce a new task to the NLP community\u2014namely, binary classification of patent decisions. We additionally show the structured metadata provided in the dataset enables us to conduct explicit studies of concept shifts for this task. Finally, we demonstrate how our dataset can be used for three additional tasks: multi-class classification of patent subject areas, language mod- eling, and summarization. Overall, HUPD is one of the largest multi-purpose NLP datasets containing domain-specific textual data, along with well-structured bibliographic metadata, and aims to advance research extending language and classification models to diverse and dynamic real-world data distributions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13117",
        "title": "AVERITEC: A Dataset for Real-world Claim Verification with Evidence from the Web",
        "abstract": "Existing datasets for automated fact-checking have substantial limitations, such as relying on artificial claims, lacking annotations for evidence and intermediate reasoning, or including evidence published after the claim. In this paper, we introduce AVERITEC, a new dataset of 4,568 real-world claims covering fact- checks by 50 different organizations. Each claim is annotated with question- answer pairs supported by evidence available online, as well as textual justifications explaining how the evidence combines to produce a verdict. Through a multi- round annotation process, we avoid common pitfalls including context dependence, evidence insufficiency, and temporal leakage, and reach a substantial inter-annotator agreement of \u03ba = 0.619 on verdicts. We develop a baseline as well as an evaluation scheme for verifying claims through question-answering against the open web.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13446",
        "title": "Video Timeline Modeling For News Story Understanding",
        "abstract": "In this paper, we present a novel problem, namely video timeline modeling. Our objective is to create a video-associated timeline from a set of videos related to a specific topic, thereby facilitating the content and structure understanding of the story being told. This problem has significant potential in various real-world applications, for instance, news story summarization. To bootstrap research in this area, we curate a realistic benchmark dataset, YouTube-News-Timeline, con- sisting of over 12k timelines and 300k YouTube news videos. Additionally, we propose a set of quantitative metrics to comprehensively evaluate and compare methodologies. With such a testbed, we further develop and benchmark sev- eral deep learning approaches to tackling this problem. We anticipate that this exploratory work will pave the way for further research in video timeline mod- eling. The assets are available via https://github.com/google-research/ google-research/tree/master/video_timeline_modeling.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08310",
        "title": "TWIGMA: A dataset of AI-Generated Images with Metadata From Twitter",
        "abstract": "Recent progress in generative artificial intelligence (gen-AI) has enabled the gener- ation of photo-realistic and artistically-inspiring photos at a single click, catering to millions of users online. To explore how people use gen-AI models such as DALLE and StableDiffusion, it is critical to understand the themes, contents, and variations present in the AI-generated photos. In this work, we introduce TWIGMA (TWItter Generative-ai images with MetadatA), a comprehensive dataset encompassing over 800,000 gen-AI images collected from Jan 2021 to March 2023 on Twitter, with associated metadata (e.g., tweet text, creation date, number of likes), available at https://zenodo.org/records/8031785. Through a comparative analysis of TWIGMA with natural images and human artwork, we find that gen-AI images possess distinctive characteristics and exhibit, on average, lower variability when compared to their non-gen-AI counterparts. Additionally, we find that the similarity between a gen-AI image and natural images is inversely correlated with the number of likes. Finally, we observe a longitudinal shift in the themes of AI-generated images on Twitter, with users increasingly sharing artistically sophisticated content such as intricate human portraits, whereas their interest in simple subjects such as natural scenes and animals has decreased. Our findings underscore the significance of TWIGMA as a unique data resource for studying AI-generated images.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.08252",
        "title": "MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning",
        "abstract": "Recently, Meta-Black-Box Optimization with Reinforcement Learning (MetaBBO- RL) has showcased the power of leveraging RL at the meta-level to mitigate manual fine-tuning of low-level black-box optimizers. However, this field is hindered by the lack of a unified benchmark. To fill this gap, we introduce MetaBox, the first benchmark platform expressly tailored for developing and evaluating MetaBBO- RL methods. MetaBox offers a flexible algorithmic template that allows users to effortlessly implement their unique designs within the platform. Moreover, it provides a broad spectrum of over 300 problem instances, collected from synthetic to realistic scenarios, and an extensive library of 19 baseline methods, including both traditional black-box optimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces three standardized performance metrics, enabling a more thorough assessment of the methods. In a bid to illustrate the utility of MetaBox for facilitating rigorous evaluation and in-depth analysis, we carry out a wide- ranging benchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-source and accessible at: https://github.com/GMC-DRL/MetaBox.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.12386",
        "title": "EFWI: Multiparameter Benchmark Datasets for Elastic Full Waveform Inversion of Geophysical Properties",
        "abstract": "Elastic geophysical properties (such as P- and S-wave velocities) are of great importance to various subsurface applications like CO2 sequestration and energy exploration (e.g., hydrogen and geothermal). Elastic full waveform inversion (FWI) is widely applied for characterizing reservoir properties. In this paper, we introduce EFWI, a comprehensive benchmark dataset that is specifically designed for elastic FWI. EFWI encompasses 8 distinct datasets that cover diverse subsurface geologic structures (flat, curve, faults, etc). The benchmark results produced by three differ- ent deep learning methods are provided. In contrast to our previously presented dataset (pressure recordings) for acoustic FWI (referred to as OPENFWI), the seismic dataset in EFWI has both vertical and horizontal components. Moreover, the velocity maps in EFWI incorporate both P- and S-wave velocities. While the multicomponent data and the added S-wave velocity make the data more realistic, more challenges are introduced regarding the convergence and computational cost of the inversion. We conduct comprehensive numerical experiments to explore the relationship between P-wave and S-wave velocities in seismic data. The relation between P- and S-wave velocities provides crucial insights into the subsurface properties such as lithology, porosity, fluid content, etc. We anticipate that EFWI will facilitate future research on multiparameter inversions and stimulate endeavors in several critical research topics of carbon-zero and new energy exploration. All datasets, codes1 and relevant information can be accessed through our website at https://efwi-lanl.github.io/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.18494",
        "title": "Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses",
        "abstract": "\nTo generate evidence regarding the safety and efficacy of artificial intelligence (AI) enabled medical devices, AI models need to be evaluated on a diverse population of patient cases, some of which may not be readily available. We propose an evaluation approach for testing medical imaging AI models that relies on in silico imaging pipelines in which stochastic digital models of human anatomy (in object space) with and without pathology are imaged using a digital replica imaging acquisition system to generate realistic synthetic image datasets. Here, we release M-SYNTH*, a dataset of cohorts with four breast fibroglandular density distributions imaged at different exposure levels using Monte Carlo x-ray simulations with the publicly available Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) toolkit. We utilize the synthetic dataset to analyze AI model performance and find that model performance decreases with increasing breast density and increases with higher mass density, as expected. As exposure levels decrease, AI model performance drops with the highest performance achieved at exposure levels lower than the nominal recommended dose for the breast type.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.12474",
        "title": "CSMED: Bridging the Dataset Gap in Automated Citation Screening for Systematic Literature Reviews",
        "abstract": "Systematic literature reviews (SLRs) play an essential role in summarising, synthe- sising and validating scientific evidence. In recent years, there has been a growing interest in using machine learning techniques to automate the identification of rele- vant studies for SLRs. However, the lack of standardised evaluation datasets makes comparing the performance of such automated literature screening systems difficult. In this paper, we analyse the citation screening evaluation datasets, revealing that many of the available datasets are either too small, suffer from data leakage or have limited applicability to systems treating automated literature screening as a classifi- cation task, as opposed to, for example, a retrieval or question-answering task. To address these challenges, we introduce CSMED, a meta-dataset consolidating nine publicly released collections, providing unified access to 325 SLRs from the fields of medicine and computer science. CSMED serves as a comprehensive resource for training and evaluating the performance of automated citation screening models. Additionally, we introduce CSMED-FT, a new dataset designed explicitly for evaluating the full text publication screening task. To demonstrate the utility of CSMED, we conduct experiments and establish baselines on new datasets.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.00741",
        "title": "FELM: Benchmarking Factuality Evaluation of Large Language Models",
        "abstract": "Assessing factuality of text generated by large language models (LLMs) is an emerging yet crucial research area, aimed at alerting users to potential errors and guiding the development of more reliable LLMs. Nonetheless, the evaluators assessing factuality necessitate suitable evaluation themselves to gauge progress and foster advancements. This direction remains under-explored, resulting in sub- stantial impediments to the progress of factuality evaluators. To mitigate this issue, we introduce a benchmark for Factuality Evaluation of large Language Models, referred to as FELM. In this benchmark, we collect responses generated from LLMs and annotate factuality labels in a fine-grained manner. Contrary to previous studies that primarily concentrate on the factuality of world knowledge (e.g. in- formation from Wikipedia), FELM focuses on factuality across diverse domains, spanning from world knowledge to math and reasoning. Our annotation is based on text segments, which can help pinpoint specific factual errors. The factuality annotations are further supplemented by predefined error types and reference links that either support or contradict the statement. In our experiments, we investigate the performance of several LLM-based factuality evaluators on FELM, including both vanilla LLMs and those augmented with retrieval mechanisms and chain-of- thought processes. Our findings reveal that while retrieval aids factuality evaluation, current LLMs are far from satisfactory to faithfully detect factual errors.1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.13336",
        "title": "FLAIR: a Country-Scale Land Cover Semantic Segmentation Dataset From Multi-Source Optical Imagery",
        "abstract": "We introduce the French Land cover from Aerospace ImageRy (FLAIR), an ex- tensive dataset from the French National Institute of Geographical and Forest Information (IGN) that provides a unique and rich resource for large-scale geospa- tial analysis. FLAIR contains high-resolution aerial imagery with a ground sample distance of 20 cm and over 20 billion individually labeled pixels for precise land- cover classification. The dataset also integrates temporal and spectral data from optical satellite time series. FLAIR thus combines data with varying spatial, spec- tral, and temporal resolutions across over 817 km2 of acquisitions representing the full landscape diversity of France. This diversity makes FLAIR a valuable resource for the development and evaluation of novel methods for large-scale land-cover semantic segmentation and raises significant challenges in terms of computer vision, data fusion, and geospatial analysis. We also provide power- ful uni- and multi-sensor baseline models that can be employed to assess algo- rithm\u2019s performance and for downstream applications. Through its extent and the quality of its annotation, FLAIR aims to spur improvements in monitoring and understanding key anthropogenic development indicators such as urban growth, deforestation, and soil artificialization. Dataset and codes can be accessed at https://ignf.github.io/FLAIR/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11547",
        "title": "Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events",
        "abstract": "Generative, pre-trained transformers (GPTs, a.k.a. \"Foundation Models\") have reshaped natural language processing (NLP) through their versatility in diverse downstream tasks. However, their potential extends far beyond NLP. This paper pro- vides a software utility to help realize this potential, extending the applicability of GPTs to continuous-time sequences of complex events with internal dependencies, such as medical record datasets. Despite their potential, the adoption of foundation models in these domains has been hampered by the lack of suitable tools for model construction and evaluation. To bridge this gap, we introduce Event Stream GPT (ESGPT), an open-source library designed to streamline the end-to-end process for building GPTs for continuous-time event sequences. ESGPT allows users to (1) build flexible, foundation-model scale input datasets by specifying only a minimal configuration file, (2) leverage a Hugging Face compatible modeling API for GPTs over this modality that incorporates intra-event causal dependency structures and autoregressive generation capabilities, and (3) evaluate models via standardized processes that can assess few and even zero-shot performance of pre-trained models on user-specified fine-tuning tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.09619",
        "title": "Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning",
        "abstract": "We introduce Dataset Grouper, a library to create large-scale group-structured (e.g., federated) datasets, enabling federated learning simulation at the scale of foundation models. This library facilitates the creation of group-structured ver- sions of existing datasets based on user-specified partitions, and directly leads to a variety of useful heterogeneous datasets that can be plugged into existing software frameworks. Dataset Grouper offers three key advantages. First, it scales to settings where even a single group\u2019s dataset is too large to fit in mem- ory. Second, it provides flexibility, both in choosing the base (non-partitioned) dataset and in defining partitions. Finally, it is framework-agnostic. We empir- ically demonstrate that Dataset Grouper enables large-scale federated language modeling simulations on datasets that are orders of magnitude larger than in pre- vious work, allowing for federated training of language models with hundreds of millions, and even billions, of parameters. Our experimental results show that algorithms like FedAvg operate more as meta-learning methods than as em- pirical risk minimization methods at this scale, suggesting their utility in down- stream personalization and task-specific adaptation. Dataset Grouper is available at https://github.com/google-research/dataset_grouper.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.05663",
        "title": "Objaverse-XL: A Universe of 10M+ 3D Objects",
        "abstract": "Natural language processing and 2D vision models have attained remarkable profi- ciency on many tasks primarily by escalating the scale of training data. However, 3D vision tasks have not seen the same progress, in part due to the challenges of acquiring high-quality 3D data. In this work, we present Objaverse-XL, a dataset of over 10 million 3D objects. Our dataset comprises deduplicated 3D objects from a diverse set of sources, including manually designed objects, photogrammetry scans of landmarks and everyday items, and professional scans of historic and antique artifacts. Representing the largest scale and diversity in the realm of 3D datasets, Objaverse-XL enables significant new possibilities for 3D vision. Our experiments demonstrate the improvements enabled with the scale provided by Objaverse-XL. We show that by training Zero123 on novel view synthesis, utilizing over 100 million multi-view rendered images, we achieve strong zero-shot generalization abilities. We hope that releasing Objaverse-XL will enable further innovations in the field of 3D vision at scale.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.14365",
        "title": "Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving",
        "abstract": "Robotic perception requires the modeling of both 3D geometry and semantics. Existing methods typically focus on estimating 3D bounding boxes, neglecting finer geometric details and struggling to handle general, out-of-vocabulary ob- jects. 3D occupancy prediction, which estimates the detailed occupancy states and semantics of a scene, is an emerging task to overcome these limitations. To support 3D occupancy prediction, we develop a label generation pipeline that produces dense, visibility-aware labels for any given scene. This pipeline com- prises three stages: voxel densification, occlusion reasoning, and image-guided voxel refinement. We establish two benchmarks, derived from the Waymo Open Dataset and the nuScenes Dataset, namely Occ3D-Waymo and Occ3D-nuScenes benchmarks. Furthermore, we provide an extensive analysis of the proposed dataset with various baseline models. Lastly, we propose a new model, dubbed Coarse-to-Fine Occupancy (CTF-Occ) network, which demonstrates superior per- formance on the Occ3D benchmarks. The code, data, and benchmarks are released at https://tsinghua-mars-lab.github.io/Occ3D/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.00142",
        "title": "BuildingsBench: A Large-Scale Dataset of 900K Buildings and Benchmark for Short-Term Load Forecasting",
        "abstract": "\nShort-term forecasting of residential and commercial building energy consumption is widely used in power systems and continues to grow in importance. Data-driven short-term load forecasting (STLF), although promising, has suffered from a lack of open, large-scale datasets with high building diversity. This has hindered exploring the pretrain-then-fine-tune paradigm for STLF. To help address this, we present BuildingsBench, which consists of: 1) Buildings-900K, a large-scale dataset of 900K simulated buildings representing the U.S. building stock; and 2) an evaluation platform with over 1,900 real residential and commercial buildings from 7 open datasets. BuildingsBench benchmarks two under-explored tasks: zero-shot STLF, where a pretrained model is evaluated on unseen buildings without fine-tuning, and transfer learning, where a pretrained model is fine-tuned on a target building. The main finding of our benchmark analysis is that synthetically pretrained models generalize surprisingly well to real commercial buildings. An exploration of the effect of increasing dataset size and diversity on zero-shot commercial building performance reveals a power-law with diminishing returns. We also show that fine- tuning pretrained models on real commercial and residential buildings improves performance for a majority of target buildings. We hope that BuildingsBench encourages and facilitates future research on generalizable STLF. All datasets and code can be accessed from https://github.com/NREL/BuildingsBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.00936",
        "title": "SatBird: Bird Species Distribution Modeling with Remote Sensing and Citizen Science Data",
        "abstract": "Biodiversity is declining at an unprecedented rate, impacting ecosystem services necessary to ensure food, water, and human health and well-being. Understanding the distribution of species and their habitats is crucial for conservation policy planning. However, traditional methods in ecology for species distribution models (SDMs) generally focus either on narrow sets of species or narrow geographical areas and there remain significant knowledge gaps about the distribution of species. A major reason for this is the limited availability of data traditionally used, due to the prohibitive amount of effort and expertise required for traditional field monitoring. The wide availability of remote sensing data and the growing adoption of citizen science tools to collect species observations data at low cost offer an opportunity for improving biodiversity monitoring and enabling the modelling of complex ecosystems. We introduce a novel task for mapping bird species to their habitats by predicting species encounter rates from satellite images, and present SatBird1, a satellite dataset of locations in the USA with labels derived from presence-absence observation data from the citizen science database eBird, considering summer (breeding) and winter seasons. We also provide a dataset in Kenya representing low-data regimes. We additionally provide environmental data and species range maps for each location. We benchmark a set of baselines on our dataset, including SOTA models for remote sensing tasks. SatBird opens up possibilities for scalably modelling properties of ecosystems worldwide.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.06202",
        "title": "NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics",
        "abstract": "Machine learning provides a valuable tool for analyzing high-dimensional func- tional neuroimaging data, and is proving effective in predicting various neurological conditions, psychiatric disorders, and cognitive patterns. In functional magnetic resonance imaging (MRI) research, interactions between brain regions are com- monly modeled using graph-based representations. The potency of graph machine learning methods has been established across myriad domains, marking a trans- formative step in data interpretation and predictive modeling. Yet, despite their promise, the transposition of these techniques to the neuroimaging domain has been challenging due to the expansive number of potential preprocessing pipelines and the large parameter search space for graph-based dataset construction. In this paper, we introduce NeuroGraph1, a collection of graph-based neuroimaging datasets, and demonstrated its utility for predicting multiple categories of behavioral and cogni- tive traits. We delve deeply into the dataset generation search space by crafting 35 datasets that encompass static and dynamic brain connectivity, running in excess of 15 baseline methods for benchmarking. Additionally, we provide generic frame- works for learning on both static and dynamic graphs. Our extensive experiments lead to several key observations. Notably, using correlation vectors as node features, incorporating larger number of regions of interest, and employing sparser graphs lead to improved performance. To foster further advancements in graph-based data driven neuroimaging analysis, we offer a comprehensive open-source Python package that includes the benchmark datasets, baseline implementations, model training, and standard evaluation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.03035",
        "title": "SEVA: Leveraging sketches to evaluate alignment between human and machine visual abstraction",
        "abstract": "Sketching is a powerful tool for creating abstract images that are sparse but meaningful. Sketch understanding poses fundamental challenges for general- purpose vision algorithms because it requires robustness to the sparsity of sketches relative to natural visual inputs and because it demands tolerance for semantic ambiguity, as sketches can reliably evoke multiple meanings. While current vision algorithms have achieved high performance on a variety of visual tasks, it remains unclear to what extent they understand sketches in a human-like way. Here we introduce SEVA, a new benchmark dataset containing approximately 90K human- generated sketches of 128 object concepts produced under different time constraints, and thus systematically varying in sparsity. We evaluated a suite of state-of-the-art vision algorithms on their ability to correctly identify the target concept depicted in these sketches and to generate responses that are strongly aligned with human response patterns on the same sketch recognition task. We found that vision algorithms that better predicted human sketch recognition performance also better approximated human uncertainty about sketch meaning, but there remains a sizable gap between model and human response patterns. To explore the potential of models that emulate human visual abstraction in generative tasks, we conducted further evaluations of a recently developed sketch generation algorithm [91] capable of generating sketches that vary in sparsity. We hope that public release of this dataset and evaluation protocol will catalyze progress towards algorithms with enhanced capacities for human-like visual abstraction.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13786",
        "title": "Perception Test: A Diagnostic Benchmark for Multimodal Video Models",
        "abstract": "We propose a novel multimodal video benchmark \u2013 the Perception Test \u2013 to eval- uate the perception and reasoning skills of pre-trained multimodal models (e.g. Flamingo, SeViLA, or GPT-4). Compared to existing benchmarks that focus on computational tasks (e.g. classification, detection or tracking), the Perception Test focuses on skills (Memory, Abstraction, Physics, Semantics) and types of reasoning (descriptive, explanatory, predictive, counterfactual) across video, audio, and text modalities, to provide a comprehensive and efficient evaluation tool. The benchmark probes pre-trained models for their transfer capabilities, in a zero-shot / few-shot or limited finetuning regime. For these purposes, the Perception Test intro- duces 11.6k real-world videos, 23s average length, designed to show perceptually interesting situations, filmed by around 100 participants worldwide. The videos are densely annotated with six types of labels (multiple-choice and grounded video question-answers, object and point tracks, temporal action and sound segments), enabling both language and non-language evaluations. The fine-tuning and valida- tion splits of the benchmark are publicly available (CC-BY license), in addition to a challenge server with a held-out test split. Human baseline results compared to state-of-the-art video QA models show a substantial gap in performance (91.4% vs 46.2%), suggesting that there is significant room for improvement in multimodal video understanding. Dataset, baseline code, and challenge server are available at https://github.com/deepmind/perception_test",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11247",
        "title": "DICES Dataset:\nDiversity in Conversational AI Evaluation for Safety",
        "abstract": "Machine learning approaches often require training and evaluation datasets with a clear separation between positive and negative examples. This risks simplifying and even obscuring the inherent subjectivity present in many tasks. Preserving such variance in content and diversity in datasets is often expensive and laborious. This is especially troubling when building safety datasets for conversational AI systems, as safety is both socially and culturally situated. To demonstrate this crucial aspect of conversational AI safety, and to facilitate in-depth model performance analyses, we introduce the DICES (Diversity In Conversational AI Evaluation for Safety) dataset that contains fine-grained demographic information about raters, high replication of ratings per item to ensure statistical power for analyses, and encodes rater votes as distributions across different demographics to allow for in- depth explorations of different aggregation strategies. In short, the DICES dataset enables the observation and measurement of variance, ambiguity, and diversity in the context of conversational AI safety. We also illustrate how the dataset offers a basis for establishing metrics to show how raters\u2019 ratings can intersects with demographic categories such as racial/ethnic groups, age groups, and genders. The goal of DICES is to be used as a shared resource and benchmark that respects diverse perspectives during safety evaluation of conversational AI systems.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.18365",
        "title": "What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks",
        "abstract": "Large Language Models (LLMs) with strong abilities in natural language process- ing tasks have emerged and have been applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper, rather than pursuing state-of-the-art performance, we aim to evaluate capabilities of LLMs in a wide range of tasks across the chemistry domain. We identify three key chemistry- related capabilities including understanding, reasoning and explaining to explore in LLMs and establish a benchmark containing eight chemistry tasks. Our anal- ysis draws on widely recognized datasets facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Five LLMs (GPT-4, GPT-3.5, Davinci-003, Llama and Galactica) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstration examples and specially crafted prompts. Our investigation found that GPT-4 outperformed other models and LLMs exhibit different competitive levels in eight chemistry tasks. In addition to the key findings from the comprehen- sive benchmark analysis, our work provides insights into the limitation of current LLMs and the impact of in-context learning settings on LLMs\u2019 performance across various chemistry tasks. The code and datasets used in this study are available at https://github.com/ChemFoundationModels/ChemLLMBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.14356",
        "title": "COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs",
        "abstract": "Counterfactual examples have proven to be valuable in the field of natural language processing (NLP) for both evaluating and improving the robustness of language models to spurious correlations in datasets. Despite their demonstrated utility for NLP, multimodal counterfactual examples have been relatively unexplored due to the difficulty of creating paired image-text data with minimal counter- factual changes. To address this challenge, we introduce a scalable framework for automatic generation of counterfactual examples using text-to-image diffu- sion models. We use our framework to create COCO-Counterfactuals, a mul- timodal counterfactual dataset of paired image and text captions based on the MS-COCO dataset. We validate the quality of COCO-Counterfactuals through human evaluations and show that existing multimodal models are challenged by our counterfactual image-text pairs. Additionally, we demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of multi- modal vision-language models via training data augmentation. We make our code2 and the COCO-Counterfactuals dataset3 publicly available.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.09064",
        "title": "Imagine the Unseen World: A Benchmark for Systematic Generalization in Visual World Models",
        "abstract": "Systematic compositionality, or the ability to adapt to novel situations by creating a mental model of the world using reusable pieces of knowledge, remains a significant challenge in machine learning. While there has been considerable progress in the language domain, efforts towards systematic visual imagination, or envisioning the dynamical implications of a visual observation, are in their infancy. We introduce the Systematic Visual Imagination Benchmark (SVIB), the first benchmark designed to address this problem head-on. SVIB offers a novel framework for a minimal world modeling problem, where models are evaluated based on their ability to generate one-step image-to-image transformations under a latent world dynamics. The framework provides benefits such as the possibility to jointly optimize for systematic perception and imagination, a range of difficulty levels, and the ability to control the fraction of possible factor combinations used during training. We provide a comprehensive evaluation of various baseline models on SVIB, offering insight into the current state-of-the-art in systematic visual imagination. We hope that this benchmark will help advance visual systematic compositionality. https: //systematic-visual-imagination.github.io",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.13216",
        "title": "Diverse Community Data for Benchmarking Data Privacy Algorithms",
        "abstract": "The Collaborative Research Cycle (CRC) is a National Institute of Standards and Technology (NIST) benchmarking program intended to strengthen understanding of tabular data deidentification technologies. Deidentification algorithms are vul- nerable to the same bias and privacy issues that impact other data analytics and machine learning applications, and it can even amplify those issues by contami- nating downstream applications. This paper summarizes four CRC contributions: theoretical work on the relationship between diverse populations and challenges for equitable deidentification; public benchmark data focused on diverse popula- tions and challenging features; a comprehensive open source suite of evaluation metrology for deidentified datasets; and an archive of more than 450 deidentified data samples from a broad range of techniques. The initial set of evaluation results demonstrate the value of the CRC tools for investigations in this field.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10088",
        "title": "Android in the Wild: A Large-Scale Dataset for Android Device Control",
        "abstract": "There is a growing interest in device-control systems that can interpret human natural language instructions and execute them on a digital device by directly con- trolling its user interface. We present a dataset for device-control research, Android in the Wild (AITW), which is orders of magnitude larger than current datasets. The dataset contains human demonstrations of device interactions, including the screens and actions, and corresponding natural language instructions. It consists of 715k episodes spanning 30k unique instructions, four versions of Android (v10\u201313), and eight device types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It contains multi-step tasks that require semantic understanding of language and visual context. This dataset poses a new challenge: actions available through the user interface must be inferred from their visual appearance, and, instead of simple UI element-based actions, the action space consists of precise gestures (e.g., hori- zontal scrolls to operate carousel widgets). We organize our dataset to encourage robustness analysis of device-control systems, i.e., how well a system performs in the presence of new task descriptions, new applications, or new platform versions. We develop two agents and report performance across the dataset. The dataset is available at https://github.com/google-research/google-research/ tree/master/android_in_the_wild.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2404.01578",
        "title": "GLEMOS: Benchmark for Instantaneous Graph Learning Model Selection",
        "abstract": "The choice of a graph learning (GL) model (i.e., a GL algorithm and its hyperpa- rameter settings) has a significant impact on the performance of downstream tasks. However, selecting the right GL model becomes increasingly difficult and time consuming as more and more GL models are developed. Accordingly, it is of great significance and practical value to equip users of GL with the ability to perform a near-instantaneous selection of an effective GL model without manual interven- tion. Despite the recent attempts to tackle this important problem, there has been no comprehensive benchmark environment to evaluate the performance of GL model selection methods. To bridge this gap, we present GLEMOS in this work, a comprehensive benchmark for instantaneous GL model selection that makes the following contributions. (i) GLEMOS provides extensive benchmark data for fundamental GL tasks, i.e., link prediction and node classification, including the performances of 366 models on 457 graphs on these tasks. (ii) GLEMOS designs multiple evaluation settings, and assesses how effectively representative model selection techniques perform in these different settings. (iii) GLEMOS is designed to be easily extended with new models, new graphs, and new performance records. (iv) Based on the experimental results, we discuss the limitations of existing ap- proaches and highlight future research directions. To promote research on this significant problem, we make the benchmark data and code publicly available at https://github.com/facebookresearch/glemos",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.06577",
        "title": "RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel Segmentation",
        "abstract": "Retinal vessel segmentation is generally grounded in image-based datasets collected with bench-top devices. The static images naturally lose the dynamic characteristics of retina fluctuation, resulting in diminished dataset richness, and the usage of bench-top devices further restricts dataset scalability due to its limited accessibility. Considering these limitations, we introduce the first video-based retinal dataset by employing handheld devices for data acquisition. The dataset comprises 635 smartphone-based fundus videos collected from four different clinics, involving 415 patients from 50 to 75 years old. It delivers comprehensive and precise annotations of retinal structures in both spatial and temporal dimensions, aiming to advance the landscape of vasculature segmentation. Specifically, the dataset provides three levels of spatial annotations: binary vessel masks for overall retinal structure delineation, general vein-artery masks for distinguishing the vein and artery, and fine-grained vein-artery masks for further characterizing the granularities of each artery and vein. In addition, the dataset offers temporal annotations that capture the vessel pulsation characteristics, assisting in detecting ocular diseases that require fine-grained recognition of hemodynamic fluctuation. In application, our dataset exhibits a significant domain shift with respect to data captured by bench-top devices, thus posing great challenges to existing methods. Thanks to rich annotations and data scales, our dataset potentially paves the path for more advanced retinal analysis and accurate disease diagnosis. In the experiments, we provide evaluation metrics and benchmark results on our dataset, reflecting both the potential and challenges it offers for vessel segmentation tasks. We hope this challenging dataset would significantly contribute to the development of eye disease diagnosis and early prevention. The dataset is available at \u0087 RVD.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11203",
        "title": "AVOIDDS: Aircraft Vision-based Intruder Detection Dataset and Simulator",
        "abstract": "Designing robust machine learning systems remains an open problem, and there is a need for benchmark problems that cover both environmental changes and evaluation on a downstream task. In this work, we introduce AVOIDDS, a re- alistic object detection benchmark for the vision-based aircraft detect-and-avoid problem. We provide a labeled dataset consisting of 72,000 photorealistic images of intruder aircraft with various lighting conditions, weather conditions, relative geometries, and geographic locations. We also provide an interface that evaluates trained models on slices of this dataset to identify changes in performance with respect to changing environmental conditions. Finally, we implement a fully- integrated, closed-loop simulator of the vision-based detect-and-avoid problem to evaluate trained models with respect to the downstream collision avoidance task. This benchmark will enable further research in the design of robust ma- chine learning systems for use in safety-critical applications. The AVOIDDS dataset and code are publicly available at https://purl.stanford.edu/hj293cv5980 and https://github.com/sisl/VisionBasedAircraftDAA, respectively.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.17290",
        "title": "RIO: A Benchmark for Reasoning Intention-Oriented Objects in Open Environments",
        "abstract": "Intention-oriented object detection aims to detect desired objects based on specific intentions or requirements. For instance, when we desire to \"lie down and rest\", we instinctively seek out a suitable option such as a \"bed\" or a \"sofa\" that can fulfill our needs. Previous work in this area is limited either by the number of in- tention descriptions or by the affordance vocabulary available for intention objects. These limitations make it challenging to handle intentions in open environments effectively. To facilitate this research, we construct a comprehensive dataset called Reasoning Intention-Oriented Objects (RIO). In particular, RIO is specifically designed to incorporate diverse real-world scenarios and a wide range of object categories. It offers the following key features: 1) intention descriptions in RIO are represented as natural sentences rather than a mere word or verb phrase, making them more practical and meaningful; 2) the intention descriptions are contextually relevant to the scene, enabling a broader range of potential functionalities associ- ated with the objects; 3) the dataset comprises a total of 40,214 images and 130,585 intention-object pairs. With the proposed RIO, we evaluate the ability of some existing models to reason intention-oriented objects in open environments.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.12424",
        "title": "VISOGENDER: A dataset for benchmarking gender bias in image-text pronoun resolution",
        "abstract": "\nWe introduce VISOGENDER, a novel dataset for benchmarking gender bias in vision-language models. We focus on occupation-related biases within a hege- monic system of binary gender, inspired by Winograd and Winogender schemas, where each image is associated with a caption containing a pronoun relation- ship of subjects and objects in the scene. VISOGENDER is balanced by gender representation in professional roles, supporting bias evaluation in two ways: i) resolution bias, where we evaluate the difference between pronoun resolution accu- racies for image subjects with gender presentations perceived as masculine versus feminine by human annotators and ii) retrieval bias, where we compare ratios of professionals perceived to have masculine and feminine gender presentations retrieved for a gender-neutral search query. We benchmark several state-of-the-art vision-language models and find that they demonstrate bias in resolving binary gender in complex scenes. While the direction and magnitude of gender bias de- pends on the task and the model being evaluated, captioning models are generally less biased than Vision-Language Encoders. Dataset and code are available at https://github.com/oxai/visogender.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.09191",
        "title": "A benchmark of categorical encoders for binary classification",
        "abstract": "\nCategorical encoders transform categorical features into numerical representa- tions that are indispensable for a wide range of machine learning models. Ex- isting encoder benchmark studies lack generalizability because of their limited choice of 1. encoders, 2. experimental factors, and 3. datasets. Addition- ally, inconsistencies arise from the adoption of varying aggregation strategies. This paper is the most comprehensive benchmark of categorical encoders to date, including an extensive evaluation of 32 configurations of encoders from diverse families, with 48 combinations of experimental factors, and on 50 datasets. The study shows the profound influence of dataset selection, exper- imental factors, and aggregation strategies on the benchmark\u2019s conclusions \u2014 aspects disregarded in previous encoder benchmarks. Our code is available at https://github.com/DrCohomology/EncoderBenchmarking. This version of the paper is identical to the one accepted at the 37th Conference on Neural Infor- mation Processing Systems (NeurIPS 2023), Track on Datasets and Benchmarks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.19053",
        "title": "Datasets and Benchmarks for Nanophotonic Structure and Parametric Design Simulations",
        "abstract": "\nNanophotonic structures have versatile applications including solar cells, anti- reflective coatings, electromagnetic interference shielding, optical filters, and light emitting diodes. To design and understand these nanophotonic structures, elec- trodynamic simulations are essential. These simulations enable us to model elec- tromagnetic fields over time and calculate optical properties. In this work, we introduce frameworks and benchmarks to evaluate nanophotonic structures in the context of parametric structure design problems. The benchmarks are instrumental in assessing the performance of optimization algorithms and identifying an optimal structure based on target optical properties. Moreover, we explore the impact of varying grid sizes in electrodynamic simulations, shedding light on how evaluation fidelity can be strategically leveraged in enhancing structure designs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.04370",
        "title": "OpenAGI: When LLM Meets Domain Experts",
        "abstract": "Human Intelligence (HI) excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence (AI) and should be embedded in comprehensive AI Agents, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence (AGI). Large Language Models (LLMs) show promising learning and reasoning abilities, and can effectively use external models, tools, plugins, or APIs to tackle complex problems. In this work, we introduce OpenAGI, an open-source AGI research and development platform designed for solving multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models, tools, plugins, or APIs for creative problem-solving. Tasks are presented as natural language queries to the LLM, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM\u2019s task-solving ability, which creates a self-improving AI feedback loop. While we acknowledge that AGI is a broad and multifaceted research challenge with no singularly defined solution path, the integration of LLMs with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards AGI. We are open-sourcing the OpenAGI project\u2019s code, dataset, benchmarks, evaluation methods, and the UI demo to foster community involvement in AGI advancement: https://github.com/agiresearch/OpenAGI.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13425",
        "title": "MiliPoint: A Point Cloud Dataset for mmWave Radar",
        "abstract": "\nMillimetre-wave (mmWave) radar has emerged as an attractive and cost-effective alternative for human activity sensing compared to traditional camera-based sys- tems. mmWave radars are also non-intrusive, providing better protection for user privacy. However, as a Radio Frequency (RF) based technology, mmWave radars rely on capturing reflected signals from objects, making them more prone to noise compared to cameras. This raises an intriguing question for the deep learning community: Can we develop more effective point set-based deep learning methods for such attractive sensors?\nTo answer this question, our work, termed MiliPoint2, delves into this idea by providing a large-scale, open dataset for the community to explore how mmWave radars can be utilised for human activity recognition. Moreover, MiliPoint stands out as it is larger in size than existing datasets, has more diverse human actions represented, and encompasses all three key tasks in human activity recognition. We have also established a range of point-based deep neural networks such as DGCNN, PointNet++ and PointTransformer, on MiliPoint, which can serve to set the ground baseline for further development.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.16342",
        "title": "LagrangeBench: A Lagrangian Fluid Mechanics Benchmarking Suite",
        "abstract": "Machine learning has been successfully applied to grid-based PDE modeling in various scientific applications. However, learned PDE solvers based on Lagrangian particle discretizations, which are the preferred approach to problems with free sur- faces or complex physics, remain largely unexplored. We present LagrangeBench, the first benchmarking suite for Lagrangian particle problems, focusing on temporal coarse-graining. In particular, our contribution is: (a) seven new fluid mechanics datasets (four in 2D and three in 3D) generated with the Smoothed Particle Hy- drodynamics (SPH) method including the Taylor-Green vortex, lid-driven cavity, reverse Poiseuille flow, and dam break, each of which includes different physics like solid wall interactions or free surface, (b) efficient JAX-based API with various recent training strategies and three neighbor search routines, and (c) JAX imple- mentation of established Graph Neural Networks (GNNs) like GNS and SEGNN with baseline results. Finally, to measure the performance of learned surrogates we go beyond established position errors and introduce physical metrics like kinetic energy MSE and Sinkhorn distance for the particle distribution. Our codebase is available under the URL: https://github.com/tumaer/lagrangebench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.12032",
        "title": "The Waymo Open Sim Agents Challenge",
        "abstract": "Simulation with realistic, interactive agents represents a key task for autonomous vehicle software development. In this work, we introduce the Waymo Open Sim Agents Challenge (WOSAC). WOSAC is the first public challenge to tackle this task and propose corresponding metrics. The goal of the challenge is to stimulate the design of realistic simulators that can be used to evaluate and train a behavior model for autonomous driving. We outline our evaluation methodology, present results for a number of different baseline simulation agent methods, and analyze several submissions to the 2023 competition which ran from March 16, 2023 to May 23, 2023. The WOSAC evaluation server remains open for submissions and we discuss open problems for the task.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.15681",
        "title": "ECG-QA: A Comprehensive Question Answering Dataset Combined With Electrocardiogram",
        "abstract": "Question answering (QA) in the field of healthcare has received much attention due to significant advancements in natural language processing. However, existing healthcare QA datasets primarily focus on medical images, clinical notes, or struc- tured electronic health record tables. This leaves the vast potential of combining electrocardiogram (ECG) data with these systems largely untapped. To address this gap, we present ECG-QA, the first QA dataset specifically designed for ECG analysis. The dataset comprises a total of 70 question templates that cover a wide range of clinically relevant ECG topics, each validated by an ECG expert to ensure their clinical utility. As a result, our dataset includes diverse ECG interpretation questions, including those that require a comparative analysis of two different ECGs. In addition, we have conducted numerous experiments to provide valuable insights for future research directions. We believe that ECG-QA will serve as a valuable resource for the development of intelligent QA systems capable of assisting clinicians in ECG interpretations.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11167",
        "title": "Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and\nEinstellung Effect with the OnlyConnect Wall Dataset",
        "abstract": "The quest for human imitative AI has been an enduring topic in AI research since its inception. The technical evolution and emerging capabilities of the latest cohort of large language models (LLMs) have reinvigorated the subject beyond academia to the cultural zeitgeist. While recent NLP evaluation benchmark tasks test some as- pects of human-imitative behavior (e.g., BIG-bench\u2019s \u2018human-like behavior\u2019 tasks), few, if not none, examine creative problem solving abilities. Creative problem solv- ing in humans is a well-studied topic in cognitive neuroscience with standardized tests that predominantly use the ability to associate (heterogeneous) connections among clue words as a metric for creativity. Exposure to misleading stimuli \u2014 distractors dubbed red herrings \u2014 impede human performance in such tasks via the fixation effect and Einstellung paradigm. In cognitive neuroscience studies, such fixations are experimentally induced by pre-exposing participants to orthographi- cally similar incorrect words to subsequent word-fragments or clues. The popular British quiz show Only Connect\u2019s Connecting Wall segment essentially mimics Mednick\u2019s Remote Associates Test (RAT) formulation with built-in, deliberate red herrings, which makes it an ideal proxy task to explore and study the fixation effect and Einstellung paradigm from cognitive neuroscience in LLMs. In this paper, we present the novel Only Connect Wall (OCW) dataset and report results from our evaluation of selected pre-trained language models and LLMs on creative problem solving tasks like grouping clue words by heterogeneous connections and identifying correct open knowledge domain connections in respective groups. We synthetically generate two additional datasets: OCW-Randomized, OCW-WordNet to further analyze our red-herrings hypothesis in language models. The code and link to the dataset are available at https://github.com/TaatiTeam/OCW.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.04657",
        "title": "BEAVERTAILS: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset",
        "abstract": "In this paper, we introduce the BEAVERTAILS dataset, aimed at fostering research on safety alignment in large language models (LLMs). This dataset uniquely separates annotations of helpfulness and harmlessness for question-answering pairs, thus offering distinct perspectives on these crucial attributes. In total, we have gathered safety meta-labels for 333,963 question-answer (QA) pairs and 361,903 pairs of expert comparison data for both the helpfulness and harmlessness metrics. We further showcase applications of BeaverTails in content moderation and reinforcement learning with human feedback (RLHF), emphasizing its potential for practical safety measures in LLMs. We believe this dataset provides vital resources for the community, contributing towards the safe development and deployment of LLMs. Our project page is available at the following URL: https://sites. google.com/view/pku-beavertails.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.04678",
        "title": "DORIS-MAE:\nScientific Document Retrieval using Multi-level Aspect-based Queries",
        "abstract": "In scientific research, the ability to effectively retrieve relevant documents based on complex, multifaceted queries is critical. Existing evaluation datasets for this task are limited, primarily due to the high cost and effort required to annotate resources that effectively represent complex queries. To address this, we propose a novel task, Scientific DOcument Retrieval using Multi-level Aspect-based quEries (DORIS- MAE), which is designed to handle the complex nature of user queries in scientific research. We developed a benchmark dataset within the field of computer science, consisting of 100 human-authored complex query cases. For each complex query, we assembled a collection of 100 relevant documents and produced annotated relevance scores for ranking them. Recognizing the significant labor of expert annotation, we also introduce Anno-GPT, a scalable framework for validating the performance of Large Language Models (LLMs) on expert-level dataset annotation tasks. LLM annotation of the DORIS-MAE dataset resulted in a 500x reduction in cost, without compromising quality. Furthermore, due to the multi-tiered structure of these complex queries, the DORIS-MAE dataset can be extended to over 4,000 sub-query test cases without requiring additional annotation. We evaluated 17 recent retrieval methods on DORIS-MAE, observing notable performance drops compared to traditional datasets. This highlights the need for better approaches to handle complex, multifaceted queries in scientific research. Our dataset and codebase are available at https://github.com/Real-Doris-Mae/Doris-Mae-Dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09077",
        "title": "Estimating Generic 3D Room Structures from 2D Annotations",
        "abstract": "Indoor rooms are among the most common use cases in 3D scene understanding. Current state-of-the-art methods for this task are driven by large annotated datasets. Room layouts are especially important, consisting of structural elements in 3D, such as wall, floor, and ceiling. However, they are difficult to annotate, especially on pure RGB video. We propose a novel method to produce generic 3D room layouts just from 2D segmentation masks, which are easy to annotate for humans. Based on these 2D annotations, we automatically reconstruct 3D plane equations for the structural elements and their spatial extent in the scene, and connect adjacent elements at the appropriate contact edges. We annotate and publicly release 2246 3D room layouts on the RealEstate10k dataset, containing YouTube videos. We demonstrate the high quality of these 3D layouts annotations with extensive experiments.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.03449",
        "title": "Into the LAION\u2019s Den: Investigating Hate in Multimodal Datasets",
        "abstract": "\u2018Scale the model, scale the data, scale the compute\u2019 is the reigning sentiment in the world of generative AI today. While the impact of model scaling has been extensively studied, we are only beginning to scratch the surface of data scaling and its consequences. This is especially of critical importance in the context of vision- language datasets such as LAION. These datasets are continually growing in size and are built based on large-scale internet dumps such as the Common Crawl, which is known to have numerous drawbacks ranging from quality, legality, and content. The datasets then serve as the backbone for large generative models, contributing to the operationalization and perpetuation of harmful societal and historical biases and stereotypes. In this paper, we investigate the effect of scaling datasets on hateful content through a comparative audit of two datasets: LAION-400M and LAION-2B. Our results show that hate content increased by nearly 12% with dataset scale, measured both qualitatively and quantitatively using a metric that we term as Hate Content Rate (HCR). We also found that filtering dataset contents based on Not Safe For Work (NSFW) values calculated based on images alone does not exclude all the harmful content in alt-text. Instead, we found that trace amounts of hateful, targeted, and aggressive text remain even when carrying out conservative filtering. We end with a reflection and a discussion of the significance of our results for dataset curation and usage in the AI community. Code and the meta-data assets curated in this paper are publicly available at https://github.com/vinayprabhu/hate_scaling.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.15162",
        "title": "YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English Parallel Corpus",
        "abstract": "Machine learning for sign languages is bottlenecked by data. In this paper, we present YouTube-ASL, a large-scale, open-domain corpus of American Sign Lan- guage (ASL) videos and accompanying English captions drawn from YouTube. With ~1000 hours of videos and >2500 unique signers, YouTube-ASL is ~3x as large and has ~10x as many unique signers as the largest prior ASL dataset. We train baseline models for ASL to English translation on YouTube-ASL and evaluate them on How2Sign, where we achieve a new finetuned state of the art of 12.39 BLEU and, for the first time, report zero-shot results.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.02034",
        "title": "SAMRS: Scaling-up Remote Sensing Segmentation Dataset with Segment Anything Model",
        "abstract": "The success of the Segment Anything Model (SAM) demonstrates the significance of data-centric machine learning. However, due to the difficulties and high costs associated with annotating Remote Sensing (RS) images, a large amount of valuable RS data remains unlabeled, particularly at the pixel level. In this study, we leverage SAM and existing RS object detection datasets to develop an efficient pipeline for generating a large-scale RS segmentation dataset, dubbed SAMRS. SAMRS totally possesses 105,090 images and 1,668,241 instances, surpassing existing high-resolution RS segmentation datasets in size by several orders of magnitude. It provides object category, location, and instance information that can be used for semantic segmentation, instance segmentation, and object detection, either individually or in combination. We also provide a comprehensive analysis of SAMRS from various aspects. Moreover, preliminary experiments highlight the importance of conducting segmentation pre-training with SAMRS to address task discrepancies and alleviate the limitations posed by limited training data during fine-tuning. The code and dataset will be available at SAMRS.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.10345",
        "title": "MM-Fi: Multi-Modal Non-Intrusive 4D Human Dataset for Versatile Wireless Sensing",
        "abstract": "4D human perception plays an essential role in a myriad of applications, such as home automation and metaverse avatar simulation. However, existing solutions which mainly rely on cameras and wearable devices are either privacy intrusive or inconvenient to use. To address these issues, wireless sensing has emerged as a promising alternative, leveraging LiDAR, mmWave radar, and WiFi signals for device-free human sensing. In this paper, we propose MM-Fi, the first multi-modal non-intrusive 4D human dataset with 27 daily or rehabilitation action categories, to bridge the gap between wireless sensing and high-level human perception tasks. MM-Fi consists of over 320k synchronized frames of five modalities from 40 human subjects. Various annotations are provided to support potential sensing tasks, e.g., human pose estimation and action recognition. Extensive experiments have been conducted to compare the sensing capacity of each or several modalities in terms of multiple tasks. We envision that MM-Fi can contribute to wireless sensing research with respect to action recognition, human pose estimation, multi-modal learning, cross-modal supervision, and interdisciplinary healthcare research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.00818",
        "title": "Motion-X: A Large-scale 3D Expressive Whole-body Human Motion Dataset",
        "abstract": "\nIn this paper, we present Motion-X, a large-scale 3D expressive whole-body motion dataset. Existing motion datasets predominantly contain body-only poses, lacking facial expressions, hand gestures, and fine-grained pose descriptions. Moreover, they are primarily collected from limited laboratory scenes with textual descrip- tions manually labeled, which greatly limits their scalability. To overcome these limitations, we develop a whole-body motion and text annotation pipeline, which can automatically annotate motion from either single- or multi-view videos and provide comprehensive semantic labels for each video and fine-grained whole-body pose descriptions for each frame. This pipeline is of high precision, cost-effective, and scalable for further research. Based on it, we construct Motion-X, which com- prises 15.6M precise 3D whole-body pose annotations (i.e., SMPL-X) covering 81.1K motion sequences from massive scenes. Besides, Motion-X provides 15.6M frame-level whole-body pose descriptions and 81.1K sequence-level semantic labels. Comprehensive experiments demonstrate the accuracy of the annotation pipeline and the significant benefit of Motion-X in enhancing expressive, diverse, and natural motion generation, as well as 3D whole-body human mesh recovery",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.07279",
        "title": "Scalable 3D Captioning with Pretrained Models",
        "abstract": "We introduce Cap3D, an automatic approach for generating descriptive text for 3D objects. This approach utilizes pretrained models from image captioning, image-text alignment, and LLM to consolidate captions from multiple views of a 3D asset, completely side-stepping the time-consuming and costly process of manual annotation. We apply Cap3D to the recently introduced large-scale 3D dataset, Objaverse, resulting in 660k 3D-text pairs. Our evaluation, conducted using 41k human annotations from the same dataset, demonstrates that Cap3D surpasses human-authored descriptions in terms of quality, cost, and speed. Through effective prompt engineering, Cap3D rivals human performance in generating geometric de- scriptions on 17k collected annotations from the ABO dataset. Finally, we finetune text-to-3D models on Cap3D and human captions, and show Cap3D outperforms; and benchmark the SOTA including Point\u00b7E, Shap\u00b7E, and DreamFusion.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.10453",
        "title": "Evaluating Graph Neural Networks for Link Prediction: Current Pitfalls and New Benchmarking",
        "abstract": "Link prediction attempts to predict whether an unseen edge exists based on only a portion of edges of a graph. A flurry of methods have been introduced in re- cent years that attempt to make use of graph neural networks (GNNs) for this task. Furthermore, new and diverse datasets have also been created to better eval- uate the effectiveness of these new models. However, multiple pitfalls currently exist that hinder our ability to properly evaluate these new methods. These pit- falls mainly include: (1) Lower than actual performance on multiple baselines, (2) A lack of a unified data split and evaluation metric on some datasets, and (3) An unrealistic evaluation setting that uses easy negative samples. To overcome these challenges, we first conduct a fair comparison across prominent methods and datasets, utilizing the same dataset and hyperparameter search settings. We then create a more practical evaluation setting based on a Heuristic Related Sampling Technique (HeaRT), which samples hard negative samples via multiple heuristics. The new evaluation setting helps promote new challenges and opportunities in link prediction by aligning the evaluation with real-world situations. Our implementa- tion and data are available at https://github.com/Juanhui28/HeaRT.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.13531",
        "title": "WBCAtt: A White Blood Cell Dataset Annotated with Detailed Morphological Attributes",
        "abstract": "The examination of blood samples at a microscopic level plays a fundamental role in clinical diagnostics. For instance, an in-depth study of White Blood Cells (WBCs), a crucial component of our blood, is essential for diagnosing blood-related diseases such as leukemia and anemia. While multiple datasets containing WBC images have been proposed, they mostly focus on cell categorization, often lacking the necessary morphological details to explain such categorizations, despite the importance of explainable artificial intelligence (XAI) in medical domains. This paper seeks to address this limitation by introducing comprehensive annotations for WBC images. Through collaboration with pathologists, a thorough literature review, and manual inspection of microscopic images, we have identified 11 morphological attributes associated with the cell and its components (nucleus, cytoplasm, and granules). We then annotated ten thousand WBC images with these attributes, resulting in 113k labels (11 attributes x 10.3k images). Annotating at this level of detail and scale is unprecedented, offering unique value to AI in pathology. Moreover, we conduct experiments to predict these attributes from cell images, and also demonstrate specific applications that can benefit from our detailed annotations. Overall, our dataset paves the way for interpreting WBC recognition models, further advancing XAI in the fields of pathology and hematology.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.02997",
        "title": "When Do Neural Nets Outperform Boosted Trees on Tabular Data?",
        "abstract": "\nTabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and question the importance of this debate. To this end, we conduct the largest tabular data analysis to date, comparing 19 algorithms across 176 datasets, and we find that the \u2018NN vs. GBDT\u2019 debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than choosing between NNs and GBDTs. A remarkable exception is the recently-proposed prior-data fitted network, TabPFN: although it is effectively limited to training sets of size 3000, we find that it outperforms all other algorithms on average, even when randomly sampling 3000 training datapoints. Next, we analyze dozens of metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better than NNs at handling skewed or heavy-tailed feature distributions and other forms of dataset irregularities. Our insights act as a guide for practitioners to determine which techniques may work best on their dataset. Finally, with the goal of accelerating tabular data research, we release the TabZilla Benchmark Suite: a collection of the 36 \u2018hardest\u2019 of the datasets we study. Our benchmark suite, codebase, and all raw results are available at https://github.com/naszilla/tabzilla.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09109",
        "title": "NAVI: Category-Agnostic Image Collections with High-Quality 3D Shape and Pose Annotations",
        "abstract": "Recent advances in neural reconstruction enable high-quality 3D object recon- struction from casually captured image collections. Current techniques mostly analyze their progress on relatively simple image collections where Structure- from-Motion (SfM) techniques can provide ground-truth (GT) camera poses. We note that SfM techniques tend to fail on in-the-wild image collections such as image search results with varying backgrounds and illuminations. To enable sys- tematic research progress on 3D reconstruction from casual image captures, we propose \u2018NAVI\u2019: a new dataset of category-agnostic image collections of objects with high-quality 3D scans along with per-image 2D-3D alignments providing near-perfect GT camera parameters. These 2D-3D alignments allow us to extract accurate derivative annotations such as dense pixel correspondences, depth and segmentation maps. We demonstrate the use of NAVI image collections on different problem settings and show that NAVI enables more thorough evaluations that were not possible with existing datasets. We believe NAVI is beneficial for systematic research progress on 3D reconstruction and correspondence estimation. Project page: https://navidataset.github.io",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13952",
        "title": "VidChapters-7M: Video Chapters at Scale",
        "abstract": "Segmenting long videos into chapters enables users to quickly navigate to the infor- mation of their interest. This important topic has been understudied due to the lack of publicly released datasets. To address this issue, we present VidChapters-7M, a dataset of 817K user-chaptered videos including 7M chapters in total. VidChapters- 7M is automatically created from videos online in a scalable manner by scraping user-annotated chapters and hence without any additional manual annotation. We introduce the following three tasks based on this data. First, the video chapter gen- eration task consists of temporally segmenting the video and generating a chapter title for each segment. To further dissect the problem, we also define two variants of this task: video chapter generation given ground-truth boundaries, which requires generating a chapter title given an annotated video segment, and video chapter grounding, which requires temporally localizing a chapter given its annotated title. We benchmark both simple baselines and state-of-the-art video-language models for these three tasks. We also show that pretraining on VidChapters-7M transfers well to dense video captioning tasks in both zero-shot and finetuning settings, largely improving the state of the art on the YouCook2 and ViTT benchmarks. Finally, our experiments reveal that downstream performance scales well with the size of the pretraining dataset. Our dataset, code, and models are publicly available at https://antoyang.github.io/vidchapters.html.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.05538",
        "title": "ImageNet-Hard: The Hardest Images Remaining from a Study of the Power of Zoom and Spatial Biases in Image Classification",
        "abstract": "Image classifiers are information-discarding machines, by design. Yet, how these models discard information remains mysterious. We hypothesize that one way for image classifiers to reach high accuracy is to zoom to the most discriminative region in the image and then extract features from there to predict image labels, discarding the rest of the image. Studying six popular networks ranging from AlexNet to CLIP, we find that proper framing of the input image can lead to the correct classification of 98.91% of ImageNet images. Furthermore, we uncover positional biases in various datasets, especially a strong center bias in two popular datasets: ImageNet-A and ObjectNet. Finally, leveraging our insights into the potential of zooming, we propose a test-time augmentation (TTA) technique that improves classification accuracy by forcing models to explicitly perform zoom-in operations before making predictions. Our method is more interpretable, accurate, and faster than MEMO, a state-of-the-art (SOTA) TTA method. We introduce ImageNet-Hard, a new benchmark that challenges SOTA classifiers including large vision-language models even when optimal zooming is allowed.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.03736",
        "title": "Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning",
        "abstract": "Neural MMO 2.0 is a massively multi-agent environment for reinforcement learning research. The key feature of this new version is a flexible task system that allows users to define a broad range of objectives and reward signals. We challenge researchers to train agents capable of generalizing to tasks, maps, and opponents never seen during training. Neural MMO features procedurally generated maps with 128 agents in the standard setting and support for up to. Version 2.0 is a complete rewrite of its predecessor with three-fold improved performance and compatibility with CleanRL. We release the platform as free and open-source software with comprehensive documentation available at neuralmmo.github.io and an active community Discord. To spark initial research on this new platform, we are concurrently running a competition at NeurIPS 2023.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.02080",
        "title": "benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models\n",
        "abstract": "Various adaptation methods, such as LoRA, prompts, and adapters, have been proposed to enhance the performance of pre-trained vision-language models in specific domains. As test samples in real-world applications usually differ from adaptation data, studying the robustness of these adaptation methods against distri- bution shifts is essential. In this study, we assess the robustness of 11 widely-used adaptation methods across 4 vision-language datasets under multimodal corrup- tions. Concretely, we introduce 7 benchmark datasets, including 96 visual and 87 textual corruptions, to investigate the robustness of different adaptation methods, the impact of available adaptation examples, and the influence of trainable parame- ter size during adaptation. Our analysis reveals that: 1) Adaptation methods are more sensitive to text corruptions than visual corruptions. 2) Full fine-tuning does not consistently provide the highest robustness; instead, adapters can achieve better robustness with comparable clean performance. 3) Contrary to expectations, our findings indicate that increasing the number of adaptation data and parameters does not guarantee enhanced robustness; instead, it results in even lower robustness. We hope this study could benefit future research in developing robust multimodal adaptation methods. The benchmark, code, and dataset used in this study can be accessed at https://adarobustness.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1409.0575",
        "title": "ImageNet Large Scale Visual Recognition Challenge",
        "abstract": "The ImageNet Large Scale Visual Recogni- tion Challenge is a benchmark in object category classi- fication and detection on hundreds of object categories and millions of images. The challenge has been run an- nually from 2010 to present, attracting participation from more than fifty institutions.\nThis paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recog- nition, provide a detailed analysis of the current state of the field of large-scale image classification and ob- ject detection, and compare the state-of-the-art com- puter vision accuracy with human accuracy. We con- clude with lessons learned in the five years of the chal- lenge, and propose future directions and improvements.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2004.02042",
        "title": "ObjectNet Dataset: Reanalysis and Correction",
        "abstract": "Recently, Barbu et al. introduced a dataset called ObjectNet which includes objects in daily life situations. They showed a dramatic performance drop of the state of the art object recognition models on this dataset. Due to the importance and implications of their results regarding generalization ability of deep models, we take a second look at their findings. We highlight a major problem with their work which is applying object recognizers to the scenes containing multiple objects rather than isolated objects. The latter results in around 20-30% performance gain using our code. Compared with the results reported in the ObjectNet paper, we observe that around 10-15% of the performance loss can be recovered, without any test time data augmentation. In accordance with Barbu et al.\u2019s conclusions, however, we also conclude that deep models suffer drastically on this dataset. Thus, we believe that ObjectNet remains a challenging dataset for testing the generalization power of models beyond datasets on which they have been trained.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11546",
        "title": "Bullying10K: A Large-Scale Neuromorphic Dataset towards Privacy-Preserving Bullying Recognition\n",
        "abstract": "The prevalence of violence in daily life poses significant threats to individuals\u2019 physical and mental well-being. Using surveillance cameras in public spaces has proven effective in proactively deterring and preventing such incidents. However, concerns regarding privacy invasion have emerged due to their widespread deploy- ment. To address the problem, we leverage Dynamic Vision Sensors (DVS) camera to detect violent incidents and preserve privacy since it captures pixel brightness variations instead of static imagery. We introduce the Bullying10K dataset, en- compassing various actions, complex movements, and occlusions from real-life scenarios. It provides three benchmarks for evaluating different tasks: action recognition, temporal action localization, and pose estimation. With 10,000 event segments, totaling 12 billion events and 255 GB of data, Bullying10K contributes significantly by balancing violence detection and personal privacy persevering. And it also poses a challenge to the neuromorphic dataset. It will serve as a valu- able resource for training and developing privacy-protecting video systems. The Bullying10K opens new possibilities for innovative approaches in these domains.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.09126",
        "title": "EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding",
        "abstract": "We introduce EgoSchema, a very long-form video question-answering dataset, and benchmark to evaluate long video understanding capabilities of modern vision and language systems. Derived from Ego4D, EgoSchema consists of over 5000 human curated multiple choice question answer pairs, spanning over 250 hours of real video data, covering a very broad range of natural human activity and behavior. For each question, EgoSchema requires the correct answer to be selected between five given options based on a three-minute-long video clip. While some prior works have proposed video datasets with long clip lengths, we posit that merely the length of the video clip does not truly capture the temporal difficulty of the video task that is being considered. To remedy this, we introduce temporal certificate sets, a general notion for capturing the intrinsic temporal understanding length associated with a broad range of video understanding tasks & datasets. Based on this metric, we find EgoSchema to have intrinsic temporal lengths over 5.7\u00d7 longer than the second closest dataset and 10\u00d7 to 100\u00d7 longer than any other video understanding dataset. Further, our evaluation of several current state-of-the-art video and language models shows them to be severely lacking in long-term video understanding capabilities. Even models with several billions of parameters achieve QA accuracy less than 33% (random is 20%) on the EgoSchema multi-choice question answering task, while humans achieve about 76% accuracy. We posit that EgoSchema, with its long intrinsic temporal structures and diverse complexity, would serve as a valuable evaluation probe for developing effective long-term video understanding systems in the future. Data and Zero-shot model evaluation code are open-sourced under the Ego4D license at egoschema.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10224",
        "title": "RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization",
        "abstract": "Visual Reinforcement Learning (Visual RL), coupled with high-dimensional ob- servations, has consistently confronted the long-standing challenge of out-of- distribution generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents\u2019 visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclu- sions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspi- ration is that RL-ViGen will serve as a catalyst in this area, and lay a foundation for the future creation of universal visual generalization RL agents suitable for real-world scenarios. Access to our code and implemented algorithms is provided at https://gemcollector.github.io/RL-ViGen/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.10440",
        "title": "OpenLane-V2: A Topology Reasoning Benchmark for Unified 3D HD Mapping",
        "abstract": "Accurately depicting the complex traffic scene is a vital component for autonomous vehicles to execute correct judgments. However, existing benchmarks tend to oversimplify the scene by solely focusing on lane perception tasks. Observing that human drivers rely on both lanes and traffic signals to operate their vehicles safely, we present OpenLane-V2, the first dataset on topology reasoning for traffic scene structure. The objective of the presented dataset is to advance research in understanding the structure of road scenes by examining the relationship between perceived entities, such as traffic elements and lanes. Leveraging existing datasets, OpenLane-V2 consists of 2,000 annotated road scenes that describe traffic elements and their correlation to the lanes. It comprises three primary sub-tasks, including the 3D lane detection inherited from OpenLane, accompanied by corresponding metrics to evaluate the model\u2019s performance. We evaluate various state-of-the-art methods, and present their quantitative and qualitative results on OpenLane-V2 to indicate future avenues for investigating topology reasoning in traffic scenes.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.12423",
        "title": "Benchmarking and Analyzing 3D-aware Image Synthesis with a Modularized Codebase",
        "abstract": "Despite the rapid advance of 3D-aware image synthesis, existing studies usually adopt a mixture of techniques and tricks, leaving it unclear how each part contributes to the final performance in terms of generality. Following the most popular and effective paradigm in this field, which incorporates a neural radiance field (NeRF) into the generator of a generative adversarial network (GAN), we build a well-structured codebase, dubbed Carver, through modularizing the generation process. Such a design allows researchers to develop and replace each module independently, and hence offers an opportunity to fairly compare various approaches and recognize their contributions from the module perspective. The reproduction of a range of cutting-edge algorithms demonstrates the availability of our modularized codebase. We also perform a variety of in-depth analyses, such as the comparison across different types of point feature, the necessity of the tailing upsampler in the generator, the reliance on the camera pose prior, etc., which deepen our understanding of existing methods and point out some further directions of the research work. We release code and models here to facilitate the development and evaluation of this field.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2206.09203",
        "title": "Interactive Visual Reasoning under Uncertainty",
        "abstract": "One of the fundamental cognitive abilities of humans is to quickly resolve uncer- tainty by generating hypotheses and testing them via active trials. Encountering a novel phenomenon accompanied by ambiguous cause-effect relationships, humans make hypotheses against data, conduct inferences from observation, test their the- ory via experimentation, and correct the proposition if inconsistency arises. These iterative processes persist until the underlying mechanism becomes clear. In this work, we devise the IVRE (pronounced as ivory) environment for evaluating artificial agents\u2019 reasoning ability under uncertainty. IVRE is an interactive environment featuring rich scenarios centered around Blicket detection. Agents in\nIVRE are placed into environments with various ambiguous action-effect pairs and asked to determine each object\u2019s role. They are encouraged to propose effective and efficient experiments to validate their hypotheses based on observations and actively gather new information. The game ends when all uncertainties are resolved or the maximum number of trials is consumed. By evaluating modern artificial agents in IVRE, we notice a clear failure of today\u2019s learning methods compared to humans. Such inefficacy in interactive reasoning ability under uncertainty calls for future research in building human-like intelligence.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2206.10668",
        "title": "BenchCLAMP: A Benchmark for Evaluating Language Models on Syntactic and Semantic Parsing\n",
        "abstract": "Recent work has shown that generation from a prompted or fine-tuned language model can perform well at semantic parsing when the output is constrained to be a valid semantic representation. We introduce BenchCLAMP, a Benchmark to evaluate Constrained LAnguage Model Parsing, that includes context-free gram- mars for seven semantic parsing datasets and two syntactic parsing datasets with varied output representations, as well as a constrained decoding interface to gen- erate only valid outputs covered by these grammars. We provide low, medium, and high resource splits for each dataset, allowing accurate comparison of various language models under different data regimes. Our benchmark supports evalua- tion of language models using prompt-based learning as well as fine-tuning. We benchmark eight language models, including two GPT-3 variants available only through an API. Our experiments show that encoder-decoder pretrained language models can achieve similar performance or surpass state-of-the-art methods for syntactic and semantic parsing when the model output is constrained to be valid.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10768",
        "title": "Decoding the Enigma: Benchmarking Humans and AIs on the Many Facets of Working Memory",
        "abstract": "Working memory (WM), a fundamental cognitive process facilitating the temporary storage, integration, manipulation, and retrieval of information, plays a vital role in reasoning and decision-making tasks. Robust benchmark datasets that capture the multifaceted nature of WM are crucial for the effective development and evaluation of AI WM models. Here, we introduce a comprehensive Working Memory (WorM) benchmark dataset for this purpose. WorM comprises 10 tasks and a total of 1 million trials, assessing 4 functionalities, 3 domains, and 11 behavioral and neural characteristics of WM. We jointly trained and tested state-of-the-art recurrent neural networks and transformers on all these tasks. For comparison, we also include human behavioral benchmarks. Note that all computational models were never trained with any human data or behavioral biases; yet, these models remarkably replicate some characteristics of WM in biological brains, such as primacy and recency effects. Moreover, we performed neural population analysis on these models and identified neural clusters specialized for different domains and functionalities of WM. Not all computational models exhibit a strong alignment with all human behaviors. Our experimental results also reveal several limitations in existing models to match with working memory capabilities of humans. This dataset serves as a valuable resource for communities in cognitive psychology, neuroscience, and AI, offering a standardized framework to compare and enhance WM models, investigate WM\u2019s neural underpinnings, and develop WM models with human-like capabilities. Our source code and data are available at: link.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.19252",
        "title": "Revisiting Evaluation Metrics for Semantic Segmentation: Optimization and Evaluation of Fine-grained Intersection over Union",
        "abstract": "Semantic segmentation datasets often exhibit two types of imbalance: class imbal- ance, where some classes appear more frequently than others and size imbalance, where some objects occupy more pixels than others. This causes traditional evalua- tion metrics to be biased towards majority classes (e.g. overall pixel-wise accuracy) and large objects (e.g. mean pixel-wise accuracy and per-dataset mean intersection over union). To address these shortcomings, we propose the use of fine-grained mIoUs along with corresponding worst-case metrics, thereby offering a more holis- tic evaluation of segmentation techniques. These fine-grained metrics offer less bias towards large objects, richer statistical information, and valuable insights into model and dataset auditing. Furthermore, we undertake an extensive benchmark study, where we train and evaluate 15 modern neural networks with the proposed metrics on 12 diverse natural and aerial segmentation datasets. Our benchmark study highlights the necessity of not basing evaluations on a single metric and confirms that fine-grained mIoUs reduce the bias towards large objects. Moreover, we identify the crucial role played by architecture designs and loss functions, which lead to best practices in optimizing fine-grained metrics. The code is available at https://github.com/zifuwanggg/JDTLosses.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.03810",
        "title": "URL: A Representation Learning Benchmark for Transferable Uncertainty Estimates",
        "abstract": "Representation learning has significantly driven the field to develop pretrained models that can act as a valuable starting point when transferring to new datasets. With the rising demand for reliable machine learning and uncertainty quantification, there is a need for pretrained models that not only provide embeddings but also transferable uncertainty estimates. To guide the development of such models, we propose the Uncertainty-aware Representation Learning (URL) benchmark. Besides the transferability of the representations, it also measures the zero-shot transferability of the uncertainty estimate using a novel metric. We apply URL to evaluate eleven uncertainty quantifiers that are pretrained on ImageNet and transferred to eight downstream datasets. We find that approaches that focus on the uncertainty of the representation itself or estimate the prediction loss directly outperform those that are based on the probabilities of upstream classes. Yet, achieving transferable uncertainty quantification remains an open challenge. Our findings indicate that it is not necessarily in conflict with traditional representation learning goals. Code is available at https://github.com/mkirchhof/url.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.01586",
        "title": "Alexa Arena: A User-Centric Interactive Platform for Embodied AI",
        "abstract": "We introduce Alexa Arena, a user-centric sim- ulation platform for Embodied AI (EAI) re- search. Alexa Arena provides a variety of multi-room layouts and interactable objects, for the creation of human-robot interaction (HRI) missions. With user-friendly graphics and control mechanisms, Alexa Arena sup- ports the development of gamified robotic tasks readily accessible to general human users, thus opening a new venue for high-efficiency HRI data collection and EAI system evaluation. Along with the platform, we introduce a dialog- enabled instruction-following benchmark and provide baseline results for it. We make Alexa Arena1 publicly available to facilitate research in building generalizable and assistive embod- ied agents.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10514",
        "title": "Building Socio-culturally Inclusive Stereotype Resources with Community Engagement",
        "abstract": "With rapid development and deployment of generative language models in global settings, there is an urgent need to also scale our measurements of harm, not just in the number and types of harms covered, but also how well they account for local cultural contexts, including marginalized identities and the social biases ex- perienced by them. Current evaluation paradigms are limited in their abilities to address this, as they are not representative of diverse, locally situated but global, socio-cultural perspectives. It is imperative that our evaluation resources are en- hanced and calibrated by including people and experiences from different cultures and societies worldwide, in order to prevent gross underestimations or skews in measurements of harm. In this work, we demonstrate a socio-culturally aware expansion of evaluation resources in the Indian societal context, specifically for the harm of stereotyping. We devise a community engaged effort to build a resource which contains stereotypes for axes of disparity that are uniquely present in India. The resultant resource increases the number of stereotypes known for and in the Indian context by over 1000 stereotypes across many unique identities. We also demonstrate the utility and effectiveness of such expanded resources for evalua- tions of language models. CONTENT WARNING: This paper contains examples of stereotypes that may be offensive.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2207.13332",
        "title": "REALTIME QA: What\u2019s the Answer Right Now?",
        "abstract": "We introduce REALTIME QA, a dynamic question answering (QA) platform that announces questions and evaluates systems on a regular basis (weekly in this version). REALTIME QA inquires about the current world, and QA systems need to answer questions about novel events or information. It therefore challenges static, conventional assumptions in open-domain QA datasets and pursues instantaneous applications. We build strong baseline models upon large pretrained language models, including GPT-3 and T5. Our benchmark is an ongoing effort, and this paper presents real-time evaluation results over the past year. Our experimental results show that GPT-3 can often properly update its generation results, based on newly-retrieved documents, highlighting the importance of up-to-date information retrieval. Nonetheless, we find that GPT-3 tends to return outdated answers when retrieved documents do not provide sufficient information to find an answer. This suggests an important avenue for future research: can an open-domain QA system identify such unanswerable cases and communicate with the user or even the retrieval module to modify the retrieval results? We hope that REALTIME QA will\nspur progress in instantaneous applications of question answering and beyond.2",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08731",
        "title": "EPIC Fields\nMarrying 3D Geometry and Video Understanding",
        "abstract": "Neural rendering is fuelling a unification of learning, 3D geometry and video understanding that has been waiting for more than two decades. Progress, however, is still hampered by a lack of suitable datasets and benchmarks. To address this gap, we introduce EPIC Fields, an augmentation of EPIC-KITCHENS with 3D camera information. Like other datasets for neural rendering, EPIC Fields removes the complex and expensive step of reconstructing cameras using photogrammetry, and allows researchers to focus on modelling problems. We illustrate the challenge of photogrammetry in egocentric videos of dynamic actions and propose innovations to address them. Compared to other neural rendering datasets, EPIC Fields is better tailored to video understanding because it is paired with labelled action segments and the recent VISOR segment annotations. To further motivate the community, we also evaluate three benchmark tasks in neural rendering and segmenting dynamic objects, with strong baselines that showcase what is not possible today. We also highlight the advantage of geometry in semi-supervised video object segmentations on the VISOR annotations. EPIC Fields reconstructs 96% of videos in EPIC- KITCHENS, registering 19M frames in 99 hours recorded in 45 kitchens, and is available from: http://epic-kitchens.github.io/epic-fields",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2011.12948",
        "title": "Nerfies: Deformable Neural Radiance Fields",
        "abstract": "We present the first method capable of photorealistically reconstructing deformable scenes using photos/videos cap- tured casually from mobile phones. Our approach augments neural radiance fields (NeRF) by optimizing an additional continuous volumetric deformation field that warps each observed point into a canonical 5D NeRF. We observe that these NeRF-like deformation fields are prone to local min- ima, and propose a coarse-to-fine optimization method for coordinate-based models that allows for more robust opti- mization. By adapting principles from geometry processing and physical simulation to NeRF-like models, we propose an elastic regularization of the deformation field that further improves robustness. We show that our method can turn casually captured selfie photos/videos into deformable NeRF models that allow for photorealistic renderings of the subject from arbitrary viewpoints, which we dub \u201cnerfies.\u201d We evalu- ate our method by collecting time-synchronized data using a rig with two mobile phones, yielding train/validation images of the same pose at different viewpoints. We show that our method faithfully reconstructs non-rigidly deforming scenes and reproduces unseen views with high fidelity.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2011.13961",
        "title": "D-NeRF: Neural Radiance Fields for Dynamic Scenes",
        "abstract": "Neural rendering techniques combining machine learn- ing with geometric reasoning have arisen as one of the most promising approaches for synthesizing novel views of a scene from a sparse set of images. Among these, stands out the Neural radiance fields (NeRF) [26], which trains a deep network to map 5D input coordinates (representing spatial location and viewing direction) into a volume density and view-dependent emitted radiance. However, despite achiev- ing an unprecedented level of photorealism on the gener- ated images, NeRF is only applicable to static scenes, where the same spatial location can be queried from different im- ages. In this paper we introduce D-NeRF, a method that extends neural radiance fields to a dynamic domain, allow- ing to reconstruct and render novel images of objects under rigid and non-rigid motions from a single camera moving around the scene. For this purpose we consider time as an additional input to the system, and split the learning process in two main stages: one that encodes the scene into a canon- ical space and another that maps this canonical represen- tation into the deformed scene at a particular time. Both\nmappings are simultaneously learned using fully-connected networks. Once the networks are trained, D-NeRF can ren- der novel images, controlling both the camera view and the time variable, and thus, the object movement. We demon- strate the effectiveness of our approach on scenes with ob- jects under rigid, articulated and non-rigid motions. Code, model weights and the dynamic scenes dataset will be re- leased.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2106.13228",
        "title": "HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields",
        "abstract": "Neural Radiance Fields (NeRF) are able to reconstruct scenes with unprece- dented fidelity, and various recent works have extended NeRF to handle dynamic scenes. A common approach to reconstruct such non-rigid scenes is through the use of a learned deformation field mapping from coordinates in each input image into a canonical template coordinate space. However, these deformation-based approaches struggle to model changes in topology, as topological changes require a discontinuity in the deformation field, but these deformation fields are necessarily continuous. We address this limita- tion by lifting NeRFs into a higher dimensional space, and by representing the 5D radiance field corresponding to each individual input image as a slice through this \u201chyper-space\u201d. Our method is inspired by level set methods, which model the evolution of surfaces as slices through a higher dimensional surface. We evaluate our method on two tasks: (i) interpolating smoothly be- tween \u201cmoments\u201d, i.e., configurations of the scene, seen in the input images while maintaining visual plausibility, and (ii) novel-view synthesis at fixed moments. We show that our method, which we dub HyperNeRF, outperforms existing methods on both tasks. Compared to Nerfies, HyperNeRF reduces average error rates by 4.1% for interpolation and 8.6% for novel-view syn- thesis, as measured by LPIPS. Additional videos, results, and visualizations are available at hypernerf.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.15123",
        "title": "Uncovering Neural Scaling Laws\nin Molecular Representation Learning",
        "abstract": "Molecular Representation Learning (MRL) has emerged as a powerful tool for drug and materials discovery in a variety of tasks such as virtual screening and inverse design. While there has been a surge of interest in advancing model- centric techniques, the influence of both data quantity and quality on molecular representations is not yet clearly understood within this field. In this paper, we delve into the neural scaling behaviors of MRL from a data-centric viewpoint, examining four key dimensions: (1) data modalities, (2) dataset splitting, (3) the role of pre-training, and (4) model capacity. Our empirical studies confirm a consistent power-law relationship between data volume and MRL performance across these dimensions. Additionally, through detailed analysis, we identify potential avenues for improving learning efficiency. To challenge these scaling laws, we adapt seven popular data pruning strategies to molecular data and benchmark their performance. Our findings underline the importance of data-centric MRL and highlight possible directions for future research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.10161",
        "title": "Building the Bridge of Schr\u00f6dinger:\nA Continuous Entropic Optimal Transport Benchmark",
        "abstract": "Over the last several years, there has been significant progress in developing neural solvers for the Schr\u00f6dinger Bridge (SB) problem and applying them to generative modelling. This new research field is justifiably fruitful as it is interconnected with the practically well-performing diffusion models and theoretically grounded entropic optimal transport (EOT). Still, the area lacks non-trivial tests allowing a researcher to understand how well the methods solve SB or its equivalent continuous EOT problem. We fill this gap and propose a novel way to create pairs of probability distributions for which the ground truth OT solution is known by the construction. Our methodology is generic and works for a wide range of OT formulations, in particular, it covers the EOT which is equivalent to SB (the main interest of our study). This development allows us to create continuous benchmark distributions with the known EOT and SB solutions on high-dimensional spaces such as spaces of images. As an illustration, we use these benchmark pairs to test how well existing neural EOT/SB solvers actually compute the EOT solution. Our code for constructing benchmark pairs under different setups is available at:\nhttps://github.com/ngushchin/EntropicOTBenchmark",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.13023",
        "title": "Seeing is not always believing: Benchmarking Human and Model Perception of AI-Generated Images\n",
        "abstract": "Photos serve as a way for humans to record what they experience in their daily lives, and they are often regarded as trustworthy sources of information. However, there is a growing concern that the advancement of artificial intelligence (AI) technology may produce fake photos, which can create confusion and diminish trust in photographs. This study aims to comprehensively evaluate agents for distinguishing state-of-the-art AI-generated visual content. Our study benchmarks both human capability and cutting-edge fake image detection AI algorithms, using a newly collected large-scale fake image dataset Fake2M. In our human perception evaluation, titled HPBench, we discovered that humans struggle significantly to distinguish real photos from AI-generated ones, with a misclassification rate of 38.7%. Along with this, we conduct the model capability of AI-Generated images detection evaluation MPBench and the top-performing model from MPBench achieves a 13% failure rate under the same setting used in the human evaluation. We hope that our study can raise awareness of the potential risks of AI-generated images and facilitate further research to prevent the spread of false information. More information can refer to https://github.com/Inf-imagine/Sentry.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.05378",
        "title": "M2Hub: Unlocking the Potential of Machine Learning for Materials Discovery",
        "abstract": "We introduce M2Hub, a toolkit for advancing machine learning in materials dis- covery. Machine learning has achieved remarkable progress in modeling molecular structures, especially biomolecules for drug discovery. However, the development of machine learning approaches for modeling materials structures lag behind, which is partly due to the lack of an integrated platform that enables access to diverse tasks for materials discovery. To bridge this gap, M2Hub will enable easy access to materials discovery tasks, datasets, machine learning methods, evaluations, and benchmark results that cover the entire workflow. Specifically, the first release of M2Hub focuses on three key stages in materials discovery: virtual screening, inverse design, and molecular simulation, including 9 datasets that covers 6 types of materials with 56 tasks across 8 types of material properties. We further provide 2 synthetic datasets for the purpose of generative tasks on materials. In addition to random data splits, we also provide 3 additional data partitions to reflect the real-world materials discovery scenarios. State-of-the-art machine learning meth- ods (including those are suitable for materials structures but never compared in the literature) are benchmarked on representative tasks. Our codes and library are publicly available at https://github.com/yuanqidu/M2Hub.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2005.00707",
        "title": "Benchmarking Materials Property Prediction Methods: The Matbench Test Set and Automatminer Reference Algorithm",
        "abstract": "We present a benchmark test suite and an automated machine learning procedure for evaluating supervised machine learning (ML) models for predicting properties of inorganic bulk materials. The test suite, Matbench, is a set of 13 ML tasks that range in size from 312 to 132k samples and contain data from 10 density functional theory-derived and experimental sources. Tasks include predicting optical, thermal, electronic, thermodynamic, tensile, and elastic properties given a materials composition and/or crystal structure. The reference algorithm, Automatminer, is a highly-extensible, fully-automated ML pipeline for predicting materials properties from materials primitives (such as composition and crystal structure) without user intervention or hyperparameter tuning. We test Automatminer on the Matbench test suite and compare its predictive power with state-of-the-art crystal graph neural networks and a traditional descriptor-based Random Forest model. We find Automatminer achieves the best performance on 8 of 13 tasks in the benchmark.\nWe also show our test suite is capable of exposing predictive advantages of each algorithm \u2013 namely, that crystal graph methods appear to outperform traditional machine learning methods given ~104 or greater data points. The pre-processed, ready-to-use Matbench tasks and the Automatminer source code are open source and available online (http://hackingmaterials.lbl.gov/automatminer/). We encourage evaluating new materials ML algorithms on the Matbench benchmark and comparing them against the latest version of Automatminer.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.11155v3",
        "title": "Beyond MD17: the reactive xxMD dataset",
        "abstract": "System specific neural force fields (NFFs) have gained popularity in computational chemistry. One of the most popular datasets as a bencharmk to develop NFFs models is the MD17 dataset and its subsequent extension. These datasets comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampled from direct adiabatic dynamics. However, many chemical reactions involve significant molecular geometrical deformations, for example, bond breaking. Therefore, MD17 is inadequate to represent a chemical reaction. To address this limitation in MD17, we introduce a new dataset, called Extended Excited-state Molecular Dynamics (xxMD) dataset. The xxMD dataset involves geometries sampled from direct non-adiabatic dynamics, and the energies are computed at both multireference wavefunction theory and density functional theory. We show that the xxMD dataset involves diverse geometries which represent chemical reactions. Assessment of NFF models on xxMD dataset reveals significantly higher predictive errors than those reported for MD17 and its variants. This work underscores the challenges faced in crafting a generalizable NFF model with extrapolation capability.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2103.09382",
        "title": "SPICE: Semantic Pseudo-Labeling for Image Clustering",
        "abstract": "The similarity among samples and the discrepancy among clusters are two crucial aspects of image clustering. However, current deep clustering methods suffer from inaccurate estimation of either feature similarity or semantic discrepancy. In this paper, we present a Semantic Pseudo-labeling-based Image ClustEring (SPICE) framework, which divides the clustering network into a feature model for measuring the instance-level similarity and a clustering head for identifying the cluster-level discrepancy. We design two semantics-aware pseudo-labeling al- gorithms, prototype pseudo-labeling and reliable pseudo-labeling, which enable accurate and reliable self-supervision over cluster- ing. Without using any ground-truth label, we optimize the clus- tering network in three stages: 1) train the feature model through contrastive learning to measure the instance similarity; 2) train the clustering head with the prototype pseudo-labeling algorithm to identify cluster semantics; and 3) jointly train the feature model and clustering head with the reliable pseudo-labeling algorithm to improve the clustering performance. Extensive experimental results demonstrate that SPICE achieves significant improvements (\u223c10%) over existing methods and establishes the new state-of-the-art clustering results on six image benchmark datasets in terms of three popular metrics. Importantly, SPICE significantly reduces the gap between unsupervised and fully- supervised classification; e.g. there is only 2% (91.8% vs 93.8%) accuracy difference on CIFAR-10. Our code is made publically available at https://github.com/niuchuangnn/SPICE.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2010.09990",
        "title": "The Open Catalyst 2020 (OC20) Dataset and Community Challenges",
        "abstract": "Catalyst discovery and optimization is key to solving many societal and energy challenges including solar fuels synthesis, long-term energy storage, and renewable fertilizer production. Despite considerable effort by the catalysis community to apply machine learning models to the computational catalyst discovery process, it remains an open challenge to build mod- els that can generalize across both elemental compositions of surfaces and adsorbate iden- tity/configurations, perhaps because datasets have been smaller in catalysis than related fields. To address this we developed the OC20 dataset, consisting of 1,281,040 Density Functional Theory (DFT) relaxations (\u223c264,890,000 single point evaluations) across a wide swath of materials, surfaces, and adsorbates (nitrogen, carbon, and oxygen chemistries). We supple- mented this dataset with randomly perturbed structures, short timescale molecular dynamics, and electronic structure analyses. The dataset comprises three central tasks indicative of day- to-day catalyst modeling and comes with pre-defined train/validation/test splits to facilitate direct comparisons with future model development efforts. We applied three state-of-the-art graph neural network models (CGCNN, SchNet, DimeNet++) to each of these tasks as base- line demonstrations for the community to build on. In almost every task, no upper limit on model size was identified, suggesting that even larger models are likely to improve on initial results. The dataset and baseline models are both provided as open resources, as well as a public leader board to encourage community contributions to solve these important tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.15895",
        "title": "Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias",
        "abstract": "Large language models (LLMs) have been recently leveraged as training data generators for various natural language processing (NLP) tasks. While previous research has explored different approaches to training models using generated data, they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM. Thus, we investigate training data generation with diversely attributed prompts (e.g., specifying attributes like length and style), which have the potential to yield diverse and attributed generated data. Our investigation focuses on datasets with high cardinality and diverse domains, wherein we demonstrate that attributed prompts outperform simple class-conditional prompts in terms of the resulting model\u2019s performance. Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations: firstly, synthetic datasets generated by simple prompts exhibit significant biases, such as regional bias; secondly, attribute diversity plays a pivotal role in enhancing model performance; lastly, attributed prompts achieve the performance of simple class-conditional prompts while utilizing only 5% of the querying cost of ChatGPT associated with the latter. We release the generated dataset and used prompts to facilitate future research2.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09467",
        "title": "AQuA: A Benchmarking Tool for Label Quality Assessment",
        "abstract": "Machine learning (ML) models are only as good as the data they are trained on. But recent studies have found datasets widely used to train and evaluate ML models, e.g. ImageNet, to have pervasive labeling errors. Erroneous labels on the train set hurt ML models\u2019 ability to generalize, and they impact evaluation and model selection using the test set. Consequently, learning in the presence of labeling errors is an active area of research, yet this field lacks a comprehensive benchmark to evaluate these methods. Most of these methods are evaluated on a few computer vision datasets with significant variance in the experimental protocols. With such a large pool of methods and inconsistent evaluation, it is also unclear how ML practitioners can choose the right models to assess label quality in their data. To this end, we propose a benchmarking environment AQuA to rigorously evaluate methods that enable machine learning in the presence of label noise. We also introduce a design space to delineate concrete design choices of label error detection models. We hope that our proposed design space and benchmark enable practitioners to choose the right tools to improve their label quality and that our benchmark enables objective and rigorous evaluation of machine learning tools facing mislabeled data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.06231",
        "title": "Learning Human Action Recognition Representations Without Real Humans",
        "abstract": "Pre-training on massive video datasets has become essential to achieve high action recognition performance on smaller downstream datasets. However, most large- scale video datasets contain images of people and hence are accompanied with issues related to privacy, ethics, and data protection, often preventing them from being publicly shared for reproducible research. Existing work has attempted to alleviate these problems by blurring faces, downsampling videos, or training on synthetic data. On the other hand, analysis on the transferability of privacy- preserving pre-trained models to downstream tasks has been limited. In this work, we study this problem by first asking the question: can we pre-train models for human action recognition with data that does not include real humans? To this end, we present, for the first time, a benchmark that leverages real-world videos with humans removed and synthetic data containing virtual humans to pre-train a model. We then evaluate the transferability of the representation learned on this data to a diverse set of downstream action recognition benchmarks. Furthermore, we propose a novel pre-training strategy, called Privacy-Preserving MAE-Align, to effectively combine synthetic data and human-removed real data. Our approach outperforms previous baselines by up to 5% and closes the performance gap between human and no-human action recognition representations on downstream tasks, for both linear probing and fine-tuning. Our benchmark, code, and models are available at https://github.com/howardzh01/PPMA.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.05107",
        "title": "OV-PARTS: Towards Open-Vocabulary Part Segmentation",
        "abstract": "Segmenting and recognizing diverse object parts is a crucial ability in applications spanning various computer vision and robotic tasks. While significant progress\nhas been made in object-level Open-Vocabulary Semantic Segmentation (OVSS),\ni.e., segmenting objects with arbitrary text, the corresponding part-level research poses additional challenges. Firstly, part segmentation inherently involves intricate boundaries, while limited annotated data compounds the challenge. Secondly, part segmentation introduces an open granularity challenge due to the diverse and often ambiguous definitions of parts in the open world. Furthermore, the large-scale vision and language models, which play a key role in the open vocabulary setting, struggle to recognize parts as effectively as objects. To comprehensively investigate and tackle these challenges, we propose an Open-Vocabulary Part Segmentation (OV-PARTS) benchmark. OV-PARTS includes refined versions of two publicly available datasets: Pascal-Part-116 and ADE20K-Part-234. And it covers three specific tasks: Generalized Zero-Shot Part Segmentation, Cross-Dataset Part Segmentation, and Few-Shot Part Segmentation, providing insights into analogical reasoning, open granularity and few-shot adapting abilities of models. Moreover, we analyze and adapt two prevailing paradigms of existing object-level OVSS methods for OV-PARTS. Extensive experimental analysis is conducted to inspire future research in leveraging foundational models for OV-PARTS. The code and dataset are available at https://github.com/OpenRobotLab/OV_PARTS.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.10012",
        "title": "MAGICBRUSH : A Manually Annotated Dataset for Instruction-Guided Image Editing",
        "abstract": "Text-guided image editing is widely needed in daily life, ranging from personal use to professional applications such as Photoshop. However, existing methods are either zero-shot or trained on an automatically synthesized dataset, which contains a high volume of noise. Thus, they still require lots of manual tun- ing to produce desirable outcomes in practice. To address this issue, we intro- duce MAGICBRUSH (https://osu-nlp-group.github.io/MagicBrush/), the first large-scale, manually annotated dataset for instruction-guided real image editing that covers diverse scenarios: single-turn, multi-turn, mask-provided, and mask-free editing. MAGICBRUSH comprises over 10K manually annotated triplets (source image, instruction, target image), which supports training large-scale text- guided image editing models. We fine-tune InstructPix2Pix on MAGICBRUSH and show that the new model can produce much better images according to human evaluation. We further conduct extensive experiments to evaluate current image editing baselines from multiple dimensions including quantitative, qualitative, and human evaluations. The results reveal the challenging nature of our dataset and the gap between current baselines and real-world editing needs.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.02028",
        "title": "EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models",
        "abstract": "While the general machine learning (ML) community has benefited from public datasets, tasks, and models, the progress of ML in healthcare has been hampered by a lack of such shared assets. The success of foundation models creates new challenges for healthcare ML by requiring access to shared pretrained models to validate performance benefits. We help address these challenges through three contributions. First, we publish a new dataset, EHRSHOT, which contains de- identified structured data from the electronic health records (EHRs) of 6,739 patients from Stanford Medicine. Unlike MIMIC-III/IV and other popular EHR datasets, EHRSHOT is longitudinal and not restricted to ICU/ED patients. Second, we publish the weights of CLMBR-T-base, a 141M parameter clinical foundation model pretrained on the structured EHR data of 2.57M patients. We are one of the first to fully release such a model for coded EHR data; in contrast, most prior models released for clinical data (e.g. GatorTron, ClinicalBERT) only work with unstructured text and cannot process the rich, structured data within an EHR. We provide an end-to-end pipeline for the community to validate and build upon its performance. Third, we define 15 few-shot clinical prediction tasks, enabling evaluation of foundation models on benefits such as sample efficiency and task adaptation. Our model and dataset are available via a research data use agreement from our website. Code to reproduce our results is available here.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.01999",
        "title": "Revisiting the Evaluation of Image Synthesis with GANs",
        "abstract": "a  good metric, which promises a reliable comparison between solutions, is essential for any well-defined task. Unlike most vision tasks that have per-sample ground- truth, image synthesis tasks target generating unseen data and hence are usually evaluated through a distributional distance between one set of real samples and another set of generated samples. This study presents an empirical investigation into the evaluation of synthesis performance, with generative adversarial networks (GANs) as a representative of generative models. In particular, we make in- depth analyses of various factors, including how to represent a data point in the representation space, how to calculate a fair distance using selected samples, and how many instances to use from each set. Extensive experiments conducted on multiple datasets and settings reveal several important findings. Firstly, a group of models that include both CNN-based and ViT-based architectures serve as reliable and robust feature extractors for measurement evaluation. Secondly, Centered Kernel Alignment (CKA) provides a better comparison across various extractors and hierarchical layers in one model. Finally, CKA is more sample- efficient and enjoys better agreement with human judgment in characterizing the similarity between two internal data correlations. These findings contribute to the development of a new measurement system, which enables a consistent and reliable re-evaluation of current state-of-the-art generative models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.16981",
        "title": "Reimagining Synthetic Tabular Data Generation through Data-Centric AI:\nA Comprehensive Benchmark",
        "abstract": "Synthetic data serves as an alternative in training machine learning models, par- ticularly when real-world data is limited or inaccessible. However, ensuring that synthetic data mirrors the complex nuances of real-world data is a challenging task. This paper addresses this issue by exploring the potential of integrating data-centric AI techniques which profile the data to guide the synthetic data generation process. Moreover, we shed light on the often ignored consequences of neglecting these data profiles during synthetic data generation \u2014 despite seemingly high statistical fidelity. Subsequently, we propose a novel framework to evaluate the integration of data profiles to guide the creation of more representative synthetic data. In an empirical study, we evaluate the performance of five state-of-the-art models for tabular data generation on eleven distinct tabular datasets. The findings offer critical insights into the successes and limitations of current synthetic data gener- ation techniques. Finally, we provide practical recommendations for integrating data-centric insights into the synthetic data generation process, with a specific focus on classification performance, model selection, and feature selection. This study aims to reevaluate conventional approaches to synthetic data generation and promote the application of data-centric AI techniques in improving the quality and effectiveness of synthetic data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.17768",
        "title": "A Dataset of Relighted 3D Interacting Hands",
        "abstract": "The two-hand interaction is one of the most challenging signals to analyze due to the self-similarity, complicated articulations, and occlusions of hands. Although several datasets have been proposed for the two-hand interaction analysis, all of them do not achieve 1) diverse and realistic image appearances and 2) diverse and large-scale groundtruth (GT) 3D poses at the same time. In this work, we propose Re:InterHand, a dataset of relighted 3D interacting hands that achieve the two goals. To this end, we employ a state-of-the-art hand relighting network with our accurately tracked two-hand 3D poses. We compare our Re:InterHand with existing 3D interacting hands datasets and show the benefit of it. Our Re:InterHand is available in here.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.03153",
        "title": "MultiVENT: Multilingual Videos of Events with Aligned Natural Text",
        "abstract": "Everyday news coverage has shifted from traditional broadcasts towards a wide range of presentation formats such as first-hand, unedited video footage. Datasets that reflect the diverse array of multimodal, multilingual news sources available online could be used to teach models to benefit from this shift, but existing news video datasets focus on traditional news broadcasts produced for English-speaking audiences. We address this limitation by constructing MultiVENT, a dataset of multilingual, event-centric videos grounded in text documents across five target languages. MultiVENT includes both news broadcast videos and non-professional event footage, which we use to analyze the state of online news videos and how they can be leveraged to build robust, factually accurate models. Finally, we provide a model for complex, multilingual video retrieval to serve as a baseline for information retrieval using MultiVENT.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.02408",
        "title": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning",
        "abstract": "chain-of-thought prompting (CoT) and tool augmentation have been validated in recent work as effective practices for improving large language models (LLMs) to perform step-by-step reasoning on complex math-related tasks. However, most existing math reasoning datasets may be not able to fully evaluate and analyze the ability of LLMs in manipulating tools and performing reasoning, as they may only require very few invocations of tools or miss annotations for evaluating intermediate reasoning steps. To address the issue, we construct CARP, a new Chinese dataset consisting of 4,886 computation-intensive algebra problems with formulated annotations on intermediate steps. In CARP, we test four LLMs with CoT prompting, and find that they are all prone to make mistakes at the early steps of the solution, leading to wrong answers. Based on this finding, we propose a new approach that can deliberate the reasoning steps with tool interfaces, namely DELI. In DELI, we first initialize a step-by-step solution based on retrieved exemplars, then iterate two deliberation procedures that check and refine the intermediate steps of the generated solution, from the perspectives of tool manipulation and natural language reasoning, until obtaining converged solutions or reaching the maximum turn. Experimental results on CARP and six other datasets show that the proposed DELI mostly outperforms competitive baselines, and can further boost the performance of existing CoT methods. Our data and code are available in https://github.com/RUCAIBox/CARP.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.07716",
        "title": "PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection",
        "abstract": "Object anomaly detection is an important problem in the field of machine vision and has seen remarkable progress recently. However, two significant challenges hinder its research and application. First, existing datasets lack comprehensive visual information from various pose angles. They usually have an unrealistic assumption that the anomaly-free training dataset is pose-aligned, and the testing samples have the same pose as the training data. However, in practice, anomaly may exist in any regions on a object, the training and query samples may have different poses, calling for the study on pose-agnostic anomaly detection. Second, the absence of a consensus on experimental protocols for pose-agnostic anomaly de- tection leads to unfair comparisons of different methods, hindering the research on pose-agnostic anomaly detection. To address these issues, we develop Multi-pose Anomaly Detection (MAD) dataset and Pose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step to address the pose-agnostic anomaly detec- tion problem. Specifically, we build MAD using 20 complex-shaped LEGO toys including 4K views with various poses, and high-quality and diverse 3D anomalies in both simulated and real environments. Additionally, we propose a novel method OmniposeAD, trained using MAD, specifically designed for pose-agnostic anomaly detection. Through comprehensive evaluations, we demonstrate the relevance of our dataset and method. Furthermore, we provide an open-source benchmark library, including dataset and baseline methods that cover 8 anomaly detection paradigms, to facilitate future research and application in this domain. Code, data, and models are publicly available at https://github.com/EricLee0224/PAD",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08772",
        "title": "Katakomba:\nTools and Benchmarks for Data-Driven NetHack",
        "abstract": "NetHack is known as the frontier of reinforcement learning research where learning- based methods still need to catch up to rule-based solutions. One of the promising directions for a breakthrough is using pre-collected datasets similar to recent developments in robotics, recommender systems, and more under the umbrella of offline reinforcement learning (ORL). Recently, a large-scale NetHack dataset was released; while it was a necessary step forward, it has yet to gain wide adoption in the ORL community. In this work, we argue that there are three major obstacles for adoption: resource-wise, implementation-wise, and benchmark-wise. To address them, we develop an open-source library2 that provides workflow fundamentals familiar to the ORL community: pre-defined D4RL-style tasks, uncluttered baseline implementations, and reliable evaluation tools with accompanying configs and logs synced to the cloud.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.07577",
        "title": "Benchmarking Distribution Shift in Tabular Data with TableShift",
        "abstract": "Robustness to distribution shift has become a growing concern for text and im- age models as they transition from research subjects to deployment in the real world. However, high-quality benchmarks for distribution shift in tabular machine learning tasks are still lacking despite the widespread real-world use of tabular data and differences in the models used for tabular data in comparison to text and images. As a consequence, the robustness of tabular models to distribution shift is poorly understood. To address this issue, we introduce TABLESHIFT, a distribution shift benchmark for tabular data. TABLESHIFT contains 15 binary classification tasks in total, each with an associated shift, and includes a diverse set of data sources, prediction targets, and distribution shifts. The benchmark covers domains including finance, education, public policy, healthcare, and civic participation, and is accessible using only a few lines of Python code via the TABLESHIFT API. We conduct a large-scale study comparing several state-of-the-art tabular data models alongside robust learning and domain generalization methods on the benchmark tasks. Our study demonstrates (1) a linear trend between in-distribution (ID) and out-of-distribution (OOD) accuracy; (2) domain robustness methods can reduce shift gaps but at the cost of reduced ID accuracy; (3) a strong relationship between shift gap (difference between ID and OOD performance) and shifts in the label distribution.1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.13587",
        "title": "Benchmarking Encoder-Decoder Architectures for Biplanar X-ray to 3D Shape Reconstruction",
        "abstract": "\nVarious deep learning models have been proposed for 3D bone shape reconstruction from two orthogonal (biplanar) X-ray images. However, it is unclear how these models compare against each other since they are evaluated on different anatomy, cohort and (often privately held) datasets. Moreover, the impact of the commonly optimized image-based segmentation metrics such as dice score on the estimation of clinical parameters relevant in 2D-3D bone shape reconstruction is not well known. To move closer toward clinical translation, we propose a benchmarking framework that evaluates tasks relevant to real-world clinical scenarios, including reconstruction of fractured bones, bones with implants, robustness to population shift, and error in estimating clinical parameters. Our open-source platform pro- vides reference implementations of 8 models (many of whose implementations were not publicly available), APIs to easily collect and preprocess 6 public datasets, and the implementation of automatic clinical parameter and landmark extraction methods. We present an extensive evaluation of 8 2D-3D models on equal footing using 6 public datasets comprising images for four different anatomies. Our results show that attention-based methods that capture global spatial relationships tend to perform better across all anatomies and datasets; performance on clinically relevant subgroups may be overestimated without disaggregated reporting; ribs are substantially more difficult to reconstruct compared to femur, hip and spine; and the dice score improvement does not always bring a corresponding improvement in the automatic estimation of clinically relevant parameters.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.15376",
        "title": "ADGym: Design Choices for Deep Anomaly Detection",
        "abstract": "Deep learning (DL) techniques have recently found success in anomaly detection (AD) across various fields such as finance, medical services, and cloud computing. However, most of the current research tends to view deep AD algorithms as a whole, without dissecting the contributions of individual design choices like loss functions and network architectures. This view tends to diminish the value of preliminary steps like data preprocessing, as more attention is given to newly designed loss functions, network architectures, and learning paradigms. In this paper, we aim to bridge this gap by asking two key questions: (i) Which design choices in deep AD methods are crucial for detecting anomalies? (ii) How can we automatically select the optimal design choices for a given AD dataset, instead of relying on generic, pre- existing solutions? To address these questions, we introduce ADGym, a platform specifically crafted for comprehensive evaluation and automatic selection of AD design elements in deep methods. Our extensive experiments reveal that relying solely on existing leading methods is not sufficient. In contrast, models developed using ADGym significantly surpass current state-of-the-art techniques.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.00164",
        "title": "Graph Neural Networks for Road Safety Modeling: Datasets and Evaluations for Accident Analysis",
        "abstract": "We consider the problem of traffic accident analysis on a road network based on road network connections and traffic volume. Previous works have designed various deep-learning methods using historical records to predict traffic accident occurrences. However, there is a lack of consensus on how accurate existing methods are, and a fundamental issue is the lack of public accident datasets for comprehensive evaluations. This paper constructs a large-scale, unified dataset of traffic accident records from official reports of various states in the US, totaling 9 million records, accompanied by road networks and traffic volume reports. Using this new dataset, we evaluate existing deep-learning methods for predicting the occurrence of accidents on road networks. Our main finding is that graph neural networks such as GraphSAGE can accurately predict the number of accidents on roads with less than 22% mean absolute error (relative to the actual count) and whether an accident will occur or not with over 87% AUROC, averaged over states. We achieve these results by using multitask learning to account for cross-state variabilities (e.g., availability of accident labels) and transfer learning to combine traffic volume with accident prediction. Ablation studies highlight the importance of road graph-structural features, amongst other features. Lastly, we discuss the implications of the analysis and develop a package for easily using our new dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.04181",
        "title": "Benchmarking Foundation Models with Language-Model-as-an-Examiner",
        "abstract": "\nNumerous benchmarks have been established to assess the performance of founda- tion models on open-ended question answering, which serves as a comprehensive test of a model\u2019s ability to understand and generate language in a manner similar to humans. Most of these works focus on proposing new datasets, however, we see two main issues within previous benchmarking pipelines, namely testing leakage and evaluation automation. In this paper, we propose a novel benchmarking frame- work, Language-Model-as-an-Examiner, where the LM serves as a knowledgeable examiner that formulates questions based on its knowledge and evaluates responses in a reference-free manner. Our framework allows for effortless extensibility as various LMs can be adopted as the examiner, and the questions can be constantly updated given more diverse trigger topics. For a more comprehensive and equitable evaluation, we devise three strategies: (1) We instruct the LM examiner to generate questions across a multitude of domains to probe for a broad acquisition, and raise follow-up questions to engage in a more in-depth assessment. (2) Upon evaluation, the examiner combines both scoring and ranking measurements, providing a reli- able result as it aligns closely with human annotations. (3) We additionally propose a decentralized Peer-examination method to address the biases in a single examiner. Our data and benchmarking results are available at: http://lmexam.xlore.cn.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.03030",
        "title": "Benchmarking Large Language Models on CMExam - A Comprehensive Chinese Medical Exam Dataset",
        "abstract": "Recent advancements in large language models (LLMs) have transformed the field of question answering (QA). However, evaluating LLMs in the medical field is challenging due to the lack of standardized and comprehensive datasets. To address this gap, we introduce CMExam, sourced from the Chinese National Medical Licensing Examination. CMExam consists of 60K+ multiple-choice questions for standardized and objective evaluations, as well as solution explanations for model reasoning evaluation in an open-ended manner. For in-depth analyses of LLMs, we invited medical professionals to label five additional question-wise annotations, including disease groups, clinical departments, medical disciplines, areas of com- petency, and question difficulty levels. Alongside the dataset, we further conducted thorough experiments with representative LLMs and QA algorithms on CMExam. The results show that GPT-4 had the best accuracy of 61.6% and a weighted F1 score of 0.617. These results highlight a great disparity when compared to human accuracy, which stood at 71.6%. For explanation tasks, while LLMs could generate relevant reasoning and demonstrate improved performance after finetuning, they fall short of a desired standard, indicating ample room for improvement. To the best of our knowledge, CMExam is the first Chinese medical exam dataset to pro- vide comprehensive medical annotations. The experiments and findings of LLM evaluation also provide valuable insights into the challenges and potential solutions in developing Chinese medical QA systems and LLM evaluation pipelines.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2209.12487",
        "title": "TARTARUS: A Benchmarking Platform for Realistic And Practical Inverse Molecular Design",
        "abstract": "\nThe efficient exploration of chemical space to design molecules with intended properties enables the accelerated discovery of drugs, materials, and catalysts, and is one of the most important outstanding challenges in chemistry. Encouraged by the recent surge in computer power and artificial intelligence development, many algorithms have been developed to tackle this problem. However, despite the emer- gence of many new approaches in recent years, comparatively little progress has been made in developing realistic benchmarks that reflect the complexity of molec- ular design for real-world applications. In this work, we develop a set of practical benchmark tasks relying on physical simulation of molecular systems mimicking real-life molecular design problems for materials, drugs, and chemical reactions. Additionally, we demonstrate the utility and ease of use of our new benchmark set by demonstrating how to compare the performance of several well-established families of algorithms. Surprisingly, we find that model performance can strongly depend on the benchmark domain. We believe that our benchmark suite will help move the field towards more realistic molecular design benchmarks, and move the development of inverse molecular design algorithms closer to designing molecules that solve existing problems in both academia and industry alike",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.15448",
        "title": "Understanding Social Reasoning in Language Models with Language Models",
        "abstract": "As Large Language Models (LLMs) become increasingly integrated into our everyday lives, understanding their ability to comprehend human mental states becomes critical for ensuring effective interactions. However, despite the recent attempts to assess the Theory-of-Mind (ToM) reasoning capabilities of LLMs, the degree to which these models can align with human ToM remains a nuanced topic of exploration. This is primarily due to two distinct challenges: (1) the presence of inconsistent results from previous evaluations, and (2) concerns surrounding the validity of existing evaluation methodologies. To address these challenges, we present a novel framework for procedurally generating evaluations with LLMs by populating causal templates. Using our framework, we create a new social reasoning benchmark (BigToM) for LLMs which consists of 25 controls and 5,000 model-written evaluations. We find that human participants rate the quality of our benchmark higher than previous crowd-sourced evaluations and comparable to expert-written evaluations. Using BigToM, we evaluate the social reasoning capabilities of a variety of LLMs and compare model performances with human performance. Our results suggest that GPT4 has ToM capabilities that mirror human inference patterns, though less reliable, while other LLMs struggle.2",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.06399",
        "title": "Lo-Hi: Practical ML Drug Discovery Benchmark",
        "abstract": "\nFinding new drugs is getting harder and harder. One of the hopes of drug discov- ery is to use machine learning models to predict molecular properties. That is why models for molecular property prediction are being developed and tested on benchmarks such as MoleculeNet. However, existing benchmarks are unrealistic and are too different from applying the models in practice. We have created a new practical Lo-Hi benchmark consisting of two tasks: Lead Optimization (Lo) and Hit Identification (Hi), corresponding to the real drug discovery process. For the Hi task, we designed a novel molecular splitting algorithm that solves the Balanced Vertex Minimum k-Cut problem. We tested state-of-the-art and classic ML models, revealing which works better under practical settings. We analyzed modern benchmarks and showed that they are unrealistic and overoptimistic.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.01116",
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "abstract": "Large language models are commonly trained on a mixture of filtered web data and curated \u201chigh-quality\u201d corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from CommonCrawl. We publicly release an extract of 600 billion tokens from our REFINEDWEB dataset, and 1.3/7.5B parameters language models trained on it",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.03111",
        "title": "Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs",
        "abstract": "Text-to-SQL parsing, which aims at converting natural language questions into executable SQLs, has gained increasing attention in recent years. In particular, GPT-4 and Claude-2 have shown impressive results in this task. However, most of the prevalent benchmarks, i.e., Spider, and WikiSQL, focus on database schema with few rows of database values leaving the gap between academic study and real-world applications. To mitigate this gap, we present BIRD, a BIg bench for laRge-scale Database grounded in text-to-SQL tasks, containing 12,751 text-to- SQL pairs and 95 databases with a total size of 33.4 GB, spanning 37 professional domains. Our emphasis on database values highlights the new challenges of dirty and noisy database values, external knowledge grounding between NL questions and database values, and SQL efficiency, particularly in the context of massive databases. To solve these problems, text-to-SQL models must feature database value comprehension in addition to semantic parsing. The experimental results demonstrate the significance of database values in generating accurate text-to-SQLs for big databases. Furthermore, even the most effective text-to-SQL models, i.e. GPT-4, only achieve 54.89% in execution accuracy, which is still far from the human result of 92.96%, proving that challenges still stand. We also provide an efficiency analysis to offer insights into generating text-to-efficient-SQLs that are beneficial to industries. We believe that BIRD will contribute to advancing real-world applications of text-to-SQL research. The leaderboard and source code are available: https://bird-bench.github.io/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.02665",
        "title": "Digital Typhoon: Long-term Satellite Image Dataset for the Spatio-Temporal Modeling of Tropical Cyclones",
        "abstract": "\nThis paper presents the official release of the Digital Typhoon dataset, the longest typhoon satellite image dataset for 40+ years aimed at benchmarking machine learning models for long-term spatio-temporal data. To build the dataset, we de- veloped a workflow to create an infrared typhoon-centered image for cropping using Lambert azimuthal equal-area projection referring to the best track data. We also address data quality issues such as inter-satellite calibration to create a homogeneous dataset. To take advantage of the dataset, we organized machine learning tasks by the types and targets of inference, with other tasks for me- teorological analysis, societal impact, and climate change. The benchmarking results on the analysis, forecasting, and reanalysis for the intensity suggest that the dataset is challenging for recent deep learning models, due to many choices that affect the performance of various models. This dataset reduces the barrier for machine learning researchers to meet large-scale real-world events called tropical cyclones and develop machine learning models that may contribute to advancing scientific knowledge on tropical cyclones as well as solving societal and sustain- ability issues such as disaster reduction and climate change. The dataset is publicly available at http://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and https://github.com/kitamoto-lab/digital-typhoon/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.12421",
        "title": "evaluating Open-QA Evaluation\n",
        "abstract": "This study focuses on the evaluation of the Open Question Answering (Open- QA) task, which can directly estimate the factuality of large language models (LLMs). Current automatic evaluation methods have shown limitations, indicating that human evaluation still remains the most reliable approach. We introduce a new task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset EVOUNA, designed to assess the accuracy of AI-generated answers in relation to standard answers within Open-QA. Our evaluation of these methods utilizes human- annotated results to measure their performance. Specifically, the work investigates methods that show high correlation with human evaluations, deeming them more reliable. We also discuss the pitfalls of current methods and methods to improve LLM-based evaluators. We believe this new QA-Eval task and corresponding dataset EVOUNA will facilitate the development of more effective automatic evaluation tools and prove valuable for future research in this area. All resources are available at https://github.com/wangcunxiang/QA-Eval and it is under the Apache-2.0 License.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.13512",
        "title": "DISCO-10M: A Large-Scale Music Dataset",
        "abstract": "Music datasets play a crucial role in advancing research in machine learning for music. However, existing music datasets suffer from limited size, accessibility, and lack of audio resources. To address these shortcomings, we present DISCO-10M, a novel and extensive music dataset that surpasses the largest previously available music dataset by an order of magnitude. To ensure high-quality data, we imple- ment a multi-stage filtering process. This process incorporates similarities based on textual descriptions and audio embeddings. Moreover, we provide precom- puted CLAP embeddings alongside DISCO-10M, facilitating direct application on various downstream tasks. These embeddings enable efficient exploration of machine learning applications on the provided data. With DISCO-10M, we aim to democratize and facilitate new research to help advance the development of novel machine learning models for music",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2212.07489",
        "title": "SMACv2: An Improved Benchmark for Cooperative Multi-Agent Reinforcement Learning",
        "abstract": "The availability of challenging benchmarks has played a key role in the recent progress of machine learning. In cooperative multi-agent reinforcement learning, the StarCraft Multi-Agent Challenge (SMAC) has become a popular testbed for the centralised training with decentralised execution paradigm. However, after years of sustained improvement on SMAC, algorithms now achieve near-perfect performance. In this work, we conduct new analysis demonstrating that SMAC lacks the stochasticity and partial observability to require complex closed-loop policies (i.e., those that condition on the observation). In particular, we show that an open-loop policy conditioned only on the timestep can achieve non-trivial win rates for many SMAC scenarios. To address this limitation, we introduce SMACv2, a new benchmark where scenarios are procedurally generated and require agents to generalise to previously unseen settings during evaluation.2 We show that these changes ensure the benchmark requires the use of closed-loop policies. We also introduce the extended partial observability challenge (EPO), which augments SMACv2 to ensure meaningful partial observability. We evaluate state-of-the-art algorithms on SMACv2 and show that it presents significant challenges not present in the original benchmark. Our analysis illustrates that SMACv2 addresses the discovered deficiencies of SMAC and can help benchmark the next generation of MARL methods. Videos of training are available on our website.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.12567",
        "title": "Safety-Gymnasium: A Unified Safe Reinforcement Learning Benchmark",
        "abstract": "Artificial intelligence (AI) systems possess significant potential to drive societal progress. However, their deployment often faces obstacles due to substantial safety concerns. Safe reinforcement learning (SafeRL) emerges as a solution to optimize policies while simultaneously adhering to multiple constraints, thereby addressing the challenge of integrating reinforcement learning in safety-critical sce- narios. In this paper, we present an environment suite called Safety-Gymnasium, which encompasses safety-critical tasks in both single and multi-agent scenar- ios, accepting vector and vision-only input. Additionally, we offer a library of algorithms named Safe Policy Optimization (SafePO), comprising 16 state-of- the-art SafeRL algorithms. This comprehensive library can serve as a validation tool for the research community. By introducing this benchmark, we aim to facilitate the evaluation and comparison of safety performance, thus fostering the development of reinforcement learning for safer, more reliable, and respon- sible real-world applications. The website of this project can be accessed at https://sites.google.com/view/safety-gymnasium.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.04755",
        "title": "Pairwise GUI Dataset Construction Between Android Phones and Tablets",
        "abstract": "In the current landscape of pervasive smartphones and tablets, apps frequently exist across both platforms. Although apps share most graphic user interfaces (GUIs) and functionalities across phones and tablets, developers often rebuild from scratch for tablet versions, escalating costs and squandering existing design resources. Researchers are attempting to collect data and employ deep learning in automated GUIs development to enhance developers\u2019 productivity. There are currently several publicly accessible GUI page datasets for phones, but none for pairwise GUIs between phones and tablets. This poses a significant barrier to the employment of deep learning in automated GUI development. In this paper, we introduce the Papt dataset, a pioneering pairwise GUI dataset tailored for Android phones and tablets, encompassing 10,035 phone-tablet GUI page pairs sourced from 5,593 unique app pairs. We propose novel pairwise GUI collection approaches for constructing this dataset and delineate its advantages over currently prevailing datasets in the field. Through preliminary experiments on this dataset, we analyze the present challenges of utilizing deep learning in automated GUI development",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.03919",
        "title": "Data Portraits: Recording Foundation Model Training Data",
        "abstract": "Foundation models are trained on increasingly immense and opaque datasets. Even while these models are now key in AI system building, it can be difficult to answer the straightforward question: has the model already encountered a given example during training? We therefore propose a widespread adoption of Data Portraits: artifacts that record training data and allow for downstream inspection. First we outline the properties of such an artifact and discuss how existing solutions can be used to increase transparency. We then propose and implement a solution based on data sketching, stressing fast and space efficient querying. Using our tools, we document a popular language modeling corpus (The Pile) and a recently released code modeling dataset (The Stack). We show that our solution enables answering questions about test set leakage and model plagiarism. Our tool is lightweight and fast, costing only 3% of the dataset size in overhead. We release a live interface of our tools at dataportraits.org and call on dataset and model creators to release Data Portraits as a complement to current documentation practices.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.12251",
        "title": "GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection",
        "abstract": "With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting, (2) whether GNNs can outperform traditional algorithms such as tree ensembles, and (3) how about their efficiency on large-scale graphs. In response, we introduce GADBench\u2014a benchmark tool dedicated to supervised anomalous node detection in static graphs. GADBench facilitates a detailed comparison across 29 distinct models on ten real-world GAD datasets, encompassing thousands to millions (\u223c6M) nodes. Our main finding is that tree ensembles with simple neighborhood aggregation can outperform the latest GNNs tailored for the GAD task. We shed light on the current progress of GAD, setting a robust groundwork for subsequent investigations in this domain. GADBench is open-sourced at https://github.com/squareRoot3/GADBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.10548",
        "title": "MARBLE: Music Audio Representation Benchmark for Universal Evaluation",
        "abstract": "In the era of extensive intersection between art and Artificial Intelligence (AI), such as image generation and fiction co-creation, AI for music remains relatively nascent, particularly in music understanding. This is evident in the limited work on deep music representations, the scarcity of large-scale datasets, and the absence of a universal and community-driven benchmark. To address this issue, we introduce the Music Audio Representation Benchmark for universaL Evaluation, termed MARBLE. It aims to provide a benchmark for various Music Information Retrieval (MIR) tasks by defining a comprehensive taxonomy with four hierarchy levels, including acoustic, performance, score, and high-level description. We establish a unified protocol based on 18 tasks on 12 public-available datasets, providing a fair and standard assessment of representations of all open-sourced pre-trained models developed on music recordings as baselines. MARBLE offers an easy-to-use, extendable, and reproducible suite for the community, with clear statements on dataset copyright. Results suggest that recently proposed large-scale pre-trained musical language models perform the best in most tasks, with room for further improvement. The leaderboard and toolkit repository are published34 to promote future music AI research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.01458",
        "title": "CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care",
        "abstract": "The recent advances in natural language processing (NLP), have led to a new trend of applying large language models (LLMs) to real-world scenarios. While the latest LLMs are astonishingly fluent when interacting with humans, they suffer from the misinformation problem by unintentionally generating factually false statements. This can lead to harmful consequences, especially when produced within sensitive contexts, such as healthcare. Yet few previous works have fo- cused on evaluating misinformation in the long-form (LF) generation of LLMs, especially for knowledge-intensive topics. Moreover, although LLMs have been shown to perform well in different languages, misinformation evaluation has been mostly conducted in English. To this end, we present a benchmark, CARE-MI, for evaluating LLM misinformation in: 1) a sensitive topic, specifically the maternity and infant care domain; and 2) a language other than English, namely Chinese. Most importantly, we provide an innovative paradigm for building LF generation evaluation benchmarks that can be transferred to other knowledge-intensive do- mains and low-resourced languages. Our proposed benchmark fills the gap between the extensive usage of LLMs and the lack of datasets for assessing the misinfor- mation generated by these models. It contains 1,612 expert-checked questions, accompanied with human-selected references. Using our benchmark, we conduct extensive experiments and found that current Chinese LLMs are far from perfect in the topic of maternity and infant care. In an effort to minimize the reliance on human resources for performance evaluation, we offer off-the-shelf judgment models for automatically assessing the LF output of LLMs given benchmark ques- tions. Moreover, we compare potential solutions for LF generation evaluation and provide insights for building better automated metrics. Code and models are available at https://github.com/Meetyou-AI-Lab/CARE-MI.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.01426",
        "title": "DeepfakeBench: A Comprehensive Benchmark of Deepfake Detection",
        "abstract": "A critical yet frequently overlooked challenge in the field of deepfake detection is the lack of a standardized, unified, comprehensive benchmark. This issue leads to unfair performance comparisons and potentially misleading results. Specifically, there is a lack of uniformity in data processing pipelines, resulting in inconsistent data inputs for detection models. Additionally, there are noticeable differences in experimental settings, and evaluation strategies and metrics lack standardization. To fill this gap, we present the first comprehensive benchmark for deepfake detec- tion, called DeepfakeBench, which offers three key contributions: 1) a unified data management system to ensure consistent input across all detectors, 2) an integrated framework for state-of-the-art methods implementation, and 3) standardized evalu- ation metrics and protocols to promote transparency and reproducibility. Featuring an extensible, modular-based codebase, DeepfakeBench contains 15 state-of-the-art detection methods, 9 deepfake datasets, a series of deepfake detection evaluation protocols and analysis tools, as well as comprehensive evaluations. Moreover, we provide new insights based on extensive analysis of these evaluations from various perspectives (e.g., data augmentations, backbones). We hope that our efforts could facilitate future research and foster innovation in this increasingly critical domain. All codes, evaluations, and analyses of our benchmark are publicly available at https://github.com/SCLBD/DeepfakeBench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.12993",
        "title": "Benchmarking Robustness to Adversarial Image Obfuscations",
        "abstract": "Automated content filtering and moderation is an important tool that allows online platforms to build striving user communities that facilitate cooperation and prevent abuse. Unfortunately, resourceful actors try to bypass automated filters in a bid to post content that violate platform policies and codes of conduct. To reach this goal, these malicious actors may obfuscate policy violating images (e.g. overlay harmful images by carefully selected benign images or visual patterns) to prevent machine learning models from reaching the correct decision. In this paper, we invite researchers to tackle this specific issue and present a new image benchmark. This benchmark, based on IMAGENET, simulates the type of obfuscations created by malicious actors. It goes beyond IMAGENET-C and IMAGENET-C \u0304 by proposing general, drastic, adversarial modifications that preserve the original content intent. It aims to tackle a more common adversarial threat than the one considered by lp-norm bounded adversaries. We evaluate 33 pretrained models on the benchmark and train models with different augmentations, architectures and training methods on subsets of the obfuscations to measure generalization. Our hope is that this benchmark will encourage researchers to test their models and methods and try to find new approaches that are more robust to these obfuscations.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.16424",
        "title": "Realistic Synthetic Financial Transactions for Anti-Money Laundering Models",
        "abstract": "With the widespread digitization of finance and the increasing popularity of cryp- tocurrencies, the sophistication of fraud schemes devised by cybercriminals is growing. Money laundering \u2013 the movement of illicit funds to conceal their origins \u2013 can cross bank and national boundaries, producing complex transaction patterns. The UN estimates 2-5% of global GDP or $0.8 - $2.0 trillion dollars are laundered globally each year. Unfortunately, real data to train machine learning models to detect laundering is generally not available, and previous synthetic data generators have had significant shortcomings. A realistic, standardized, publicly-available benchmark is needed for comparing models and for the advancement of the area. To this end, this paper contributes a synthetic financial transaction dataset generator and a set of synthetically generated AML (Anti-Money Laundering) datasets. We have calibrated this agent-based generator to match real transactions as closely as possible and made the datasets public. We describe the generator in detail and demonstrate how the datasets generated can help compare different machine learning models in terms of their AML abilities. In a key way, using synthetic data in these comparisons can be even better than using real data: the ground truth labels are complete, whilst many laundering transactions in real data are never detected.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.05766",
        "title": "Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting",
        "abstract": "Radiology reporting is a crucial part of the communication between radiologists and other medical professionals, but it can be time- consuming and error-prone. One approach to alleviate this is structured reporting, which saves time and enables a more accurate evaluation than free-text reports. However, there is limited research on automating struc- tured reporting, and no public benchmark is available for evaluating and comparing different methods. To close this gap, we introduce Rad- ReStruct, a new benchmark dataset that provides fine-grained, hierarchi- cally ordered annotations in the form of structured reports for X-Ray im- ages. We model the structured reporting task as hierarchical visual ques- tion answering (VQA) and propose hi-VQA, a novel method that consid- ers prior context in the form of previously asked questions and answers for populating a structured radiology report. Our experiments show that hi-VQA achieves competitive performance to the state-of-the-art on the medical VQA benchmark VQARad while performing best among meth- ods without domain-specific vision-language pretraining and provides a strong baseline on Rad-ReStruct. Our work represents a significant step towards the automated population of structured radiology reports and provides a valuable first benchmark for future research in this area. Our dataset and code is available at https://github.com/ChantalMP/Rad- ReStruct.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2102.09542",
        "title": "SLAKE: A SEMANTICALLY-LABELED KNOWLEDGE-ENHANCED DATASET FOR MEDICAL VISUAL QUESTION ANSWERING",
        "abstract": "Medical visual question answering (Med-VQA) has tremendous potential in healthcare. However, the devel- opment of this technology is hindered by the lacking of publicly-available and high-quality labeled datasets for train- ing and evaluation. In this paper, we present a large bilin- gual dataset, SLAKE, with comprehensive semantic labels annotated by experienced physicians and a new structural medical knowledge base for Med-VQA. Besides, SLAKE includes richer modalities and covers more human body parts than the currently available dataset. We show that SLAKE can be used to facilitate the development and evaluation of Med-VQA systems. The dataset can be downloaded from http://www.med-vqa.com/slake.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.03830",
        "title": "QSlack: A slack-variable approach for variational quantum semi-definite programming",
        "abstract": "Solving optimization problems is a key task for which quantum computers could possibly provide a speedup over the best known classical algorithms. Particular classes of optimization problems in- cluding semi-definite programming (SDP) and linear programming (LP) have wide applicability in many domains of computer science, engineering, mathematics, and physics. Here we focus on semi- definite and linear programs for which the dimensions of the variables involved are exponentially large, so that standard classical SDP and LP solvers are not helpful for such large-scale problems. We propose the QSlack and CSlack methods for estimating their optimal values, respectively, which work by 1) introducing slack variables to transform inequality constraints to equality constraints, 2) transforming a constrained optimization to an unconstrained one via the penalty method, and 3) replacing the optimizations over all possible non-negative variables by optimizations over parame- terized quantum states and parameterized probability distributions. Under the assumption that the SDP and LP inputs are efficiently measurable observables, it follows that all terms in the resulting objective functions are efficiently estimable by either a quantum computer in the SDP case or a quantum or probabilistic computer in the LP case. Furthermore, by making use of SDP and LP duality theory, we prove that these methods provide a theoretical guarantee that, if one could find global optima of the objective functions, then the resulting values sandwich the true optimal values from both above and below. Finally, we showcase the QSlack and CSlack methods on a variety of example optimization problems and discuss details of our implementation, as well as the resulting performance. We find that our implementations of both the primal and dual for these problems approach the ground truth, typically achieving errors of the order 10\u22122.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2003.10286",
        "title": "PATHVQA: 30000+ QUESTIONS FOR MEDICAL VISUAL QUESTION ANSWERING",
        "abstract": "Is it possible to develop an \u201cAI Pathologist\" to pass the board-certified examination of the American Board of Pathology? To achieve this goal, the first step is to create a visual question answering (VQA) dataset where the AI agent is presented with a pathology image together with a question and is asked to give the correct answer. Our work makes the first attempt to build such a dataset. Different from creating general-domain VQA datasets where the images are widely accessible and there are many crowdsourcing workers available and capable of generating question-answer pairs, developing a medical VQA dataset is much more challenging. First, due to privacy concerns, pathology images are usually not publicly available. Second, only well-trained pathologists can understand pathology images, but they barely have time to help create datasets for AI research. To address these challenges, we resort to pathology textbooks and online digital libraries. We develop a semi-automated pipeline to extract pathology images and captions from textbooks and generate question-answer pairs from captions using natural language processing. We collect 32,799 open-ended questions from 4,998 pathology images where each question is manually checked to ensure correctness. To our best knowledge, this is the first dataset for pathology VQA. Our dataset will be released publicly to promote research in medical VQA.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.03213",
        "title": "EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset",
        "abstract": "Visual object tracking is key to many egocentric vision problems. However, the full spectrum of challenges of egocentric tracking faced by an embodied AI is under- represented in many existing datasets, which tend to focus on short, third-person videos. Egocentric video has several distinguishing characteristics from those com- monly found in past datasets: frequent large camera motions and hand interactions with objects commonly lead to occlusions or objects exiting the frame, and object appearance can change rapidly due to widely different points of view, scale, or object states. Embodied tracking is also naturally long-term, and being able to con- sistently (re-)associate objects to their appearances and disappearances over as long as a lifetime is critical. Previous datasets under-emphasize this re-detection prob- lem, and their \u201cframed\u201d nature has led to adoption of various spatiotemporal priors that we find do not necessarily generalize to egocentric video. We thus introduce EgoTracks, a new dataset for long-term egocentric visual object tracking. Sourced from the Ego4D dataset, EgoTracks presents a significant challenge to recent state- of-the-art single-object trackers, which we find score more poorly on our new dataset than existing popular benchmarks, according to traditional tracking metrics. We further show improvements that can be made to the STARK tracker to signifi- cantly increase its performance on egocentric data, resulting in a baseline model we call EgoSTARK. We publicly release our annotations and benchmark (https:// github.com/EGO4D/episodic-memory/tree/main/EgoTracks), hoping our dataset leads to further advancements in tracking.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.13924",
        "title": "trajdata: A Unified Interface to Multiple Human Trajectory Datasets",
        "abstract": "The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking. While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets. To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets. At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data. As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights. trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.03831",
        "title": "GEO-Bench:\nToward Foundation Models for Earth Monitoring",
        "abstract": "Recent progress in self-supervision has shown that pre-training large neural networks on vast amounts of unsupervised data can lead to substantial increases in generalization to downstream tasks. Such models, recently coined foundation models, have been transformational to the field of natural language processing. Variants have also been proposed for image data, but their applicability to remote sensing tasks is limited. To stimulate the development of foundation models for Earth monitoring, we propose a benchmark comprised of six classification and six segmentation tasks, which were carefully curated and adapted to be both relevant to the field and well-suited for model evaluation. We accompany this benchmark with a robust methodology for evaluating models and reporting aggregated results to enable a reliable assessment of progress. Finally, we report results for 20 baselines to gain information about the performance of existing models. We believe that this benchmark will be a driver of progress across a variety of Earth monitoring tasks.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.06070",
        "title": "MIND2WEB: Towards a Generalist Agent for the Web",
        "abstract": "We introduce MIND2WEB, the first dataset for developing and evaluating generalist agents for the web that can follow language instructions to complete complex tasks on any website. Existing datasets for web agents either use simulated websites or only cover a limited set of websites and tasks, thus not suitable for generalist web agents. With over 2,000 open-ended tasks collected from 137 websites spanning 31 domains and crowdsourced action sequences for the tasks, MIND2WEB pro- vides three necessary ingredients for building generalist web agents: 1) diverse domains, websites, and tasks, 2) use of real-world websites instead of simulated and simplified ones, and 3) a broad spectrum of user interaction patterns. Based on MIND2WEB, we conduct an initial exploration of using large language models (LLMs) for building generalist web agents. While the raw HTML of real-world web- sites are often too large to be fed to LLMs, we show that first filtering it with a small LM significantly improves the effectiveness and efficiency of LLMs. Our solution demonstrates a decent level of performance, even on websites or entire domains the model has never seen before, but there is still a substantial room to improve towards truly generalizable agents. We open-source our dataset, model implementation, and trained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further research on building a generalist agent for the web.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.06828",
        "title": "RoboHive: A Unified Framework for Robot Learning",
        "abstract": "We present RoboHive, a comprehensive software platform and ecosystem for re- search in the field of Robot Learning and Embodied Artificial Intelligence. Our platform encompasses a diverse range of pre-existing and novel environments, including dexterous manipulation with the Shadow Hand, whole-arm manipulation tasks with Franka and Fetch robots, quadruped locomotion, among others. Included environments are organized within and cover multiple domains such as hand ma- nipulation, locomotion, multi-task, multi-agent, muscles, etc. In comparison to prior works, RoboHive offers a streamlined and unified task interface taking depen- dency on only a minimal set of well-maintained packages, features tasks with high physics fidelity and rich visual diversity, and supports common hardware drivers for real-world deployment. The unified interface of RoboHive offers a convenient and accessible abstraction for algorithmic research in imitation, reinforcement, multi-task, and hierarchical learning. Furthermore, RoboHive includes expert demonstrations and baseline results for most environments, providing a standard for benchmarking and comparisons. Details: https://sites.google.com/view/robohiveW",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.10455",
        "title": "A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset",
        "abstract": "In an effort to catalog insect biodiversity, we propose a new large dataset of hand-labelled insect images, the BIOSCAN-1M Insect Dataset. Each record is taxonomically classified by an expert, and also has associated genetic information including raw nucleotide barcode sequences and assigned barcode index numbers, which are genetically-based proxies for species classification. This paper presents a curated million-image dataset, primarily to train computer-vision models capa- ble of providing image-based taxonomic assessment, however, the dataset also presents compelling characteristics, the study of which would be of interest to the broader machine learning community. Driven by the biological nature inherent to the dataset, a characteristic long-tailed class-imbalance distribution is exhib- ited. Furthermore, taxonomic labelling is a hierarchical classification scheme, presenting a highly fine-grained classification problem at lower levels. Beyond spurring interest in biodiversity research within the machine learning community, progress on creating an image-based taxonomic classifier will also further the ultimate goal of all BIOSCAN research: to lay the foundation for a comprehensive survey of global biodiversity. This paper introduces the dataset and explores the classification task through the implementation and analysis of a baseline clas- sifier. The code repository of the BIOSCAN-1M-Insect dataset is available at https://github.com/zahrag/BIOSCAN-1M",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.12284",
        "title": "D4: Improving LLM Pretraining via Document De-Duplication and Diversification",
        "abstract": "Over recent years, an increasing amount of compute and data has been poured into training large language models (LLMs), usually by doing one-pass learning on as many tokens as possible randomly selected from large-scale web corpora. While training on ever-larger portions of the internet leads to consistent perfor- mance improvements, the size of these improvements diminishes with scale, and there has been little work exploring the effect of data selection on pre-training and downstream performance beyond simple de-duplication methods such as Min- Hash. Here, we show that careful data selection (on top of de-duplicated data) via pre-trained model embeddings can speed up training (20% efficiency gains) and improves average downstream accuracy on 16 NLP tasks (up to 2%) at the 6.7B model scale. Furthermore, we show that repeating data intelligently consistently outperforms baseline training (while repeating random data performs worse than baseline training). Our results indicate that clever data selection can significantly improve LLM pre-training, calls into question the common practice of training for a single epoch on as much data as possible, and demonstrates a path to keep improving our models past the limits of randomly sampling web data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.12477",
        "title": "American Stories: A Large-Scale Structured Text Dataset of Historical U.S. Newspapers",
        "abstract": "Existing full text datasets of U.S. public domain newspapers do not recognize the often complex layouts of newspaper scans, and as a result the digitized content scrambles texts from articles, headlines, captions, advertisements, and other lay- out regions. OCR quality can also be low. This study develops a novel, deep learn- ing pipeline for extracting full article texts from newspaper images and applies it to the nearly 20 million scans in Library of Congress\u2019s public domain Chronicling America collection. The pipeline includes layout detection, legibility classifica- tion, custom OCR, and association of article texts spanning multiple bounding boxes. To achieve high scalability, it is built with efficient architectures designed for mobile phones. The resulting American Stories dataset provides high quality data that could be used for pre-training a large language model to achieve better understanding of historical English and historical world knowledge. The dataset could also be added to the external database of a retrieval-augmented language model to make historical information - ranging from interpretations of political events to minutiae about the lives of people\u2019s ancestors - more widely accessible. Furthermore, structured article texts facilitate using transformer-based methods for popular social science applications like topic classification, detection of repro- duced content, and news story clustering. Finally, American Stories provides a massive silver quality dataset for innovating multimodal layout analysis models and other multimodal applications.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.17810",
        "title": "A Massive Scale Semantic Similarity Dataset of Historical English",
        "abstract": "A diversity of tasks use language models trained on semantic similarity data. While there are a variety of datasets that capture semantic similarity, they are either constructed from modern web data or are relatively small datasets created in the past decade by human annotators. This study utilizes a novel source, newly digitized articles from off-copyright, local U.S. newspapers, to assemble a massive-scale semantic similarity dataset spanning 70 years from 1920 to 1989 and containing nearly 400M positive semantic similarity pairs. Historically, around half of articles in U.S. local newspapers came from newswires like the Associated Press. While local papers reproduced articles from the newswire, they wrote their own headlines, which form abstractive summaries of the associated articles. We associate articles and their headlines by exploiting document layouts and language understanding. We then use deep neural methods to detect which articles are from the same underlying source, in the presence of substantial noise and abridgement. The headlines of reproduced articles form positive semantic similarity pairs. The resulting publicly available HEADLINES dataset is significantly larger than most existing semantic similarity datasets and covers a much longer span of time. It will facilitate the application of contrastively trained semantic similarity models to a variety of tasks, including the study of semantic change across space and time.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.02560",
        "title": "GeoDE: a Geographically Diverse Evaluation Dataset for Object Recognition",
        "abstract": "Current dataset collection methods typically scrape large amounts of data from the web. While this technique is extremely scalable, data collected in this way tends to reinforce stereotypical biases, can contain personally identifiable information, and typically originates from Europe and North America. In this work, we rethink the dataset collection paradigm and introduce GeoDE , a geographically diverse dataset with 61,940 images from 40 classes and 6 world regions, and no personally identifiable information, collected through crowd-sourcing. We analyse GeoDE to understand differences in images collected in this manner compared to web-scraping. Despite the smaller size of this dataset, we demonstrate its use as both an evaluation and training dataset, allowing us to highlight shortcomings in current models, as well as demonstrate improved performances even when training on the small dataset. We release the full dataset and code at https://geodiverse-data-collection.cs. princeton.edu/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.05284",
        "title": "On the Need of a Modeling Language for Distribution Shifts: Illustrations on Tabular Datasets",
        "abstract": "Different distribution shifts require different interventions, and algorithms must be grounded in the specific shifts they address. However, methodological development for \u201crobust\u201d methods typically relies on structural assumptions that lack empirical validation. Advocating for an empirically grounded inductive approach to research, we build an empirical testbed compris- ing natural shifts across 5 tabular datasets and 60,000 method configurations encompassing imbalanced learning methods and distributionally robust optimization (DRO) methods. We find Y |X-shifts are most prevalent on our testbed, in stark contrast to the heavy focus on X\n(covariate)-shifts in the ML literature. The performance of \u201crobust\u201d methods varies significantly over shift types, and is no better than that of vanilla methods. To understand why, we conduct an in-depth empirical analysis of DRO methods and find that although often neglected by researchers, implementation details\u2014such as the choice of underlying model class (e.g., XGBoost) and hyperparameter selection\u2014have a bigger impact on performance than the ambiguity set or its radius. To further bridge that gap between methodological research and practice, we design case studies that illustrate how such a refined, inductive understanding of distribution shifts can enhance both data-centric and algorithmic interventions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.10798",
        "title": "INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and Prognosis",
        "abstract": "Synthesizing information from multiple data sources plays a crucial role in the prac- tice of modern medicine. Current applications of artificial intelligence in medicine often focus on single-modality data due to a lack of publicly available, multimodal medical datasets. To address this limitation, we introduce INSPECT, which con- tains de-identified longitudinal records from a large cohort of patients at risk for pulmonary embolism (PE), along with ground truth labels for multiple outcomes. INSPECT contains data from 19,402 patients, including CT images, radiology report impression sections, and structured electronic health record (EHR) data (i.e. demographics, diagnoses, procedures, vitals, and medications). Using INSPECT, we develop and release a benchmark for evaluating several baseline modeling approaches on a variety of important PE related tasks. We evaluate image-only, EHR-only, and multimodal fusion models. Trained models and the de-identified dataset are made available for non-commercial use under a data use agreement. To the best of our knowledge, INSPECT is the largest multimodal dataset integrating 3D medical imaging and EHR for reproducible methods evaluation and research",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.19909",
        "title": "Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks",
        "abstract": "Neural network based computer vision systems are typically built on a backbone, a pretrained or randomly initialized feature extractor. Several years ago, the default option was an ImageNet-trained convolutional neural network. However, the re- cent past has seen the emergence of countless backbones pretrained using various algorithms and datasets. While this abundance of choice has led to performance increases for a range of systems, it is difficult for practitioners to make informed decisions about which backbone to choose. Battle of the Backbones (BoB) makes this choice easier by benchmarking a diverse suite of pretrained models, including vision-language models, those trained via self-supervised learning, and the Stable Diffusion backbone, across a diverse set of computer vision tasks ranging from clas- sification to object detection to OOD generalization and more. Furthermore, BoB sheds light on promising directions for the research community to advance com- puter vision by illuminating strengths and weakness of existing approaches through a comprehensive analysis conducted on more than 1500 training runs. While vision transformers (ViTs) and self-supervised learning (SSL) are increasingly popular, we find that convolutional neural networks pretrained in a supervised fashion on large training sets still perform best on most tasks among the models we consider. More- over, in apples-to-apples comparisons on the same architectures and similarly sized pretraining datasets, we find that SSL backbones are highly competitive, indicating that future works should perform SSL pretraining with advanced architectures and larger pretraining datasets. We release the raw results of our experiments along with code that allows researchers to put their own backbones through the gauntlet here: https://github.com/hsouri/Battle-of-the-Backbones.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.05326",
        "title": "OpenProteinSet: Training data for structural biology at scale",
        "abstract": "Multiple sequence alignments (MSAs) of proteins encode rich biological infor- mation and have been workhorses in bioinformatic methods for tasks like protein design and protein structure prediction for decades. Recent breakthroughs like Al- phaFold2 that use transformers to attend directly over large quantities of raw MSAs have reaffirmed their importance. Generation of MSAs is highly computationally intensive, however, and no datasets comparable to those used to train AlphaFold2 have been made available to the research community, hindering progress in machine learning for proteins. To remedy this problem, we introduce OpenProteinSet, an open-source corpus of more than 16 million MSAs, associated structural homologs from the Protein Data Bank, and AlphaFold2 protein structure predictions. We have previously demonstrated the utility of OpenProteinSet by successfully retraining AlphaFold2 on it. We expect OpenProteinSet to be broadly useful as training and validation data for 1) diverse tasks focused on protein structure, function, and design and 2) large-scale multimodal machine learning research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.12829",
        "title": "Intelligent Knee Sleeves: A Real-time Multimodal Dataset for 3D Lower Body Motion Estimation Using Smart Textile",
        "abstract": "The kinematics of human movements and locomotion are closely linked to the activation and contractions of muscles. To investigate this, we present a multimodal dataset with benchmarks collected using a novel pair of Intelligent Knee Sleeves (Texavie MarsWear Knee Sleeves) for human pose estimation. Our system utilizes synchronized datasets that comprise time-series data from the Knee Sleeves and the corresponding ground truth labels from visualized motion capture camera system. We employ these to generate 3D human models solely based on the wearable data of individuals performing different activities. We demonstrate the effectiveness of this camera-free system and machine learning algorithms in the assessment of various movements and exercises, including extension to unseen exercises and individuals. The results show an average error of 7.21 degrees across all eight lower body joints when compared to the ground truth, indicating the effectiveness and reliability of the Knee Sleeve system for the prediction of different lower body joints beyond knees. The results enable human pose estimation in a seamless manner without being limited by visual occlusion or the field of view of cameras. Our results show the potential of multimodal wearable sensing in a variety of applications from home fitness to sports, healthcare, and physical rehabilitation focusing on pose and movement estimation.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.05179",
        "title": "M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models",
        "abstract": "Despite the existence of various benchmarks for evaluating natural language pro- cessing models, we argue that human exams are a more suitable means of evaluating general intelligence for large language models (LLMs), as they inherently demand a much wider range of abilities such as language understanding, domain knowledge, and problem-solving skills. To this end, we introduce M3Exam, a novel bench- mark sourced from real and official human exam questions for evaluating LLMs in a multilingual, multimodal, and multilevel context. M3Exam exhibits three unique characteristics: (1) multilingualism, encompassing questions from multiple countries that require strong multilingual proficiency and cultural knowledge; (2) multimodality, accounting for the multimodal nature of many exam questions to test the model\u2019s multimodal understanding capability; and (3) multilevel struc- ture, featuring exams from three critical educational periods to comprehensively assess a model\u2019s proficiency at different levels. In total, M3Exam contains 12,317 questions in 9 diverse languages with three educational levels, where about 23% of the questions require processing images for successful solving. We assess the performance of top-performing LLMs on M3Exam and find that current models, including GPT-4, still struggle with multilingual text, particularly in low-resource and non-Latin script languages. Multimodal LLMs also perform poorly with com- plex multimodal questions. We believe that M3Exam can be a valuable resource for comprehensively evaluating LLMs by examining their multilingual and multimodal abilities and tracking their development. Data and evaluation code is available at https://github.com/DAMO-NLP-SG/M3Exam.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.14610",
        "title": "SUGARCREPE: Fixing Hackable Benchmarks for Vision-Language Compositionality",
        "abstract": "In the last year alone, a surge of new benchmarks to measure compositional understanding of vision-language models have permeated the machine learning ecosystem. Given an image, these benchmarks probe a model\u2019s ability to identify its associated caption amongst a set of compositional distractors. Surprisingly, we find significant biases in all these benchmarks rendering them hackable. This hackability is so dire that blind models with no access to the image outperform state-of-the-art vision-language models. To remedy this rampant vulnerability, we introduce SUGARCREPE, a new benchmark for vision-language compositionality evaluation. We employ large language models, instead of rule-based templates used in previous benchmarks, to generate fluent and sensical hard negatives, and utilize an adversarial refinement mechanism to maximally reduce biases. We re-evaluate state-of-the-art models and recently proposed compositionality inducing strategies, and find that their improvements were hugely overestimated, suggesting that more innovation is needed in this important direction. We release SUGARCREPE and the code for evaluation at: https://github.com/RAIVNLab/sugar-crepe.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.13831",
        "title": "Minigrid & Miniworld: Modular & Customizable Reinforcement Learning Environments for Goal-Oriented Tasks",
        "abstract": "We present the Minigrid and Miniworld libraries which provide a suite of goal- oriented 2D and 3D environments. The libraries were explicitly created with a minimalistic design paradigm to allow users to rapidly develop new environments for a wide range of research-specific needs. As a result, both have received widescale adoption by the RL community, facilitating research in a wide range of areas. In this paper, we outline the design philosophy, environment details, and their world generation API. We also showcase the additional capabilities brought by the unified API between Minigrid and Miniworld through case studies on transfer learning (for both RL agents and humans) between the different observation spaces. The source code of Minigrid and Miniworld can be found at https: //github.com/Farama-Foundation/{Minigrid,Miniworld} along with their documentation at https://{minigrid,miniworld}.farama.org/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.01909",
        "title": "ClimateLearn: Benchmarking Machine Learning for Weather and Climate Modeling",
        "abstract": "Modeling weather and climate is an essential endeavor to understand the near- and long-term impacts of climate change, as well as inform technology and policymak- ing for adaptation and mitigation efforts. In recent years, there has been a surging interest in applying data-driven methods based on machine learning for solving core problems such as weather forecasting and climate downscaling. Despite promising results, much of this progress has been impaired due to the lack of large-scale, open- source efforts for reproducibility, resulting in the use of inconsistent or underspeci- fied datasets, training setups, and evaluations by both domain scientists and artificial intelligence researchers. We introduce ClimateLearn, an open-source PyTorch library that vastly simplifies the training and evaluation of machine learning mod- els for data-driven climate science. ClimateLearn consists of holistic pipelines for dataset processing (e.g., ERA5, CMIP6, PRISM), implementation of state-of- the-art deep learning models (e.g., Transformers, ResNets), and quantitative and qualitative evaluation for standard weather and climate modeling tasks. We supple- ment these functionalities with extensive documentation, contribution guides, and quickstart tutorials to expand access and promote community growth. We have also performed comprehensive forecasting and downscaling experiments to showcase the capabilities and key features of our library. To our knowledge, ClimateLearn is the first large-scale, open-source effort for bridging research in weather and climate modeling with modern machine learning systems. Our library is available publicly at https://github.com/aditya-grover/climate-learn.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.14898",
        "title": "InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback",
        "abstract": "Humans write code in a fundamentally interactive manner and rely on constant execution feedback to correct errors, resolve ambiguities, and decompose tasks. While LLMs have recently exhibited promising coding capabilities, current coding benchmarks mostly consider a static instruction-to-code sequence transduction process, which has the potential for error propagation and a disconnect between the generated code and its final execution environment. To address this gap, we introduce InterCode, a lightweight, flexible, and easy-to-use framework of interactive coding as a standard reinforcement learning (RL) environment, with code as actions and execution feedback as observations. Our framework is language and platform agnostic, uses self-contained Docker environments to provide safe and reproducible execution, and is compatible out-of-the-box with traditional seq2seq coding methods, while enabling the development of new methods for interactive code generation. We use InterCode to create three interactive code environments with Bash, SQL, and Python as action spaces, leveraging data from the static NL2Bash [32], Spider [55], and MBPP [4] datasets. We demonstrate InterCode\u2019s viability as a testbed by evaluating multiple state-of-the-art LLMs configured with different prompting strategies such as ReAct [51] and Plan & Solve [43]. Our results showcase the benefits of interactive code generation and demonstrate that InterCode can serve as a challenging benchmark for advancing code understanding and generation capabilities. InterCode is designed to be easily extensible and can even be used to create new tasks such as Capture the Flag, a popular coding puzzle that is inherently multi-step and involves multiple programming languages.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2309.01812",
        "title": "Into the Single Cell Multiverse:\nan End-to-End Dataset for Procedural Knowledge Extraction in Biomedical Texts",
        "abstract": "Many of the most commonly explored natural language processing (NLP) informa- tion extraction tasks can be thought of as evaluations of declarative knowledge, or fact-based information extraction. Procedural knowledge extraction, i.e., breaking down a described process into a series of steps, has received much less attention, perhaps in part due to the lack of structured datasets that capture the knowledge ex- traction process from end-to-end. To address this unmet need, we present FlaMB\u00e9 (Flow annotations for Multiverse Biological entities), a collection of expert-curated datasets across a series of complementary tasks that capture procedural knowledge in biomedical texts. This dataset is inspired by the observation that one ubiquitous source of procedural knowledge that is described as unstructured text is within aca- demic papers describing their methodology. The workflows annotated in FlaMB\u00e9 are from texts in the burgeoning field of single cell research, a research area that has become notorious for the number of software tools and complexity of workflows used. Additionally, FlaMB\u00e9 provides, to our knowledge, the largest manually curated named entity recognition (NER) and disambiguation (NED) datasets for tissue/cell type, a fundamental biological entity that is critical for knowledge ex- traction in the biomedical research domain. Beyond providing a valuable dataset to enable further development of NLP models for procedural knowledge extraction, automating the process of workflow mining also has important implications for advancing reproducibility in biomedical research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.16917",
        "title": "The Drunkard\u2019s Odometry: Estimating Camera Motion in Deforming Scenes",
        "abstract": "Estimating camera motion in deformable scenes poses a complex and open research challenge. Most existing non-rigid structure from motion techniques assume to observe also static scene parts besides deforming scene parts in order to establish an anchoring reference. However, this assumption does not hold true in certain relevant application cases such as endoscopies. Deformable odometry and SLAM pipelines, which tackle the most challenging scenario of exploratory trajectories, suffer from a lack of robustness and proper quantitative evaluation methodolo- gies. To tackle this issue with a common benchmark, we introduce the Drunkard\u2019s Dataset, a challenging collection of synthetic data targeting visual navigation and reconstruction in deformable environments. This dataset is the first large set of exploratory camera trajectories with ground truth inside 3D scenes where every surface exhibits non-rigid deformations over time. Simulations in realistic 3D build- ings lets us obtain a vast amount of data and ground truth labels, including camera poses, RGB images and depth, optical flow and normal maps at high resolution and quality. We further present a novel deformable odometry method, dubbed the Drunkard\u2019s Odometry, which decomposes optical flow estimates into rigid-body camera motion and non-rigid scene deformations. In order to validate our data, our work contains an evaluation of several baselines as well as a novel tracking error metric which does not require ground truth data. Dataset and code: https: //davidrecasens.github.io/TheDrunkard\u2019sOdometry/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.15668",
        "title": "Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties",
        "abstract": "General physical scene understanding requires more than simply localizing and recognizing objects \u2013 it requires knowledge that objects can have different latent properties (e.g., mass or elasticity), and that those properties affect the outcome of physical events. While there has been great progress in physical and video prediction models in recent years, benchmarks to test their performance typically do not require an understanding that objects have individual physical properties, or at best test only those properties that are directly observable (e.g., size or color). This work proposes a novel dataset and benchmark, termed Physion++, that rigorously evaluates visual physical prediction in artificial systems under circumstances where those predictions rely on accurate estimates of the latent physical properties of objects in the scene. Specifically, we test scenarios where accurate prediction relies on estimates of properties such as mass, friction, elasticity, and deformability, and where the values of those properties can only be inferred by observing how objects move and interact with other objects or fluids. We evaluate the performance of a number of state-of-the-art prediction models that span a variety of levels of learning vs. built-in knowledge, and compare that performance to a set of human predictions. We find that models that have been trained using standard regimes and datasets do not spontaneously learn to make inferences about latent properties, but also that models that encode objectness and physical states tend to make better predictions. However, there is still a huge gap between all models and human performance, and all models\u2019 predictions correlate poorly with those made by humans, suggesting that no state-of-the-art model is learning to make physical predictions in a human- like way. These results show that current deep learning models that succeed in some settings nevertheless fail to achieve human-level physical prediction in other cases, especially those where latent property inference is required. Project page: https://dingmyu.github.io/physion_v2/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.17503",
        "title": "Pgx: Hardware-Accelerated Parallel Game Simulators for Reinforcement Learning",
        "abstract": "We propose Pgx, a suite of board game reinforcement learning (RL) environments written in JAX and optimized for GPU/TPU accelerators. By leveraging JAX\u2019s auto-vectorization and parallelization over accelerators, Pgx can efficiently scale to thousands of simultaneous simulations over accelerators. In our experiments on a DGX-A100 workstation, we discovered that Pgx can simulate RL environments 10-100x faster than existing implementations available in Python. Pgx includes RL environments commonly used as benchmarks in RL research, such as backgammon, chess, shogi, and Go. Additionally, Pgx offers miniature game sets and baseline models to facilitate rapid research cycles. We demonstrate the efficient training of the Gumbel AlphaZero algorithm with Pgx environments. Overall, Pgx provides high-performance environment simulators for researchers to accelerate their RL experiments. Pgx is available at https://github.com/sotetsuk/pgx.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.01135",
        "title": "Generating QM1B with PySCFIPU",
        "abstract": "The emergence of foundation models in Computer Vision and Natural Language Processing have resulted in immense progress on downstream tasks. This progress was enabled by datasets with billions of training examples. Similar benefits are yet to be unlocked for quantum chemistry, where the potential of deep learning is constrained by comparatively small datasets with 100k to 20M training examples. These datasets are limited in size because the labels are computed using the accurate (but computationally demanding) predictions of Density Functional Theory (DFT). Notably, prior DFT datasets were created using CPU supercomputers without leveraging hardware acceleration. In this paper, we take a first step towards utilising hardware accelerators by introducing the data generator PySCFIPU using Intelligence Processing Units (IPUs). This allowed us to create the dataset QM1B with one billion training examples containing 9-11 heavy atoms. We demonstrate that a simple baseline neural network (SchNet 9M) improves its performance by simply increasing the amount of training data without additional inductive biases. To encourage future researchers to use QM1B responsibly, we highlight several limitations of QM1B and emphasise the low-resolution of our DFT options, which also serves as motivation for even larger, more accurate datasets. Code and dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.16900",
        "title": "Learning to Taste : A Multimodal Wine Dataset",
        "abstract": "We present WineSensed, a large multimodal wine dataset for studying the relations between visual perception, language, and flavor. The dataset encompasses 897k im- ages of wine labels and 824k reviews of wines curated from the Vivino platform. It has over 350k unique bottlings, annotated with year, region, rating, alcohol percent- age, price, and grape composition. We obtained fine-grained flavor annotations on a subset by conducting a wine-tasting experiment with 256 participants who were asked to rank wines based on their similarity in flavor, resulting in more than 5k pairwise flavor distances. We propose a low-dimensional concept embedding algo- rithm that combines human experience with automatic machine similarity kernels. We demonstrate that this shared concept embedding space improves upon separate embedding spaces for coarse flavor classification (alcohol percentage, country, grape, price, rating) and aligns with the intricate human perception of flavor.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.01525",
        "title": "VisAlign: Dataset for Measuring the Degree of Alignment between AI and Humans in Visual Perception",
        "abstract": "AI alignment refers to models acting towards human-intended goals, preferences, or ethical principles. Given that most large-scale deep learning models act as black boxes and cannot be manually controlled, analyzing the similarity between models and humans can be a proxy measure for ensuring AI safety. In this paper, we focus on the models\u2019 visual perception alignment with humans, further referred to as AI-human visual alignment. Specifically, we propose a new dataset for measuring AI-human visual alignment in terms of image classification, a fundamental task in machine perception. In order to evaluate AI-human visual alignment, a dataset should encompass samples with various scenarios that may arise in the real world and have gold human perception labels. Our dataset consists of three groups of samples, namely Must-Act (i.e., Must-Classify), Must-Abstain, and Uncertain, based on the quantity and clarity of visual information in an image and further divided into eight categories. All samples have a gold human perception label; even Uncertain (e.g., severely blurry) sample labels were obtained via crowd- sourcing. The validity of our dataset is verified by sampling theory, statistical theories related to survey design, and experts in the related fields. Using our dataset, we analyze the visual alignment and reliability of five popular visual perception models and seven abstention methods. Our code and data is available at https://github.com/jiyounglee-0523/VisAlign.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09126",
        "title": "STARSS23: An Audio-Visual Dataset of Spatial Recordings of Real Scenes with Spatiotemporal Annotations of Sound Events",
        "abstract": "While direction of arrival (DOA) of sound events is generally estimated from multichannel audio data recorded in a microphone array, sound events usually derive from visually perceptible source objects, e.g., sounds of footsteps come from the feet of a walker. This paper proposes an audio-visual sound event localization and detection (SELD) task, which uses multichannel audio and video information to estimate the temporal activation and DOA of target sound events. Audio- visual SELD systems can detect and localize sound events using signals from a microphone array and audio-visual correspondence. We also introduce an audio- visual dataset, Sony-TAu Realistic Spatial Soundscapes 2023 (STARSS23), which consists of multichannel audio data recorded with a microphone array, video data, and spatiotemporal annotation of sound events. Sound scenes in STARSS23 are recorded with instructions, which guide recording participants to ensure adequate activity and occurrences of sound events. STARSS23 also serves human-annotated temporal activation labels and human-confirmed DOA labels, which are based on tracking results of a motion capture system. Our benchmark results demonstrate the benefits of using visual object positions in audio-visual SELD tasks. The data is available at https://zenodo.org/record/7880637.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.04937",
        "title": "Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine",
        "abstract": "We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a comprehensive benchmark for evaluating foundation models in Emergency Medicine using a dataset of 100K+ continuously monitored Emergency Department visits from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at timescales from minutes to days, including predicting patient decompensation, disposition, and emergency department (ED) revisit, and includes a standardized evaluation framework with train-test splits and evaluation metrics. The multimodal dataset includes a wide range of detailed clinical data, including triage information, prior diagnoses and medications, continuously measured vital signs, electrocar- diogram and photoplethysmograph waveforms, orders placed and medications administered throughout the visit, free-text reports of imaging studies, and informa- tion on ED diagnosis, disposition, and subsequent revisits. We provide performance baselines for each prediction task to enable the evaluation of multimodal, multitask models. We believe that MC-BEC will encourage researchers to develop more effective, generalizable, and accessible foundation models for multimodal clinical data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.00723",
        "title": "HOH: Markerless Multimodal Human-Object-Human Handover Dataset with Large Object Count",
        "abstract": "We present the HOH (Human-Object-Human) Handover Dataset, a large object count dataset with 136 objects, to accelerate data-driven research on handover studies, human-robot handover implementation, and artificial intelligence (AI) on handover parameter estimation from 2D and 3D data of two-person interactions. HOH contains multi-view RGB and depth data, skeletons, fused point clouds, grasp type and handedness labels, object, giver hand, and receiver hand 2D and 3D segmentations, giver and receiver comfort ratings, and paired object metadata and aligned 3D models for 2,720 handover interactions spanning 136 objects and 20 giver-receiver pairs\u201440 with role-reversal\u2014organized from 40 participants. We also show experimental results of neural networks trained using HOH to perform grasp, orientation, and trajectory prediction. As the only fully markerless handover capture dataset, HOH represents natural human-human handover interactions, overcoming challenges with markered datasets that require specific suiting for body tracking, and lack high-resolution hand tracking. To date, HOH is the largest handover dataset in terms of object count, participant count, pairs with role reversal accounted for, and total interactions captured.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.07902",
        "title": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted Sentiment Classification Benchmark",
        "abstract": "Despite impressive advancements in multilingual corpora collection and model training, developing large-scale deployments of multilingual models still presents a significant challenge. This is particularly true for language tasks that are culture- dependent. One such example is the area of multilingual sentiment analysis, where affective markers can be subtle and deeply ensconced in culture. This work presents the most extensive open massively multilingual corpus of datasets for training sentiment models. The corpus consists of 79 manually selected datasets from over 350 datasets reported in the scientific literature based on strict quality criteria. The corpus covers 27 languages representing 6 language families. Datasets can be queried using several linguistic and functional features. In addition, we present a multi-faceted sentiment classification benchmark summarizing hundreds of experiments conducted on different base models, training objectives, dataset collections, and fine-tuning strategies.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2207.13250",
        "title": "Spatio-Temporal Wildfire Prediction using\nMulti-Modal Data",
        "abstract": "Due to severe societal and environmental impacts, wildfire prediction using multi-modal sensing data has become a highly sought-after data-analytical tool by various stakeholders (such as state governments and power utility companies) to achieve a more informed understanding of wildfire activities and plan preventive measures. A desirable algorithm should precisely predict fire risk and magnitude for a location in real time. In this paper, we develop a flexible spatio-temporal wildfire prediction framework using multi-modal time series data. We first predict the wildfire risk (the chance of a wildfire event) in real-time, considering the historical events using discrete mutually exciting point process models. Then we further develop a wildfire magnitude prediction set method based on the flexible distribution-free time-series conformal prediction (CP) approach. Theoretically, we prove a risk model parameter recovery guarantee, as well as coverage and set size guarantees for the CP sets. Through extensive real-data experiments with wildfire data in California, we demonstrate the effectiveness of our methods, as well as their flexibility and scalability in large regions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.16005",
        "title": "MLFMF: Data Sets for Machine Learning for Mathematical Formalization",
        "abstract": "We introduce MLFMF, a collection of data sets for benchmarking recommendation systems used to support formalization of mathematics with proof assistants. These systems help humans identify which previous entries (theorems, constructions, datatypes, and postulates) are relevant in proving a new theorem or carrying out a new construction. Each data set is derived from a library of formalized mathematics written in proof assistants Agda or Lean. The collection includes the largest Lean 4 library Mathlib, and some of the largest Agda libraries: the standard library, the library of univalent mathematics Agda-unimath, and the TypeTopology library. Each data set represents the corresponding library in two ways: as a heterogeneous network, and as a list of s-expressions representing the syntax trees of all the entries in the library. The network contains the (modular) structure of the library and the references between entries, while the s-expressions give complete and easily parsed information about every entry. We report baseline results using standard graph and word embeddings, tree ensembles, and instance-based learning algorithms. The MLFMF data sets provide solid benchmarking support for further investigation of the numerous machine learning approaches to formalized mathematics. The methodology used to extract the networks and the s-expressions readily applies to other libraries, and is applicable to other proof assistants. With more than 250 000 entries in total, this is currently the largest collection of formalized mathematical knowledge in machine learnable format.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.03977",
        "title": "PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning",
        "abstract": "Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited \u2013 and often played down \u2013 mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models. The datasets can be downloaded at https://pug.metademolab.com/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.09073",
        "title": "Consensus and Subjectivity of Skin Tone Annotation for ML Fairness",
        "abstract": "Understanding different human attributes and how they affect model behavior may become a standard need for all model creation and usage, from traditional computer vision tasks to the newest multimodal generative AI systems. In computer vision specifically, we have relied on datasets augmented with perceived attribute signals (e.g., gender presentation, skin tone, and age) and benchmarks enabled by these datasets. Typically labels for these tasks come from human annotators. However, annotating attribute signals, especially skin tone, is a difficult and subjective task. Perceived skin tone is affected by technical factors, like lighting conditions, and social factors that shape an annotator\u2019s lived experience.\nThis paper examines the subjectivity of skin tone annotation through a series of annotation experiments using the Monk Skin Tone (MST) scale [59], a small pool of professional photographers, and a much larger pool of trained crowdsourced annotators. Along with this study we release the Monk Skin Tone Examples (MST- E) dataset, containing 1515 images and 31 videos spread across the full MST scale. MST-E is designed to help train human annotators to annotate MST effectively. Our study shows that annotators can reliably annotate skin tone in a way that aligns with an expert in the MST scale, even under challenging environmental conditions. We also find evidence that annotators from different geographic regions rely on different mental models of MST categories resulting in annotations that systematically vary across regions. Given this, we advise practitioners to use a diverse set of annotators and a higher replication count for each image when annotating skin tone for fairness research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.11249",
        "title": "OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning",
        "abstract": "Spatio-temporal predictive learning is a learning paradigm that enables models to learn spatial and temporal patterns by predicting future frames from given past frames in an unsupervised manner. Despite remarkable progress in recent years, a lack of systematic understanding persists due to the diverse settings, complex implementation, and difficult reproducibility. Without standardization, comparisons can be unfair and insights inconclusive. To address this dilemma, we propose OpenSTL, a comprehensive benchmark for spatio-temporal predictive learning that categorizes prevalent approaches into recurrent-based and recurrent-free models. OpenSTL provides a modular and extensible framework implementing various state-of-the-art methods. We conduct standard evaluations on datasets across various domains, including synthetic moving object trajectory, human motion, driving scenes, traffic flow, and weather forecasting. Based on our observations, we provide a detailed analysis of how model architecture and dataset properties affect spatio-temporal predictive learning performance. Surprisingly, we find that recurrent-free models achieve a good balance between efficiency and performance than recurrent models. Thus, we further extend the common MetaFormers to boost recurrent-free spatial-temporal predictive learning. We open-source the code and models at https://github.com/chengtan9907/OpenSTL.Most neural networks assume that input images have a fixed number of channels (three for RGB images). However, there are many settings where the number of channels may vary, such as microscopy images where the number of channels changes depending on instruments and experimental goals. Yet, there has not been a systemic attempt to create and evaluate neural networks that are invariant to the number and type of channels. As a result, trained models remain specific to individual studies and are hardly reusable for other microscopy settings. In this paper, we present a benchmark for investigating channel-adaptive models in microscopy imaging, which consists of 1) a dataset of varied-channel single-cell im- ages, and 2) a biologically relevant evaluation framework. In addition, we adapted several existing techniques to create channel-adaptive models and compared their performance on this benchmark to fixed-channel, baseline models. We find that channel-adaptive models can generalize better to out-of-domain tasks and can be computationally efficient. We contribute a curated dataset1 and an evaluation API2 to facilitate objective comparisons in future research and applications.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.19224",
        "title": "CHAMMI: A benchmark for channel-adaptive models in microscopy imaging",
        "abstract": "Most neural networks assume that input images have a fixed number of channels (three for RGB images). However, there are many settings where the number of channels may vary, such as microscopy images where the number of channels changes depending on instruments and experimental goals. Yet, there has not been a systemic attempt to create and evaluate neural networks that are invariant to the number and type of channels. As a result, trained models remain specific to individual studies and are hardly reusable for other microscopy settings. In this paper, we present a benchmark for investigating channel-adaptive models in microscopy imaging, which consists of 1) a dataset of varied-channel single-cell im- ages, and 2) a biologically relevant evaluation framework. In addition, we adapted several existing techniques to create channel-adaptive models and compared their performance on this benchmark to fixed-channel, baseline models. We find that channel-adaptive models can generalize better to out-of-domain tasks and can be computationally efficient. We contribute a curated dataset1 and an evaluation API2 to facilitate objective comparisons in future research and applications.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.11513",
        "title": "GENEVAL: An Object-Focused Framework for Evaluating Text-to-Image Alignment",
        "abstract": "Recent breakthroughs in diffusion models, multimodal pretraining, and efficient finetuning have led to an explosion of text-to-image generative models. Given human evaluation is expensive and difficult to scale, automated methods are critical for evaluating the increasingly large number of new models. However, most current automated evaluation metrics like FID or CLIPScore only offer a holistic measure of image quality or image-text alignment, and are unsuited for fine-grained or instance- level analysis. In this paper, we introduce GENEVAL, an object-focused framework to evaluate compositional image properties such as object co-occurrence, position, count, and color. We show that current object detection models can be leveraged to evaluate text-to-image models on a variety of generation tasks with strong human agreement, and that other discriminative vision models can be linked to this pipeline to further verify properties like object color. We then evaluate several open- source text-to-image models and analyze their relative generative capabilities on our benchmark. We find that recent models demonstrate significant improvement on these tasks, though they are still lacking in complex capabilities such as spatial relations and attribute binding. Finally, we demonstrate how GENEVAL might be used to help discover existing failure modes, in order to inform development of the next generation of text-to-image models. Our code to run the GENEVAL framework is publicly available at https://github.com/djghosh13/geneval.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.16527",
        "title": "OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents",
        "abstract": "Large multimodal models trained on natural documents, which interleave images and text, outperform models trained on image-text pairs on various multimodal benchmarks. However, the datasets used to train these models have not been released, and the collection process has not been fully specified. We introduce the OBELICS dataset, an open web-scale filtered dataset of in- terleaved image-text documents comprising 141 million web pages extracted from Common Crawl, 353 million associated images, and 115 billion text tokens. We describe the dataset creation process, present comprehensive filtering rules, and provide an analysis of the dataset\u2019s content. To show the viability of OBELICS, we train vision and language models of 9 and 80 billion parameters named IDEFICS, and obtain competitive performance on different multimodal benchmarks. We release our dataset, models and code.1.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.16186",
        "title": "Large-scale Training Data Search for Object Re-identification",
        "abstract": "We consider a scenario where we have access to the tar- get domain, but cannot afford on-the-fly training data an- notation, and instead would like to construct an alternative training set from a large-scale data pool such that a com- petitive model can be obtained. We propose a search and pruning (SnP) solution to this training data search prob- lem, tailored to object re-identification (re-ID), an appli- cation aiming to match the same object captured by differ- ent cameras. Specifically, the search stage identifies and merges clusters of source identities which exhibit similar distributions with the target domain. The second stage, subject to a budget, then selects identities and their im- ages from the Stage I output, to control the size of the re- sulting training set for efficient training. The two steps provide us with training sets 80% smaller than the source pool while achieving a similar or even higher re-ID accu- racy. These training sets are also shown to be superior to a few existing search methods such as random sampling and greedy sampling under the same budget on training data size. If we release the budget, training sets resulting from the first stage alone allow even higher re-ID accu- racy. We provide interesting discussions on the specificity of our method to the re-ID problem and particularly its role in bridging the re-ID domain gap. The code is available at https://github.com/yorkeyao/SnP",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.05938",
        "title": "V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting",
        "abstract": "Utilizing infrastructure and vehicle-side information to track and forecast the behaviors of surrounding traf- fic participants can significantly improve decision-making and safety in autonomous driving. However, the lack of real-world sequential datasets limits research in this area. To address this issue, we introduce V2X-Seq, the first large-scale sequential V2X dataset, which includes data frames, trajectories, vector maps, and traffic lights captured from natural scenery. V2X-Seq comprises two parts: the sequential perception dataset, which includes more than 15,000 frames captured from 95 scenarios, and the trajectory forecasting dataset, which contains about 80,000 infrastructure-view scenarios, 80,000 vehicle-view scenarios, and 50,000 cooperative-view scenarios cap- tured from 28 intersections\u2019 areas, covering 672 hours of data. Based on V2X-Seq, we introduce three new tasks for vehicle-infrastructure cooperative (VIC) autonomous driv- ing: VIC3D Tracking, Online-VIC Forecasting, and Offline- VIC Forecasting. We also provide benchmarks for the intro- duced tasks. Find data, code, and more up-to-date informa- tion at https://github.com/AIR-THU/DAIR-V2X-Seq.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2212.06152",
        "title": "Accelerating Dataset Distillation via Model Augmentation",
        "abstract": "Dataset Distillation (DD), a newly emerging field, aims at generating much smaller but efficient synthetic training datasets from large ones. Existing DD methods based on gradient matching achieve leading performance; however, they are extremely computationally intensive as they re- quire continuously optimizing a dataset among thousands of randomly initialized models. In this paper, we assume that training the synthetic data with diverse models leads to better generalization performance. Thus we propose two model augmentation techniques, i.e. using early-stage models and parameter perturbation to learn an informative synthetic set with significantly reduced training cost. Exten- sive experiments demonstrate that our method achieves up to 20\u00d7 speedup and comparable performance on par with state-of-the-art methods.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.17096",
        "title": "ImageNet-E: Benchmarking Neural Network Robustness via Attribute Editing",
        "abstract": "Recent studies have shown that higher accuracy on Im- ageNet usually leads to better robustness against differ- ent corruptions. Therefore, in this paper, instead of fol- lowing the traditional research paradigm that investigates new out-of-distribution corruptions or perturbations deep models may encounter, we conduct model debugging in in- distribution data to explore which object attributes a model may be sensitive to. To achieve this goal, we create a toolkit for object editing with controls of backgrounds, sizes, po- sitions, and directions, and create a rigorous benchmark named ImageNet-E(diting) for evaluating the image clas- sifier robustness in terms of object attributes. With our ImageNet-E, we evaluate the performance of current deep learning models, including both convolutional neural net- works and vision transformers. We find that most models are quite sensitive to attribute changes. A small change in the background can lead to an average of 9.23% drop on top-1 accuracy. We also evaluate some robust models including both adversarially trained models and other ro- bust trained models and find that some models show worse robustness against attribute changes than vanilla models. Based on these findings, we discover ways to enhance at- tribute robustness with preprocessing, architecture designs, and training strategies. We hope this work can provide some insights to the community and open up a new av- enue for research in robust computer vision. The code and dataset are available at https://github.com/ alibaba/easyrobust.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.01112",
        "title": "Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves",
        "abstract": "Formula-driven supervised learning (FDSL) has been shown to be an effective method for pre-training vision transformers, where ExFractalDB-21k was shown to exceed the pre-training effect of ImageNet-21k. These studies also indicate that contours mattered more than textures when pre-training vision transformers. However, the lack of a systematic investigation as to why these contour-oriented synthetic datasets can achieve the same accuracy as real datasets leaves much room for skepticism. In the present work, we develop a novel methodology based on circular harmonics for systematically investigating the design space of contour-oriented synthetic datasets. This allows us to efficiently search the optimal range of FDSL parameters and maximize the variety of synthetic images in the dataset, which we found to be a critical factor. When the resulting new dataset VisualAtom-21k is used for pre-training ViT- Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k. This is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training, while the number of images is 1/14. Unlike JFT-300M which is a static dataset, the quality of synthetic datasets will continue to improve, and the current work is a testament to this possibility. FDSL is also free of the common issues associated with real im- ages, e.g. privacy/copyright issues, labeling costs/errors, and ethical biases.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09310",
        "title": "Infinite Photorealistic Worlds using Procedural Generation",
        "abstract": "We introduce Infinigen, a procedural generator of photo- realistic 3D scenes of the natural world. Infinigen is entirely procedural: every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source and allowing infinite variation and composi- tion. Infinigen offers broad coverage of objects and scenes in the natural world including plants, animals, terrains, and natural phenomena such as fire, cloud, rain, and snow. In- finigen can be used to generate unlimited, diverse training data for a wide range of computer vision tasks including object detection, semantic segmentation, optical flow, and 3D reconstruction. We expect Infinigen to be a useful re- source for computer vision research and beyond. Please visit infinigen.org for videos, code and pre-generated data.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.14717",
        "title": "CelebV-Text: A Large-Scale Facial Text-Video Dataset",
        "abstract": "Text-driven generation models are flourishing in video generation and editing. However, face-centric text-to-video generation remains a challenge due to the lack of a suitable dataset containing high-quality videos and highly relevant texts. This paper presents CelebV-Text, a large-scale, di- verse, and high-quality dataset of facial text-video pairs, to facilitate research on facial text-to-video generation tasks. CelebV-Text comprises 70,000 in-the-wild face video clips with diverse visual content, each paired with 20 texts gen- erated using the proposed semi-automatic text generation strategy. The provided texts are of high quality, describ- ing both static and dynamic attributes precisely. The supe- riority of CelebV-Text over other datasets is demonstrated via comprehensive statistical analysis of the videos, texts, and text-video relevance. The effectiveness and potential of CelebV-Text are further shown through extensive self- evaluation. A benchmark is constructed with representa- tive methods to standardize the evaluation of the facial text- to-video generation task. All data and models are publicly available",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.01943",
        "title": "Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo",
        "abstract": "While recent methods for motion and stereo estimation recover an unprecedented amount of details, such highly detailed structures are neither adequately reflected in the data of existing benchmarks nor their evaluation methodol- ogy. Hence, we introduce Spring \u2013 a large, high-resolution, high-detail, computer-generated benchmark for scene flow, optical flow, and stereo. Based on rendered scenes from the open-source Blender movie \u201cSpring\u201d, it provides photo- realistic HD datasets with state-of-the-art visual effects and ground truth training data. Furthermore, we provide a web- site to upload, analyze and compare results. Using a novel evaluation methodology based on a super-resolved UHD ground truth, our Spring benchmark can assess the quality of fine structures and provides further detailed performance statistics on different image regions. Regarding the num- ber of ground truth frames, Spring is 60\u00d7 larger than the only scene flow benchmark, KITTI 2015, and 15\u00d7 larger than the well-established MPI Sintel optical flow bench- mark. Initial results for recent methods on our benchmark show that estimating fine details is indeed challenging, as their accuracy leaves significant room for improvement. The Spring benchmark and the corresponding datasets are available at http://spring-benchmark.org.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2302.11217",
        "title": "Connecting Vision and Language with Video Localized Narratives",
        "abstract": "We propose Video Localized Narratives, a new form of multimodal video annotations connecting vision and lan- guage. In the original Localized Narratives [40], annota- tors speak and move their mouse simultaneously on an im- age, thus grounding each word with a mouse trace segment. However, this is challenging on a video. Our new protocol empowers annotators to tell the story of a video with Local- ized Narratives, capturing even complex events involving multiple actors interacting with each other and with sev- eral passive objects. We annotated 20k videos of the OVIS, UVO, and Oops datasets, totalling 1.7M words. Based on this data, we also construct new benchmarks for the video narrative grounding and video question answering tasks, and provide reference results from strong baseline models. Our annotations are available at https://google. github.io/video-localized-narratives/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.15166",
        "title": "Towards Artistic Image Aesthetics Assessment: a Large-scale Dataset and a New Method",
        "abstract": "Image aesthetics assessment (IAA) is a challenging task due to its highly subjective nature. Most of the current stud- ies rely on large-scale datasets (e.g., AVA and AADB) to learn a general model for all kinds of photography images. However, little light has been shed on measuring the aes- thetic quality of artistic images, and the existing datasets only contain relatively few artworks. Such a defect is a great obstacle to the aesthetic assessment of artistic images. To fill the gap in the field of artistic image aesthetics assess- ment (AIAA), we first introduce a large-scale AIAA dataset: Boldbrush Artistic Image Dataset (BAID), which consists of 60,337 artistic images covering various art forms, with more than 360,000 votes from online users. We then pro- pose a new method, SAAN (Style-specific Art Assessment Network), which can effectively extract and utilize style- specific and generic aesthetic information to evaluate artis- tic images. Experiments demonstrate that our proposed approach outperforms existing IAA methods on the pro- posed BAID dataset according to quantitative comparisons. We believe the proposed dataset and method can serve as a foundation for future AIAA works and inspire more re- search in this field. Dataset and code are available at: https://github.com/Dreemurr-T/BAID.git",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.14933",
        "title": "MD-VQA: Multi-Dimensional Quality Assessment for UGC Live Videos",
        "abstract": "User-generated content (UGC) live videos are often bothered by various distortions during capture procedures and thus exhibit diverse visual qualities. Such source videos are further compressed and transcoded by media server providers before being distributed to end-users. Because of the flourishing of UGC live videos, effective video qual- ity assessment (VQA) tools are needed to monitor and per- ceptually optimize live streaming videos in the distributing process. In this paper, we address UGC Live VQA prob- lems by constructing a first-of-a-kind subjective UGC Live VQA database and developing an effective evaluation tool. Concretely, 418 source UGC videos are collected in real live streaming scenarios and 3,762 compressed ones at dif- ferent bit rates are generated for the subsequent subjective VQA experiments. Based on the built database, we de- velop a Multi-Dimensional VQA (MD-VQA) evaluator to measure the visual quality of UGC live videos from seman- tic, distortion, and motion aspects respectively. Extensive experimental results show that MD-VQA achieves state-of- the-art performance on both our UGC Live VQA database and existing compressed UGC VQA databases.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2212.08051",
        "title": "Objaverse: A Universe of Annotated 3D Objects",
        "abstract": "Massive data corpora like WebText, Wikipedia, Concep- tual Captions, WebImageText, and LAION have propelled recent dramatic progress in AI. Large neural models trained on such datasets produce impressive results and top many of today\u2019s benchmarks. A notable omission within this fam- ily of large-scale datasets is 3D data. Despite considerable interest and potential applications in 3D vision, datasets of high-fidelity 3D models continue to be mid-sized with limited diversity of object categories. Addressing this gap, we present Objaverse 1.0, a large dataset of objects with 800K+ (and growing) 3D models with descriptive captions, tags, and animations. Objaverse improves upon present day 3D repositories in terms of scale, number of categories, and in the visual diversity of instances within a category. We demonstrate the large potential of Objaverse via four diverse applications: training generative 3D models, improving tail category segmentation on the LVIS benchmark, training open-vocabulary object-navigation models for Em- bodied AI, and creating a new benchmark for robustness analysis of vision models. Objaverse can open new direc- tions for research and enable new applications across the field of AI.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.05633",
        "title": "Habitat-Matterport 3D Semantics Dataset",
        "abstract": "We present the Habitat-Matterport 3D Semantics (HM3DSEM) dataset. HM3DSEM is the largest dataset of 3D real-world spaces with densely annotated seman- tics that is currently available to the academic commu- nity. It consists of 142,646 object instance annotations across 216 3D spaces and 3,100 rooms within those spaces. The scale, quality, and diversity of object annotations far exceed those of prior datasets. A key difference setting apart HM3DSEM from other datasets is the use of tex- ture information to annotate pixel-accurate object bound- aries. We demonstrate the effectiveness of HM3DSEM dataset for the Object Goal Navigation task using differ- ent methods. Policies trained using HM3DSEM perform outperform those trained on prior datasets. Introduction of HM3DSEM in the Habitat ObjectNav Challenge lead to an increase in participation from 400 submissions in 2021 to 1022 submissions in 2022. Project page: https: //aihabitat.org/datasets/hm3d-semantics/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.01932",
        "title": "MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices",
        "abstract": "High-quality 3D ground-truth shapes are critical for 3D object reconstruction evaluation. However, it is difficult to create a replica of an object in reality, and even 3D re- constructions generated by 3D scanners have artefacts that cause biases in evaluation. To address this issue, we in- troduce a novel multi-view RGBD dataset captured using a mobile device, which includes highly precise 3D ground- truth annotations for 153 object models featuring a diverse set of 3D structures. We obtain precise 3D ground-truth shape without relying on high-end 3D scanners by utilizing LEGO models with known geometry as the 3D structures for image capture. The distinct data modality offered by high- resolution RGB images and low-resolution depth maps cap- tured on a mobile device, when combined with precise 3D geometry annotations, presents a unique opportunity for fu- ture research on high-fidelity 3D reconstruction. Further- more, we evaluate a range of 3D reconstruction algorithms on the proposed dataset.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.15443",
        "title": "GeoNet: Benchmarking Unsupervised Adaptation across Geographies",
        "abstract": "In recent years, several efforts have been aimed at im- proving the robustness of vision models to domains and environments unseen during training. An important practi- cal problem pertains to models deployed in a new geography that is under-represented in the training dataset, posing a direct challenge to fair and inclusive computer vision. In this paper, we study the problem of geographic robust- ness and make three main contributions. First, we intro- duce a large-scale dataset GeoNet for geographic adapta- tion containing benchmarks across diverse tasks like scene recognition (GeoPlaces), image classification (GeoImNet) and universal adaptation (GeoUniDA). Second, we inves- tigate the nature of distribution shifts typical to the prob- lem of geographic adaptation and hypothesize that the ma- jor source of domain shifts arise from significant varia- tions in scene context (context shift), object design (de- sign shift) and label distribution (prior shift) across ge- ographies. Third, we conduct an extensive evaluation of several state-of-the-art unsupervised domain adaptation al- gorithms and architectures on GeoNet, showing that they do not suffice for geographical adaptation, and that large-scale pre-training using large vision models also does not lead to geographic robustness. Our dataset is publicly available at https://tarun005.github.io/GeoNet.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2302.11102",
        "title": "Logical Consistency and Greater Descriptive Power for Facial Hair Attribute Learning",
        "abstract": "Face attribute research has so far used only simple bi- nary attributes for facial hair; e.g., beard / no beard. We have created a new, more descriptive facial hair annotation scheme and applied it to create a new facial hair attribute dataset, FH37K. Face attribute research also so far has not dealt with logical consistency and completeness. For ex- ample, in prior research, an image might be classified as both having no beard and also having a goatee (a type of beard). We show that the test accuracy of previous classifi- cation methods on facial hair attribute classification drops significantly if logical consistency of classifications is en- forced. We propose a logically consistent prediction loss, LCPLoss, to aid learning of logical consistency across at- tributes, and also a label compensation training strategy to eliminate the problem of no positive prediction across a set of related attributes. Using an attribute classifier trained on FH37K, we investigate how facial hair affects face recognition accuracy, including variation across de- mographics. Results show that similarity and difference in facial hairstyle have important effects on the impostor and genuine score distributions in face recognition. The code is at https://github.com/HaiyuWu/LogicalConsistency.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2301.01795",
        "title": "PACO: Parts and Attributes of Common Objects",
        "abstract": "Object models are gradually progressing from predict- ing just category labels to providing detailed descriptions of object instances. This motivates the need for large datasets which go beyond traditional object masks and pro- vide richer annotations such as part masks and attributes. Hence, we introduce PACO: Parts and Attributes of Com- mon Objects. It spans 75 object categories, 456 object- part categories and 55 attributes across image (LVIS) and video (Ego4D) datasets. We provide 641K part masks an- notated across 260K object boxes, with roughly half of them exhaustively annotated with attributes as well. We design evaluation metrics and provide benchmark results for three tasks on the dataset: part mask segmentation, ob- ject and part attribute prediction and zero-shot instance de- tection. Dataset, models, and code are open-sourced at https://github.com/facebookresearch/paco.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09780",
        "title": "Understanding Deep Generative Models with Generalized Empirical Likelihoods",
        "abstract": "Understanding how well a deep generative model captures a distribution of high-dimensional data remains an important open challenge. It is especially difficult for certain model classes, such as Generative Adversarial Networks and Diffu- sion Models, whose models do not admit exact likelihoods. In this work, we demonstrate that generalized empirical like- lihood (GEL) methods offer a family of diagnostic tools that can identify many deficiencies of deep generative models (DGMs). We show, with appropriate specification of moment conditions, that the proposed method can identify which modes have been dropped, the degree to which DGMs are mode imbalanced, and whether DGMs sufficiently capture intra-class diversity. We show how to combine techniques from Maximum Mean Discrepancy and Generalized Empiri- cal Likelihood to create not only distribution tests that retain per-sample interpretability, but also metrics that include la- bel information. We find that such tests predict the degree of mode dropping and mode imbalance up to 60% better than metrics such as improved precision/recall. We provide an im- plementation at https://github.com/deepmind/ understanding _ deep _ generative _ models _ with_generalized_empirical_likelihood/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.10036",
        "title": "Visual DNA:\nRepresenting and Comparing Images using Distributions of Neuron Activations",
        "abstract": "Selecting appropriate datasets is critical in modern com- puter vision. However, no general-purpose tools exist to evaluate the extent to which two datasets differ. For this, we propose representing images \u2013 and by extension datasets \u2013 using Distributions of Neuron Activations (DNAs). DNAs fit distributions, such as histograms or Gaussians, to activa- tions of neurons in a pre-trained feature extractor through which we pass the image(s) to represent. This extractor is frozen for all datasets, and we rely on its generally expres- sive power in feature space. By comparing two DNAs, we can evaluate the extent to which two datasets differ with granular control over the comparison attributes of inter- est, providing the ability to customise the way distances are measured to suit the requirements of the task at hand. Furthermore, DNAs are compact, representing datasets of any size with less than 15 megabytes. We demonstrate the value of DNAs by evaluating their applicability on several tasks, including conditional dataset comparison, synthetic image evaluation, and transfer learning, and across diverse datasets, ranging from synthetic cat images to celebrity faces and urban driving scenes.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2211.12914",
        "title": "Open-vocabulary Attribute Detection",
        "abstract": "Vision-language modeling has enabled open-vocabulary tasks where predictions can be queried using any text prompt in a zero-shot manner. Existing open-vocabulary tasks focus on object classes, whereas research on object attributes is limited due to the lack of a reliable attribute- focused evaluation benchmark. This paper introduces the Open-Vocabulary Attribute Detection (OVAD) task and the corresponding OVAD benchmark. The objective of the novel task and benchmark is to probe object-level attribute information learned by vision-language models. To this end, we created a clean and densely annotated test set cov- ering 117 attribute classes on the 80 object classes of MS COCO. It includes positive and negative annotations, which enables open-vocabulary evaluation. Overall, the bench- mark consists of 1.4 million annotations. For reference, we provide a first baseline method for open-vocabulary at- tribute detection. Moreover, we demonstrate the bench- mark\u2019s value by studying the attribute detection perfor- mance of several foundation models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.10448",
        "title": "ReLight My NeRF: A Dataset for\nNovel View Synthesis and Relighting of Real World Objects",
        "abstract": "In this paper, we focus on the problem of rendering novel views from a Neural Radiance Field (NeRF) under unob- served light conditions. To this end, we introduce a novel dataset, dubbed ReNe (Relighting NeRF), framing real world objects under one-light-at-time (OLAT) conditions, annotated with accurate ground-truth camera and light poses. Our acquisition pipeline leverages two robotic arms holding, respectively, a camera and an omni-directional point-wise light source. We release a total of 20 scenes depicting a variety of objects with complex geometry and challenging materials. Each scene includes 2000 images, acquired from 50 different points of views under 40 different OLAT conditions. By leveraging the dataset, we perform an ablation study on the relighting capability of variants of the vanilla NeRF architecture and identify a lightweight archi- tecture that can render novel views of an object under novel light conditions, which we use to establish a non-trivial baseline for the dataset. Dataset and benchmark are avail- able at https://eyecan-ai.github.io/rene.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2302.09997",
        "title": "A Large-Scale Homography Benchmark",
        "abstract": "We present a large-scale dataset of Planes in 3D, Pi3D, of roughly 1000 planes observed in 10 000 images from the 1DSfM dataset, and HEB, a large-scale homography estimation benchmark leveraging Pi3D. The applications of the Pi3D dataset are diverse, e.g. training or evaluat- ing monocular depth, surface normal estimation and image matching algorithms. The HEB dataset consists of 226 260 homographies and includes roughly 4M correspondences. The homographies link images that often undergo signifi- cant viewpoint and illumination changes. As applications of HEB, we perform a rigorous evaluation of a wide range of robust estimators and deep learning-based correspon- dence filtering methods, establishing the current state-of- the-art in robust homography estimation. We also evalu- ate the uncertainty of the SIFT orientations and scales w.r.t. the ground truth coming from the underlying homographies and provide codes for comparing uncertainty of custom de- tectors. The dataset is available at https://github. com/danini/homography-benchmark.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2211.13190",
        "title": "BiasBed \u2013 Rigorous Texture Bias Evaluation\n",
        "abstract": "The well-documented presence of texture bias in modern convolutional neural networks has led to a plethora of al- gorithms that promote an emphasis on shape cues, often to support generalization to new domains. Yet, common datasets, benchmarks and general model selection strate- gies are missing, and there is no agreed, rigorous evaluation protocol. In this paper, we investigate difficulties and limi- tations when training networks with reduced texture bias. In particular, we also show that proper evaluation and mean- ingful comparisons between methods are not trivial. We introduce BiasBed, a testbed for texture- and style-biased training, including multiple datasets and a range of exist- ing algorithms. It comes with an extensive evaluation pro- tocol that includes rigorous hypothesis testing to gauge the significance of the results, despite the considerable train- ing instability of some style bias methods. Our extensive experiments, shed new light on the need for careful, sta- tistically founded evaluation protocols for style bias (and beyond). E.g., we find that some algorithms proposed in the literature do not significantly mitigate the impact of style bias at all. With the release of BiasBed, we hope to fos- ter a common understanding of consistent and meaning- ful comparisons, and consequently faster progress towards learning methods free of texture bias. Code is available at https://github.com/D1noFuzi/BiasBed",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.01816",
        "title": "Toward Verifiable and Reproducible Human Evaluation for Text-to-Image Generation",
        "abstract": "Human evaluation is critical for validating the perfor- mance of text-to-image generative models, as this highly cognitive process requires deep comprehension of text and images. However, our survey of 37 recent papers reveals that many works rely solely on automatic measures (e.g., FID) or perform poorly described human evaluations that are not reliable or repeatable. This paper proposes a stan- dardized and well-defined human evaluation protocol to fa- cilitate verifiable and reproducible human evaluation in fu- ture works. In our pilot data collection, we experimentally show that the current automatic measures are incompatible with human perception in evaluating the performance of the text-to-image generation results. Furthermore, we provide insights for designing human evaluation experiments reli- ably and conclusively. Finally, we make several resources publicly available to the community to facilitate easy and fast implementations.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13611",
        "title": "A New Comprehensive Benchmark for Semi-supervised Video Anomaly Detection and Anticipation",
        "abstract": "Semi-supervised video anomaly detection (VAD) is a critical task in the intelligent surveillance system. How- ever, an essential type of anomaly in VAD named scene- dependent anomaly has not received the attention of re- searchers. Moreover, there is no research investigating anomaly anticipation, a more significant task for preventing the occurrence of anomalous events. To this end, we pro- pose a new comprehensive dataset, NWPU Campus, con- taining 43 scenes, 28 classes of abnormal events, and 16 hours of videos. At present, it is the largest semi-supervised VAD dataset with the largest number of scenes and classes of anomalies, the longest duration, and the only one con- sidering the scene-dependent anomaly. Meanwhile, it is also the first dataset proposed for video anomaly antici- pation. We further propose a novel model capable of de- tecting and anticipating anomalous events simultaneously. Compared with 7 outstanding VAD algorithms in recent years, our method can cope with scene-dependent anomaly detection and anomaly anticipation both well, achieving state-of-the-art performance on ShanghaiTech, CUHK Av- enue, IITB Corridor and the newly proposed NWPU Cam- pus datasets consistently. Our dataset and code is available at: https://campusvad.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.16940",
        "title": "BEDLAM: A Synthetic Dataset of\nBodies Exhibiting Detailed Lifelike Animated Motion",
        "abstract": "We show, for the first time, that neural networks trained only on synthetic data achieve state-of-the-art accuracy on the problem of 3D human pose and shape (HPS) estima- tion from real images. Previous synthetic datasets have been small, unrealistic, or lacked realistic clothing. Achiev- ing sufficient realism is non-trivial and we show how to do this for full bodies in motion. Specifically, our BED- LAM dataset contains monocular RGB videos with ground- truth 3D bodies in SMPL-X format. It includes a diver- sity of body shapes, motions, skin tones, hair, and cloth- ing. The clothing is realistically simulated on the moving bodies using commercial clothing physics simulation. We render varying numbers of people in realistic scenes with varied lighting and camera motions. We then train vari- ous HPS regressors using BEDLAM and achieve state-of- the-art accuracy on real-image benchmarks despite train- ing with synthetic data. We use BEDLAM to gain insights\ninto what model design choices are important for accu- racy. With good synthetic training data, we find that a basic method like HMR approaches the accuracy of the current SOTA method (CLIFF). BEDLAM is useful for a variety of tasks and all images, ground truth bodies, 3D clothing, support code, and more are available for research purposes. Additionally, we provide detailed information about our synthetic data generation pipeline, enabling oth- ers to generate their own datasets. See the project page: https://bedlam.is.tue.mpg.de/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.14968",
        "title": "Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective",
        "abstract": "We aim at advancing blind image quality assessment (BIQA), which predicts the human perception of image quality without any reference information. We develop a general and automated multitask learning scheme for BIQA to exploit auxiliary knowledge from other tasks, in a way that the model parameter sharing and the loss weighting are determined automatically. Specifically, we first describe all candidate label combinations (from multiple tasks) us- ing a textual template, and compute the joint probability from the cosine similarities of the visual-textual embed- dings. Predictions of each task can be inferred from the joint distribution, and optimized by carefully designed loss functions. Through comprehensive experiments on learn- ing three tasks - BIQA, scene classification, and distor- tion type identification, we verify that the proposed BIQA method 1) benefits from the scene classification and dis- tortion type identification tasks and outperforms the state- of-the-art on multiple IQA datasets, 2) is more robust in the group maximum differentiation competition, and 3) re- aligns the quality annotations from different IQA datasets more effectively. The source code is available at https: //github.com/zwx8981/LIQE .",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2210.01946",
        "title": "AFFECTION: LEARNING AFFECTIVE EXPLANATIONS FOR REAL-WORLD VISUAL DATA",
        "abstract": "In this work, we explore the emotional reactions that real-world images tend to induce by using natural language as the medium to express the rationale behind an affective response to a given visual stimulus. To embark on this journey, we introduce and share with the research community a large-scale dataset that contains emotional reactions and free-form textual explanations for 85,007 publicly available images, analyzed by 6,283 annotators who were asked to indicate and explain how and why they felt in a particular way when observing a particular image, producing a total of 526,749 responses. Even though emotional reactions are subjective and sensitive to context (personal mood, social status, past experiences) \u2013 we show that there is significant common ground to capture potentially plausible emotional responses with a large support in the subject population. In light of this key observation, we ask the following questions: i) Can we develop multi-modal neural networks that provide reasonable affective responses to real-world visual data, explained with language? ii) Can we steer such methods towards producing explanations with varying degrees of pragmatic language or justifying different emotional reactions while adapting to the underlying visual stimulus? Finally, iii) How can we evaluate the performance of such methods for this novel task? With this work, we take the first steps in addressing all of these questions, thus paving the way for richer, more human-centric, and emotionally-aware image analysis systems. Our introduced dataset and all developed methods are available on https://affective-explanations.org.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2207.01398",
        "title": "A LARGE-SCALE ROBUSTNESS ANALYSIS OF VIDEO ACTION RECOGNITION MODELS",
        "abstract": "We have seen a great progress in video action recognition in recent years. There are several models based on convolutional neural network (CNN) and some recent transformer based approaches which provide top performance on existing benchmarks. In this work, we perform a large-scale robustness analysis of these existing models for video action recognition. We focus on robustness against real- world distribution shift perturbations instead of adversarial perturbations. We propose four different benchmark datasets, HMDB51-P, UCF101-P, Kinetics400-P, and SSv2-P to perform this analysis. We study robustness of six state-of-the-art action recognition models against 90 different perturbations. The study reveals some interesting findings, 1) transformer based models are consistently more robust compared to CNN based models, 2) Pretraining improves robustness for Transformer based models more than CNN based models, and 3) All of the studied models are robust to temporal perturbations for all datasets but SSv2; suggesting the importance of temporal information for action recognition varies based on the dataset and activities. Next, we study the role of augmentations in model robustness and present a real-world dataset, UCF101-DS, which contains realistic distribution shifts, to further validate some of these findings. We believe this study will serve as a benchmark for future research in robust video action recognition",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.00576",
        "title": "MammalNet: A Large-scale Video Benchmark\nfor Mammal Recognition and Behavior Understanding",
        "abstract": "Monitoring animal behavior can facilitate conservation efforts by providing key insights into wildlife health, popula- tion status, and ecosystem function. Automatic recognition of animals and their behaviors is critical for capitalizing on the large unlabeled datasets generated by modern video devices and for accelerating monitoring efforts at scale. However, the development of automated recognition systems is cur- rently hindered by a lack of appropriately labeled datasets. Existing video datasets 1) do not classify animals according to established biological taxonomies; 2) are too small to fa- cilitate large-scale behavioral studies and are often limited to a single species; and 3) do not feature temporally localized annotations and therefore do not facilitate localization of targeted behaviors within longer video sequences. Thus, we propose MammalNet, a new large-scale animal behav- ior dataset with taxonomy-guided annotations of mammals and their common behaviors. MammalNet contains over 18K videos totaling 539 hours, which is \u223c10 times larger than the largest existing animal behavior dataset [36]. It covers 17 orders, 69 families, and 173 mammal categories for animal categorization and captures 12 high-level animal behaviors that received focus in previous animal behavior studies. We establish three benchmarks on MammalNet: standard animal and behavior recognition, compositional low-shot animal and behavior recognition, and behavior detection. Our dataset and code have been made available at: https://mammal-net.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.14152",
        "title": "Fantastic Breaks: A Dataset of Paired 3D Scans of Real-World Broken Objects and Their Complete Counterparts",
        "abstract": "Automated shape repair approaches currently lack ac- cess to datasets that describe real-world damaged geome- try. We present Fantastic Breaks (and Where to Find Them: https://terascale-all-sensing-research- studio.github.io/FantasticBreaks), a dataset containing scanned, waterproofed, and cleaned 3D meshes for 150 broken objects, paired and geometrically aligned with complete counterparts. Fantastic Breaks contains class and material labels, proxy repair parts that join to broken meshes to generate complete meshes, and manually anno- tated fracture boundaries. Through a detailed analysis of fracture geometry, we reveal differences between Fantastic Breaks and synthetic fracture datasets generated using ge- ometric and physics-based methods. We show experimental shape repair evaluation with Fantastic Breaks using mul- tiple learning-based approaches pre-trained with synthetic datasets and re-trained with subset of Fantastic Breaks",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.05947",
        "title": "Visual Localization using Imperfect 3D Models from the Internet",
        "abstract": "Visual localization is a core component in many applica- tions, including augmented reality (AR). Localization algo- rithms compute the camera pose of a query image w.r.t. a scene representation, which is typically built from images. This often requires capturing and storing large amounts of data, followed by running Structure-from-Motion (SfM) algorithms. An in- teresting, and underexplored, source of data for building scene representations are 3D models that are readily available on the Internet, e.g., hand-drawn CAD models, 3D models generated from building footprints, or from aerial images. These mod- els allow to perform visual localization right away without the time-consuming scene capturing and model building steps. Yet, it also comes with challenges as the available 3D models are of- ten imperfect reflections of reality. E.g., the models might only have generic or no textures at all, might only provide a simple approximation of the scene geometry, or might be stretched. This paper studies how the imperfections of these models af- fect localization accuracy. We create a new benchmark for this task and provide a detailed experimental evaluation based on multiple 3D models per scene. We show that 3D models from the Internet show promise as an easy-to-obtain scene represen- tation. At the same time, there is significant room for improve- ment for visual localization pipelines. To foster research on this interesting and challenging task, we release our benchmark at v-pnk.github.io/cadloc.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2303.13174",
        "title": "3D-POP - An automated annotation approach to facilitate markerless 2D-3D tracking of freely moving birds with marker-based motion capture",
        "abstract": "Recent advances in machine learning and computer vi- sion are revolutionizing the field of animal behavior by en- abling researchers to track the poses and locations of freely moving animals without any marker attachment. However, large datasets of annotated images of animals for marker- less pose tracking, especially high-resolution images taken from multiple angles with accurate 3D annotations, are still scant. Here, we propose a method that uses a motion cap- ture (mo-cap) system to obtain a large amount of annotated data on animal movement and posture (2D and 3D) in a semi-automatic manner. Our method is novel in that it ex- tracts the 3D positions of morphological keypoints (e.g eyes, beak, tail) in reference to the positions of markers attached to the animals. Using this method, we obtained, and offer here, a new dataset - 3D-POP with approximately 300k an- notated frames (4 million instances) in the form of videos having groups of one to ten freely moving birds from 4 dif- ferent camera views in a 3.6m x 4.2m area. 3D-POP is the first dataset of flocking birds with accurate keypoint annota- tions in 2D and 3D along with bounding box and individual identities and will facilitate the development of solutions for problems of 2D to 3D markerless pose, trajectory tracking, and identification in birds.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2203.06111",
        "title": "Multi-sensor large-scale dataset for multi-view 3D reconstruction",
        "abstract": "We present a new multi-sensor dataset for multi-view 3D surface reconstruction. It includes registered RGB and depth data from sensors of different resolutions and modalities: smartphones, Intel RealSense, Microsoft Kinect, industrial cameras, and structured-light scanner. The scenes are se- lected to emphasize a diverse set of material properties challenging for existing algorithms. We provide around 1.4 million images of 107 different scenes acquired from 100 viewing directions under 14 lighting conditions. We expect our dataset will be useful for evaluation and training of 3D reconstruction algorithms and for related tasks. The dataset is available at skoltech3d.appliedai.tech.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.05772",
        "title": "An Image Quality Assessment Dataset for Portraits",
        "abstract": "Year after year, the demand for ever-better smartphone photos continues to grow, in particular in the domain of portrait photography. Manufacturers thus use perceptual quality criteria throughout the development of smartphone cameras. This costly procedure can be partially replaced by automated learning-based methods for image quality as- sessment (IQA). Due to its subjective nature, it is necessary to estimate and guarantee the consistency of the IQA pro- cess, a characteristic lacking in the mean opinion scores (MOS) widely used for crowdsourcing IQA. In addition, existing blind IQA (BIQA) datasets pay little attention to the difficulty of cross-content assessment, which may de- grade the quality of annotations. This paper introduces PIQ23, a portrait-specific IQA dataset of 5116 images of 50 predefined scenarios acquired by 100 smartphones, cov- ering a high variety of brands, models, and use cases. The dataset includes individuals of various genders and ethnic- ities who have given explicit and informed consent for their photographs to be used in public research. It is annotated by pairwise comparisons (PWC) collected from over 30 im- age quality experts for three image attributes: face detail preservation, face target exposure, and overall image qual- ity. An in-depth statistical analysis of these annotations allows us to evaluate their consistency over PIQ23. Fi- nally, we show through an extensive comparison with ex- isting baselines that semantic information (image context) can be used to improve IQA predictions. The dataset along with the proposed statistical analysis and BIQA algorithms are available: https : / / github . com / DXOMARK - Research/PIQ2023",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.08401",
        "title": "LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically Constructed from Live Streaming",
        "abstract": "Open-domain dialogue systems have made promising progress in recent years. While the state-of-the-art dialogue agents are built upon large-scale text-based social media data and large pre-trained models, there is no guaran- tee these agents could also perform well in fast-growing scenarios, such as live stream- ing, due to the bounded transferability of pre- trained models and biased distributions of pub- lic datasets from Reddit and Weibo, etc. To improve the essential capability of responding and establish a benchmark in the live open- domain scenario, we introduce the LiveChat dataset, composed of 1.33 million real-life Chi- nese dialogues with almost 3800 average ses- sions across 351 personas and fine-grained pro- files for each persona. LiveChat is automati- cally constructed by processing numerous live videos on the Internet and naturally falls within the scope of multi-party conversations, where the issues of Who says What to Whom should be considered. Therefore, we target two criti- cal tasks of response modeling and addressee recognition and propose retrieval-based base- lines grounded on advanced techniques. Ex- perimental results have validated the positive effects of leveraging persona profiles and larger average sessions per persona. In addition, we also benchmark the transferability of advanced generation-based models on LiveChat and pose some future directions for current challenges. ",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2403.07354",
        "title": "BID: Boundary-Interior Decoding\nfor Unsupervised Temporal Action Localization Pre-Training",
        "abstract": "Skeleton-based motion representations are robust for action localization and understanding for their invariance to perspective, lighting, and occlu- sion, compared with images. Yet, they are of- ten ambiguous and incomplete when taken out of context, even for human annotators. As in- fants discern gestures before associating them with words, actions can be conceptualized be- fore being grounded with labels. Therefore, we propose the first unsupervised pre-training frame- work, Boundary-Interior Decoding (BID), that partitions a skeleton-based motion sequence into discovered semantically meaningful pre-action segments. By fine-tuning our pre-training net- work with a small number of annotated data, we show results out-performing SOTA methods by a large margin.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2105.14550",
        "title": "Blind Quality Assessment for in-the-Wild Images\nvia Hierarchical Feature Fusion and Iterative Mixed\nDatabase Training",
        "abstract": "Image quality assessment (IQA) is very important for both end-users and service providers since a high-quality image can significantly improve the user\u2019s quality of experience (QoE) and also benefit lots of computer vision algorithms. Most existing blind image quality assessment (BIQA) models were developed for synthetically distorted images, however, they perform poorly on in-the-wild images, which are widely existed in various practical applications. In this paper, we propose a novel BIQA model for in-the-wild images by addressing two critical problems in this field: how to learn better quality-aware feature representation, and how to solve the problem of insufficient training samples in terms of their content and distortion diversity. Considering that perceptual visual quality is affected by both low-level visual features (e.g. distortions) and high-level semantic information (e.g. content), we first propose a staircase structure to hierarchically integrate the features from intermediate layers into the final feature representation, which enables the model to make full use of visual information from low-level to high- level. Then an iterative mixed database training (IMDT) strategy is proposed to train the BIQA model on multiple databases simultaneously, so the model can benefit from the increase in both training samples and image content and distortion diversity and can learn a more general feature representation. Experimental results show that the proposed model outperforms other state- of-the-art BIQA models on six in-the-wild IQA databases by a large margin. Moreover, the proposed model shows an excellent performance in the cross-database evaluation experiments, which further demonstrates that the learned feature representation is robust to images with diverse distortions and content. The code is available at https://github.com/sunwei925/StairIQA.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1910.06180",
        "title": "KonIQ-10k: An ecologically valid database for deep learning of blind image quality assessment",
        "abstract": "Deep learning methods for image quality assessment (IQA) are limited due to the small size of existing datasets. Extensive datasets require substantial resources both for generating publishable content and annotating it accurately. We present a systematic and scalable approach to creating KonIQ-10k, the largest IQA dataset to date, con- sisting of 10,073 quality scored images. It is the first in-the-wild database aiming for ecological validity, concerning the authenticity of distortions, the diversity of content, and quality-related indicators. Through the use of crowdsourcing, we obtained 1.2 million reliable quality ratings from 1,459 crowd workers, paving the way for more general IQA models. We propose a novel, deep learning model (KonCept512), to show an excel- lent generalization beyond the test set (0.921 SROCC), to the current state-of-the-art database LIVE-in-the-Wild (0.825 SROCC). The model derives its core performance from the InceptionResNet architecture, being trained at a higher resolution than previous models (512 \u00d7 384). Correlation analysis shows that KonCept512 performs similar to having 9 subjective scores for each test image.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2204.08040",
        "title": "NICO++: Towards Better Benchmarking for Domain Generalization",
        "abstract": "\nDespite the remarkable performance that modern deep neural networks have achieved on in- dependent and identically distributed (I.I.D.) data, they can crash under distribution shifts. Most current evaluation methods for domain generalization (DG) adopt the leave-one-out strategy as a compromise on the limited number of domains. We propose a large-scale benchmark with extensive labeled domains named NICO++\u2021 along with more rational evaluation methods for comprehensively evaluating DG algorithms. To evaluate DG datasets, we propose two metrics to quantify covariate shift and concept shift, respectively. Two novel generalization bounds from the perspective of data construction are proposed to prove that limited concept shift and significant covariate shift favor the evaluation capability for generalization. Through extensive experiments, NICO++ shows its superior evaluation capability compared with current DG datasets and its contribution in alleviating unfairness caused by the leak of oracle knowledge in model selection.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2306.09944",
        "title": "REALIMPACT: A Dataset of Impact Sound Fields for Real Objects",
        "abstract": "\nObjects make unique sounds under different perturba- tions, environment conditions, and poses relative to the listener. While prior works have modeled impact sounds and sound propagation in simulation, we lack a standard dataset of impact sound fields of real objects for audio- visual learning and calibration of the sim-to-real gap. We present REALIMPACT, a large-scale dataset of real object impact sounds recorded under controlled conditions. RE- ALIMPACT contains 150,000 recordings of impact sounds of 50 everyday objects with detailed annotations, includ- ing their impact locations, microphone locations, contact force profiles, material labels, and RGBD images.* We make preliminary attempts to use our dataset as a reference to current simulation methods for estimating object impact sounds that match the real world. Moreover, we demon- strate the usefulness of our dataset as a testbed for acoustic and audio-visual learning via the evaluation of two bench- mark tasks, including listener location classification and vi- sual acoustic matching.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03321",
        "title": "Planetarium\ud83e\ude90: A Rigorous Benchmark for Translating Text to Structured Planning Languages",
        "abstract": "Many recent works have explored using language models for planning problems. One line of research focuses on translating natural language descriptions of plan- ning tasks into structured planning languages, such as the planning domain defini- tion language (PDDL). While this approach is promising, accurately measuring the quality of generated PDDL code continues to pose significant challenges. First, generated PDDL code is typically evaluated using planning validators that check whether the problem can be solved with a planner. This method is insufficient because a language model might generate valid PDDL code that does not align with the natural language description of the task. Second, existing evaluation sets often have natural language descriptions of the planning task that closely resemble the ground truth PDDL, reducing the challenge of the task. To bridge this gap, we introduce Planetarium, a benchmark designed to evaluate language models\u2019 ability to generate PDDL code from natural language descriptions of planning tasks. We begin by creating a PDDL equivalence algorithm that rigorously evaluates the correctness of PDDL code generated by language models by flexibly comparing it against a ground truth PDDL. Then, we present a dataset of 132, 037 text-to-PDDL pairs across 13 different tasks, with varying levels of difficulty. Finally, we eval- uate several API-access and open-weight language models that reveal this task\u2019s complexity. For example, 87.6% of the PDDL problem descriptions generated by GPT-4o are syntactically parseable, 82.2% are valid, solve-able problems, but only 35.1% are semantically correct, highlighting the need for a more rigorous benchmark for this problem.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03236",
        "title": "CATT: Character-based Arabic Tashkeel Transformer",
        "abstract": "Tashkeel, or Arabic Text Diacritization (ATD), greatly enhances the comprehension of Ara- bic text by removing ambiguity and minimiz- ing the risk of misinterpretations caused by its absence. It plays a crucial role in improv- ing Arabic text processing, particularly in ap- plications such as text-to-speech and machine translation. This paper introduces a new ap- proach to training ATD models. First, we finetuned two transformers, encoder-only and encoder-decoder, that were initialized from a pretrained character-based BERT. Then, we applied the Noisy-Student approach to boost the performance of the best model. We evalu- ated our models alongside 11 commercial and open-source models using two manually la- beled benchmark datasets: WikiNews and our CATT dataset. Our findings show that our top model surpasses all evaluated models by rela- tive Diacritic Error Rates (DERs) of 30.83% and 35.21% on WikiNews and CATT, respec- tively, achieving state-of-the-art in ATD. In ad- dition, we show that our model outperforms GPT-4-turbo on CATT dataset by a relative DER of 9.36%. We open-source our CATT models and benchmark dataset for the research community",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03239",
        "title": "Solving the inverse problem of microscopy deconvolution with a residual Beylkin-Coifman-Rokhlin neural network",
        "abstract": "Optic deconvolution in light microscopy (LM) refers to re- covering the object details from images, revealing the ground truth of samples. Traditional explicit methods in LM rely on the point spread function (PSF) during image acquisition. Yet, these approaches often fall short due to inaccurate PSF models and noise artifacts, hampering the overall restoration quality. In this paper, we approached the optic decon- volution as an inverse problem. Motivated by the nonstandard-form com- pression scheme introduced by Beylkin, Coifman, and Rokhlin (BCR), we proposed an innovative physics-informed neural network Multi-Stage Residual-BCR Net (m-rBCR) to approximate the optic deconvolution. We validated the m-rBCR model on four microscopy datasets - two sim- ulated microscopy datasets from ImageNet and BioSR, real dSTORM microscopy images, and real widefield microscopy images. In contrast to the explicit deconvolution methods (e.g. Richardson-Lucy) and other state-of-the-art NN models (U-Net, DDPM, CARE, DnCNN, ESRGAN, RCAN, Noise2Noise, MPRNet, and MIMO-U-Net), the m-rBCR model demonstrates superior performance to other candidates by PSNR and SSIM in two real microscopy datasets and the simulated BioSR dataset. In the simulated ImageNet dataset, m-rBCR ranks the second-best place (right after MIMO-U-Net). With the backbone from the optical physics, m-rBCR exploits the trainable parameters with better performances (from \u223c30 times fewer than the benchmark MIMO-U-Net to \u223c210 times than ESRGAN). This enables m-rBCR to achieve a shorter runtime (from \u223c3 times faster than MIMO-U-Net to \u223c300 times faster than DDPM). To summarize, by leveraging physics constraints our model re- duced potentially redundant parameters significantly in expertise-oriented NN candidates and achieved high efficiency with superior performance.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2403.13317v1",
        "title": "Flickr30K-CFQ: A Compact and Fragmented Query Dataset for Text-image Retrieval",
        "abstract": "Withtheexplosivegrowthofmulti-modalinformationonthe Internet, unimodal search cannot satisfy the requirement of Internet ap- plications. Text-image retrieval research is needed to realize high-quality and efficient retrieval between different modalities. Existing text-image retrieval research is mostly based on general vision-language datasets (e.g. MS-COCO, Flickr30K), in which the query utterance is rigid and unnatural (i.e. verbosity and formality). To overcome the shortcoming, we construct a new Compact and Fragmented Query challenge dataset (named Flickr30K-CFQ) to model text-image retrieval task consid- ering multiple query content and style, including compact and fine- grained entity-relation corpus. We propose a novel LLM-based Query- enhanced method using prompt engineering based on LLM. Experiments show that our proposed Flickr30-CFQ reveals the insufficiency of ex- isting vision-language datasets in realistic text-image tasks. Our LLM- based Query-enhanced method applied on different existing text-image retrieval models improves query understanding performance both on public dataset and our challenge set Flickr30-CFQ with over 0.9% and 2.4% respectively. Our project can be available anonymously in https: //sites.google.com/view/Flickr30K-cfq.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1505.04870",
        "title": "Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models",
        "abstract": "The Flickr30k dataset has become a standard benchmark for sentence-based image description. This pa- per presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains, link- ing mentions of the same entities across different captions for the same image, and associating them with 276k man- ually annotated bounding boxes. Such annotations are es- sential for continued progress in automatic image descrip- tion and grounded language understanding. They enable us to define a new benchmark for localization of textual entity mentions in an image. We present a strong baseline for this task that combines an image-text embedding, detectors for common objects, a color classifier, and a bias towards se- lecting larger objects. While our baseline rivals in accuracy more complex state-of-the-art models, we show that its gains cannot be easily parlayed into improvements on such tasks as image-sentence retrieval, thus underlining the limitations of current methods and the need for further research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2104.08541",
        "title": "TransVG: End-to-End Visual Grounding with Transformers",
        "abstract": "In this paper, we present a neat yet effective transformer- based framework for visual grounding, namely TransVG, to address the task of grounding a language query to the corresponding region onto an image. The state-of-the-art methods, including two-stage or one-stage ones, rely on a complex module with manually-designed mechanisms to perform the query reasoning and multi-modal fusion. How- ever, the involvement of certain mechanisms in fusion mod- ule design, such as query decomposition and image scene graph, makes the models easily overfit to datasets with spe- cific scenarios, and limits the plenitudinous interaction be- tween the visual-linguistic context. To avoid this caveat, we propose to establish the multi-modal correspondence by leveraging transformers, and empirically show that the complex fusion modules (e.g., modular attention network, dynamic graph, and multi-modal tree) can be replaced by a simple stack of transformer encoder layers with higher per- formance. Moreover, we re-formulate the visual grounding as a direct coordinates regression problem and avoid mak- ing predictions out of a set of candidates (i.e., region pro- posals or anchor boxes). Extensive experiments are con- ducted on five widely used datasets, and a series of state- of-the-art records are set by our TransVG. We build the benchmark of transformer-based visual grounding frame- work and make the code available at https://github. com/djiajunustc/TransVG.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2304.13216",
        "title": "Exploiting CNNs for Semantic Segmentation with Pascal VOC",
        "abstract": "In this paper, we present a comprehensive study on semantic segmentation with the Pascal VOC dataset. Here, we have to label each pixel with a class which in turn segments the entire image based on the objects/entities present. To tackle this, we firstly use a Fully Convolution Network (FCN) baseline which gave 71.31% pixel accuracy and 0.0527 mean IoU. We analyze its performance and working and subsequently address the issues in the baseline with three improvements - a) cosine annealing learning rate scheduler(pixel accuracy: 72.86%, IoU: 0.0529), b) data augmentation(pixel accuracy: 69.88%, IoU: 0.0585) c) class imbalance weights(pixel accuracy: 68.98%, IoU: 0.0596). Apart from these changes in train- ing pipeline, we also explore three different architectures - a) Our proposed model - Advanced FCN (pixel accuracy: 67.20%, IoU: 0.0602) b) Transfer Learning with ResNet (Best performance) (pixel accuracy: 71.33%, IoU: 0.0926 ) c) U- Net(pixel accuracy: 72.15%, IoU: 0.0649). We observe that the improvements help in greatly improving the performance, as reflected both, in metrics and seg- mentation maps. Interestingly, we observe that among the improvements, dataset augmentation has the greatest contribution. Also, note that transfer learning model performs the best on the pascal dataset. We analyse the performance of these using loss, accuracy and IoU plots along with segmentation maps, which help us draw valuable insights about the working of the models.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2009.05686",
        "title": "LQR-augmented neural networks",
        "abstract": " In this paper we propose a new computa- tional method for designing optimal regulators for high- dimensional nonlinear systems. The proposed approach leverages physics-informed machine learning to solve high-dimensional Hamilton-Jacobi-Bellman equations aris- ing in optimal feedback control. Concretely, we augment linear quadratic regulators with neural networks to handle nonlinearities. We train the augmented models on data generated without discretizing the state space, enabling application to high-dimensional problems. We use the pro- posed method to design a candidate optimal regulator for an unstable Burgers\u2019 equation, and through this example, demonstrate improved robustness and accuracy compared to existing neural network formulations.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03247",
        "title": "Bridging Model Heterogeneity in Federated Learning via Uncertainty-based Asymmetrical Reciprocity Learning",
        "abstract": "This paper presents FedType, a simple yet pio- neering framework designed to fill research gaps in heterogeneous model aggregation within feder- ated learning (FL). FedType introduces small identical proxy models for clients, serving as agents for information exchange, ensuring model security, and achieving efficient communication simultaneously. To transfer knowledge between large private and small proxy models on clients, we propose a novel uncertainty-based asymmetri- cal reciprocity learning method, eliminating the need for any public data. Comprehensive experi- ments conducted on benchmark datasets demon- strate the efficacy and generalization ability of FedType across diverse settings. Our approach redefines federated learning paradigms by bridg- ing model heterogeneity, eliminating reliance on public data, prioritizing client privacy, and reduc- ing communication costs.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.04414",
        "title": "CIFAR-10-WAREHOUSE: BROAD AND MORE REALIS- TIC TESTBEDS IN MODEL GENERALIZATION ANALYSIS",
        "abstract": "Analyzing model performance in various unseen environments is a critical research problem in the machine learning community. To study this problem, it is important to construct a testbed with out-of-distribution test sets that have broad coverage of environmental discrepancies. However, existing testbeds typically either have a small number of domains or are synthesized by image corruptions, hindering algo- rithm design that demonstrates real-world effectiveness. In this paper, we introduce CIFAR-10-Warehouse, consisting of 180 datasets collected by prompting image search engines and diffusion models in various ways. Generally sized between 300 and 8,000 images, the datasets contain natural images, cartoons, certain colors, or objects that do not naturally appear. With CIFAR-10-W, we aim to enhance the evaluation and deepen the understanding of two generalization tasks: domain gener- alization and model accuracy prediction in various out-of-distribution environments. We conduct extensive benchmarking and comparison experiments and show that CIFAR-10-W offers new and interesting insights inherent to these tasks. We also discuss other fields that would benefit from CIFAR-10-W. Data and code are avail- able at https://sites.google.com/view/CIFAR-10-warehouse/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.03251",
        "title": "ACTRESS: Active Retraining for Semi-supervised Visual Grounding",
        "abstract": "Semi-Supervised Visual Grounding (SSVG) is a new chal- lenge for its sparse labeled data with the need for multimodel under- standing. A previous study, RefTeacher [30], makes the first attempt to tackle this task by adopting the teacher-student framework to provide pseudo confidence supervision and attention-based supervision. However, this approach is incompatible with current state-of-the-art visual ground- ing models, which follow the Transformer-based pipeline. These pipelines directly regress results without region proposals or foreground binary classification, rendering them unsuitable for fitting in RefTeacher due to the absence of confidence scores. Furthermore, the geometric difference in teacher and student inputs, stemming from different data augmentations, induces natural misalignment in attention-based constraints. To estab- lish a compatible SSVG framework, our paper proposes the ACTive REtraining approach for Semi-Supervised Visual Grounding, abbrevi- ated as ACTRESS. Initially, the model is enhanced by incorporating an additional quantized detection head to expose its detection confi- dence. Building upon this, ACTRESS consists of an active sampling strategy and a selective retraining strategy. The active sampling strategy iteratively selects high-quality pseudo labels by evaluating three crucial aspects: Faithfulness, Robustness, and Confidence, optimizing the uti- lization of unlabeled data. The selective retraining strategy retrains the model with periodic re-initialization of specific parameters, facilitating the model\u2019s escape from local minima. Extensive experiments demon- strates our superior performance on widely-used benchmark datasets.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1503.04424",
        "title": "Bridging Social Media via Distant Supervision",
        "abstract": "Microblog classification has received a lot of attention in recent years. Different classification tasks have been investigated, most of them fo- cusing on classifying microblogs into a small number of classes (five or less) using a training set of manually annotated tweets. Unfortunately, labelling data is tedious and expensive, and finding tweets that cover all the classes of interest is not always straightforward, especially when some of the classes do not frequently arise in practice. In this paper we study an approach to tweet classification based on distant supervision, whereby we automatically transfer labels from one social medium to another for a single-label multi-class classi- fication task. In particular, we apply YouTube video classes to tweets linking to these videos. This provides for free a virtually unlimited number of labelled instances that can be used as training data. The classification experiments we have run show that training a tweet classifier via these automatically labelled data achieves substantially better performance than training the same clas- sifier with a limited amount of manually labelled data; this is advantageous, given that the automatically labelled data come at no cost. Further investiga- tion of our approach shows its robustness when applied with different numbers of classes and across different languages",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1908.01456",
        "title": "A Deep Learning Approach for Tweet Classification and Rescue Scheduling for Effective Disaster Management (Industrial)",
        "abstract": "\nEvery activity in disaster management such as managing evacu- ation plan, and running rescue missions demands accurate and up-to-date information to allow a quick, easy, and cost-effective response to reduce the possible loss of lives and properties. It is a challenging and complex task to acquire information from different regions of a disaster-affected area in a timely fashion. The exten- sive spread and reach of social media and networks allow people to share information in real-time. However, the processing of social media data and gathering of valuable information require a series of operations such as (1) processing each specific tweet for a text classi- fication, (2) possible location determination of people needing help based on tweets, and (3) priority calculations of rescue tasks based on the classification of tweets. These are three primary challenges in developing an effective rescue scheduling operation using social media data. In this paper, first, we propose a deep learning model combining attention based Bi-directional Long Short-Term Mem- ory (BLSTM) and Convolutional Neural Network (CNN) to classify the tweets under different categories. We use pre-trained crisis word vectors and global vectors for word representation (GLoVe) for capturing semantic meaning from tweets. Next, we perform feature engineering to create an auxiliary feature map which dra- matically increases the model accuracy. In our experiments using real data sets from Hurricanes Harvey and Irma, it is observed that our proposed approach performs better compared to other classifi- cation methods based on Precision, Recall, F1-score, and Accuracy, and is highly effective to determine the correct priority of a tweet. Furthermore, to evaluate the effectiveness and robustness of the proposed classification model a merged dataset comprises of 4 dif- ferent datasets from CrisisNLP and another 15 different disasters data from CrisisLex are used. Finally, we develop an adaptive multi- task hybrid scheduling algorithm considering resource constraints to perform an effective rescue scheduling operation considering different rescue priorities.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.12793",
        "title": "ShareGPT4V: Improving Large Multi-Modal Models with Better Captions",
        "abstract": "In the realm of large multi-modal models (LMMs), efficient modality alignment is crucial yet often constrained by the scarcity of high-quality image-text data. To address this bottleneck, we introduce the ShareGPT4V dataset, a pio- neering large-scale resource featuring 1.2 million highly descriptive captions, which surpasses existing datasets in diversity and information content, covering world knowl- edge, object properties, spatial relationships, and aesthetic evaluations. Specifically, ShareGPT4V originates from a curated 100K high-quality captions collected from ad- vanced GPT4-Vision and has been expanded to 1.2M with a superb caption model trained on this subset. ShareGPT4V\nfirst demonstrates its effectiveness for the Supervised Fine-Tuning (SFT) phase, by substituting an equivalent quantity of detailed captions in existing SFT datasets with a subset of our high-quality captions, significantly enhancing the LMMs like LLaVA-7B, LLaVA-1.5-13B, and Qwen- VL-Chat-7B on the MME and MMBench benchmarks, with respective gains of 222.8/22.0/22.3 and 2.7/1.3/1.5. We further incorporate ShareGPT4V data into both the pre-training and SFT phases, obtaining ShareGPT4V-7B, a superior LMM based on a simple architecture that has remarkable performance across a majority of the multi-modal benchmarks. This project is available at https : / / ShareGPT4V . github . io to serve as a pivotal resource for advancing the LMMs community.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1812.08658",
        "title": "nocaps: novel object captioning at scale",
        "abstract": "Image captioning models have achieved impressive results on datasets containing limited visual concepts and large amounts of paired image-caption training data. However, if these models are to ever function in the wild, a much larger variety of visual concepts must be learned, ideally from less supervision. To encourage the development of im- age captioning models that can learn visual concepts from alternative data sources, such as object detection datasets, we present the first large-scale benchmark for this task. Dubbed \u2018nocaps\u2019, for novel object captioning at scale, our benchmark consists of 166,100 human-generated captions describing 15,100 images from the Open Images valida- tion and test sets. The associated training data consists of COCO image-caption pairs, plus Open Images image- level labels and object bounding boxes. Since Open Images contains many more classes than COCO, nearly 400 object classes seen in test images have no or very few associated training captions (hence, nocaps). We extend existing novel object captioning models to establish strong baselines for this benchmark and provide analysis to guide future work.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1612.00837",
        "title": "Making the V in VQA Matter:\nElevating the Role of Image Understanding in Visual Question Answering",
        "abstract": "\nProblems at the intersection of vision and language are of significant importance both as challenging research questions and for the rich set of applications they enable. However, inherent structure in our world and bias in our language tend to be a simpler signal for learning than vi- sual modalities, resulting in models that ignore visual infor- mation, leading to an inflated sense of their capability.\nWe propose to counter these language priors for the task of Visual Question Answering (VQA) and make vision (the V in VQA) matter! Specifically, we balance the popular VQA dataset [3] by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question. Our dataset is by construction more balanced than the origi- nal VQA dataset and has approximately twice the number of image-question pairs. Our complete balanced dataset is publicly available at http://visualqa.org/ as part of the 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA v2.0).\nWe further benchmark a number of state-of-art VQA models on our balanced dataset. All models perform sig- nificantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language pri- ors. This finding provides the first concrete empirical evi- dence for what seems to be a qualitative sense among prac- titioners.\nFinally, our data collection protocol for identifying com- plementary images enables us to develop a novel inter- pretable model, which in addition to providing an answer to the given (image, question) pair, also provides a counter- example based explanation. Specifically, it identifies an im- age that is similar to the original image, but it believes has a different answer to the same question. This can help in building trust for machines among their users.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2305.13245",
        "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
        "abstract": "Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference. We (1) propose a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5% of original pre-training compute, and (2) intro- duce grouped-query attention (GQA), a gener- alization of multi-query attention which uses an intermediate (more than one, less than num- ber of query heads) number of key-value heads. We show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1906.00067",
        "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge",
        "abstract": "Visual Question Answering (VQA) in its ideal form lets us study reasoning in the joint space of vision and lan- guage and serves as a proxy for the AI task of scene understanding. However, most VQA benchmarks to date are focused on questions such as simple counting, visual attributes, and object detection that do not require rea- soning or knowledge beyond what is in the image. In this paper, we address the task of knowledge-based visual question answering and provide a benchmark, called OK- VQA, where the image content is not sufficient to answer the questions, encouraging methods that rely on external knowledge resources. Our new dataset includes more than 14,000 questions that require external knowledge to an- swer. We show that the performance of the state-of-the-art VQA models degrades drastically in this new setting. Our analysis shows that our knowledge-based VQA task is di- verse, difficult, and large compared to previous knowledge- based VQA datasets. We hope that this dataset enables re- searchers to open up new avenues for research in this do- main. See http://okvqa.allenai.org to download and browse the dataset.\n",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2206.01718",
        "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge",
        "abstract": "The Visual Question Answering (VQA) task aspires to provide a meaningful testbed for the development of AI models that can jointly reason over visual and natural language inputs. Despite a proliferation of VQA datasets, this goal is hindered by a set of common limitations. These include a reliance on relatively simplistic questions that are repetitive in both concepts and linguistic structure, little world knowledge needed outside of the paired image, and limited reasoning required to arrive at the correct answer. We introduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about 25K questions requiring a broad base of commonsense and world knowledge to answer. In contrast to the existing knowledge-based VQA datasets, the questions generally cannot be answered by simply querying a knowledge base, and instead require some form of commonsense reasoning about the scene depicted in the image. We demonstrate the potential of this new dataset through a detailed analysis of its contents and baseline performance measurements over a variety of state-of-the-art vision\u2013language models.\n                   http://a-okvqa.allenai.org/",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2402.11684",
        "title": "ALLaVA: Harnessing GPT4V-Synthesized Data for Lite Vision-Language Models",
        "abstract": "Large vision-language models (LVLMs) have shown premise in a broad range of vision-language tasks with their strong reasoning and generalization capabilities. However, they require considerable computational resources for training and de- ployment. This study aims to bridge the performance gap between traditional-scale LVLMs and resource-friendly lite versions by adopting high-quality training data. To this end, we propose a comprehensive pipeline for generating a synthetic dataset. The key idea is to leverage strong proprietary models to generate (i) fine-grained image annotations for vision-language alignment and (ii) complex reasoning vi- sual question-answering pairs for visual instruction fine-tuning, yielding 1.3M samples in total. We train a series of lite VLMs on the synthetic dataset and ex- perimental results demonstrate the effectiveness of the proposed scheme, where they achieve competitive performance on 17 benchmarks among 4B LVLMs, and even perform on par with 7B/13B-scale models on various benchmarks. This work highlights the feasibility of adopting high-quality data in crafting more efficient LVLMs. We name our dataset ALLaVA, and open-source it to research community for developing better resource-efficient LVLMs for wider usage.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2006.01038",
        "title": "DocBank: A Benchmark Dataset for Document Layout Analysis",
        "abstract": "Document layout analysis usually relies on computer vision models to understand documents while ignoring textual information that is vital to capture. Meanwhile, high quality labeled datasets with both visual and textual information are still insufficient. In this paper, we present DocBank, a benchmark dataset that contains 500K document pages with fine-grained token- level annotations for document layout analysis. DocBank is constructed using a simple yet effective way with weak supervision from the LATEX documents available on the arXiv.com. With DocBank, models from different modalities can be compared fairly and multi-modal ap- proaches will be further investigated and boost the performance of document layout analysis. We build several strong baselines and manually split train/dev/test sets for evaluation. Ex- periment results show that models trained on DocBank accurately recognize the layout infor- mation for a variety of documents. The DocBank dataset is publicly available at https: //github.com/doc-analysis/DocBank.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1908.07836",
        "title": "PubLayNet: largest dataset ever for document layout analysis",
        "abstract": "Recognizing the layout of unstructured digital documents is an important step when parsing the documents into structured machine-readable format for downstream applications. Deep neural networks that are developed for computer vision have been proven to be an effective method to analyze layout of document images. However, document layout datasets that are currently publicly available are several magnitudes smaller than established computing vision datasets. Models have to be trained by transfer learning from a base model that is pre-trained on a traditional computer vision dataset. In this paper, we develop the PubLayNet dataset for document layout analysis by automatically matching the XML representations and the content of over 1 million PDF articles that are publicly available on PubMed CentralTM. The size of the dataset is comparable to established computer vision datasets, containing over 360 thousand document images, where typical document layout elements are annotated. The experiments demonstrate that deep neural networks trained on PubLayNet accurately recognize the layout of scientific articles. The pre-trained models are also a more effective base mode for transfer learning on a different document domain. We release the dataset (https://github.com/ibm-aur-nlp/PubLayNet) to support development and evaluation of more advanced models for document layout analysis.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1912.03879",
        "title": "AI2D-RST: A multimodal corpus of 1000 primary school science diagrams",
        "abstract": "This article introduces AI2D-RST, a multimodal corpus of 1000 English-language diagrams that represent topics in primary school natural sciences, such as food webs, life cycles, moon phases and human physiology. The corpus is based on the Allen Institute for Artificial Intelli- gence Diagrams (AI2D) dataset, a collection of diagrams with crowd-sourced descriptions, which was originally developed to support research on automatic diagram understanding and visual question answering. Building on the segmentation of diagram layouts in AI2D, the AI2D-RST corpus presents a new multi-layer annotation schema that provides a rich description of their multimodal structure. Annotated by trained experts, the layers describe (1) the grouping of diagram elements into perceptual units, (2) the connections set up by diagrammatic elements such as arrows and lines, and (3) the discourse relations between diagram elements, which are described using Rhetorical Structure Theory (RST). Each annotation layer in AI2D-RST is represented using a graph. The corpus is freely available for research and teaching.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.11833v1",
        "title": "MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs",
        "abstract": "Generating natural and meaningful responses to communicate with multi-modal hu- man inputs is a fundamental capability of Large Vision-Language Models (LVLMs). While current open-source LVLMs demonstrate promising performance in simpli- fied scenarios such as single-turn single-image input, they fall short in real-world conversation scenarios such as following instructions in a long context history with multi-turn and multi-images. Existing LVLM benchmarks primarily focus on single-choice questions or short-form responses, which do not adequately as- sess the capabilities of LVLMs in real-world human-AI interaction applications. Therefore, we introduce MMDU, a comprehensive benchmark, and MMDU-45k, a large-scale instruction tuning dataset, designed to evaluate and improve LVLMs\u2019 abilities in multi-turn and multi-image conversations. We employ the clustering algorithm to find the relevant images and textual descriptions from the open-source Wikipedia and construct the question-answer pairs by human annotators with the assistance of the GPT-4o model. MMDU has a maximum of 18k image+text tokens, 20 images, and 27 turns, which is at least 5\u00d7 longer than previous benchmarks and poses challenges to current LVLMs. Our in-depth analysis of 15 representative LVLMs using MMDU reveals that open-source LVLMs lag behind closed-source counterparts due to limited conversational instruction tuning data. We demonstrate that fine-tuning open-source LVLMs on MMDU-45k significantly address this gap, generating longer and more accurate conversations, and improving scores on MMDU and existing benchmarks (MMStar: +1.1%, MathVista: +1.5%, ChartQA:\n+1.2%). Our contributions pave the way for bridging the gap between current LVLM models and real-world application demands. This project is available at https://github.com/Liuziyu77/MMDU.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2110.13214",
        "title": "IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning",
        "abstract": "Current visual question answering (VQA) tasks mainly consider answering human- annotated questions for natural images. However, aside from natural images, abstract diagrams with semantic richness are still understudied in visual under- standing and reasoning research. In this work, we introduce a new challenge of Icon Question Answering (IconQA) with the goal of answering a question in an icon image context. We release IconQA, a large-scale dataset that consists of 107,439 questions and three sub-tasks: multi-image-choice, multi-text-choice, and filling-in- the-blank. The IconQA dataset is inspired by real-world diagram word problems that highlight the importance of abstract diagram understanding and comprehensive cognitive reasoning. Thus, IconQA requires not only perception skills like object recognition and text understanding, but also diverse cognitive reasoning skills, such as geometric reasoning, commonsense reasoning, and arithmetic reasoning. To facilitate potential IconQA models to learn semantic representations for icon images, we further release an icon dataset Icon645 which contains 645,687 colored icons on 377 classes. We conduct extensive user studies and blind experiments and reproduce a wide range of advanced VQA methods to benchmark the IconQA task. Also, we develop a strong IconQA baseline Patch-TRM that applies a pyramid cross-modal Transformer with input diagram embeddings pre-trained on the icon dataset. IconQA and Icon645 are available at https://iconqa.github.io.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2404.18585",
        "title": "FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering",
        "abstract": "Table Question Answering (TQA) aims at com- posing an answer to a question based on tabu- lar data. While prior research has shown that TQA models lack robustness, understanding the underlying cause and nature of this issue remains predominantly unclear, posing a sig- nificant obstacle to the development of robust TQA systems. In this paper, we formalize three major desiderata for a fine-grained evaluation of robustness of TQA systems. They should (i) answer questions regardless of alterations in table structure, (ii) base their responses on the content of relevant cells rather than on biases, and (iii) demonstrate robust numerical reason- ing capabilities. To investigate these aspects, we create and publish a novel TQA evaluation benchmark in English. Our extensive experi- mental analysis reveals that none of the exam- ined state-of-the-art TQA systems consistently excelsinthesethreeaspects. Ourbenchmark is a crucial instrument for monitoring the be- havior of TQA systems and paves the way for the development of robust TQA systems. We release our benchmark publicly.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1811.00232",
        "title": "Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension",
        "abstract": "In this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with anal- ysis of the TQA dataset. First, solving the TQA problems requires to comprehend multi- modal contexts in complicated input data. To tackle this issue of extracting knowledge fea- tures from long text lessons and merging them with visual features, we establish a context graph from texts and images, and propose a new module f-GCN based on graph con- volutional networks (GCN). Second, scien- tific terms are not spread over the chapters and subjects are split in the TQA dataset. To overcome this so called \u2018out-of-domain\u2019 is- sue, before learning QA problems, we intro- duce a novel self-supervised open-set learn- ing process without any annotations. The ex- perimental results show that our model signifi- cantly outperforms prior state-of-the-art meth- ods. Moreover, ablation studies validate that both methods of incorporating f-GCN for ex- tracting knowledge from multi-modal contexts and our newly proposed self-supervised learn- ing process are effective for TQA problems.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1801.08163",
        "title": "DVQA: Understanding Data Visualizations via Question Answering",
        "abstract": "Bar charts are an effective way to convey numeric in- formation, but today\u2019s algorithms cannot parse them. Ex- isting methods fail when faced with even minor variations in appearance. Here, we present DVQA, a dataset that tests many aspects of bar chart understanding in a ques- tion answering framework. Unlike visual question answer- ing (VQA), DVQA requires processing words and answers that are unique to a particular bar chart. State-of-the-art VQA algorithms perform poorly on DVQA, and we pro- pose two strong baselines that perform considerably better. Our work will enable algorithms to automatically extract numeric and semantic information from vast quantities of bar charts found in scientific publications, Internet articles, business reports, and many other areas.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2403.00816",
        "title": "CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering",
        "abstract": "Document Visual Question Answering (DVQA) is a task that involves responding to queries based on the content of images. Existing work is limited to locating information within a single page and does not facilitate cross-page question-and-answer interaction. Furthermore, the token length limitation imposed on inputs to the model may lead to truncation of segments pertinent to the answer. In this study, we introduce a simple but effective methodology called CFRet-DVQA, which focuses on retrieval and efficient tuning to address this critical issue effectively. For that, we initially retrieve multiple segments from the document that correlate with the question at hand. Subsequently, we leverage the advanced reasoning abilities of the large language model (LLM), further augmenting its performance through instruction tuning. This approach enables the generation of answers that align with the style of the document labels. The experiments demonstrate that our methodology achieved state-of-the-art or competitive results with both single-page and multi-page documents in various fields.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2203.10244",
        "title": "ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning",
        "abstract": "Charts are very popular for analyzing data. When exploring charts, people often ask a variety of complex reasoning questions that involve several logical and arithmetic opera- tions. They also commonly refer to visual fea- tures of a chart in their questions. However, most existing datasets do not focus on such complex reasoning questions as their ques- tions are template-based and answers come from a fixed-vocabulary. In this work, we present a large-scale benchmark covering 9.6K human-written questions as well as 23.1K questions generated from human-written chart summaries. To address the unique challenges in our benchmark involving visual and log- ical reasoning over charts, we present two transformer-based models that combine visual features and the data table of the chart in a uni- fied way to answer questions. While our mod- els achieve the state-of-the-art results on the previous datasets as well as on our benchmark, the evaluation also reveals several challenges in answering complex reasoning questions.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1905.13319",
        "title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
        "abstract": "\nWe introduce a large-scale dataset of math word problems and an interpretable neural math problem solver that learns to map prob- lems to operation programs. Due to an- notation challenges, current datasets in this domain have been either relatively small in scale or did not offer precise operational an- notations over diverse problem types. We introduce a new representation language to model precise operation programs correspond- ing to each math problem that aim to im- prove both the performance and the inter- pretability of the learned models. Using this representation language, our new dataset, MathQA, significantly enhances the AQuA dataset with fully-specified operational pro- grams. We additionally introduce a neu- ral sequence-to-program model enhanced with automatic problem categorization. Our exper- iments show improvements over competitive baselines in our MathQA as well as the AQuA datasets. The results are still significantly lower than human performance indicating that the dataset poses new challenges for future re- search. Our dataset is available at: https: //math-qa.github.io/math-QA/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2105.04165",
        "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning",
        "abstract": "Geometry problem solving has attracted much attention in the NLP community recently. The task is challenging as it requires abstract prob- lem understanding and symbolic reasoning with axiomatic knowledge. However, current datasets are either small in scale or not pub- licly available. Thus, we construct a new large- scale benchmark, Geometry3K, consisting of 3,002 geometry problems with dense annota- tion in formal language. We further propose a novel geometry solving approach with for- mal language and symbolic reasoning, called Interpretable Geometry Problem Solver (Inter- GPS). Inter-GPS first parses the problem text and diagram into formal language automati- cally via rule-based text parsing and neural ob- ject detecting, respectively. Unlike implicit learning in existing methods, Inter-GPS in- corporates theorem knowledge as conditional rules and performs symbolic reasoning step by step. Also, a theorem predictor is designed to infer the theorem application sequence fed to the symbolic solver for the more efficient and reasonable searching path. Extensive experi- ments on the Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves signifi- cant improvements over existing methods.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2205.09947",
        "title": "PGDP5K: A Diagram Parsing Dataset for Plane Geometry Problems",
        "abstract": "Diagram parsing is an important foundation for geometry problem solving, attracting increasing attention in the field of intelligent education and document image understanding. Due to the complex layout and between-primitive relationship, plane geometry diagram parsing (PGDP) is still a challenging task deserving further research and exploration. An appropriate dataset is critical for the research of PGDP. Although some datasets with rough annotations have been proposed to solve geometric problems, they are either small in scale or not publicly available. The rough annotations also make them not very useful. Thus, we propose a new large-scale geometry diagram dataset named PGDP5K and a novel annotation method. Our dataset consists of 5000 diagram samples composed of 16 shapes, covering 5 positional relations, 22 symbol types and 6 text types. Different from previous datasets, our PGDP5K dataset is labeled with more fine-grained annotations at primitive level, including primitive classes, locations and relationships. What is more, combined with above annotations and geometric prior knowledge, it can generate intelligible geometric propositions automatically and uniquely. We performed experiments on PGDP5K and IMP- Geometry3K datasets reveal that the state-of-the-art (SOTA) method achieves only 66.07% F1 value. This shows that PGDP5K presents a challenge for future research. Our dataset is available at http://www.nlpr.ia.ac.cn/databases/CASIA-PGDP5K/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2209.14610",
        "title": "DYNAMIC PROMPT LEARNING VIA POLICY GRADIENT FOR SEMI-STRUCTURED MATHEMATICAL REASONING",
        "abstract": "Mathematical reasoning, a core ability of human intelligence, presents unique challenges for machines in abstract thinking and logical reasoning. Recent large pre-trained language models such as GPT-3 have achieved remarkable progress on mathematical reasoning tasks written in text form, such as math word problems (MWP). However, it is unknown if the models can handle more complex prob- lems that involve math reasoning over heterogeneous information, such as tabular data. To fill the gap, we present Tabular Math Word Problems (TABMWP), a new dataset containing 38,431 open-domain grade-level problems that require mathe- matical reasoning on both textual and tabular data. Each question in TABMWP is aligned with a tabular context, which is presented as an image, semi-structured text, and a structured table. There are two types of questions: free-text and multi- choice, and each problem is annotated with gold solutions to reveal the multi-step reasoning process. We evaluate different pre-trained models on TABMWP, in- cluding the GPT-3 model in a few-shot setting. As earlier studies suggest, since few-shot GPT-3 relies on the selection of in-context examples, its performance is unstable and can degrade to near chance. The unstable issue is more severe when handling complex problems like TABMWP. To mitigate this, we further propose a novel approach, PROMPTPG, which utilizes policy gradient to learn to select in-context examples from a small amount of training data and then constructs the corresponding prompt for the test example. Experimental results show that our method outperforms the best baseline by 5.31% on the accuracy metric and re- duces the prediction variance significantly compared to random selection, which verifies its effectiveness in selecting in-context examples.1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1909.05405",
        "title": "SuPer: A Surgical Perception Framework for Endoscopic Tissue Manipulation with Surgical Robotics",
        "abstract": " Traditional control and task automation have been successfully demonstrated in a variety of structured, controlled environments through the use of highly specialized modeled robotic systems in conjunction with multiple sensors. However, the application of autonomy in endoscopic surgery is very challenging, particularly in soft tissue work, due to the lack of high-quality images and the unpredictable, constantly deforming environment. In this work, we propose a novel surgical perception framework, SuPer, for surgical robotic control. This framework continuously collects 3D geometric information that allows for mapping a deformable surgical field while tracking rigid instruments within the field. To achieve this, a model-based tracker is employed to localize the surgical tool with a kinematic prior in conjunction with a model-free tracker to reconstruct the deformable environment and provide an estimated point cloud as a mapping of the environment. The proposed framework was implemented on the da Vinci Surgical\u20ddR System in real-time with an end-effector controller where the target configurations are set and regulated through the framework. Our proposed framework successfully completed soft tissue manipulation tasks with high accuracy. The demonstration of this novel framework is promising for the future of surgical autonomy. In addition, we provide our dataset for further surgical research",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.16890",
        "title": "TouchStone: Evaluating Vision-Language Models by Language Models",
        "abstract": "Large vision-language models (LVLMs) have recently witnessed rapid advancements, exhibiting a remarkable capacity for perceiving, understanding, and processing visual information by connecting visual receptor with large language models (LLMs). However, current assessments mainly focus on recognizing and reasoning abilities, lacking direct evaluation of conversational skills and neglecting visual storytelling abilities. In this paper, we propose an evaluation method that uses strong LLMs as judges to comprehensively evaluate the various abilities of LVLMs. Firstly, we construct a comprehensive visual dialogue dataset TouchStone, consisting of open-world images and questions, covering five major categories of abilities and 27 subtasks. This dataset not only covers funda- mental recognition and comprehension but also extends to literary creation. Secondly, by integrating detailed image annotations we effectively transform the multimodal in- put content into a form understandable by LLMs. This enables us to employ advanced LLMs for directly evaluating the quality of the multimodal dialogue without requiring human intervention. Through validation, we demonstrate that powerful LVLMs, such as GPT-4, can effectively score dialogue quality by leveraging their textual capabilities alone, aligning with human preferences. We hope our work can serve as a touchstone for LVLMs\u2019 evaluation and pave the way for building stronger LVLMs. The evaluation code is available at https://github.com/OFA-Sys/TouchStone.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/1904.08920",
        "title": "Towards VQA Models That Can Read",
        "abstract": "Studies have shown that a dominant class of questions\nasked by visually impaired users on images of their surroundings involves reading text in the image. but today's VQA models can not read! Our paper takes a first step to-\nwards addressing this problem. First, we introduce a new\n\u201cTextVQA\u201d dataset to facilitate progress on this important\nproblem. Existing datasets either have a small proportion of\nquestions about text (e.g., the VQA dataset) or are too small\n(e.g., the VizWiz dataset). TextVQA contains 45,336 ques-\ntions on 28,408 images that require reasoning about text to\nanswer. Second, we introduce a novel model architecture\nthat reads text in the image, reasons about it in the con-\ntext of the image and the question, and predicts an answer\nwhich might be a deduction based on the text and the image\nor is composed of the strings found in the image. Conse-\nquently, we call our approach Look, Read, Reason & An-swer(lorra). we show th that lorra outperforms existing state-of-the-art vqa models on our textVQA dataset. we find that the gap between human performance and machine performance is significantly larger on textVQA than on\nVQA 2.0, suggesting that TextVQA is well-suited to bench-mark progress along directions complementary to VQA 2.0.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2310.02255",
        "title": "MATHVISTA: EVALUATING MATHEMATICAL REASON- ING OF FOUNDATION MODELS IN VISUAL CONTEXTS",
        "abstract": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MATHVISTA, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 ex- amples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging.\nWith MATHVISTA, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT- 4V is mainly attributed to its enhanced visual perception and mathematical rea- soning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MATHVISTA will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2308.02490",
        "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities",
        "abstract": "We propose MM-Vet1, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown var- ious intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the compli- cated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capa- bilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combination. For evaluation metrics, we propose an LLM-based evaluator for open-ended outputs. The evaluator enables the evaluation across different question types and answer styles, resulting in a unified scoring metric. We evaluate representative LMMs on MM-Vet, providing insights into the capabilities of different LMM system paradigms and models. Code and data are available at https://github.com/yuweihao/MM-Vet.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.16502",
        "title": "MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI",
        "abstract": "We introduce MMMU: a new benchmark designed to eval- uate multimodal models on massive multi-discipline tasks demanding college-level subject knowledge and deliberate reasoning. MMMU includes 11.5K meticulously collected multimodal questions from college exams, quizzes, and text- books, covering six core disciplines: Art & Design, Busi- ness, Science, Health & Medicine, Humanities & Social Science, and Tech & Engineering. These questions span 30 subjects and 183 subfields, comprising 30 highly het- erogeneous image types, such as charts, diagrams, maps, tables, music sheets, and chemical structures. Unlike ex- isting benchmarks, MMMU focuses on advanced perception and reasoning with domain-specific knowledge, challenging models to perform tasks akin to those faced by experts. The evaluation of 28 open-source LMMs as well as the propri- etary GPT-4V(ision) and Gemini highlights the substantial\nchallenges posed by MMMU. Even the advanced GPT-4V and Gemini Ultra only achieve accuracies of 56% and 59% re- spectively, indicating significant room for improvement. We believe MMMU will stimulate the community to build next- generation multimodal foundation models towards expert artificial general intelligence",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2407.00468",
        "title": "MMEVALPRO: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation",
        "abstract": "Large Multimodal Models (LMMs) exhibit impressive cross-modal understanding and reasoning abilities, often assessed through multiple-choice questions (MCQs) that include an image, a question, and several options. However, many benchmarks used for such evaluations suffer from systematic biases. Remarkably, Large Lan- guage Models (LLMs) without any visual perception capabilities achieve non-trivial performance, undermining the credibility of these evaluations. To address this issue while maintaining the efficiency of MCQ evaluations, we propose MMEVALPRO, a benchmark designed to avoid Type-I errors through a trilogy evaluation pipeline and more rigorous metrics. For each original question from existing benchmarks, human annotators augment it by creating one perception question and one knowl- edge anchor question through a meticulous annotation process. MMEVALPRO comprises 2, 138 question triplets, totaling 6, 414 distinct questions. Two-thirds of these questions are manually labeled by human experts, while the rest are sourced from existing benchmarks (MMMU, ScienceQA, and MathVista). Compared with the existing benchmarks, our experiments with the latest LLMs and LMMs demon- strate that MMEVALPRO is more challenging (the best LMM lags behind human performance by 31.73%, compared to an average gap of 8.03% in previous bench- marks) and more trustworthy (the best LLM trails the best LMM by 23.09%, whereas the gap for previous benchmarks is just 14.64%). Our in-depth analysis explains the reason for the large performance gap and justifies the trustworthiness of evaluation, underscoring its significant potential for advancing future research.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2312.00784",
        "title": "ViP-LLaVA:\nMaking Large Multimodal Models Understand Arbitrary Visual Prompts",
        "abstract": "While existing large vision-language multimodal mod- els focus on whole image understanding, there is a promi- nent gap in achieving region-specific comprehension. Cur- rent approaches that use textual coordinates or spatial en- codings often fail to provide a user-friendly interface for visual prompting. To address this challenge, we intro- duce a novel multimodal model capable of decoding arbi- trary (free-form) visual prompts. This allows users to intu- itively mark images and interact with the model using nat- ural cues like a \u201cred bounding box\u201d or \u201cpointed arrow\u201d. Our simple design directly overlays visual markers onto the RGB image, eliminating the need for complex region encod- ings, yet achieves state-of-the-art performance on region- understanding tasks like Visual7W, PointQA, and Visual Commonsense Reasoning benchmark. Furthermore, we present ViP-Bench, a comprehensive benchmark to assess the capability of models in understanding visual prompts across multiple dimensions, enabling future research in this domain. Code, data, and model are publicly available.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2311.13951",
        "title": "MLLM-BENCH: EVALUATING MULTIMODAL LLMS WITH PER-SAMPLE CRITERIA",
        "abstract": "Multimodal large language models (MLLMs) (e.g., GPT-4V, LLaVA, and Claude- 3) have broadened the scope of AI applications. Yet, evaluating their performance presents a significant challenge owing to the inherently subjective nature of tasks that do not yield clear-cut solutions especially for those open-ended queries. Exist- ing automatic evaluation methodologies are mainly limited in evaluating objective queries without considering real-world user experiences, inadequately addressing the nuances of creative and associative multimodal tasks. In our paper, we pro- pose a new evaluation paradigm for MLLMs, which is evaluating MLLMs with per-sample criteria using potent MLLM as the judge. To validate the feasibility and effectiveness of this paradigm, we design a benchmark, dubbed MLLM-Bench, with the evaluation samples across six critical levels following the revised Bloom\u2019s Taxonomy with the ethical consideration. We benchmark 21 popular MLLMs in a pairwise-comparison fashion, showing diverse performance across models. More- over, the validity of our benchmark manifests itself in reaching 88.02% agreement with human evaluation. We contend that the proposed paradigm explores the poten- tial of MLLMs as effective evaluation tools with the help of per-sample criteria, and that MLLM-Bench will serve as a catalyst for encouraging the development of user- centric MLLMs tailored to real-world applications. Our benchmark data, online leaderboard and submission entry are at https://mllm-bench.llmzoo.com/.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2404.16790",
        "title": "SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension",
        "abstract": "Comprehending text-rich visual content is paramount for the practical application of Multimodal Large Language Models (MLLMs), since text-rich scenarios are ubiquitous in the real world, which are characterized by the presence of extensive texts embedded within images. Recently, the advent of MLLMs with impressive versatility has raised the bar for what we can expect from MLLMs. However, their proficiency in text-rich scenarios has yet to be comprehen- sively and objectively assessed, since current MLLM bench- marks primarily focus on evaluating general visual compre- hension. In this work, we introduce SEED-Bench-2-Plus, a benchmark specifically designed for evaluating text-rich vi- sual comprehension of MLLMs. Our benchmark comprises 2.3K multiple-choice questions with precise human anno- tations, spanning three broad categories: Charts, Maps, and Webs, each of which covers a wide spectrum of text- rich scenarios in the real world. These categories, due to their inherent complexity and diversity, effectively sim- ulate real-world text-rich environments. We further conduct a thorough evaluation involving 34 prominent MLLMs (in- cluding GPT-4V, Gemini-Pro-Vision and Claude-3-Opus) and emphasize the current limitations of MLLMs in text- rich visual comprehension. We hope that our work can serve as a valuable addition to existing MLLM benchmarks, providing insightful observations and inspiring further re- search in the area of text-rich visual comprehension with MLLMs. The dataset and evaluation code can be accessed at https://github.com/AILab-CVC/SEED-Bench.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.06281",
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "abstract": "Large vision-language models (VLMs) have recently achieved remarkable progress, exhibiting impressive multimodal perception and reasoning abilities. However, effectively evaluating these large VLMs remains a major challenge, hindering future development in this domain. Traditional benchmarks like VQAv2 or COCO Caption provide quantitative performance measurements but lack fine-grained abil- ity assessment and robust evaluation metrics. Meanwhile, subjective benchmarks, such as OwlEval, offer comprehensive evaluations of a model\u2019s abilities by incor- porating human labor, which is not scalable and may display significant bias. In response to these challenges, we propose MMBench, a bilingual benchmark for assessing the multi-modal capabilities of VLMs. MMBench methodically develops a comprehensive evaluation pipeline, primarily comprised of the following key features: 1. MMBench is meticulously curated with well-designed quality con- trol schemes, surpassing existing similar benchmarks in terms of the number and variety of evaluation questions and abilities; 2. MMBench introduces a rigorous CircularEval strategy and incorporates large language models to convert free-form predictions into pre-defined choices, which helps to yield accurate evaluation results for models with limited instruction-following capabilities. 3. MMBench incorpo- rates multiple-choice questions in both English and Chinese versions, enabling an apples-to-apples comparison of VLMs\u2019 performance under a bilingual context. To summarize, MMBench is a systematically designed objective benchmark for a robust and holistic evaluation of vision-language models. We hope MMBench will assist the research community in better evaluating their models and facilitate future progress in this area. The evalutation code of MMBench has been integrated into VLMEvalKit: https://github.com/open-compass/VLMEvalKit. 1",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2406.14515",
        "title": "MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding",
        "abstract": "The advent of large vision-language models (LVLMs) has spurred research into their applications in multi-modal contexts, particularly in video understanding. Traditional VideoQA benchmarks, despite providing quantitative metrics, often fail to encompass the full spectrum of video content and inadequately assess models\u2019 temporal comprehension. To address these limitations, we introduce MMBench- Video, a quantitative benchmark designed to rigorously evaluate LVLMs\u2019 pro- ficiency in video understanding. MMBench-Video incorporates lengthy videos from YouTube and employs free-form questions, mirroring practical use cases. The benchmark is meticulously crafted to probe the models\u2019 temporal reasoning skills, with all questions human-annotated according to a carefully constructed ability taxonomy. We employ GPT-4 for automated assessment, demonstrating superior accuracy and robustness over earlier LLM-based evaluations. Utilizing MMBench-Video, we have conducted comprehensive evaluations that include both proprietary and open-source LVLMs for images and videos. MMBench-Video stands as a valuable resource for the research community, facilitating improved evaluation of LVLMs and catalyzing progress in the field of video understanding. The evalutation code of MMBench-Video will be integrated into VLMEvalKit: https://github.com/open-compass/VLMEvalKit.",
        "label": 1
    },
    {
        "url": "https://arxiv.org/pdf/2307.16125",
        "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension",
        "abstract": "Based on powerful Large Language Models (LLMs), recent generative Multi- modal Large Language Models (MLLMs) have gained prominence as a pivotal research area, exhibiting remarkable capability for both comprehension and gen- eration. In this work, we address the evaluation of generative comprehension in MLLMs as a preliminary step towards a comprehensive assessment of generative models, by introducing a benchmark named SEED-Bench. SEED-Bench consists of 19K multiple choice questions with accurate human annotations (\u00d76 larger than existing benchmarks), which spans 12 evaluation dimensions including the comprehension of both the image and video modality. We develop an advanced pipeline for generating multiple-choice questions that target specific evaluation dimensions, integrating both automatic filtering and manual verification processes. Multiple-choice questions with groundtruth options derived from human annotation enables an objective and efficient assessment of model performance, eliminating the need for human or GPT intervention during evaluation. We further evaluate the performance of 18 models across all 12 dimensions, covering both the spatial and temporal understanding. By revealing the limitations of existing MLLMs through evaluation results, we aim for SEED-Bench to provide insights for motivating future research. We will launch and consistently maintain a leaderboard to provide a platform for the community to assess and investigate model capability.",
        "label": 1
    }
]